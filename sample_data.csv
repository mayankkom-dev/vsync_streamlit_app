,_id,id_,writer_image,write_name,writer_link,writer_details,post_text,post_title,post_link,post_link_img
0,65a104f1a5b8f0720000218c,4e9f6974-0662-7afd-13ce-d33b1de49987,https://media.licdn.com/dms/image/C5103AQG-sbJuzuZSew/profile-displayphoto-shrink_100_100/0/1517435574361?e=1710374400&v=beta&t=8aosMtsKDDFXHbzceblLSDSuiyfsXT2NQhsdvXCEcdU,"Sophia Yang, Ph.D.",https://www.linkedin.com/in/ACoAAAytG2sBz1Uitwp8s1x-B29DhSICyU5D0Mo?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAytG2sBz1Uitwp8s1x-B29DhSICyU5D0Mo,"
Head of Developer Relations @ Mistral AI
","
üìΩ Deep dive into 4 NeurIPS 2023 best paper award winners: - Are Emergent Abilities of Large Language Models a Mirage? https://lnkd.in/gj8DNnDx- Scaling Data-Constrained Language Models. https://lnkd.in/gz_Gutfm- Direct Preference Optimization: Your Language Model is Secretly a Reward Model. https://lnkd.in/gWPpK6ym- DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models. https://lnkd.in/g5a8HaQJCongrats and thanks to all the authors! - Rylan Schaeffer, Brando Miranda, Sanmi Koyejo- Niklas Muennighoff, Boaz Barak, Teven Le Scao,  Aleksandra Piktus, Nouamane Tazi, Sampo Pyysalo, Thomas Wolf- Archit S., Eric Mitchell, Stefano Ermon, Christopher Manning, Chelsea Finn- Boxin Wang, Chulin Xie, Mintong Kang, Chenhui Zhang, Chejian Xu, Zidi Xiong, Ritik Dutta, Rylan SchaefferShout out to Jerry Liu for the NeurIPS 2023 reading list: https://lnkd.in/gYintndmhttps://lnkd.in/g-CV3HMf

          ‚Ä¶see more
        


Deep dive: 4 NeurIPS 2023 best paper award papers - emergent ability, scaling, DPO, trustworthiness
",,https://www.linkedin.com/feed/update/urn:li:activity:7142273832353955840?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7142273832353955840%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQG9E1N3WPednA/articleshare-shrink_800/0/1704254677680?e=1705658400&v=beta&t=cOvTgOLanD02sZYj53Z1aOZ3EPFtamtJ8MmPud_VX64
1,65a104d5a5b8f07200002151,ceabf86c-eb4f-8685-6751-b296a58615ae,,Donna Morelli,https://www.linkedin.com/in/ACoAAANdDGEBFeo1Nj3g3i8MAGCA7k4hoLVW2vQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAANdDGEBFeo1Nj3g3i8MAGCA7k4hoLVW2vQ,"
Data Analyst, Science | Technology | Health Care
","
Newly Discovered Genetic Mutation Protects Against Parkinson‚Äôs Disease and Offers Hope for New Therapies. A previously unidentified genetic mutation in a small protein provides significant protection against Parkinson‚Äôs disease and offers a new direction for exploring potential treatments, according to a new University of Southern California (USC) Leonard Davis School of Gerontology study. Published: January 02. 2024.Excerpt: The variant, located in a mitochondrial microprotein dubbed SHLP2, was found to be highly protective against Parkinson‚Äôs disease; individuals with this mutation are half as likely to develop the disease as those who do not carry it. The variant form of the protein is relatively rare and is found primarily in people of European descent.The findings appear January 3, 2024, in the journal Molecular Psychiatry.First discovered by Pinchas Cohen at USC Leonard Davis School in 2016, SHLP2 is made within the cell‚Äôs mitochondria. Previous research from Cohen Lab established SHLP2 is associated with protection from aging-related diseases including cancer and that levels of the microprotein change in patients with Parkinson‚Äôs disease; they rise as the body attempts to counteract the pathology of Parkinson‚Äôs disease but often fail to mount additional production as the disease progresses.This latest finding builds upon the USC team‚Äôs prior mitochondrial research and represents an advance at the intersection of longevity science, precision health, and microprotein discovery.Note: ‚ÄúThis study advances our understanding of why people might get Parkinson‚Äôs and how we might develop new therapies for this devastating disease,‚Äù said Cohen, professor of gerontology, medicine and biological sciences and senior author of the study. ‚ÄúAlso, because most research is done on well-established protein-coding genes in the nucleus, it underscores the relevance of exploring mitochondrial-derived microproteins as a new approach to the prevention and treatment of diseases of aging.‚ÄùPublication: Nature | Molecular Psychiatry03 January 2024A naturally occurring variant of SHLP2 is a protective factor in Parkinson‚Äôs diseasehttps://lnkd.in/ePtGaHsghttps://lnkd.in/esFZtStA

          ‚Ä¶see more
        


Newly Discovered Genetic Mutation Protects Against Parkinson‚Äôs Disease and Offers Hope for New Therapies
",,https://www.linkedin.com/feed/update/urn:li:activity:7148297377207001088?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7148297377207001088%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQEvH_pEC7mE4Q/articleshare-shrink_800/0/1704286216530?e=1705658400&v=beta&t=e2Yi5j_ub-YoRiNhvMYTdKncTfNB8NHJKOvWNxDfSpI
2,65a104d5a5b8f07200002153,b596fb23-ef87-25f6-244f-3cea8e981c26,https://media.licdn.com/dms/image/D4D03AQFpramTnkoElw/profile-displayphoto-shrink_100_100/0/1670580633493?e=1710374400&v=beta&t=S032I_0r57qA_Thm98T7Xu_Nn46maV3uUmXnh4kYuiU,Bruno Neri,https://www.linkedin.com/in/ACoAAABlS2EBjKE-dekAzG21UIzH0d46NEotnuQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAABlS2EBjKE-dekAzG21UIzH0d46NEotnuQ,"
Technical Leader - Artificial Intelligence and Deep Learning Enthusiast - Senior Software Engineer at ALTEN Italia
","
""TimeGraphs: Graph-based Temporal Reasoning"" by Paridhi Maheshwari, Hongyu Ren, Rok Sosic, Jure Leskovec et al.""Many real-world systems exhibit temporal, dynamic behaviors, which are captured as time series of complex agent interactions. To perform temporal reasoning, current methods primarily encode temporal dynamics through simple sequence-based models. However, in general these models fail to efficiently capture the full spectrum of rich dynamics in the input, since the dynamics is not uniformly distributed. In particular, relevant information might be harder to extract and computing power is wasted for processing all individual timesteps, even if they contain no significant changes or no new information. Here we propose TimeGraphs, a novel approach that characterizes dynamic interactions as a hierarchical temporal graph, diverging from traditional sequential representations. Our approach models the interactions using a compact graph-based representation, enabling adaptive reasoning across diverse time scales. Adopting a self-supervised method, TimeGraphs constructs a multi-level event hierarchy from a temporal input, which is then used to efficiently reason about the unevenly distributed dynamics. This construction process is scalable and incremental to accommodate streaming data. We evaluate TimeGraphs on multiple datasets with complex, dynamic agent interactions, including a football simulator, the Resistance game, and the MOMA human activity dataset. The results demonstrate both robustness and efficiency of TimeGraphs on a range of temporal reasoning tasks. Our approach obtains state-of-the-art performance and leads to a performance increase of up to 12.2% on event prediction and recognition tasks over current approaches. Our experiments further demonstrate a wide array of capabilities including zero-shot generalization, robustness in case of data sparsity, and adaptability to streaming data flow.""Paper: https://lnkd.in/dsvCC-T5#machinelearning 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7150838439242895360?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7150838439242895360%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQFHLD9wlnfetw/feedshare-shrink_480/0/1704892738339?e=1707955200&v=beta&t=WcZjO7ruBH3NaecAhudEyylhVm3M3s70Au9mgIt36rE
3,65a104d6a5b8f07200002154,63d33327-6f36-86f2-d381-1ce5e51b284e,https://media.licdn.com/dms/image/D4E03AQFh6L32y18PAw/profile-displayphoto-shrink_100_100/0/1687119571913?e=1710374400&v=beta&t=haaUeeJhfZhTmEUwRGIj23AhHaRZGieNAKyHee2dScE,Maxime Labonne,https://www.linkedin.com/in/ACoAACHMnvUBcdKptayD76qA_A4NmTapmg0ti-Q?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACHMnvUBcdKptayD76qA_A4NmTapmg0ti-Q,"
Sr. Machine Learning Scientist @ JPMorgan
","
üîÄ PhixtralI made the first efficient Mixture of Experts with phi-2 models. ü•≥It combines 2 to 4 fine-tuned models (2.8B parameters) and is better than each individual expert. It's inspired by the Mixtral architecture made by Mistral AI.You can compare the results of Phixtral with other models on my new leaderboard YALL - Yet Another LLM Leaderboard: https://lnkd.in/gjWKF-5uA big thanks to Vincent Nguyen for the inference code and the dynamic configuration of the number of experts!phixtral-2/4x2_8 were made with a custom version of the mergekit library (by Charles Goddard) and the following models:- dolphin-2_6-phi-2 (Eric Hartford)- phi-2-dpo (Xuechen Li)- phi-2-sft-dpo-gpt4_en-ep1 (Yhyu13)- phi-2-coder (Manuel Romero)Thanks to the authors of these amazing models!I'm sharing a Colab notebook to run these models in 4-bit precision on a free T4 GPU and a link to the models on Hugging Face.ü§ó phixtral-2x2_8: https://lnkd.in/e-FKsEMuü§ó phixtral-4x2_8: https://lnkd.in/epwh4j37üíª Colab: https://lnkd.in/ebJQKT3D

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7150758415961620481?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7150758415961620481%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQGyoxC3WzgWJg/feedshare-shrink_480/0/1704847527778?e=1707955200&v=beta&t=m7gGsVsI5TQTLmKGRaUB6lNvI35NDDMbunSShJ8YXCM
4,65a104d6a5b8f07200002155,85dddc98-422e-cfbe-fc04-0b325d02374b,https://media.licdn.com/dms/image/D5635AQHHCW7gXpgoqQ/profile-framedphoto-shrink_100_100/0/1697123720926?e=1705658400&v=beta&t=1AwQaUjf6MNQFcy9hDFZmbRBo8__l0v0iZdNU2pqYU8,Zhihao Wang,https://www.linkedin.com/in/ACoAACU5qNcB__wes2Mt7ovXmlHQKJIn_OjSMmc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACU5qNcB__wes2Mt7ovXmlHQKJIn_OjSMmc,"
Phd Student at University of Maryland
","
Excited to share our latest publication: the development of DeepED, the first AI-powered model for Ecosystem Demography (EDv3). This model, now integrated into NASA's Carbon Monitoring System and the GEDI mission, revolutionizes process-based ecosystem modeling. DeepED enables rapid, sophisticated computations across any spatial scale and supports extensive long-term projections. Its application heralds a new era in ecosystem research, offering broader implications for global carbon monitoring.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7150564593856102400?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7150564593856102400%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D10AQFH1Gtitn4fng/image-shrink_480/0/1704747916258?e=1705658400&v=beta&t=a_lXm0ZqlZ7DNWKgOsGCJYb-Flyd7uYy15LxvJl5odg
5,65a104d6a5b8f07200002156,13aa5259-fcdb-7aab-88dd-f84515c99398,https://media.licdn.com/dms/image/C4D0BAQG1yEbzvWYiXw/company-logo_100_100/0/1642603423308/towards_data_science_logo?e=1713398400&v=beta&t=y8CIwK9dQB-BTSDO6I7B3oL7VUGVvPS986H7M3mioNE,Towards Data Science,https://www.linkedin.com/company/towards-data-science/,"
601K followers
","
Conditional Variational Autoencoders with Learnable Conditional Embeddings - An approach to add conditions to CVAE models without retraining by Tim Daniel Rose
 

Conditional Variational Autoencoders with Learnable Conditional Embeddings
",,https://www.linkedin.com/feed/update/urn:li:activity:7150260744494678016?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7150260744494678016%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5610AQE-1LagdVNXVg/image-shrink_800/0/1704754981608?e=1705658400&v=beta&t=gXJ7IsQWxfmLZ6beWIEFYoZJbi4RpikbrohKp2pEisk
6,65a104d6a5b8f07200002157,a6440100-2128-ac15-984a-5253b5d47a17,https://media.licdn.com/dms/image/D4E03AQGkUXwoJ7Rfmw/profile-displayphoto-shrink_100_100/0/1697745181281?e=1710374400&v=beta&t=aHVPt5WxqVVs2HScs_bul9lEtPeJRfSdbS_uzwbvhPE,Lu√≠s Fernando Torres,https://www.linkedin.com/in/ACoAAC6XxAgBjJ2wCMoFG8Ya7038pmsXf8VTCCM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAC6XxAgBjJ2wCMoFG8Ya7038pmsXf8VTCCM,"
Data Science | Machine Learning | Deep Learning | Artificial Intelligence | Neural Networks | Computer Vision | NLP | Seeking Remote Positions
","
Large language models are one of the most amazing tools to have surfaced in recent years. But, although powerful, they still have some shortcomings. Hallucinations, for example, happen when a model comes up with a convincing answer to something it doesn't really have access to. Retrieval-augmented generation (RAG) is one of the ways we can help a large language model reduce its hallucinations and provide more accurate and source-based answers to the questions a user makes. In my recent Kaggle Notebook, Retrieval Augmented Generation with Mistral 7b üìÅ, we explore how to build an RAG system to fetch relevant information from documents to power an LLM response. You can read the notebook on the PDF file, but for a more enhanced reading experience, I suggest you view it on Kaggle by clicking the link below üëáüèª: üîó https://shorturl.at/cvGH9Thank you very much!

          ‚Ä¶see more
        


RAG
",,https://www.linkedin.com/feed/update/urn:li:activity:7150224333070589953?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7150224333070589953%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D1FAQF8rvVCZxhQ0Q/feedshare-document-cover-images_480/0/1704741032333?e=1705658400&v=beta&t=5WvKPougeeaqI-v57KhGYWJlVs6zth8CJOqhP9JvqGU
7,65a104d6a5b8f07200002158,fe139009-b21c-a5d3-1d1a-db23050a1702,https://media.licdn.com/dms/image/C4E03AQEl5grbZGDr1A/profile-displayphoto-shrink_100_100/0/1623379778435?e=1710374400&v=beta&t=yK_pYvwY6i9B5sU31gKb_pIjqwOt9VcbKWnw-EbH_6Y,Akshay Pachaar,https://www.linkedin.com/in/ACoAACDRc3cBwnfUnZ2dYUQEIPx2zG1QfUqNJ84?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACDRc3cBwnfUnZ2dYUQEIPx2zG1QfUqNJ84,"
Lead Data Scientist at TomTom | BITS Pilani | 3 Patents | ùïè (113K+)
","
5 GitHub repositories that will give you superpowers as an AI/ML Engineer: 1Ô∏è‚É£ Awesome Artificial IntelligenceA curated list of Artificial Intelligence:- courses- books- video lectures- and papers with codeCheck this out üëáhttps://lnkd.in/g3bQGjfr2Ô∏è‚É£ CleanlabYou're missing out on a lot if you haven't started using Cleanlab yet!Cleanlab helps you clean data and labels by automatically detecting issues in a ML dataset. It's like a magic wand! ü™Ñ‚ú® Check this outüëáhttps://lnkd.in/dY2fp5YW3Ô∏è‚É£ 500 projects with codeA curated list of 500 AI, Machine learning, Computer vision & NLP Projects with codeCheck this outüëáhttps://lnkd.in/gnY3K75d4Ô∏è‚É£ Prompt Engineering GuideA guide that contains all the latest papers, learning guides, lectures, references, and tools related to prompt engineering for LLMs.Happy Prompting!Check this outüëáhttps://lnkd.in/dC6jBSDZ5Ô∏è‚É£ Lit-GPTLit-GPT is a fully open-source & hackable implementation of SOTA LLMs, it provides everything you need as an LLM Developer. Key features include:- Flash attention- 4 & 8-bit quantization- Finetuning using LoRA & LLaMA-adapterCheck thisüëáhttps://lnkd.in/dzKepQUvThat's a wrap!If you interested in:- Python üêç- ML/MLOps üõ†- CV/NLP üó£- LLMs üß†- AI Engineering ‚öôÔ∏èFind me ‚Üí https://lnkd.in/em_V4unu ‚úîÔ∏èEveryday, I share tutorials on above topics!Cheers!

          ‚Ä¶see more
        


GitHub - Lightning-AI/lit-gpt: Hackable implementation of state-of-the-art open-source LLMs based on nanoGPT. Supports flash attention, 4-bit and 8-bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed.
",,https://www.linkedin.com/feed/update/urn:li:activity:7149376618468114434?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7149376618468114434%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5610AQFOaJddFOnyUw/image-shrink_800/0/1704544214832?e=1705658400&v=beta&t=UZXm9yxyT7qOwEOLEZ9ALnX-U9uBZ0aScyZRxRKsp90
8,65a104d6a5b8f07200002159,e6a4d29e-0f8d-3d38-75d1-97e21cd36f79,https://media.licdn.com/dms/image/D4E03AQEg0ivtNmCzpw/profile-displayphoto-shrink_100_100/0/1684743177342?e=1710374400&v=beta&t=9abWo0RShxCrDyu8qPHl6FRnmd9zeW7FEiWfzUkexVs,Will Dean,https://www.linkedin.com/in/ACoAABinjcMBMxlMMi7hAMZLK8HhpGzWhB1_L3s?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABinjcMBMxlMMi7hAMZLK8HhpGzWhB1_L3s,"
Bayesian Statistics | Data Science
","
üêç Excited to share the journey behind my Python package, ""conjugate-models""!In my first Bayesian Statistics course, I encountered Bayesian conjugate models, having to solve for the posterior and posterior predictive distributions. Today, they're a cornerstone in my toolkit‚Äîtheir closed-form solutions enable rapid data analysis.In developing this package, I sought to merge these models with a practical, robust API. One that I wish I had in my earlier career use-cases. Whether you're new to Bayesian stats or a seasoned pro, discover how ""conjugate-models"" can elevate your analyses! üöÄRepo: https://lnkd.in/d2TQCfTgDocumentation: https://lnkd.in/d-Zx-88J#BayesianStatistics #PythonPackage #DataScience #conjugatemodels

          ‚Ä¶see more
        


GitHub - wd60622/conjugate: Bayesian Conjugate Models in Python
",,https://www.linkedin.com/feed/update/urn:li:activity:7150035508872503296?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7150035508872503296%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQHqrId1Lt0wwA/articleshare-shrink_800/0/1704700745925?e=1705658400&v=beta&t=-curXgPApmslUSpYqzvToiyNvaMejbALBu9xbgTIDCY
9,65a104d6a5b8f0720000215a,0eba8877-a4a2-25d8-e373-be8cc34c8410,https://media.licdn.com/dms/image/C5603AQGsZ_F6Fn1gIw/profile-displayphoto-shrink_100_100/0/1642350086001?e=1710374400&v=beta&t=TI1Xb-oIhXqeNwHTQRyG-s3Cv3QeMWD1lZiaPShqePk,Dmytro Nikolaiev,https://www.linkedin.com/in/ACoAADWKdycBqHyKinzwK7QI9d7OLWtWcwDD-TA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADWKdycBqHyKinzwK7QI9d7OLWtWcwDD-TA,"
ML Scientist @ ChainML | DS Mentor @ Lighthouse Labs | #keep_AI_posted
","
üìú Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body TeleoperationIncredible work by Stanford University introduces Mobile ALOHA, a low-cost and whole-body robot that can complete complex autonomously with 50 demonstrations. The total price of a robot is under $32k and all code, data, and tutorials were publicly released.Website: https://lnkd.in/gRXnCmWMPaper: https://lnkd.in/gEMvSfqnTutorial: https://lnkd.in/gdGYNj6q#keep_AI_posted #ai #nlp #llm #robotics

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7150154237174251520?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7150154237174251520%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5605AQGaJSEsVjNoOQ/videocover-low/0/1704723162694?e=1705658400&v=beta&t=myxhCXlitFGcuPZOwgN3Z2UHT76S2TT8Ir0SXgI-jNo
10,65a1050da5b8f072000021bd,c31b7a89-faf2-c907-ca4b-1b8eb0daae52,https://media.licdn.com/dms/image/C4D03AQF_-kQ03U4msg/profile-displayphoto-shrink_100_100/0/1584435191754?e=1710374400&v=beta&t=-HIW8V7GpTjbZLkMQJlGFlrPi6H4Ls8JX8RpXNpBVJo,Patrick von Platen,https://www.linkedin.com/in/ACoAAB5-aKMBohjiXH10o4Zjn4vD9c_VQ5d3Oq4?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAB5-aKMBohjiXH10o4Zjn4vD9c_VQ5d3Oq4,"
Technical Team Lead (Audio & Diffusers)
","
Announcing Distil-Whisper üöÄLed by Sanchit Gandhi, we've distilled OpenAI's Whisper on 20,000 hours of open-sourced audio data.Distil-Whisper is up to 6x faster than Whisper while performing within 1% Word-Error-Rate on out-of-distribution eval sets üéØWhy?OpenAI's Whisper yields astonishing accuracy for most audio, but it's too slow and expensive for most production use cases. In addition, it has a tendency to hallucinate.How?Encoding takes O(1) passes while decoding takes O(N) => Reducing decoder layers is N time more effective. We keep the whole encoder, but only 2 decoder layers.The encoder is frozen during distillation to ensure Whisper's robustness to noise is kept.To make sure Distil-Whisper does not inherit hallucinations, we filtered out all data samples below a certain WER threshold. By doing so, we were able to reduce hallucinations and actually beat the teacher on long-form audio evaluation ü§ØCheckpoints? License?The checkpoints will be released in two days and will be directly available in ü§ó Transformers. All with MIT License.For more information, please see:üëâ Official paper: https://lnkd.in/eujPsKYa üëâ GitHub page (checkpoints will be published here): https://lnkd.in/enGQzUwB 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7125178922224230401?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7125178922224230401%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQG69FUHkwtkOA/feedshare-shrink_480/0/1698775032754?e=1707955200&v=beta&t=Z7RGtIbJThTHOFwiryxLVA6DIPb4Ww4NfMaR7PVOy44
11,65a104d6a5b8f0720000215c,1f1f68fc-eced-c202-613b-0c47cc7b7d10,https://media.licdn.com/dms/image/C5603AQFvncvflX_kMQ/profile-displayphoto-shrink_100_100/0/1564316873635?e=1710374400&v=beta&t=DRxjFCzRMNJSc3QM233eAmSZ8rflNQHLrn8k0KQuOhg,Elvis S.,https://www.linkedin.com/in/ACoAACxhXeUBTYZYCwIa4nsvSBsETtrS0uhGNPc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACxhXeUBTYZYCwIa4nsvSBsETtrS0uhGNPc,"
Co-Founder at DAIR.AI | Prev: Meta AI, Galactica LLM, PapersWithCode, Elastic
","
From LLM to Conversational AgentProposes RAISE, an advanced architecture to enhance LLMs for conversational agents. It's inspired by the ReAct framework and integrates a dual-component memory system. It utilizes a scratchpad and retrieved examples to augment the agent's capabilities. The scratchpad serves as a transient storage (akin to short-term memory) and the retrieval module operates as the agent's long-term memory. So you can think of this as a framework that combines ReAcT, a scratchpad, and a retrieval system.This system mirrors human short-term and long-term memory and helps to maintain context and continuity which are key in conversational systems.One benefit of such a system is the ability to customize and control the behavior of the conversational system. This work also shows the potential to fine-tune the LLM within the RAISE framework which leads to enhanced controllability. RAISE was tested on the real-estate domain and showed superior performance as compared to the conventional conversational agents. For every use case, there might be a need to control for different aspects of an LLM-powered agent. This can range from customizing the working memory components to changing the effectiveness of retrieval of certain types of information.I like the idea of modularity in a conversational agent but that means there are more variables to control. Lots of potential with this framework for building more tailored and personalized agents. (paper link in the comments)

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7150166307680784384?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7150166307680784384%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQETajxJy7vKAQ/feedshare-shrink_480/0/1704732490627?e=1707955200&v=beta&t=PrerkaNSbjm0gnmPVwWxk6279-korKAhKNuGt3XKd-Y
12,65a104d6a5b8f0720000215d,ba8527b8-ef96-f0cf-a6f2-eb607f0bcb1b,https://media.licdn.com/dms/image/C4D03AQEl_LZo3E4U8w/profile-displayphoto-shrink_100_100/0/1625227462036?e=1710374400&v=beta&t=AZZ8_WJhW7OxUnde6VlTTlqQjUnXCyKytKt-PR236uU,David Sauerwein,https://www.linkedin.com/in/ACoAABbvcqABBMag23QcD1slzswS9n4Do7rO3CM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABbvcqABBMag23QcD1slzswS9n4Do7rO3CM,"
AI/ML at AWS | PhD in Quantum Physics
","
Many aspects of large language models are still poorly understood. At the outset, the simple fact that they can be trained at all is not obvious.Training a 65 Billion parameter large language model (LLM) boils down to trying to find the global minimum of a highly non-convex loss function with 65 Billion parameters. That's a daunting task.While it‚Äôs typically impossible to get to the global minimum for any deep learning algorithm (even if you did, there is no way to know), the community has developed a range of heuristics and tricks that help to find ‚Äúgood enough‚Äù local minima that work surprisingly well.Examples are:1/ Changes to the gradient descent algorithm (e.g. batch gradient descent, batch normalization, introduction of momentum,...)2/ Learning methods (e.g. annealing, teacher learning,...)3/ Reshaping of the loss landscape itself (e.g. skip connections, regularization, ‚Ä¶)The reasons why these methods work better in some scenarios than in others are often not well understood. However, new theoretical insights into the loss landscape of neural networks and the algorithms we use to explore them can have deep practical implications.For example, researchers found new ways to visualize the loss landscape of neural networks to understand why some algorithms work better than others (see image, link in comments). They are also still learning about new and unintuitive properties of gradient descent that may help optimize its performance (see comments for links).I expect 2024 to be the year of highly effective, smaller models. But I‚Äôd be amazing if we also find faster, more reliable ways to train them.#machinelearning #datascience #science #optimization

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7149843419677237248?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7149843419677237248%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQEyiYJJqBFGvg/feedshare-shrink_480/0/1704655508162?e=1707955200&v=beta&t=m09CjVy-8crd4RU81dK1onksefprlSHI-SNRi-h_KZY
13,65a104d6a5b8f0720000215e,0e531164-e51b-3b05-5d4c-533266bee2ac,https://media.licdn.com/dms/image/C4D0BAQG1yEbzvWYiXw/company-logo_100_100/0/1642603423308/towards_data_science_logo?e=1713398400&v=beta&t=y8CIwK9dQB-BTSDO6I7B3oL7VUGVvPS986H7M3mioNE,Towards Data Science,https://www.linkedin.com/company/towards-data-science/,"
601K followers
","
AutoGluon-TimeSeries: Every Time Series Forecasting Model In One Library - A powerful library by Amazon‚Ää (coding example included) by Nikos Kafritsas
 

AutoGluon-TimeSeries: Every Time Series Forecasting Model In One Library
",,https://www.linkedin.com/feed/update/urn:li:activity:7149070658092552192?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7149070658092552192%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5610AQFe2ivzxZ6iVA/image-shrink_800/0/1704471242944?e=1705658400&v=beta&t=QqiuYCLVRb2Usil1sjvd5EnIORHj9e03bAzgCK-lFd8
14,65a104d6a5b8f0720000215f,19428c68-7279-318f-012a-1574e0a7bd9b,https://media.licdn.com/dms/image/D4E03AQFXoR8Xgye8Vw/profile-displayphoto-shrink_100_100/0/1680859507281?e=1710374400&v=beta&t=jLguKrRofJ6IswdFpriAPlNTnCz6meovl2QS-rg00l4,Maria Vechtomova,https://www.linkedin.com/in/ACoAAA52t5EBCgJM7kgrMphKQD3ijSGTLl2xHzU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA52t5EBCgJM7kgrMphKQD3ijSGTLl2xHzU,"
MLOps Tech Lead | Join 22k followers to learn about MLOps | Marvelous MLOps | Public speaker
","
Evidently AI  has a blog on ML system design: 300 case studies to learn from. They constantly update the page (last update is in December 2023).Check it out: https://lnkd.in/edCE5vaBThis is pure gold! Collection of papers and blogs from the industry leaders like Netflix, Spotify, Meta, Uber, and many more. Couple of interesting use cases:‚û°Ô∏è Call routing by Nubank: https://lnkd.in/ecXUNXC4‚û°Ô∏è Prevent fraudulent transactions by Stripe: https://lnkd.in/ep_qFUvR‚û°Ô∏è Demand forecast in fashion by Zalando: https://lnkd.in/e7893N3M#machinelearning #datascience #systemdesign

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7149260803865530368?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7149260803865530368%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQEoCrD9FzwU9A/feedshare-shrink_480/0/1704516600836?e=1707955200&v=beta&t=lkWz1HKIm09QwOWT_-qPgwfzoYjWdW4zKPKZNeXIAPw
15,65a104d6a5b8f07200002160,2c3e4ec4-f051-fe55-88a4-ff423e06feea,https://media.licdn.com/dms/image/D4E03AQF6vorKIc_rDg/profile-displayphoto-shrink_100_100/0/1703628958212?e=1710374400&v=beta&t=mDh5ASm_Bz6tI7AUJ3L_iWFs4lPuSq8z7wpor2_Lz4c,Aniket Maurya,https://www.linkedin.com/in/ACoAABX5KEgBX_f0Ap7tJvvr9yXhqh9jp_rYCws?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABX5KEgBX_f0Ap7tJvvr9yXhqh9jp_rYCws,"
Developer Advocate @ Lightning AI ‚ö°Ô∏è | Creator of GradsFlow
","
TinyLlama 1.1B built with Lit-GPT ‚ö°Ô∏è - Pretrained on 1 trillion tokens - Total 3 epochs- Built upon existing Llama architecture and tokenizer- Full pretraining code - https://lnkd.in/eEKNXHMA- Paper: https://lnkd.in/eWs3VGcn

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7149248215375126528?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7149248215375126528%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQFM2_dB6ZX6oQ/feedshare-shrink_480/0/1704473632270?e=1707955200&v=beta&t=Hok4SlhWFaJ6L_LCRLjenw0EM-STP1WT6KneHb8Q52k
16,65a104d6a5b8f07200002161,a879fc26-ba07-13bc-45f1-33921b906673,https://media.licdn.com/dms/image/D5635AQEBzEFRC2EzLg/profile-framedphoto-shrink_100_100/0/1704907585971?e=1705658400&v=beta&t=x71pDAJzCbSPZxvt91sIkpmEr_5_pGLZIt6VZgw5eV0,Aman Chadha,https://www.linkedin.com/in/ACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU,"
GenAI Leadership @ Amazon AWS ‚Ä¢ Stanford AI ‚Ä¢ EB-1 ""Einstein Visa"" Recipient/Mentor ‚Ä¢ Ex-Ô£ø, Amazon Alexa, Nvidia, Qualcomm ‚Ä¢ EMNLP 2023 Outstanding Paper Award
","
üîπ All you need to know about Large Language Models: http://llm.aman.ai‚û°Ô∏è Embeddings‚û°Ô∏è Contextualized vs. Non-Contextualized Embeddings‚û°Ô∏è How do Large Language Models (LLMs) work?‚û°Ô∏è LLM Training Steps‚û°Ô∏è Computing Similarity between Embeddings (Dot Product Similarity, Geometric Intuition, Cosine Similarity, Cosine Similarity vs. Dot Product Similarity)‚û°Ô∏è Retrieval/Knowledge-Augmented LLMs (Process, Summary, LLM Knobs, Token Sampling, Prompt Engineering, Token Healing)‚û°Ô∏è Vector Database Feature Matrix‚û°Ô∏è Context Length Scaling (Challenges with Context Scaling, The ‚ÄúNeedle in a Haystack‚Äù Test, Positional Interpolation, Rotary Positional Encoding. Attention with Linear Biases, Dynamically Scaled RoPE)‚û°Ô∏è Traditional DBs v/s Vector DBs (When Not to Use Vector DBs?‚û°Ô∏è Knowledge Graphs with LLMs: Best of Both WorldsContinuous V/s Discrete Knowledge Representation‚û°Ô∏è Leaderboards (ü§ó Open LLM Leaderboard, ü§ó Massive Text Embedding Benchmark (MTEB) Leaderboard, ü§ó Chatbot Arena Leaderboard, Hallucination Leaderboard)‚û°Ô∏è Methods to Knowledge-Augment LLMs (RAG, Fine-tuning vs. Prompting, RAG vs. Fine-tuning)‚û°Ô∏è Recent Techniques Powering LLMs‚û°Ô∏è List of Popular LLMs- LLaMA- Llama 2- GPT-4- Bard API- Claude- Claude 2.1- Alpaca- Vicuna- StableVicuna- Dolly 2.0- StableLM- OpenLLaMA- MPT- Falcon- RedPajama- Pythia- Orca- XGen- OpenLLMs- LlongMA-2- Qwen- Mistral 7B- Mixtral: Mistral‚Äôs 8x7B MoE Model- Zephyr: Direct Distillation of LM Alignment- Yi- Effi- Starling- NexusRaven-V2- MediTron-70B: Scaling Medical Pretraining for Large Language Models- Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations- Notus- OpenChat- Phi-2- DeciLM- LLM360‚û°Ô∏è Popular Indic LLMs- OpenHathi- BharatGPT- Dhenu- Krutrim‚û°Ô∏è Popular Code LLMs- SQLCoder- Panda-Coder- Magicoder: Source Code is All You Need- AlphaCode 2‚û°Ô∏è Frameworks- LangChain- LangFlow- Flowise- Ragas- LLaMA2-Accessory- LLaMA Factory üëâüèº Connect/follow for more AI resources and drop me a message to share feedback!#artificialintelligence #machinelearning #deeplearning #neuralnetworks

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7149247448874385408?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7149247448874385408%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQEHiRl1RMEecw/feedshare-shrink_480/0/1704513418014?e=1707955200&v=beta&t=AOMoTIU89rj46Bb9vmziQpDUv1IpWyiwpR4FpbRYr3Y
17,65a104d6a5b8f07200002162,07cb20e6-9ae4-6102-a14a-95ceb0089223,https://media.licdn.com/dms/image/D4D03AQE_lAgtIt6K3Q/profile-displayphoto-shrink_100_100/0/1668585420879?e=1710374400&v=beta&t=Qfwc0_1TJnp967Ob5QtZDRSesX4DRmKETG8cAMP19CA,Eduardo Ordax,https://www.linkedin.com/in/ACoAAAJXQIEBA0FD4IckM2LrQQQUyKaXcBEIz68?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAJXQIEBA0FD4IckM2LrQQQUyKaXcBEIz68,"
MLOps EMEA Lead at AWS | Helping customers to accelerate their Machine Learning Journey
","
Today, I'll delve into the Vector Database landscape, exploring the diverse options available in the market. If you're curious to learn more, keep reading!This post aims to provide a high-level overview rather than a technical summary or an in-depth explanation of how Vector DB operates. It will focus on presenting the various available options and guide you on choosing the most suitable one based on your specific use case.Although Vector DB has been a longstanding technology, it is currently gaining traction as a trending topic, especially with the rise of Generative AI and the increasing demand for RAG architectures. In fact, companies like Amazon leverages vector databases to power their recommendation systems, resulting in more personalized and accurate recommendations.A vector database is a type of database that stores data as high-dimensional vectors, which are mathematical representations of features or attributes. Each vector has a certain number of dimensions, which can range from tens to thousands, depending on the complexity and granularity of the data(they just created applying some kind of transformation or embedding function to the raw data).As follows, some of its unique differences and advantages:üî∏ Data type: Unlike traditional relational databases, vector databases are designed to handle one specific type of data: vector embeddings.üî∏ Similarity search: Vector databases have the ability to perform similarity searches that find the best match between a user's prompt and a particular vector embedding. üî∏ Scalability: Vector databases are designed to handle large-scale data. They can store and search billions of high-dimensional vectors, making them suitable for large-scale machine-learning applications.üî∏ Performance: Vector databases provide high-speed search performance. They use advanced indexing techniques to ensure fast retrieval of similar vectors, even in large-scale databases.üî∏ Flexibility: Vector databases support flexible data models. They can handle structured and unstructured data.üî∏ Efficiency: They use dimensionality reduction techniques to compress high-dimensional vectors into lower-dimensional spaces without losing significant informationDeciding between options can be challenging. In the document shared below, you'll find a comprehensive overview of various solutions, neatly categorized by   languages, cloud vs on-prem, open source vs closed-source, and more. Explore as well the available choices on AWS and discover what's ready to be utilized at Amazon Bedrock for leveraging knowledge bases instead of constructing your own RAG architecture from the ground up. To know more about available Vector DB at Amazon Web Services (AWS) click here: https://lnkd.in/e2p4KQ4XIf you find this information valuable, please consider liking the post.#vectorDB #RAG #LLM #GenerativeAI Pinecone Chroma Vespa.ai Qdrant Redis Zilliz Elasticsearch developer 

          ‚Ä¶see more
        


Vector DB Landscape
",,https://www.linkedin.com/feed/update/urn:li:activity:7148916026972205056?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7148916026972205056%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E1FAQGwsAizp18yFQ/feedshare-document-cover-images_480/0/1704406138420?e=1705658400&v=beta&t=etT76xj3qNBJEXrgway0bUxwVEpQOQIqk80s4ZGepy4
18,65a104d6a5b8f07200002163,2a894e11-20e9-64b6-de40-4578a5534b79,https://media.licdn.com/dms/image/D560BAQFbVTDw-oWXmw/company-logo_100_100/0/1681327675102?e=1713398400&v=beta&t=Ir5hx7xUuaUo5T2BZZ9XorhXXE6Rv1XeKkDVGjYlWDo,LlamaIndex,https://www.linkedin.com/company/llamaindex/,"
67K followers
","
Advanced RAG Cheat Sheet + Recipes üßë‚Äçüç≥We‚Äôre publishing a comprehensive diagram outlining all the different components of advanced RAG, the pain points they solve, and links to LlamaIndex resources. Here‚Äôs some core concepts that motivate advanced RAGs:üí° Success metric for RAG is: retrieval is good, and generation is good.üí° Ways to improve retrieval: chunk-sizes, structured knowledge, sliding windows, KGs, ensemble retrieval, and moreüí° Generation must be able to use the documents effectively, with help from: compression, reranking, and moreüí° Interleave generation and retrieval for greater query understandingWhether you‚Äôre looking to start building with LLMs for the first time, or you‚Äôre a seasoned RAG veteran, there‚Äôs something here for everyone üî•(Seriously you could print this as a poster! üñ®Ô∏è)Our full blog post also contains code recipes for each of the components mentioned here: https://lnkd.in/eW8k9xxTCredits: Full credits go to Val Andrei Fajardo for driving this as a holiday project üéÑAlso credits to ‚ÄúRetrieval-Augmented Generation for Large Language Models: A Survey‚Äù by Gao et al. which served as inspiration for this! https://lnkd.in/g3cBvndU

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7149087685326864384?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7149087685326864384%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQEVzH-1BN1w1Q/feedshare-shrink_480/0/1704475326626?e=1707955200&v=beta&t=9aMfk6uKmwhhTW26pc39sLFvAyoL7--caWc_h3zAB0U
19,65a104d6a5b8f07200002164,3833cb79-5892-0b39-12fa-8d91643a8330,https://media.licdn.com/dms/image/D5603AQG9NK0CAgKtVg/profile-displayphoto-shrink_100_100/0/1687301791875?e=1710374400&v=beta&t=Bolt2zUMX7vi6uTl04U5LmzIk8J4LR-CV26o0v_KAIU,Lior S.,https://www.linkedin.com/in/ACoAADMTPYsBtfLtDZlCPxc0G4n0-rFYtqhC0yE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADMTPYsBtfLtDZlCPxc0G4n0-rFYtqhC0yE,"
I cover the latest breakthroughs in AI ‚Üí Ex-ML Engineer/Researcher ‚Üí Built the most read technical newsletter in AI
","
Big for finance. JPMorgan just announced DocLLM. Their new LLM can understand documents, invoices, financial reports and contracts.They key? The model skips costly image encoders and only focuses on bounding box data to understand layout structure.Trained on 5.5M documents in outperforms SotA LLMs on 14 out of 16 datasets across all tasks, and generalizes well to 4 out of 5 previously unseen datasets.Paper: https://lnkd.in/ggMHXDGy‚ÜìAre you technical? Check out https://AlphaSignal.ai to get a weekly summary of the latest models, repos and papers in AI. Read by 150,000+ engineers and researchers.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7148739975784673280?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7148739975784673280%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHRTc2F88jkOg/feedshare-shrink_480/0/1704392426859?e=1707955200&v=beta&t=ZLfF9P0j6NvEcjx57f9MniwmP9PKxWcw9coBQrYnLCY
20,65a104d6a5b8f07200002165,f37d141b-28c4-6f47-b519-12b5e0c501c5,https://media.licdn.com/dms/image/C5603AQH0vt7JCOIZ2g/profile-displayphoto-shrink_100_100/0/1659622741519?e=1710374400&v=beta&t=oD7v-H5eftQLYDRlvUvk2VE7-lsZDVk9VuRckoG8nZk,Jim Fan,https://www.linkedin.com/in/ACoAAA1AILwBEWpiY_CZ_I03PL9inU_8YB3s5nQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA1AILwBEWpiY_CZ_I03PL9inU_8YB3s5nQ,"
NVIDIA Sr. Research Scientist & Lead of AI Agents. Stanford Ph.D. Creator of Voyager, Eureka, MineDojo (Best Paper). OpenAI's first intern. Sharing insights on the bleeding edge of AI research & industry.
","
What did I tell you a few days ago? 2024 is the year of robotics. Mobile-ALOHA is an open-source robot hardware that can do dexterous, bimanual tasks like cooking a meal (with human teleoperation). Very soon, hardware will no longer bottleneck us on the quest for human-level, generally capable robots. The brain will be.This work is done by 3 researchers with academic budget. What an incredible job! Stanford rocks! Congrats to Zipeng Fu, Tony Z. Zhao, Chelsea FinnAcademia is no longer the place for the biggest frontier LLMs, simply because of resource constraints. But robotics levels the playing field a bit between academia and industry, at least in the near term. More affordable hardware is the inevitable trend. Advice for aspiring PhD students: embrace robotics - less crowded, more impactful. Website: https://lnkd.in/gZaF5XxkHardware assembly tutorial (oh yes we need more of these!): https://lnkd.in/gqJbUZxBCodebase: https://lnkd.in/gcaHMCZ5

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7148697097872039936?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7148697097872039936%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5605AQE_8FOvKtkPsA/videocover-low/0/1704345732020?e=1705658400&v=beta&t=0x2X1aPlslpqPO9dJzFTWhkoeDS1Uuw4UtXQtIQZfp4
21,65a104d6a5b8f07200002166,b25fbc25-4b09-78ce-514b-57bc2ef50e8f,https://media.licdn.com/dms/image/C4D03AQHOF7UW5eWsaw/profile-displayphoto-shrink_100_100/0/1648958000184?e=1710374400&v=beta&t=ejzUZTllc9uAjeG0xp88i3PvlFLBiHhO7sFbx8qXE_A,Mohit Mayank,https://www.linkedin.com/in/ACoAABvOglUB-66kUzaRYk07fKNimVaEgJ7a6oo?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABvOglUB-66kUzaRYk07fKNimVaEgJ7a6oo,"
Lead Data Scientist @ Outplay | Helping SaaS Startups scale their AI Game ü§ñ | Generative AI, LLM, Graphs, RL | Author & Consultant
","
ü¶ô Forget LLMs, SLMs i.e. Small Language Models are the new thing in AI with the recent TinyLLaMA model of only 1B size but trained on 3 Trillion tokens!üëâ LLMs are infamous for being too big and slow for production or edge use cases. This led to an interest in training a much smaller model with relatively comparable performance. Tiny LLaMA is an attempt in that direction which is only 1B big and can give more than 100 tokens/sec speed on Apple chipset! ‚ö†Ô∏è Note that the scaling rule still holds and bigger models are still better. But recent developments in the SLMs space will surely drive more interest in developing compact and efficient models.üîó Github: https://lnkd.in/ddXs6rFvüîó Download Model: https://lnkd.in/dF49dnRküîó Run on Mac: https://lnkd.in/dZ8rSkvR#ai #ml #llama2 #opensource #python #peft #research #llm #slm #developers

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7147643740453601280?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7147643740453601280%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQHMGnHPLlbUBA/feedshare-shrink_480/0/1704131063031?e=1707955200&v=beta&t=bP75kwEO8O2NepGpPeqH-wI95JAFrQVEF7trCAX5MKM
22,65a104d6a5b8f07200002167,76b5b90d-973a-1e43-a656-f4f07eee7753,https://media.licdn.com/dms/image/D5635AQEBzEFRC2EzLg/profile-framedphoto-shrink_100_100/0/1704907585971?e=1705658400&v=beta&t=x71pDAJzCbSPZxvt91sIkpmEr_5_pGLZIt6VZgw5eV0,Aman Chadha,https://www.linkedin.com/in/ACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU,"
GenAI Leadership @ Amazon AWS ‚Ä¢ Stanford AI ‚Ä¢ EB-1 ""Einstein Visa"" Recipient/Mentor ‚Ä¢ Ex-Ô£ø, Amazon Alexa, Nvidia, Qualcomm ‚Ä¢ EMNLP 2023 Outstanding Paper Award
","
ü§ñ LLM Alignment Primer (RLHF, RLAIF, DPO, KTO): http://rlhf.aman.ai- Reinforcement Learning with Human Feedback (RLHF) is used to align LLM behavior with human preferences. It has been pivotal for the optimal performance of current LLMs, resulting in more accurate and contextually appropriate responses. - On the other hand, Reinforcement Learning with AI Feedback (RLAIF) involves an LLM providing feedback to another LLM based on certain criteria. This could potentially enable faster training, better scalability, and remove annotation bottlenecks by leveraging the insights of one AI to refine another.- Direct Preference Optimization (DPO) obliterates the need for RL and optimizes for human preferences using your LLM as a reward model.- Kahneman-Tversky Optimization (KTO) circumvents the need for paired-preference ranking/comparison data and simplifies data requirements significantly. It only needs binary labels indicating whether an LLM output is desirable or undesirable.- Here are primers for RLHF, RLAIF, DPO, KTO, and Diffusion-DPO.üîπ RLHF- Overview: OpenAI's PPO and InstructGPT papers- Refresher: Basics of RL- Training Process (Pre-training Language Models, Training a Reward Model, Fine-tuning the LM with RL)- Bias Concerns and Mitigation Strategiesüîπ RLAIF- Overview: Anthropic‚Äôs Constitutional AI paper- Using AI feedback instead of human feedback to steer LLMs- Architecture: Supervised Learning and Reinforcement Learningüîπ DPO- Overview: Stanford University‚Äôs DPO paper- Aligning LLMs using human feedback without RL and an explicit reward modelüîπ KTO- Overview: Stanford University and Contextual AI University‚Äôs KTO paper- Unlike DPO and PPO, which require paired-preference data (i.e., ranking/comparison data) which is difficult to obtain, KTO operates efficiently with simpler binary feedback on outputs.üîπ Aligning Diffusion Models- Overview: Stanford University‚Äôs Diffusion-DPO paper- Results indicate improved visual appeal and prompt alignment while ensuring stable training and efficient performanceNotes written in collaboration with Vinija Jain.#artificialintelligence #machinelearning #ai #ml

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7147431158148923392?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7147431158148923392%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHrGQ-gO-zVMg/feedshare-shrink_480/0/1704080379932?e=1707955200&v=beta&t=YltF-h7RAAoTkh9jvC4B8AbZetC7yFgVfqswyaGGkC4
23,65a104d6a5b8f07200002168,7635c43f-bb95-04bf-6133-b3b243612bca,,Albert Chun,https://www.linkedin.com/in/ACoAAAawZ4wBrcvTjgnIlVEhsdJ1clkITyMlXDM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAawZ4wBrcvTjgnIlVEhsdJ1clkITyMlXDM,"
GenAI Operations @ Invisible | Advisor | Harvard Venture
","
Before I joined Invisible, I spent 25+ hours listening to several courses on AI at Stanford University.When Lex Fridman interviewed Andrew Ng (https://lnkd.in/eSXYGmkx), Andrew mentioned that the best way to learn about AI is through courses. Here are my three favorite lectures:1. CS229: Machine Learning with Andrew Ng(https://lnkd.in/e4fXXPpg)- Andrew started programming when he was 5 years old - He started reading about neural networks as a teen- He started Google Brain later merged with Google DeepMind- He went on to found Coursera, the AI Fund, DeepLearning.AI, LANDING AI while teaching at Stanford University2. CS221: Artificial Intelligence: Principles and Techniques with Percy Liang (https://lnkd.in/efHajfNA)- Percy coined the term ""Foundation Model"" referring to large language models being trained on large data sets to be tuned - along with ""emergence"" and ""homogenization""- He received BS and MEng from Massachusetts Institute of Technology and a PhD from UC Berkeley- His course, coupled with CS 229, is staple to any Stanford CS undergrad and are world renown3. CS234: Reinforcement Learning with Emma Brunskill(https://lnkd.in/e-b4YEKN)- A personal favorite because this is what I'm working on- Great high level overview of Reinforcement Learning with real-world events- Emma studied at University of Washington, Oxford, and MIT- She went on to teach at University of California, Berkeley (Go Bears), Carnegie Mellon University, and Stanford (in case you wanted to know, these are the top three schools for #artificialintelligence in North America)-If you want to help your networks break into AI, please like and reshare this post.If you found this helpful, follow me for more at Albert Chun.#ai #startup #machinelearning 

          ‚Ä¶see more
        


Stanford CS229: Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018)
",,https://www.linkedin.com/feed/update/urn:li:activity:7146457833868328960?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7146457833868328960%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/C4D27AQEwXtZF9kwpKw/articleshare-shrink_800/0/1704816398744?e=1705658400&v=beta&t=6jWhy1H1CpVn9g8cnoVEzPALHaEt6K29J6UMA_KaNWs
24,65a104d6a5b8f07200002169,99086438-9b0c-38cf-9fe1-93106e07ad5d,,William Falcon,https://www.linkedin.com/in/ACoAAA0NGL8BEFcrXjADw5LpXjHUl43GjsfaXsY?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA0NGL8BEFcrXjADw5LpXjHUl43GjsfaXsY,"
PyTorch Lightning ‚ö°Ô∏ècreator. CEO Lightning AI. AI researcher.
","
Spin up hundreds of models, each on their own GPU machine in seconds to find the best model - with zero cloud setup. Follow this example:https://lnkd.in/eBq-BT5P

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7146988567402053632?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7146988567402053632%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQGuWWp9YY7LNw/feedshare-shrink_480/0/1703919676397?e=1707955200&v=beta&t=9o5ysmf11zq07MjV4z_oENLnZN0jzNlXSY2Nq1d3cBU
25,65a104d6a5b8f0720000216a,5593a2a9-1e05-857a-7fcb-eae5b66c446b,https://media.licdn.com/dms/image/C4E0BAQEH4nbL2sl5gA/company-logo_100_100/0/1635539130887/facebookai_logo?e=1713398400&v=beta&t=sFixUTJyqFvVkiEiDy7X9VTcRcgGTR2jo-a3QyjRJ70,AI at Meta,https://www.linkedin.com/company/aiatmeta/,"
672K followers
","
To close out 2023, here are 10 of the most popular AI advancements we shared on our feed from researchers at Meta this year ‚Äî and where you can find more details on the work.‚Ä¢ Segment Anything (SAM)A promptable segmentation system with zero-shot generalization to unfamiliar objects and images, without the need for additional training. Details: https://bit.ly/3H0AuWo ‚Ä¢ DINOv2The first method for training computer vision models that uses self-supervised learning to achieve results matching or exceeding industry standards. Details: https://bit.ly/4aBAM3o‚Ä¢ Llama 2The next generation of our open source large language model, available for free for research and commercial use. Details: https://bit.ly/3H51sfi‚Ä¢ Emu Video & Emu EditGenerative AI research for high quality, diffusion-based text-to-video generation & controlled image editing with text instructions. Details: https://bit.ly/48ex4LE‚Ä¢ I-JEPASelf-supervised computer vision that learns to understand the world by predicting it. The first model based on a component of Yann LeCun's vision to make AI systems learn and reason like animals and humans. Details: https://bit.ly/3GYrP6D ‚Ä¢ AudioboxOur new foundation research model for audio generation. Details: https://bit.ly/4ayXFVb ‚Ä¢ Brain decoding - toward real-time reconstruction of visual perceptionUsing MEG, this AI system can decode the unfolding of visual representations in the brain with an unprecedented temporal resolution. Details: https://bit.ly/3tyW2pQ‚Ä¢ Open Catalyst demoA service that allows researchers to accelerate work in material sciences by enabling them to simulate the reactivity of catalyst materials faster than existing computational methods. Details: : https://bit.ly/3tybOBo‚Ä¢ Seamless CommunicationA new family of AI translation models that preserve expression and deliver near-real time streaming translations. Details: https://bit.ly/3H0ykpC‚Ä¢ ImageBindThe first AI model capable of binding data from six modalities at once. A breakthrough that brings machines one step closer to the human ability to bind together information from many different senses. Details: https://bit.ly/3vhS5Xn

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7146923810976411648?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7146923810976411648%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5605AQFox3r2sKA8xQ/videocover-low/0/1703810442885?e=1705658400&v=beta&t=hZM7TReEiH9eAUL99HXVodtUTRWx7sgcZkbNbmY6f-g
26,65a104d6a5b8f0720000216b,0bd0a47f-f05b-86ae-73b4-44ef72b2fe9d,https://media.licdn.com/dms/image/C5603AQGj_TL98bZDfg/profile-displayphoto-shrink_100_100/0/1636910271275?e=1710374400&v=beta&t=3esSntrot7SK9DE1U8gYV40vKBbP9cUuqMukE1SIbpA,Jaime Teevan,https://www.linkedin.com/in/ACoAAAAUUfMBGeJvK5oTJbIJ2FDDqJ4vrrVr0Ek?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAAUUfMBGeJvK5oTJbIJ2FDDqJ4vrrVr0Ek,"
Chief Scientist & Technical Fellow at Microsoft - for speaking requests please contact teevan-externalopps@microsoft.com
","
The 2023 New Future of Work AI report is a must-read for anyone who wants to stay ahead of the curve in the rapidly evolving world of work. Read it to find the answers to questions like:üí° How do LLMs affect the speed and quality of common information work tasks? üí° How can LLMs help us break down and build up complex tasks?üí° How can we collaborate effectively with LLMs?üí° How can LLMs tackle tasks that go beyond simple search or generation?üí° How are LLMs being used and affecting different domains of work?üí° How can LLMs help teams work and communicate better?üí° How is AI changing the nature and distribution of knowledge in organizations? üí° What are the implications AI will have for the future of work and society?http://aka.ms/nfw2023Editors: Dr. Jenna Butler, Sonia Jaffe, Nancy Baym, Mary Czerwinski, Shamsi Iqbal, Kate Nowak, Sean Rintel, Abigail Sellen, Jaime Teevan. Additional authors in the comments.

          ‚Ä¶see more
        


Microsoft New Future of Work Report 2023 - Microsoft Research
",,https://www.linkedin.com/feed/update/urn:li:activity:7142649725324775424?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7142649725324775424%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,
27,65a104d6a5b8f0720000216c,4549fb36-4c45-aa9b-b7a8-65c67521161b,https://media.licdn.com/dms/image/C4E03AQFbYWRArqfw6g/profile-displayphoto-shrink_100_100/0/1516313754118?e=1710374400&v=beta&t=QkGhaFwwyIimyp01nfFr1ky60H1x6Kitm4NkwWxlmYw,Raghavendra Veera,https://www.linkedin.com/in/ACoAAACgyGEBg2_m0WY6nRDB-GlNfSgxfKhAqS0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAACgyGEBg2_m0WY6nRDB-GlNfSgxfKhAqS0,"
Senior Applied Scientist
","
I'm delighted to share that our papers ""Generalized zero-shot audio-to-intent classification"" and ""AdaBERT-CTC: Leveraging BERT-CTC for text-only domain adaptation in ASR"" have been presented at ASRU 2023 and EMNLP 2023, respectively.1. Generalized zero-shot audio-to-intent classification: Spoken language understanding systems using audio-only data are gaining popularity, yet their ability to handle unseen intents remains limited. In this study, we propose a generalized zero-shot audio-to-intent classification framework with only a few sample text sentences per intent. To achieve this, we first train a supervised audio-to-intent classifier by making use of a self-supervised pre-trained model. We then leverage a neural audio synthesizer to create audio embeddings for sample text utterances and perform generalized zero-shot classification on unseen intents using cosine similarity. We also propose a multimodal training strategy that incorporates lexical information into the audio representation to improve zero-shot performance. Our multimodal training approach improves the accuracy of zero-shot intent classification on unseen intents of SLURP by 2.75% and 18.2% for the SLURP and internal goal-oriented dialog datasets, respectively, compared to audio-only training. Paper link: https://lnkd.in/gBNzaWZv2. AdaBERT-CTC: Leveraging BERT-CTC for text-only domain adaptation in ASR: End-to-end (E2E) automatic speech recognition (ASR) models are becoming increasingly popular in commercial applications, such as virtual assistants, closed captioning, and dictation systems. The accuracy of the ASR is crucial to their success. However, E2E models still struggle to recognize out-of-domain words such as proper nouns and domain-specific terms. In this paper we introduce AdaBERT-CTC, a domain adaptation technique that relies solely on textual data. Our method allows for text-only adaptation by fine-tuning a pre-trained self-supervised text encoder model. Additionally, we show that our method can be made parameter-efficient by adding bottleneck adapters to the pre-trained model. This allows for adaptation with less than a 5% increase in parameters and minimal computational overhead during inference. We demonstrate that our approach outperforms the base BERT-CTC model by up to 14% relative word error rate improvement on several out-of-domain, publicly available datasets.Paper link: https://lnkd.in/gwxeb2Zn

          ‚Ä¶see more
        


Generalized zero-shot audio-to-intent classification
",,https://www.linkedin.com/feed/update/urn:li:activity:7142053955651387393?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7142053955651387393%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQH--PRXMIgsfg/articleshare-shrink_800/0/1704007787819?e=1705658400&v=beta&t=kaqQD21T_-4suTba2ThAR7GONZzP4NSaiYg-ptvNOKE
28,65a104d6a5b8f0720000216d,cc43b042-29f4-02a6-d1f8-737db497b0ad,https://media.licdn.com/dms/image/C5603AQFvncvflX_kMQ/profile-displayphoto-shrink_100_100/0/1564316873635?e=1710374400&v=beta&t=DRxjFCzRMNJSc3QM233eAmSZ8rflNQHLrn8k0KQuOhg,Elvis S.,https://www.linkedin.com/in/ACoAACxhXeUBTYZYCwIa4nsvSBsETtrS0uhGNPc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACxhXeUBTYZYCwIa4nsvSBsETtrS0uhGNPc,"
Co-Founder at DAIR.AI | Prev: Meta AI, Galactica LLM, PapersWithCode, Elastic
","
LLM Interpretability hasn't received as much attention but it's as important as any other research area to keep advancing LLMs. This area of study has implications for how to optimize and make LLMs more performant, reliable, and safer. I really like this repo that curates tools and recent papers on LLM interpretability.Great way to catch up on an exciting and important topic. Regardless if you follow the topic or not, the repository contains a good set of papers worth checking out. https://lnkd.in/ePanB6pp--I also provide technical summaries of the latest LLM research and developments here: https://lnkd.in/embzyF3F

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7144352405428604928?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7144352405428604928%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQFTzSniKvL_ww/feedshare-shrink_480/0/1703346348195?e=1707955200&v=beta&t=7TgmIJGb3FAzAIMYCCUKw9gJg3VhA1VAJqDSpSr34B8
29,65a104d6a5b8f0720000216e,472e230a-7ce7-7c00-8e69-c92b4ae93de9,https://media.licdn.com/dms/image/C4D03AQEmDwFNREkaIA/profile-displayphoto-shrink_100_100/0/1517524291944?e=1710374400&v=beta&t=9H8wRu-S3Mr0BN5zZEZBtWwefLpa0ZU_FPNQ9dTlNws,Robin Gras,https://www.linkedin.com/in/ACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ,"
Professor at University of Windsor, CSO and partner at Movyl Technologies and MVYL Associates
","

 

EPFL and Apple Researchers Open-Sources 4M: An Artificial Intelligence Framework for Training Multimodal Foundation Models Across Tens of Modalities and Tasks
",,https://www.linkedin.com/feed/update/urn:li:activity:7142868342905708545?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7142868342905708545%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQHFy8FDEhgluQ/articleshare-shrink_800/0/1704482550229?e=1705658400&v=beta&t=6xVoucyCG-ZSUyyVJXHldGUoWYLaJKWPtFEb28IIUyA
30,65a104d6a5b8f0720000216f,59ba5b6e-787b-30e5-1f7c-7bf3a31f5461,https://media.licdn.com/dms/image/D5603AQE94mYfarH9Lw/profile-displayphoto-shrink_100_100/0/1697773916134?e=1710374400&v=beta&t=6hvYIsQcQDWCnS1u3H0YzMM17hoNUapyUSgFw9oQA1o,"Cameron R. Wolfe, Ph.D.",https://www.linkedin.com/in/ACoAADsnd7cBgs-Y6WaLENv0ewpNCOs9qsnJngw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADsnd7cBgs-Y6WaLENv0ewpNCOs9qsnJngw,"
Director of AI @ Rebuy
","
Want to train a specialized LLM on your own data? The easiest way to do this is with low rank adaptation (LoRA), but many variants of LoRA exist. Here‚Äôs an overview of all (or at least most) of the techniques that are out there‚Ä¶LoRA models the update derived for a model‚Äôs weights during finetuning with a low rank decomposition, implemented in practice as a pair of linear projections. LoRA leaves the pretrained layers of the LLM fixed and injects a trainable rank decomposition matrix into each layer of the model.QLoRA is (arguably) the most popular LoRA variant and uses model quantization techniques to reduce memory usage during finetuning while maintaining (roughly) equal levels of performance. QLoRA uses 4-bit quantization on the pretrained model weights and trains LoRA modules on top of this. In practice, QLoRA saves memory at the cost of slightly-reduced training speed.QA-LoRA is an extension of LoRA/QLoRA that further reduces the computational burden of training and deploying LLMs. It does this by combining parameter-efficient finetuning with quantization (i.e., group-wise quantization applied during training/inference).LoftQ studies a similar idea to QA-LoRA‚Äîapplying quantization and LoRA finetuning on a pretrained model simultaneously.LongLoRA attempts to cheaply adapt LLMs to longer context lengths using a parameter-efficient (LoRA-based) finetuning scheme. In particular, we start with a pretrained model and finetune it to have a longer context length. This finetuning is made efficient by:1. Using sparse local attention instead of dense global attention (optional at inference time).2. Using LoRA (authors find that this works well for context extension).S-LoRA aims to solve the problem of deploying multiple LoRA modules that are used to adapt the same pretrained model to a variety of different tasks. Put simply, S-LoRA does the following to serve thousands of LoRA modules on a single GPU (or across GPUs):- Stores all LoRA modules in main memory.- Puts modules being used to run the current query into GPU memory.- Uses unified paging to allocate GPU memory and avoid fragmentation.- Proposes a new tensor parallelism strategy to batch LoRA computations.Many other LoRA variants exist as well‚Ä¶- LQ-LoRA: uses a more sophisticated quantization scheme within QLoRA that performs better and can be adapted to a target memory budget.- MultiLoRA: extension of LoRA that better handles complex multi-task learning scenarios.- LoRA-FA: freezes half of the low-rank decomposition matrix (i.e., the A matrix within the product AB) to further reduce memory overhead.- Tied-LoRA: leverages weight tying to further improve the parameter efficiency of LoRA.- GLoRA: extends LoRA to adapt pretrained model weights and activations to each task in addition to an adapter for each layer.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7142972699147980800?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7142972699147980800%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQF1kwEik1-urQ/feedshare-shrink_480/0/1703017400686?e=1707955200&v=beta&t=Z4oQqG5jlaRBCcslZesBKNUtLVSFLYpKa3cwa_TNJUs
31,65a104d6a5b8f07200002170,08f25f09-0bfe-09c4-ae6b-7b1088c3cb24,https://media.licdn.com/dms/image/C5603AQE32W2GZCfj3Q/profile-displayphoto-shrink_100_100/0/1636039573108?e=1710374400&v=beta&t=NnJs2z_mBGV4urIcy8CQmJTQwxtILx06fNQomvM5Mtk,Jasper Lai Woen Yon,https://www.linkedin.com/in/ACoAAA1YOCQBZ85Ld29mkBG4LJDc66f9PpbFNAQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA1YOCQBZ85Ld29mkBG4LJDc66f9PpbFNAQ,"
Senior Algorithm Engineer @ Shopee | LLM | NLP | Multimodal
","
Excellent roadmap to learn about the LLM end to end workflow It covers1Ô∏è‚É£ The basics of NLP2Ô∏è‚É£ How to do pre-training3Ô∏è‚É£ How to prepare instruction dataset4Ô∏è‚É£ How to do supervise fine tuning on off-the-shelf models 5Ô∏è‚É£ Learning from human feedback6Ô∏è‚É£ Quantization to serve your model faster and more efficiently 7Ô∏è‚É£ How to optimize your model during inferenceHave you checked out this repository? Any valuable materials you‚Äôd recommend for deepening understanding? #LLM #NLP #MachineLearning

          ‚Ä¶see more
        


GitHub - mlabonne/llm-course: Course to get into Large Language Models (LLMs) with roadmaps and Colab notebooks.
",,https://www.linkedin.com/feed/update/urn:li:activity:7146183572087844864?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7146183572087844864%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQE7ajz4REvXmA/articleshare-shrink_800/0/1704990173654?e=1705658400&v=beta&t=y25h5f-ZSlgP6VKDZf5B2SekIpCZ5Ae8izXDFsbYlTY
32,65a104d6a5b8f07200002171,28f11a3a-c077-d735-0340-6abde91c0117,https://media.licdn.com/dms/image/D4E03AQGXdP0v2gnoYg/profile-displayphoto-shrink_100_100/0/1704138079968?e=1710374400&v=beta&t=3iINXsXeaB4vSPqzt5bTVhH7sYu9dOhr0rJi8ia_Oe8,Abhishek Bisht,https://www.linkedin.com/in/ACoAAAScmW8BVvmZ5jxLUUWypxdVKvFWX_oDJiU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAScmW8BVvmZ5jxLUUWypxdVKvFWX_oDJiU,"
‚îî‚ñ∫ Data Scientist|Healthcare|NLP|ü§ó |ü¶ôü¶ô|
","
Exciting news! Mixtral-8x7B is now available on Google Colab for free! üöÄ‚ú®Key highlights:- Innovative offloading technique combined with mixed quantization. üîÑüîç- Successfully ran Mixtral-8x7B on the free-tier Google Colab platform. üíªüÜìCheck out the notebook for a demonstration: https://lnkd.in/eyPETYyf üììExplore the code on GitHub: https://lnkd.in/e3cjddCy üöÄRead the paper for in-depth insights: https://lnkd.in/ead9PSMe  üìÑüß†#MachineLearning #Mixtral #GoogleColab #Innovation #opensource #opensourceai 

          ‚Ä¶see more
        


2312.17238.pdf
",,https://www.linkedin.com/feed/update/urn:li:activity:7146592691697451008?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7146592691697451008%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,
33,65a104f1a5b8f07200002198,d3a6945d-3e35-4a0a-9bbc-f48ae0023a40,https://media.licdn.com/dms/image/D560BAQGFpRpGKIeK6w/company-logo_100_100/0/1688581512782/pytorch_logo?e=1713398400&v=beta&t=PpzZq2REepkndNguYHvGhBbKkm4iNPBKoATlVMFfHc0,PyTorch,https://www.linkedin.com/company/pytorch/,"
228K followers
","
Introducing PyPose, one of our latest ecosystem tools üî•PyPose is a PyTorch-based robotics-oriented library that provides a set of tools and algorithms for connecting deep learning with physics-based optimization.Learn more üëáhttps://hubs.ly/Q02cbCvQ0

          ‚Ä¶see more
        


PyPose: A Library for Robot Learning with Physics-based Optimization
",,https://www.linkedin.com/feed/update/urn:li:activity:7138213004533239808?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7138213004533239808%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5610AQHi4oUhJ0weXA/image-shrink_800/0/1701882601802?e=1705658400&v=beta&t=BEONGaPuD0uwIvZX77ssggpmJBtJSBkpCax34u7raZ8
34,65a104d6a5b8f07200002173,46d85f39-3fd9-6bae-7bfe-809cfdad99ba,https://media.licdn.com/dms/image/D4D03AQHJ4fAqeTdHbw/profile-displayphoto-shrink_100_100/0/1665336481233?e=1710374400&v=beta&t=DEzCXmizOOmljnFOeZTGAXJuX80PUADeUWuE1xTA-Ew,Harsh Nigam,https://www.linkedin.com/in/ACoAACC9ybIBnJFcBIpm_tRfdMdmgostnU9LhYI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACC9ybIBnJFcBIpm_tRfdMdmgostnU9LhYI,"
Data Engineer at PriceLabs
","
I fine-tuned my first LLM Mistra-7B-instructionAt PriceLabs, we have our SAAS platform that helps our customer manage their revenue for their properties like Airbnb. Our product is heavily customer centric and we have quite a bit of back and forth with our customer base, mostly answering their queries regarding operating our platform.Naturally, we spend a significant amount of time creating content to train our customers and even employees to use our SAAS product. Even so, if the product is not used on a regular basis, a refresher might be required. This is true for any SAAS platform providing a rich set of features.This is a use-case where LLMs can help improve the process, its not necessarily a reasoning task but rather a memorization task, as we would want a bot assistant that answer simple questions like: How to set 'X' feature? or Where is feature 'X' located? and response from an LLM assistant would be a step by step guide.So to build this bot, I followed the following steps:1. Created a dataset of 100 examples. Examples consisted of user questions for different features on our platform, these are called 'prompts', then for each prompt I created 'response' which is step by step guide on how to tack that question for our users.2. This is a very small dataset, to inflate it and decrease the chance of overfitting, I use ChatGpt, to create 10 variants for each prompts keeping the response same. This increased my dataset 10x, though the set of response stayed same.3. The choice to repeat the response for different variants was in hopes to force the model to memorize these tasks. 4. Bought subscription to google colab pro+ to get limited access to A100, lesser GPUs cant training a 7B model.5. Quantized the model twice + applied lora to train an adapter which is then merged with main model to produce our fine tuned model.Link to my colab training notebook: https://lnkd.in/eQ_D6QyQObservation:1. This approach did not work. According to some papers, LLM when fine-tuned can memorize singular examples (almost like overfitting) which is what I was hoping to see. But model failed the learn the new information I provided in my dataset and hallucinated to my question.2. The model started overfitting from the 2nd epoch itself which  could mean, I need to work on my dataset or its just too small to work with.3. I posed this question on huggingface discord and few people who worked on similar issue, told me that fine-tuning fails to inject new knowledge in the LLM and is often used to only change the behavior of the model. Next step: Building a RAG pipeline to build this LLM-assistant with Mistral-7b, so stay tuned:)If any of you working on similar project and have insights to share, you are very welcome:)

          ‚Ä¶see more
        


Google Colaboratory
",,https://www.linkedin.com/feed/update/urn:li:activity:7145965512697532416?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7145965512697532416%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQHjTvy8okM6Tg/articleshare-shrink_480/0/1705043415051?e=1705658400&v=beta&t=D-zlVPGq5MTPuxrKC8AJ5LQMhn1GVkPSQZKXLnFQOx8
35,65a104d6a5b8f07200002174,14c5e667-7066-2197-e858-4bee10a8354b,https://media.licdn.com/dms/image/C4E03AQGaJicfkdx0OA/profile-displayphoto-shrink_100_100/0/1621628083925?e=1710374400&v=beta&t=dCq_JLW2qmUQT5QYTGVPNi3F2JpNOfG-SGxWiIli7z4,Matt Payne,https://www.linkedin.com/in/ACoAACMNIUkBR6vQlxXWze4xhzbN-CSqpPpr1MI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACMNIUkBR6vQlxXWze4xhzbN-CSqpPpr1MI,"
Building Machine Learning & Ai software tools for organizations to automate business processes and enhance product capabilities. | Primarily focused on generative ai | ex - Capital One | Focused on Width.ai & Pumice.ai
","
One of the most relevant research papers you should read today:
 

Lost in the Middle: How Language Models Use Long Contexts
",,https://www.linkedin.com/feed/update/urn:li:activity:7146583851157319680?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7146583851157319680%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQHS3Z1uOBAUcw/articleshare-shrink_800/0/1703878397899?e=1705658400&v=beta&t=EApWZvMkgFTdTljNeqsm6BT5pIllhvDbf9udG1YeA4Q
36,65a104d6a5b8f07200002175,224b4709-040b-4964-c263-626ebe976584,https://media.licdn.com/dms/image/D4E03AQEuowZzIofWfQ/profile-displayphoto-shrink_100_100/0/1682176616292?e=1710374400&v=beta&t=zCaoDLLLOf35Yi-Om5V8sRTh9AEgH-IOm4AaO60XMmk,Pooja Srinivasan,https://www.linkedin.com/in/ACoAACrZP9YBUSGkeiftTX4ycDX1MAB4Lsul7qY?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACrZP9YBUSGkeiftTX4ycDX1MAB4Lsul7qY,"
MS in Data Science @Columbia University | GHC'23 | MITACS GRI'21| NLP | Machine Learning
","
I am thrilled to have presented my research poster on 'Editing Large Language Models' at Columbia University in collaboration with JPMorgan Chase & Co.'s AI research team. Addressing the potency of Large Language Models (LLMs) and their challenge in maintaining current factual knowledge, my research centers on developing efficient editing methods to sidestep extensive retraining. Delving into the storage paradigm of autoregressive transformer models, I analyze and edit factual associations for real-time information. The research emphasizes the limitations of current editing methods, stressing the importance of distinct locations (layers) for various prompt types. Additionally, scrutinizing incorrectly predicted prompts opens avenues for deeper investigations into the model's behavior, suggesting potential accuracy improvements through activation pattern insights. This work pioneers a pathway to ensure LLMs adeptly store both vast and current knowledge. I am grateful for the opportunity to contribute to the evolving landscape of AI and language models!#largelanguagemodels #columbiauniversity #research #ai 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7146218104107270144?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7146218104107270144%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQFPcbNeF1temw/feedshare-shrink_480/0/1703791165744?e=1707955200&v=beta&t=9Be5pT8YtCCHR4ALjR87A7lAt_9Mzxnep-ZexIcvCBs
37,65a104d6a5b8f07200002176,7dc3a8cf-d05e-355d-21bb-392c9d585014,https://media.licdn.com/dms/image/C5603AQG-dM4ML4UxFA/profile-displayphoto-shrink_100_100/0/1557023095050?e=1710374400&v=beta&t=LQ_tNrPtF7gFIxFApoMUaL1VAONTORvd7GgrPHM-uKY,Eric Vyacheslav,https://www.linkedin.com/in/ACoAACgVdBIBnVU5t_1PfWzjEm4SjOgQ1yY3Tsc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACgVdBIBnVU5t_1PfWzjEm4SjOgQ1yY3Tsc,"
AI/ML Engineer | Ex-Google | MIT Alumni
","
Just came across the most comprehensive LLM course on github. It covers various articles, roadmaps, Colab notebooks, and other learning resources that help you to become an expert in the field:‚û° The LLM architecture‚û° Building an instruction dataset‚û° Pre-training models‚û° Supervised fine-tuning‚û° Reinforcement Learning from Human Feedback‚û° Evaluation‚û° Quantization‚û° Inference optimizationRepo (3.2k stars): https://lnkd.in/g-42Yjgu‚ÜìAre you technical? Check out https://AlphaSignal.ai to get a weekly summary of the latest models, repos and papers in AI. Read by 150,000+ engineers and researchers.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7146153808933400576?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7146153808933400576%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQGiM5dr1quAxA/feedshare-shrink_480/0/1703775836551?e=1707955200&v=beta&t=KsodfcsNa1MoNs_PF0zhNmNOcL9T5T-8MfDGlM7D1t8
38,65a104d6a5b8f07200002177,13f5998e-253e-d805-39ad-fa8a1e3bda54,https://media.licdn.com/dms/image/D4E03AQGbzofEDAk3iQ/profile-displayphoto-shrink_100_100/0/1691922361843?e=1710374400&v=beta&t=gpHkAyHRvlkoOiG8JNJnvzGPohVnP3ICHNiLo1UfedY,Thomas Wolf,https://www.linkedin.com/in/ACoAAAFYZ2UBzPnShY0OkuyWzB3BaoJCf5FRgCk?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAFYZ2UBzPnShY0OkuyWzB3BaoJCf5FRgCk,"
Co-founder at ü§ó Hugging Face
","
The rise of open (source/access) AI models back from the ashes in 2023source: https://lnkd.in/emRnug82

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7144973584006873088?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7144973584006873088%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQF6bu5ybiQj8Q/feedshare-shrink_480/0/1703494448185?e=1707955200&v=beta&t=Vfnfv33IlBjrashXQXqIOLxo3-oULNb8H_stqyVsJy0
39,65a104d6a5b8f07200002178,68c056d1-dd0b-2ad4-854c-3137643e3175,https://media.licdn.com/dms/image/C5603AQFvncvflX_kMQ/profile-displayphoto-shrink_100_100/0/1564316873635?e=1710374400&v=beta&t=DRxjFCzRMNJSc3QM233eAmSZ8rflNQHLrn8k0KQuOhg,Elvis S.,https://www.linkedin.com/in/ACoAACxhXeUBTYZYCwIa4nsvSBsETtrS0uhGNPc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACxhXeUBTYZYCwIa4nsvSBsETtrS0uhGNPc,"
Co-Founder at DAIR.AI | Prev: Meta AI, Galactica LLM, PapersWithCode, Elastic
","
Nice work surveying 300+ papers and summarizing research developments to look at in the space of Generative AI. It covers computational challenges, scalability, real-world implications, and the potential for Gen AI to drive progress in fields like healthcare, finance, and education.https://lnkd.in/enB5GsvE---I also provide technical summaries of the latest LLM research papers here: https://lnkd.in/embzyF3F

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7145885923581317120?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7145885923581317120%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQFEln2lu32fEg/feedshare-shrink_480/0/1703711967133?e=1707955200&v=beta&t=YSU943t25Em_5ovXWYu9xYRpuYQp0aqFJkik6UyRUTc
40,65a104d6a5b8f07200002179,641dcfb1-fecf-2b19-89f0-e5e6ef801dba,https://media.licdn.com/dms/image/D5635AQEj-jQxSTfccg/profile-framedphoto-shrink_100_100/0/1692621143446?e=1705658400&v=beta&t=_USqCJEBdJAuHjzL6Mw3MFqpPg7ZtT1bs-wI27DHKHo,Tarun Annapareddy,https://www.linkedin.com/in/ACoAAB3GGCQBm_w5ljkZA-5fFjurldLlqPgoSVA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAB3GGCQBm_w5ljkZA-5fFjurldLlqPgoSVA,"
MSCS - University of Colorado Boulder | Looking for Summer 2024 Internships | Ex SDE-3 Nutanix | I develop scalable software solutions
","
Have you worked with workflow #orchestrator? ( #netflix Conductor and #temporal were some of my gotos)Do you realize this subtle tradeoff we make with Orchestrators? Every Activity/Task has to read the input from Orchestrator and write back the output to execute the next Activity/Task. What do we get with this? #durability. What do we sacrifice? #performance You might feel that Network overhead is insignificant. Now Imagine each data block is an image of the video stream and you are working at the #scale of an #amazonwebservices live stream. Did you get the heat?Why did #amazon move from Distributed Microservices to Monolith1. What is the Usecase and Scale?2. What is the previous pipeline and Bottlenecks?3. Solution Implemented and Tradeoffs4. Problems I see with the new pipeline5. My Takeaways#distributedsystems #cloudcomputing #orchestration #temporal #netflix #amazon #softwareengineering #microservices #softwaredevelopment University of Colorado Boulder

          ‚Ä¶see more
        


Scaling Up: Why did Amazon move from Distributed Microservices to monolith?
",,https://www.linkedin.com/feed/update/urn:li:activity:7145761767351009281?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7145761767351009281%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5612AQG6nK_Jz4DMLw/article-cover_image-shrink_720_1280/0/1703681402170?e=1710374400&v=beta&t=wLGInjcMo_lW8VlBj-UeMR35iaPbtBhj6-_sT7srIdM
41,65a104d6a5b8f0720000217a,75b869d0-f5d6-09be-5116-b056f24d3a76,https://media.licdn.com/dms/image/D4D03AQEQq6BxsNE6nA/profile-displayphoto-shrink_100_100/0/1668699790008?e=1710374400&v=beta&t=uA3k8hT2i_CZ5qFzJ8tvkY0oTEj3gQlweNoS3hYy-qg,Vaibhav Srivastav,https://www.linkedin.com/in/ACoAAByTX7UBK8s_Cqa76oX2vI4LckCiWMaVNZI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAByTX7UBK8s_Cqa76oX2vI4LckCiWMaVNZI,"
Open Source @ Hugging Face
","
We made Whisper even faster. ~40% faster!! üî•Whisper solidifies its lead by an even larger margin!With the latest changes in transformers - large v3 is the best* and the fastest among the top 5 on the Open ASR Leaderboard.Below is the reduction in Real-time factor (RTF):whisper large v3: 10.3 -> 7.45distil whisper v2: 4.93 -> 2.08How did we achieve this speed-up?1. Native SDPA (Scaled Dot Product Attention) integration.2. Torch backend for STFT (Short-Term Fourier Transform).How can you benefit from this?pip install --upgrade git+https://github. com/huggingface/transformers.gitThat's it! ü§ó

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7145747578725310464?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7145747578725310464%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQEqGrFweSdwCw/feedshare-shrink_480/0/1703678982843?e=1707955200&v=beta&t=ASNSydYLAmWwvc014wEOEdm9ipSiNSdDZOp1UBy9l-0
42,65a104d6a5b8f0720000217b,0d2f665d-3b84-38d5-3c02-c5d0bc8f9302,https://media.licdn.com/dms/image/D5603AQFLxP3Wc11NpQ/profile-displayphoto-shrink_100_100/0/1701660169908?e=1710374400&v=beta&t=w6AsEq1gD9f_U0cew5qBgH-9YSzJKXvBfZjh80-pfTo,Umar Jamil,https://www.linkedin.com/in/ACoAAAS4KQ0B452oUZRY7yW_wZADknbemhD_sQI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAS4KQ0B452oUZRY7yW_wZADknbemhD_sQI,"
AI | Data Science | Machine Learning
","
Mistral 7B and Mixtral 8x7B introduced many innovations: Sliding Window Attention, Rolling Buffer (KV) Cache, Pre-Fill and Chunking, Model Sharding and in the case of Mistral 8x7B also Sparse Mixture of Experts (SMoE). In this video I will be explaining all these concepts, using diagrams to make it easier to understand all these advanced topics. The open source implementation of the Mistral model also makes use of the xformers library to calculate the attention of multiple prompts in a single sequence, so as to optimize the inference, but it can make it very hard for researchers and engineers to visualize what's happening under the hood. In the video I describe the process of packing multiple prompts in a single sequence, also by visualizing the attention mask that's created using the xformers library (BlockDiagonalCausalMask, BlockDiagonalMask and BlockDiagonalCausalWithOffsetPaddedKeysMask).I also show you why the Sliding Window Attention allows a token to ""attend"" other tokens outside the attention window by linking it with the concept of Receptive Field, typical of Convolutional Neural Networks (CNNs). Of course I prove it mathematically.When introducing Model Sharding, I will also talk about Pipeline Parallelism, because in the official mistral repository they refer to microbatching.I am also releasing a commented version of the official Mistral code to better understand the Sparse Mixture of Experts (SMoE), Pre-Fill, Chunking and the integration with the xformers library (refer to the cache.py and moe.py files).Link to the video: https://lnkd.in/eHDfQPwm#mistral #llm #mistral7b #mistral8x7b #mixtureofexperts #sparsemixtureofexperts #deeplearning #machinelearning

          ‚Ä¶see more
        


Mistral Explained: Sliding Window Attention, Sparse Mixture of Experts, Rolling Buffer, Sharding
",,https://www.linkedin.com/feed/update/urn:li:activity:7145650591531241472?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7145650591531241472%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQEE8L6-z7HMNA/articleshare-shrink_800/0/1704608683902?e=1705658400&v=beta&t=mzxZ9NPKj1sj55v-bxpde7A8f0eAhDUmgOrt_NdzeCQ
43,65a104d6a5b8f0720000217c,da8c8d26-6717-daff-53d9-e997678029ae,https://media.licdn.com/dms/image/C4D03AQGDFbjO_tCOrQ/profile-displayphoto-shrink_100_100/0/1658153978072?e=1710374400&v=beta&t=dd54ciDwzafSJyr-YnKXLsXrZzNxWvC0AD_ZvBb4F0A,Dr.Prof.Dimitry Mihaylov,https://www.linkedin.com/in/ACoAACg2fFMBPgRyEFLNA4iuTOeKjA-5upIqe5Q?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACg2fFMBPgRyEFLNA4iuTOeKjA-5upIqe5Q,"
AI scientists | Executive | Deeptech entrepreneur
","
The fusion of physical principles with ML capabilities is truly remarkablePhysics-informed neural networks (PINN) represent an innovative deep learning approach that serves to connect machine learning with scientific computing. By integrating physical laws, PINN excels at managing intricate systems, utilizing these laws to produce precise predictions, and effectively completing missing data sets, even when working with limited information. PINN's exceptional ability to approximate and generalize has propelled its widespread adoption for solving high-dimensional partial differential equations. Moreover, its application spans a wide range of fields, including weather modeling, healthcare, and manufacturing.Credits: Alex Wang, Ben Moseley

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7143895609001893890?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7143895609001893890%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D05AQEb2jA-Al0qDw/videocover-low/0/1703237441502?e=1705658400&v=beta&t=EP8iuDOkt_4HCAa2nh9liWaalkRo1CrJVVS5IzaaY50
44,65a104d6a5b8f0720000217d,9678c0b6-6a0a-6c13-b117-ef19c7a1c7bd,,William Falcon,https://www.linkedin.com/in/ACoAAA0NGL8BEFcrXjADw5LpXjHUl43GjsfaXsY?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA0NGL8BEFcrXjADw5LpXjHUl43GjsfaXsY,"
PyTorch Lightning ‚ö°Ô∏ècreator. CEO Lightning AI. AI researcher.
","
Our gift to the AI world. Enjoy!https://lightning.ai/

          ‚Ä¶see more
        


Lightning AI debuts 'iPhone approach' to new AI dev platform
",,https://www.linkedin.com/feed/update/urn:li:activity:7140771653424144384?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7140771653424144384%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQHSPmd0SNnhLw/articleshare-shrink_800/0/1704006325816?e=1705658400&v=beta&t=7yHWdxiiqtmR1WaLM47KcdB_v6QNeWXXMXAQzaPKlPo
45,65a104d6a5b8f0720000217e,51cca8b1-cf0d-d552-da44-f570393e514b,https://media.licdn.com/dms/image/C5603AQGL-jtAfNfY5Q/profile-displayphoto-shrink_100_100/0/1517359397526?e=1710374400&v=beta&t=WWcd_C4Np63Xlcd_FwhBZtqpXYj0p9p5vcVCS7VcTUo,"Mike Tamir, PhD",https://www.linkedin.com/in/ACoAAA4nX3ABkkBcWs4lpNTpQrM0ucxXVDOJgOs?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA4nX3ABkkBcWs4lpNTpQrM0ucxXVDOJgOs,"
Distinguished ML Scientist @Shopify, Data Science Faculty at UC Berkeley
","
GitHub - hiyouga/LLaMA-Factory: Easy-to-use LLM fine-tuning framework (LLaMA, BLOOM, Mistral, Baichuan, Qwen, ChatGLM)
 

GitHub - hiyouga/LLaMA-Factory: Easy-to-use LLM fine-tuning framework (LLaMA, BLOOM, Mistral, Baichuan, Qwen, ChatGLM)
",,https://www.linkedin.com/feed/update/urn:li:activity:7145141511578398720?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7145141511578398720%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5610AQGCNDflJExa3w/image-shrink_800/0/1703534461576?e=1705658400&v=beta&t=5xWE2nEb4vYLrFqGN_3QNP7JB-PqZPFD4T_HE9DudD8
46,65a104d6a5b8f0720000217f,b6ca151f-a8fa-c913-4d43-6a95950669b1,https://media.licdn.com/dms/image/C5603AQEGK_kIML5FYw/profile-displayphoto-shrink_100_100/0/1595864198140?e=1710374400&v=beta&t=6CC4QiBsF-0SuD53fsfS3gV_mVcn3rXMzcrbPHGnAqE,Prakhar Mishra,https://www.linkedin.com/in/ACoAAA7J_U4BNtFcrfzwXdbfaajkC_m2PB-8EsU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA7J_U4BNtFcrfzwXdbfaajkC_m2PB-8EsU,"
AI/ML Engineer @ UnitedHealth Group | MS in Data Science
","
ùë™ùíâùíêùíêùíîùíäùíèùíà ùíïùíâùíÜ ùíìùíäùíàùíâùíï prompt ùíéùíÇùíèùíñùíÇùíçùíçùíö ùíÑùíÇùíè ùíÉùíÜ ùíâùíÇùíìùíÖ & ùíïùíäùíéùíÜ ùíÑùíêùíèùíîùíñùíéùíäùíèùíà. ùëæùíâùíÇùíï ùíäùíá ùë≥ùë≥ùë¥ùíî ùíÑùíÇùíè rephrase it ùíáùíêùíì ùíïùíâùíÜùíéùíîùíÜùíçùíóùíÜùíî? ü§© üòáThis video discusses simple yet effective prompting method for improving performance of LLMs. üí´ This work from UCLA presents a method named `Rephrase and Respond' (RaR), which allows LLMs to rephrase and expand questions posed by humans and provide responses in a single prompt showcasing significant improvements over typical prompting over multiple models.üé• Video link in the description ‚¨áÔ∏è #naturallanguageprocessing #machinelearning #promptengineering #llms #chatgpt #ai #datascience #deeplearning #technology

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7144590666285596672?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7144590666285596672%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHG91t8wSgvOQ/feedshare-shrink_480/0/1703403153497?e=1707955200&v=beta&t=hD0Kggs1yQmTH03Hq1FgEgIgaoO2uNgJXPGatYe4DQo
47,65a104d6a5b8f07200002180,f34f33d2-2fc0-e9c1-7adc-39f0accea937,https://media.licdn.com/dms/image/C4D03AQHEVBtJQZ-fSA/profile-displayphoto-shrink_100_100/0/1640868231748?e=1710374400&v=beta&t=i8q38BfagM82UZVhO_UpB8wHfZQIFGoTzII63qxKtHg,"Guy Revach, Ph.D. Candidate",https://www.linkedin.com/in/ACoAAACxvxcBTZEL9QpKHWdAGh9NhgmofzhvNR0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAACxvxcBTZEL9QpKHWdAGh9NhgmofzhvNR0,"
Model-Based Deep-Learning 4 Statistical Signal-Processing Researcher | Problem Solver | Innovator | Ex System Engineer | Ex Software Manager | Experienced C++ RT Embedded Software Developer
","
Dear friends and colleagues,I am excited to share that our journal paper, _""Latent-KalmanNet: Learned Kalman Filtering for Tracking from High-Dimensional Signals,""_ led by Master's student Itay Buchnik (BGU) and co-authored with Damiano Steger (ETHZ), Ruud van Sloun (TUe), Tirza Routtenberg (BGU), and Nir Shelzinger (BGU), has been accepted for publication in the IEEE Transactions on Signal Processing (TSP). It is now available online at [IEEE Xplore](https://lnkd.in/eN63gmkF).This paper is an extended and detailed version of our work previously published at ICASSP 2023, ""Learned Kalman Filtering in Latent Space with High-Dimensional Data"" (https://lnkd.in/ewJP3ejP).Here, we consider our previously TSP-published KalmanNet architecture (https://lnkd.in/enVZNYsm) in particularly relevant and highly practical use cases of tracking dynamical systems from high-dimensional and non-linear measurements, such as video frames or measurements of a radiating source from an antenna array.We propose adding an encoder before the filter to estimate the underlying latent state (or part of it) based on current or batch observations. The encoder's output then becomes an input to the KalmanNet-based filter. A key feature of this architecture is the feedback loop between the encoder and the filter. The filter's prior estimate enhances the encoder's performance, facilitating more focused estimation processes. Although this paper considers only the first statistical moment of the prior, future work will explore higher statistical moments that characterize the uncertainties of the prior.While the encoder, considered in this paper for visual data, is neural network-based, in practice it is not limited to neural architectures and can be any algorithm effectively extracting information from measurements (such as Grid-Search, Evolutionary Serch, Optimization-based and more). For instance, in follow-up work, we explore tracking a radiating source using an antenna array. Here, we employ an off-the-shelf DoA estimation algorithm (such as MUSIC) as the encoder and also our recently proposed DoA estimation based on the NUV and Sparse Bayesian Learning (https://lnkd.in/eiaaEKmF).The idea of combining an encoder with a filter in a feedback loop can also work well in some situations with the MB Kalman Filter. However, the main difficulty would be characterizing the error distribution of the encoder as a noise parameter for the KF. By using KalmanNet, and learning the Kalman Gain directly, we can bypass this issue.We believe this architecture will lead to more stable filtering, as the compactness of observed and latent spaces results in a more compact Kalman Gain and more stable filtering.As the holiday season approaches, I wish everybody joy and collaboration. May the new year bring us more opportunities to innovate and succeed together.Happy Holidays and Merry Christmas!#signalprocessing #deeplearning #ethzurich ShlezingerLab

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7144372514876506112?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7144372514876506112%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQFEGMapyHEkBw/feedshare-shrink_480/0/1703351141771?e=1707955200&v=beta&t=mxq0KNbp-fnW1zYLGQ7kzf_fyi7TrFMLFXdIrVsWuUA
48,65a104f1a5b8f07200002181,140262c0-d558-1e93-e9c3-112d46f77724,https://media.licdn.com/dms/image/C5603AQFvncvflX_kMQ/profile-displayphoto-shrink_100_100/0/1564316873635?e=1710374400&v=beta&t=DRxjFCzRMNJSc3QM233eAmSZ8rflNQHLrn8k0KQuOhg,Elvis S.,https://www.linkedin.com/in/ACoAACxhXeUBTYZYCwIa4nsvSBsETtrS0uhGNPc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACxhXeUBTYZYCwIa4nsvSBsETtrS0uhGNPc,"
Co-Founder at DAIR.AI | Prev: Meta AI, Galactica LLM, PapersWithCode, Elastic
","
Multimodal Agents as Smartphone UsersIntroduces an LLM-based multimodal agent framework to operate smartphone applications.Learns to navigate new apps through autonomous exploration or observing human demonstrations.Shows proficiency in handling diverse tasks across different applications like email, social media, shopping, editing tools, and more.So far, I have not used any type LLM-powered agent to automate any of my day-to-day tasks but I am experimenting with things like automated research assistants and personalized tutoring systems.Not sure if I would trust this yet but the papers provide a case study with interesting insights into security and adaptability.(paper link in the comments)

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7144032088567005184?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7144032088567005184%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQHXVNWnw3ukmA/feedshare-shrink_480/0/1703269978214?e=1707955200&v=beta&t=fACDYroLIMlLz3iQKJnod_EmL_09GXw-p-HEK294hvk
49,65a104f1a5b8f07200002182,8f677493-10f1-98b5-743a-1eae991303bb,https://media.licdn.com/dms/image/D5603AQGINuJyQHQibw/profile-displayphoto-shrink_100_100/0/1683820114150?e=1710374400&v=beta&t=eUo3EzawkS_c3qiRtIi0YPnO9UL1ZSzb-cU3TDfgbe0,Xhoni Shollaj,https://www.linkedin.com/in/ACoAABQEX3YBBIPqac0TyAqjarEo1ggk1IvYZBg?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABQEX3YBBIPqac0TyAqjarEo1ggk1IvYZBg,"
AI Researcher @ National University of Singapore
","
For anyone interested in LLM Interpretability, I have created the following repository:https://lnkd.in/gk5RvpCwIt contains a curated set of open source tools, papers, articles, groups, etc.Feel free to check it out & hopefully it helps with your research.#explainableai  #interpretability 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7144216357599887361?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7144216357599887361%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQFiwqeQ0BexaA/feedshare-shrink_480/0/1703313911347?e=1707955200&v=beta&t=3EFRihzCf3anN3Ul7Mr8yY2sRqYLVapnVIY1pC1wHc0
50,65a104f1a5b8f0720000219a,07b8bcaa-0c19-4e16-39bc-7e8a7d0f14ba,https://media.licdn.com/dms/image/C4E03AQGCmz60TR4U_A/profile-displayphoto-shrink_100_100/0/1548387165698?e=1710374400&v=beta&t=HBx2vUOpilvOTIG2cAztZlGw5XYBFYfm_Zv7qdfxDBY,Russell Jurney,https://www.linkedin.com/in/ACoAAABfD7wB1ProJaev__Cskc2izd0_t4nIhDI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAABfD7wB1ProJaev__Cskc2izd0_t4nIhDI,"
Graph AI meets LLMs
","
New paper[!]: Large Language Models on Graphs: A Comprehensive SurveyThis is a huge review of LLM and LLM/GNN graph learning methods that highlights how fast the field of LLMs to perform graph machine learning tasks is growing and developing. Methods include LLMs alone and hybrid LLM/GNN strategies.* ArXiv Paper: https://lnkd.in/gUqHK_88* Github Code: https://lnkd.in/gC34bZ3H

          ‚Ä¶see more
        


GitHub - PeterGriffinJin/Awesome-Language-Model-on-Graphs: A curated list of papers and resources based on ""Large Language Models on Graphs: A Comprehensive Survey"".
",,https://www.linkedin.com/feed/update/urn:li:activity:7138219984295526400?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7138219984295526400%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQH45ZkV8dHA4Q/articleshare-shrink_800/0/1704304180405?e=1705658400&v=beta&t=KJlbepvWfsbMJsGtG_6CEWgZmKDJwT0Ieen1XE1UXRU
51,65a104f1a5b8f07200002184,0230732d-c312-9b19-0800-dff1d2fcfed4,https://media.licdn.com/dms/image/C5603AQFvncvflX_kMQ/profile-displayphoto-shrink_100_100/0/1564316873635?e=1710374400&v=beta&t=DRxjFCzRMNJSc3QM233eAmSZ8rflNQHLrn8k0KQuOhg,Elvis S.,https://www.linkedin.com/in/ACoAACxhXeUBTYZYCwIa4nsvSBsETtrS0uhGNPc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACxhXeUBTYZYCwIa4nsvSBsETtrS0uhGNPc,"
Co-Founder at DAIR.AI | Prev: Meta AI, Galactica LLM, PapersWithCode, Elastic
","
Cool survey of ways to make LLMs go brrrr, from better hardware utilization to clever decoding tricks.https://lnkd.in/eRRQ_WDs

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7143996840818929665?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7143996840818929665%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQFeA0kRYze-5Q/feedshare-shrink_480/0/1703261575246?e=1707955200&v=beta&t=_0ku6W-qsrzhN14HaDfawS9DgOFRqIbRpcIXL8ltZT0
52,65a104f1a5b8f07200002185,13ec0088-c022-fe4c-13dc-cae5751c0367,https://media.licdn.com/dms/image/C4D03AQHXDB3ctl1lyg/profile-displayphoto-shrink_100_100/0/1608478225318?e=1710374400&v=beta&t=2ZzuxAfv-7ph_OFqiiK8atxZ1Lyp3dMczUglen0sEL4,Arsenii Gorin,https://www.linkedin.com/in/ACoAAAnq5ekB3LA1EetfrHl7oRdfYEWAhcJRwys?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAnq5ekB3LA1EetfrHl7oRdfYEWAhcJRwys,"
ML Researcher: Audio and Speech | Ubenwa Health
","

 ",,https://www.linkedin.com/feed/update/urn:li:activity:7143963388925153280?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7143963388925153280%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQFug9BEcKfqrg/feedshare-shrink_480/0/1703184641787?e=1707955200&v=beta&t=0N-61LV1yHf-WBGVfBapvM0ZUUbUheBBeuLYYGi6oF8
53,65a104f1a5b8f07200002186,325734c4-5d63-f699-dcaf-8d529fc315d1,https://media.licdn.com/dms/image/D5603AQG9NK0CAgKtVg/profile-displayphoto-shrink_100_100/0/1687301791875?e=1710374400&v=beta&t=Bolt2zUMX7vi6uTl04U5LmzIk8J4LR-CV26o0v_KAIU,Lior S.,https://www.linkedin.com/in/ACoAADMTPYsBtfLtDZlCPxc0G4n0-rFYtqhC0yE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADMTPYsBtfLtDZlCPxc0G4n0-rFYtqhC0yE,"
I cover the latest breakthroughs in AI ‚Üí Ex-ML Engineer/Researcher ‚Üí Built the most read technical newsletter in AI
","
PowerInfer is a must. It can massively speed up your LLM inference on consumer GPUs and almost reach A100 levels.It outperforms llama.cpp by up to 11.69x while retaining model accuracy.PowerInfer reached an average token generation rate of 13.20 tokens/s, with a peak of 29.08 tokens/s, across various LLMs (including OPT-175B) on a single NVIDIA RTX 4090 GPU, only 18% lower than that achieved by a top-tier server-grade A100 GPU.You can use these models with PowerInfer today:- Falcon-40B- Llama2 family‚ÜìAre you technical? Check out https://AlphaSignal.ai to get a weekly summary of the latest models, repos and papers in AI. Read by 150,000+ engineers and researchers.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7143268004011663360?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7143268004011663360%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5605AQF8RtrP3AsxTA/videocover-low/0/1703087801620?e=1705658400&v=beta&t=TK-M2n_S94RTbi61YI23x9FELvyavW8DQMdT5gnkCzs
54,65a104f1a5b8f07200002187,f4b775d6-dd11-fcc2-b2d4-db56bd84d2b2,https://media.licdn.com/dms/image/C4D03AQFcFViXg1T69g/profile-displayphoto-shrink_100_100/0/1516303645074?e=1710374400&v=beta&t=B8NcAcO7HYN5DPDIEZpJtUtwghc43sWTR9AiLdRXUaU,"Bojan Tunguz, Ph.D.",https://www.linkedin.com/in/ACoAAACtHQMBTsH6C8rrVqP5YOv1H9T55PU6NPA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAACtHQMBTsH6C8rrVqP5YOv1H9T55PU6NPA,"
Machine Learning at NVIDIA | Physicist | Quadruple Kaggle Grandmaster
","
The rise of LLMs has been the main push for the adoption of vector databases. Turning text (or even multimodal) data into an embedding vector can significantly improve performance of any AI application. However, it is quite possible that we can get even better performance if we first build that basis workhorse of the Internet era - a search engine. Read more in the following blog post:‚ÄúBuild a search engine, not a vector DB‚Äùhttps://lnkd.in/eAiAEg3t

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7143263594682470400?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7143263594682470400%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQFALJoOpC6oUg/feedshare-shrink_480/0/1703086755147?e=1707955200&v=beta&t=GiiL75lN3iei1PTxAACVXhwmyR2jE4IvLtbyn1QJJYQ
55,65a104f1a5b8f07200002188,b478f3a5-9ba8-0e89-ca4b-daf4e989c8a6,https://media.licdn.com/dms/image/D4D03AQH3wS5hKI9QnA/profile-displayphoto-shrink_100_100/0/1702053485701?e=1710374400&v=beta&t=4gp0MIgKpNHQFQaGkG2vvAzInm137YMZ53bICM4MuI8,"Cristiano De Nobili, PhD",https://www.linkedin.com/in/ACoAAAk8qBMBwBsXlR3VzMPVrsej3xYsJdLSZ9U?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAk8qBMBwBsXlR3VzMPVrsej3xYsJdLSZ9U,"
Physicist ‚à£‚Üë‚Üì‚ü© | Lead AI Scientist | Lecturer & Speaker
","
Over the past six months, I have been working on several ùêãùêãùêå ùê©ùê´ùê®ùê£ùêûùêúùê≠ùê¨, spanning the Space, Education and Healthcare sectors. With my teams at Pi School, we tested all the ùêÜùêèùêì-ùüí and different open-source models, such as ùêãùê•ùêöùê¶ùêö ùüê and ùêåùê¢ùê¨ùê≠ùê´ùêöùê•ùêãùê¢ùê≠ùêû. While learning about the behaviour of these different #LLMs, their prompting techniques and many new methods such as RAG, I read many resources. Among them, I found the ùêüùê®ùê•ùê•ùê®ùê∞ùê¢ùêßùê† ùê©ùêöùê©ùêûùê´ùê¨ quite useful and rich in detail.üîπ The first is 'ùêäùüê: ùêãùêãùêåùê¨ ùêüùê®ùê´ ùêÜùêûùê®ùê¨ùêúùê¢ùêûùêßùêúùêû', in which an LLama-7B model is fine-tuned on specific texts for the Geosciences. How many tokens are needed to fine-tune a pre-trained LLM on a specific domain? The full answer can be found in this article (spoiler 5.5B). Furthermore, the authors share a protocol that can efficiently collect domain-specific data and construct domain-supervised data, even in situations where manpower is scarce.üîπ The second is 'ùêåùêûùêùùê¢ùêìùê´ùê®ùêß: ùêåùêûùêùùê¢ùêúùêöùê• ùêãùêãùêå', where an LLama-70B was adapted on 47B tokens in a cluster of 16 nodes, each with eight 80GB Nvidia A100 GPUs. It is also interesting to study the evaluation pipeline, which involved ùê©ùê´ùê®ùê¶ùê©ùê≠ùê¢ùêßùê† ùê≠ùêûùêúùê°ùêßùê¢ùê™ùêÆùêûùê¨ such as Chain-of-thought (CoT) and Self-Consistency CoT to improve performance by up to 3%.ùêìùêã;ùêÉùêë: in short, if you want to understand in depth how to create domain-specific LLMs, studying these papers in detail can help you a lot.üîó You can find them in the comments! üëá #machinelearning #deeplearning #generativeai 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7143147650249396225?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7143147650249396225%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQEK9ihNKdlWtg/feedshare-shrink_480/0/1703022551132?e=1707955200&v=beta&t=OFKhWg-57Fp0xwz85FWym-3Hi2V55GYnrpks5pRkT2s
56,65a104f1a5b8f07200002189,4e791875-acb7-2960-f383-811815f3c283,https://media.licdn.com/dms/image/C4D03AQFcFViXg1T69g/profile-displayphoto-shrink_100_100/0/1516303645074?e=1710374400&v=beta&t=B8NcAcO7HYN5DPDIEZpJtUtwghc43sWTR9AiLdRXUaU,"Bojan Tunguz, Ph.D.",https://www.linkedin.com/in/ACoAAACtHQMBTsH6C8rrVqP5YOv1H9T55PU6NPA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAACtHQMBTsH6C8rrVqP5YOv1H9T55PU6NPA,"
Machine Learning at NVIDIA | Physicist | Quadruple Kaggle Grandmaster
","
Training large language models is a very technically demanding and resource intensive task. Many such models also require lots of specialized compute to use. Fortunately, we have recently been blessed by public releases of several ""small"" LLMs that can in principle be used for many of important tasks for which their much heftier big cousins had originally been utilized. However, unless you are an ML specialist even those models have been somewhat tricky to fine tune and customize. Nonetheless, with just a bit of tinkering, even those models can be easily tamed by most practicing Data Scientists. In his latest post Luca Massaron shows how to do such fine tuning using nothing more than Kaggle environment. Read more about it in the link below:""Fine-tuning a large language model on Kaggle Notebooks for solving real-world tasks ‚Äî part 3""https://lnkd.in/emmrwcBb#AI #ArtificialIntelligence #GenerativeAI #GenAI #largelanguagemodels #llm #llms

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7142872336629657600?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7142872336629657600%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQENDj_fRZ2crg/feedshare-shrink_480/0/1702993471661?e=1707955200&v=beta&t=Oj7-aTc2umjSKx0sVtUGoSTapUwEfOlH4vZgq4H-8Cw
57,65a104f1a5b8f0720000218a,23de3ff0-c253-b1af-f9ae-dfadd0776de6,https://media.licdn.com/dms/image/D5603AQGEADhHyEQ8rw/profile-displayphoto-shrink_100_100/0/1682553354695?e=1710374400&v=beta&t=kfjA-KO1Ea4gqAJ68vTh1_4ORnZzWv1qSW4bXFvg_tc,"Damien Benveniste, PhD",https://www.linkedin.com/in/ACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw,"
The ML Guy - Follow me to learn about Machine Learning Engineering, Machine Learning System Design, MLOps, and the latest techniques and news about the field. Join my AI newsletter and keep learning!
","
The TikTok recommender system is widely regarded as one of the best in the world at the scale it operates at. It can recommend videos or ads, and even the other big tech companies could not compete. Recommending on a platform like TikTok is tough because the training data is non-stationary as a user's interest can change in a matter of minutes and the number of users, videos, and ads keeps changing.The predictive performance of a recommender system on a social media platform deteriorates in a matter of hours, so it needs to be updated as often as possible. TikTok built a streaming engine to ensure the model is continuously trained in an online manner. The model server generates features for the model to recommend videos, and in return, the user interacts with the recommended items. This feedback loop leads to new training samples that are immediately sent to the training server. The training server holds a copy of the model, and the model parameters are updated in the parameter server. Every minute, the parameter server synchronizes itself with the production model.The recommendation model is several terabytes in size, so it is very slow to synchronize such a big model across the network. That is why the model is only partially updated. The leading cause of non-stationary (concept drift) comes from the sparse variables (users, videos, ads, etc.) that are represented by embedding tables. When a user interacts with a recommended item, only the vectors associated with the user and the item get updated, as well as some of the weights on the network. Therefore, only the updated vectors get synchronized on a minute basis, and the network weights are synchronized on a longer time frame. Typical recommender systems use fixed embedding tables, and the categories of the sparse variables get assigned to a vector through a hash function. Typically, the hash size is smaller than the number of categories, and multiple categories get assigned to the same vector. For example, multiple users share the same vector. This allows us to deal with the cold start problem for new users, and it puts a constraint on the maximum memory that the whole table will use. But this also tends to reduce the performance of the model because user behaviors get conflated. Instead, TikTok uses dynamic embedding sizes such that new users can be added to their own vector. They use a collisionless hashing function so each user gets its own vector. Low-activity users will not influence the model performance that much, so they dynamically remove those low-occurrence IDs as well as stale IDs. This keeps the embedding table small while preserving the quality of the model.Here is the TikTok paper: https://lnkd.in/g9fA62GD!#machinelearning #datascience #artificialintelligence--üëâ Learn more Machine Learning on my website: https://www.TheAiEdge.io--

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7142556155993542656?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7142556155993542656%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHBMUfaXxNKAA/feedshare-shrink_480/0/1702918087948?e=1707955200&v=beta&t=fIQnA2JpQIu3oguzPHvKnPfIBD0OsqSAn9NGm8Qf-28
58,65a104f1a5b8f0720000218b,bb93e873-3ced-9acd-bb9f-e59f753f6a84,https://media.licdn.com/dms/image/C4E03AQHrp_ClCxhLsQ/profile-displayphoto-shrink_100_100/0/1516194433484?e=1710374400&v=beta&t=omZM8DZSBKw3TPRZKpxfnJn92MMTD4KzmtJCxmeBOM4,Luca Massaron,https://www.linkedin.com/in/ACoAAAAEtOUBU5I8g_rjU2rIIdCAr8OAs6W4N2w?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAAEtOUBU5I8g_rjU2rIIdCAr8OAs6W4N2w,"
Data Science & Modelling Senior Expert at illimity Bank | MBA | Book Author @ Wiley, Packt, Manning | Kaggle Grandmaster
","
After fine-tuning LLama 7B on a dataset for financial sentiment analysis on consumer-grade, easily accessible, and free GPUs (https://lnkd.in/d_Wr-efW) you can re-use the very same code to fine-tune also most recently appeared large language models such as :* Mistral‚Äôs Mistral 7B Instruct v0.2 : https://lnkd.in/dfsNnQQP* Microsoft‚Äôs Phi-2 : https://lnkd.in/dWe7ZvuFIn this article, I will present the exciting characteristics of these new large language models and how to modify the starting LLama fine-tuning to adapt to each of them.https://lnkd.in/dE43BVng

          ‚Ä¶see more
        


Fine-tuning a large language model on Kaggle Notebooks for solving real-world tasks‚Ää‚Äî‚Ääpart 3
",,https://www.linkedin.com/feed/update/urn:li:activity:7142523932082970624?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7142523932082970624%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQG_AssENbbNIw/articleshare-shrink_800/0/1704152611925?e=1705658400&v=beta&t=PC2DgirMcDAJcCn0SoUadysdXVRQj45xY8Pmkvu9lVE
59,65a1050da5b8f072000021d7,0e33aa68-94ed-db03-1f4c-a16d2e88b971,https://media.licdn.com/dms/image/C4E03AQG5i8y-Wq7cyQ/profile-displayphoto-shrink_100_100/0/1606138444798?e=1710374400&v=beta&t=lOyh0Bxp_yCMHd4M7jI7Iy4o_WCttzHu2lrFWi1PayU,Denys Linkov,https://www.linkedin.com/in/ACoAABB2hFkBunHn_Z76otBLWoOQOvWU3pGhFkM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABB2hFkBunHn_Z76otBLWoOQOvWU3pGhFkM,"
Head of ML @ Voiceflow | FEO Board Member
","
How does a computer science concept invented in 1962 improve LLMs?Paged Attention, an important implementation from this summer improves LLM throughput immensely by 1.7-4x by improving memory management for attention.It borrows many important concepts from operating systems including:- Pages (virtual and logical)- Page tables- ""Forking"" requests These concepts have been implemented in operating systems we use day to day for many years, but are just now making their way into the ML world.A great example on how technical breadth, creativity and multidisciplinary knowledge can improve the state of the art in a field. Below is a video by the authors of vLLM that covers the main ideas of how the

          ‚Ä¶see more
        


Fast LLM Serving with vLLM and PagedAttention
",,https://www.linkedin.com/feed/update/urn:li:activity:7118976086452957184?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7118976086452957184%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQFclzV3-eQ65A/articleshare-shrink_800/0/1704645848851?e=1705658400&v=beta&t=J64TuuH7-23va8gqzbsqfzlfUw9OkYQPxxMqfHAbJuo
60,65a104f1a5b8f0720000218d,eb307646-af3a-ac71-d299-63c5df44b2a8,https://media.licdn.com/dms/image/C4D0BAQG1yEbzvWYiXw/company-logo_100_100/0/1642603423308/towards_data_science_logo?e=1713398400&v=beta&t=y8CIwK9dQB-BTSDO6I7B3oL7VUGVvPS986H7M3mioNE,Towards Data Science,https://www.linkedin.com/company/towards-data-science/,"
601K followers
","
""One of the main advantages of low-rank adaptors is their efficiency. By utilizing fewer parameters, LoRAs significantly lower computational complexity and memory usage.""In a new guide, Martin Dittgen shows how to implement LoRA ‚Äî from scratch.

          ‚Ä¶see more
        


Implementing LoRA from Scratch
",,https://www.linkedin.com/feed/update/urn:li:activity:7142167674427482112?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7142167674427482112%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5610AQFtgqCfQV6A6Q/image-shrink_800/0/1702825443887?e=1705658400&v=beta&t=OemW7EGYjuqCHja6RXn8y37IaJ6ftnvZSLO45U42QnM
61,65a104f1a5b8f0720000218e,576c4818-0bac-dd5b-958d-781a46263a11,https://media.licdn.com/dms/image/D4E03AQFXoR8Xgye8Vw/profile-displayphoto-shrink_100_100/0/1680859507281?e=1710374400&v=beta&t=jLguKrRofJ6IswdFpriAPlNTnCz6meovl2QS-rg00l4,Maria Vechtomova,https://www.linkedin.com/in/ACoAAA52t5EBCgJM7kgrMphKQD3ijSGTLl2xHzU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA52t5EBCgJM7kgrMphKQD3ijSGTLl2xHzU,"
MLOps Tech Lead | Join 22k followers to learn about MLOps | Marvelous MLOps | Public speaker
","
There are so many resources on #MLOps and #LLM Ops. It is so easy to get lost in them! I hope this helps.üìï MLOps books:‚û° Machine Learning Engineering with Python - Second Edition by Andy McMahon published by Packt‚û° Reliable Machine Learning: Applying SRE Principles to ML in Production by Cathy Chen, MA, CPCC, Niall Murphy, Kranti K. Parisa, D. Sculley, Todd Underwoodüì∞ MLOps and LLM(Ops) blogs:‚û° Chip Huyen: https://lnkd.in/gVB22DuE‚û° Eugene Yan: https://lnkd.in/gPwN8mSm‚û° Decoding ML by Paul Iusztin: https://lnkd.in/gQehWnHr‚û° LLM watch by Pascal Biese: https://lnkd.in/gJhZH4mbüìΩ LLM(Ops) courses:‚û° Hands-on LLMs by Pau Labarta Bajo, Alexandru RƒÉzvan»õ, and Paul Iusztin: https://lnkd.in/ggpxRsc7‚û° LLM BootCamp by Sergey Karayev, Charles Frye, and Josh Tobin: https://lnkd.in/gKMZGYSQ ‚û° Introduction to Q&A Systems with LLMs by Rahul Parundekar and MLOps Community: https://lnkd.in/gMYaFcTgüîñ Curated lists of references for MLOps/LLM(Ops):‚û° Awesome LLMOps by Ce Gao: https://lnkd.in/gFrri858‚û° Awesome MLOps by Dr. Larysa Visengeriyeva: https://lnkd.in/eMttRFhA‚û° LLM roadmaps by Maxime Labonne: https://lnkd.in/dgpe7p4Hüí°Together with Ba≈üak and Rapha√´l, we run Marvelous MLOps, where we share MLOps cheatsheets, memes, and articles on MLOps.üí°Check out my other recommendations on learning resources:‚û° Part 1: https://lnkd.in/gb36cyGG‚û° Part 2: https://lnkd.in/gYiXFDdD#machinelearning #datascience

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7142045758307901440?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7142045758307901440%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQE37D5U6Bmk0Q/feedshare-shrink_480/0/1702768789038?e=1707955200&v=beta&t=1SnzekqD6K3x5eDO0M064mVzeXF1ZSfekRlzC9-qomc
62,65a104f1a5b8f0720000218f,eac92d6a-ae5e-a15a-2777-66a42d36c190,https://media.licdn.com/dms/image/D4D03AQG-8DpsMNKl1A/profile-displayphoto-shrink_100_100/0/1675096656485?e=1710374400&v=beta&t=F7xyPR0IF8JasP5eQMfyX42XY9d5M0eSNvynB7QT5wQ,Bruno Scalia Carneiro Ferreira Leite,https://www.linkedin.com/in/ACoAACYU6hMB_opM5L1iO9YKm-IVw0wPxmw3igE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACYU6hMB_opM5L1iO9YKm-IVw0wPxmw3igE,"
Data Scientist | M.Sc. in Chemical Engineering | Optimization Specialist
","
üíª pip install tspgraspüåê The Traveling Salesman Problem (TSP) is arguably the most studied combinatorial optimization problem. It holds significant importance in real-world scenarios, particularly in logistics and delivery services, and serves as a foundational concept for various other routing challenges.Finding the exact solution to large instances can be impractical due to the combinatorial complexity of the problem, and #heuristics might be an interesting alternative. So, combining constructive heuristics with local search, tspgrasp can be your #Python alternative to come up with fast and good quality solutions.üöÄ Behind the simple coding lines (from a user perspective), the main engine written in Cython can perform operations nearly 50 times faster than native Python for ~1000 city instances exploring 7 neighborhoods in its default local search. So suppose you have a 2-dimensional distance matrix ""D"". You can simply run:from tspgrasp import Graspgrasp = Grasp()  # you can specify more solver parameters heregrasp(D, time_limit=...)  # you can specify more termination criteria hereI'd love to hear some feedback in the comment section! Feel free to also reach out to me on DM ;)PS: If you are also interested in real-world applications, take a look at my previous Towards Data Science on a streamlit routing application: https://lnkd.in/dYbsMvCk#operationsresearch #optimization #tsphttps://lnkd.in/d6W7HmRE

          ‚Ä¶see more
        


GitHub - bruscalia/tsp-grasp: A Greedy Randomized Adaptive Search Procedure (GRASP) for the Traveling Salesman Problem (TSP)
",,https://www.linkedin.com/feed/update/urn:li:activity:7133103332155437056?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7133103332155437056%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQHTMmJI_ah1Dw/articleshare-shrink_800/0/1705042088028?e=1705658400&v=beta&t=XMoTPLCu2D3uvVHheBhPsJn5I6_kXzwPxOg3138biug
63,65a104f1a5b8f07200002190,dc011aaa-47ff-2046-e6d5-ba49a1763388,https://media.licdn.com/dms/image/C4E0BAQEH4nbL2sl5gA/company-logo_100_100/0/1635539130887/facebookai_logo?e=1713398400&v=beta&t=sFixUTJyqFvVkiEiDy7X9VTcRcgGTR2jo-a3QyjRJ70,AI at Meta,https://www.linkedin.com/company/aiatmeta/,"
672K followers
","
Together with the Ego4D consortium, today we're releasing Ego-Exo4D, the largest ever public dataset of its kind to support research on video learning & multimodal perception.Download the dataset ‚û°Ô∏è https://bit.ly/3tiS3ObMore details ‚û°Ô∏è https://bit.ly/3RsWkIbThe dataset features over 1,400 hours of videos of skilled human activities collected across 13 cities by 800+ research participants. Using Meta‚Äôs Project Aria, the dataset also includes:‚Ä¢ Time-aligned seven-channel audio‚Ä¢ IMU‚Ä¢ Eye gaze‚Ä¢ Head poses‚Ä¢ 3D point clouds of the environmentThis work was made possible by collaboration between FAIR, Meta‚Äôs Project Aria and 15 university partners.

          ‚Ä¶see more
        


Ego-Exo4D: The largest ever public dataset of its kind to support research on video learning & multimodal perception
",,https://www.linkedin.com/feed/update/urn:li:activity:7141109670819082241?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7141109670819082241%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5605AQGoYXDOy0M6tQ/feedshare-thumbnail_720_1280/0/1702483333688?e=1705658400&v=beta&t=tLTMh0k6rdyMKnbT6wkq8o0huQvFgLwagais2a1y4zg
64,65a104f1a5b8f07200002191,68a0167e-d0a9-35b4-d5f3-a04f82a71904,https://media.licdn.com/dms/image/D5603AQHxUzqt5ibu8Q/profile-displayphoto-shrink_100_100/0/1670820076513?e=1710374400&v=beta&t=jDLfZwZFFu2iGz5MnJjGW-UsIgg6W6Y2_uU05Hzvakw,Michael Galkin,https://www.linkedin.com/in/ACoAABQJ9wsBGHSNQWOUK2OVHWIhE26F7icbcLc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABQJ9wsBGHSNQWOUK2OVHWIhE26F7icbcLc,"
AI Research Scientist at Intel AI Lab | Graph ML & GNNs & Knowledge Graphs & ML
","

 ",,https://www.linkedin.com/feed/update/urn:li:activity:7140736522084831235?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7140736522084831235%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQHSSKXRVPP4WQ/feedshare-shrink_480/0/1702469977853?e=1707955200&v=beta&t=E2KuYu21UQipgHNBDpb9IbrEUxkN6ZZwxFHEHy6Y_4U
65,65a104f1a5b8f07200002192,c6822a2e-b667-5a3a-7d40-1420fa53f86b,https://media.licdn.com/dms/image/D4D03AQHl8bWxWCqAJg/profile-displayphoto-shrink_100_100/0/1688957845463?e=1710374400&v=beta&t=wVVZ18b7i64BqzlEDIBQ-CCzaLQIyaR0O8bSatN4aAA,Yan Barros,https://www.linkedin.com/in/ACoAADUWD-MBwH94iNwhnJVzdTxaWCvPyrOnN_0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADUWD-MBwH94iNwhnJVzdTxaWCvPyrOnN_0,"
üöÄ Data Scientist | Computational Astrophysics | Machine Learning | Physics Informed Neural
","
Hi, Fellows!Physics Informed Neural Networks are one of my favorite Science Computing subjects and Today I've decided to bring you some refferences for studying :)1. Explore the power of PINNs with NVIDIA 's open-source Modulus platform: [NVIDIA Blog](https://lnkd.in/dq4xqt_R)2. Check out an intuitive guide to PINNs on Towards Data Science : [Towards Science](https://lnkd.in/dAZ_pbX8)3. Dive into an important paper by M. Raiss, P. Perdikaris, and G.E. George Karniadakis  on ScienceDirect: [ScienceDirect](https://lnkd.in/d3pMQiwe)4. Build your understanding from the basis with the GitHub Repository: [GitHub Repository](https://lnkd.in/dF5iKmg3)5. Explore solving differential equations with neural networks in this Towards Science article: [Towards Science](https://lnkd.in/dC3EcX32)6. Read another great paper on PINNs by Zhiping Mao, Ameya D. Jagtan, and G. E. Karniadakis: [ScienceDirect](https://lnkd.in/di2tcuva)7. Watch a fantastic video by Ben Moseley: [Ben Moseley Video](https://lnkd.in/dqAg4Sit)8. Don't miss an awesome video from the brilliant Steve Brunton: [Steve Brunton Video](https://lnkd.in/dTpCAZsv)9. Gain insights into PyTorch for beginners with this helpful video: [PyTorch Video](https://lnkd.in/dDc2BTt8)10. Read an amazing article by Ben Moseley about PINNs: [Ben Moseley Article](https://lnkd.in/d5Bd2f_i)11. Explore an interesting resource on physics-based deep learning: [Physics-Based Deep Learning](https://lnkd.in/dBjMv85t)12. Discover my introductory article on PINNs on LinkedIn: [LinkedIn Article](https://lnkd.in/e2EH3JYQ) Feel free to share your sources, experiences and to contact me! #PINNs #NeuralNetworks #PhysicsInformedAI

          ‚Ä¶see more
        


Exploring the Power of Neural Networks: An Introduction to PINNs
",,https://www.linkedin.com/feed/update/urn:li:activity:7140453982287691776?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7140453982287691776%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E12AQF0QgWDYm5PYg/article-cover_image-shrink_600_2000/0/1695175706465?e=1710374400&v=beta&t=nEENxnFDNEWKaoZ70UwnIojRYctwg37TGCCXT7j3THM
66,65a104f1a5b8f07200002193,d25e3baa-e1d6-c2eb-6918-e044089f335d,https://media.licdn.com/dms/image/C560BAQEg7UfAyEoKWg/company-logo_100_100/0/1637414049335/nlplanet_logo?e=1713398400&v=beta&t=_QvY1xSefLEyzgG6cO_2hVnEPcwkGrAcB32ORRVOZbM,NLPlanet | Breaking Down Generative AI Daily,https://www.linkedin.com/company/nlplanet/,"
9K followers
","
Top 10 AI Research Papers of 2023 üìöüëâ Sparks of AGI by MicrosoftThis paper from Microsoft Research analyzes GPT-4, highlighting its advanced intelligence across domains like mathematics, coding, and psychology. It positions GPT-4 as a step toward Artificial General Intelligence (AGI).üëâ PALM-E by GoogleGoogle's PaLM-E bridges the gap between words and percepts, integrating sensor inputs with language models for tasks like robotic manipulation and visual question answering.üëâ LLaMA 2 by Meta AIMeta AI's LLaMA 2, with models ranging from 7 to 70 billion parameters, shows superior performance in dialogue benchmarks and emphasizes responsible large language model development.üëâ LLaVA by University of Wisconsin‚ÄìMadison, Microsoft, and Columbia UniversityLLaVA, a multimodal model, uses GPT-4 for generating instruction-following data, integrating visual and language processing for a general-purpose visual assistant.üëâ Generative Agents by Stanford University and GoogleThis research introduces agents simulating human behavior, extending language models for memory storage, reflection, and behavior planning, with diverse applications.üëâ Segment Anything by Meta AIMeta AI's paper introduces SAM, a model for image segmentation, creating a large dataset and focusing on promptable models for diverse tasks.üëâ DALL-E 3 by OpenAIOpenAI's paper addresses text-to-image model challenges, particularly in prompt following, through a specialized image captioning system for improved training datasets.üëâ ControlNet by Stanford UniversityControlNet, from Stanford, enhances pretrained diffusion models with task-specific conditions, facilitating new ways to control large diffusion models.üëâ Gen-1 by RunwayRunway's Gen-1 presents advancements in text-guided video editing using generative diffusion models, allowing detailed control over video synthesis.üëâ DreamerV3 by DeepMind and University of TorontoDreamerV3, a world model-based algorithm, excels across diverse domains and challenges, notably in the video game Minecraft, showcasing scalable, efficient learning.Source: https://lnkd.in/dthPxGBJ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚ÄîWant to stay at the forefront of Generative AI developments? Follow NLPlanet for daily insights into the most relevant news, guides, and research! üöÄ

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7140384812195909632?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7140384812195909632%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQF1EdtrNcctFA/feedshare-shrink_480/0/1702375758144?e=1707955200&v=beta&t=VwLpfg15fBMBA5jcxJqysVmvQ6ofN3yHw1R6vdw4e58
67,65a104f1a5b8f07200002194,606892f8-e6fe-ed9c-866d-17bd5c9784b0,https://media.licdn.com/dms/image/C5603AQEwQ_qPSfCrKg/profile-displayphoto-shrink_100_100/0/1576363445013?e=1710374400&v=beta&t=vIOY9aWTr7uQUQrBYX96bnYQCIaL4d55RBy-ZeMfSSQ,Brandon Smock,https://www.linkedin.com/in/ACoAABU4TjMB5fIw1qKpIyfePSy5HG29SFYPWdk?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABU4TjMB5fIw1qKpIyfePSy5HG29SFYPWdk,"
Machine Learning Researcher and Applied Scientist
","
Table Transformer models on Hugging Face have been downloaded more than 2 million times in the last month! üöÄNot only does this put them in the top 100 out of more than 420k models, it means right now they are the 2 most popular models in object detection! ü§ØA little over a year ago NeurIPS conference reviewers told us our work on evaluation metrics for table extraction was good but ‚Äútoo niche‚Äù. How did extracting tables from documents go from a niche area to the hottest topic in object detection? üî•Big thank you to Niels Rogge for porting and maintaining the Hugging Face version of Table Transformer.Original project on GitHub: https://lnkd.in/gF5iiM7pRohith Pesala, Robin Abraham

          ‚Ä¶see more
        


GitHub - microsoft/table-transformer: Table Transformer (TATR) is a deep learning model for extracting tables from unstructured documents (PDFs and images). This is also the official repository for the PubTables-1M dataset and GriTS evaluation metric.
",,https://www.linkedin.com/feed/update/urn:li:activity:7138940321568096256?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7138940321568096256%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/C4D27AQGoUzQ59i7LzA/articleshare-shrink_800/0/1704526396902?e=1705658400&v=beta&t=l6sx6qLBRvJhE7NHwStLeV4U2AHaVfSah4GUoFi2FMU
68,65a104f1a5b8f07200002195,2a7754b9-11f1-96b7-59f3-9bfa0e978d91,https://media.licdn.com/dms/image/C4D03AQEmDwFNREkaIA/profile-displayphoto-shrink_100_100/0/1517524291944?e=1710374400&v=beta&t=9H8wRu-S3Mr0BN5zZEZBtWwefLpa0ZU_FPNQ9dTlNws,Robin Gras,https://www.linkedin.com/in/ACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ,"
Professor at University of Windsor, CSO and partner at Movyl Technologies and MVYL Associates
","
Everything of Thoughts: Defying the Law of Penrose Triangle for Thought Generation - Mircosoft 2023Paper: https://lnkd.in/gfhnyHnJAbstract:""Recent advancements in Large Language Models (LLMs) have revolutionized decision-making by breaking down complex problems into more manageable language sequences referred to as ``thoughts''. An effective thought design should consider three key perspectives: performance, efficiency, and flexibility. However, existing thought can at most exhibit two of these attributes. To address these limitations, we introduce a novel thought prompting approach called ``Everything of Thoughts'' (XoT) to defy the law of ``Penrose triangle of existing thought paradigms. XoT leverages pretrained reinforcement learning and Monte Carlo Tree Search (MCTS) to incorporate external domain knowledge into thoughts, thereby enhancing LLMs' capabilities and enabling them to generalize to unseen problems efficiently. Through the utilization of the MCTS-LLM collaborative thought revision framework, this approach autonomously produces high-quality comprehensive cognitive mappings with minimal LLM interactions. Additionally, XoT empowers LLMs to engage in unconstrained thinking, allowing for flexible cognitive mappings for problems with multiple solutions. We evaluate XoT on several challenging multi-solution problem-solving tasks, including Game of 24, 8-Puzzle, and Pocket Cube. Our results demonstrate that XoT significantly outperforms existing approaches. Notably, XoT can yield multiple solutions with just one LLM call, showcasing its remarkable proficiency in addressing complex problems across diverse domains.""

          ‚Ä¶see more
        


Everything of Thoughts: Defying the Law of Penrose Triangle for Thought Generation
",,https://www.linkedin.com/feed/update/urn:li:activity:7139611022838964224?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7139611022838964224%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQGecMB4GNE0ow/articleshare-shrink_800/0/1704737517829?e=1705658400&v=beta&t=ZouaSPvTXLuAuVv3EESPNl0HOw-mMW280xuX9HOpwnw
69,65a104f1a5b8f07200002196,3070472e-fc5f-80fc-5fe0-1dcaa60c199b,https://media.licdn.com/dms/image/D5603AQGlGCPCan7ydg/profile-displayphoto-shrink_100_100/0/1703841913518?e=1710374400&v=beta&t=_yCxro_4jjelGtqcnn97rxhk3dtzP57WA_MRkgtZwl8,Sonu Kumar,https://www.linkedin.com/in/ACoAABMYUFYBDepzrhJHManPormCvL9X24lHWM4?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABMYUFYBDepzrhJHManPormCvL9X24lHWM4,"
Generative AI Evangelist @ Capgemini Innovation Team | AI Researcher | Creator of ""AI Anytime"" YouTube Channel Top Voice LinkedIn
","
üöÄ Exciting news in the Gen AI community!  I'm thrilled to share that AI Bloks / LLMWare has introduced innovative models for Retrieval Augmented Generation (RAG) that are reshaping how we handle complex business documents in enterprise workflows. Their latest creations, ùêÉùêëùêÄùêÜùêéùêç ùêåùê®ùêùùêûùê•ùê¨ (Production-grade RAG-optimized 6-7B parameter models),  ùêÅùêãùêàùêçùêÜ ùêåùê®ùêùùêûùê•ùê¨ (Small CPU-based RAG-optimized, instruct-following 1B-3B parameter models), and ùêàùêßùêùùêÆùê¨ùê≠ùê´ùê≤ ùêÅùêÑùêëùêì ùêåùê®ùêùùêûùê•ùê¨ (For Feature Extraction) are true game-changers! üåêHad a chat with Namee Oberst recently on the developments and their vision on building models which are enterprise grade üëè . As someone deeply invested in the power of AI, I've always believed that domain-specific embedding models like 'industry-bert-insurance-v0.1 (One of the model by LLMWare)' offer superior performance. Why? Because they're trained on industry-specific data, leading to more nuanced and relevant ùíóùíÜùíÑùíïùíêùíì ùíÇùíîùíîùíäùíàùíèùíéùíÜùíèùíïùíî. But it's not just about big models; sometimes, smaller, specialized language models are the real MVPs, especially for RAG. That's where 'bling-sheared-llama-1.3b-0.1' shines. These models are fine-tuned with high-quality data, making them inference-ready even on a simple CPU laptop. This means more efficient processing, less compute power required, and accessibility to a wider audience. üíªWhat's more exciting? All these models are available on Hugging Face, ensuring they're easily accessible to the open-source community. This is a big win for collaboration and innovation! ü§ùTo demonstrate the power of these tools, I've created a tutorial video specifically for the insurance industry. This step-by-step guide showcases how you can leverage these models for insightful data analysis and enhanced customer interactions using a simple Streamlit app. üé•https://lnkd.in/gxdcBDw7Let's embrace this advancement together and strengthen the open-source community. KUDOS to Namee and team for the work they are doing......#llm #llms #rag #generativeai #genai #gemini #linkedin #tech #ai 

          ‚Ä¶see more
        


Unlocking RAG Potential with LLMWare's CPU-Friendly Smaller Models
",,https://www.linkedin.com/feed/update/urn:li:activity:7139626719258312704?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7139626719258312704%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQGsmsLQNcv6vg/articleshare-shrink_800/0/1704640737121?e=1705658400&v=beta&t=4zcq6JxGHxT-iIBHKnyjgH8y2-3dJCkRQlEj6TVprKg
70,65a104f1a5b8f07200002197,ef0bbcd2-2e45-3cf9-7de0-7635e8c164e1,https://media.licdn.com/dms/image/C5603AQHfJaqMrmsj5w/profile-displayphoto-shrink_100_100/0/1590370532020?e=1710374400&v=beta&t=ZDvroThIQAzqVNV-3j-ClJrbEX8qQ3O9rLS4aZXzuTs,Vikas Chandra,https://www.linkedin.com/in/ACoAAAA4W_cBETRw0PJtyRrpWrTj6MfLotIgHF8?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAA4W_cBETRw0PJtyRrpWrTj6MfLotIgHF8,"
Senior Director, AI @ Meta
","
ùêÑùêüùêüùê¢ùêúùê¢ùêûùêßùê≠ùêíùêÄùêåJust a few months ago, Meta released Segment Anything Model (SAM), a model that can ‚Ä¶ well ‚Ä¶ segment anything. It has already been used in photography apps, medical image analysis, and video-generation. However, SAM wasn‚Äôt designed to be deployed in a computationally constrained device, such as a smartphone. So we‚Äôve invented SAM‚Äôs little brother, EfficientSAM. It is small but mighty! With 20x fewer parameters and 20x faster runtime, EfficientSAM is within 2 points (44.4 AP vs 46.5 AP) of the original SAM model. EfficientSAM also produces dramatically better results than MobileSAM, FastSAM, and other efficient models. For those of you who want to know how we did it, we have 2 words for you: Masked Autoencoders. Check out the following for more details!Paper: https://lnkd.in/gEEVRTRjProject details and demo: https://lnkd.in/gW4t3uHyYunyang Xiong, Bala Varadarajan, Lemeng Wu, Xiao-Yu Xiang, Fanyi Xiao, Chenchen Zhu, Xiaoliang Dai, Dilin Wang, Fei Sun, Forrest Iandola, Raghuraman Krishnamoorthi

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7137927166998040576?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7137927166998040576%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQFEKWCeeE-_Bg/feedshare-shrink_480/0/1701814452081?e=1707955200&v=beta&t=XcJAiU1bruCQcATj0cT4cI1kEGcFAxG_1OcJ_kpj8vg
71,65a104d6a5b8f07200002172,84510ebc-4f08-f758-a2c3-1abcd620dc1b,https://media.licdn.com/dms/image/C560BAQGvLn9-Y96Jew/company-logo_100_100/0/1630667257285/neuroscience_news_logo?e=1713398400&v=beta&t=u4aMtYyUL2VQ9dP9cxF6bjBjUdkC-OdKFwuFYgIxasg,Neuroscience News,https://www.linkedin.com/company/neuroscience-news/,"
424K followers
","
Synaptic Transistor Mirrors Human Brain FunctionA synaptic transistor inspired by the human brain can process info efficiently at room temperature, advancing AI with higher-level thinking. Researchers reveal the future of energy-efficient computing.

          ‚Ä¶see more
        


Synaptic Transistor Mirrors Human Brain Function - Neuroscience News
",,https://www.linkedin.com/feed/update/urn:li:activity:7146632767714340864?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7146632767714340864%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQF95MUAAdkkUQ/articleshare-shrink_800/0/1704468392797?e=1705658400&v=beta&t=ggYY5QR1OLmg8de4GB4FocivVHp7BcV0NIqsVl19Ws0
72,65a104f1a5b8f07200002199,6eb02bac-830f-2e53-43a5-3dd6f41eeb65,https://media.licdn.com/dms/image/C4D03AQGsBskbBZ3fQQ/profile-displayphoto-shrink_100_100/0/1614534462823?e=1710374400&v=beta&t=qNMq_bYgWNgoA2VAF7eQmC7A48grXKS--I4WZpVpkU0,Leonie Monigatti,https://www.linkedin.com/in/ACoAABdZ4YQB5f0bhOeOvQJ3YEUtKThe0GEP4tc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABdZ4YQB5f0bhOeOvQJ3YEUtKThe0GEP4tc,"
Developer Advocate @ Weaviate | Kaggle Notebooks Grandmaster
","
Building a prototype of a RAG application is a piece of cake - but making it production-ready is a real challenge.Here are 12 ‚Äúhyperparameters‚Äù and tuning strategies you can experiment with to improve the performance of your RAG application.Ingestion stage:‚Ä¢ Data cleaning‚Ä¢ Chunking (chunk_size and overlap)‚Ä¢ Embedding models‚Ä¢ Metadata‚Ä¢ Multi-indexing‚Ä¢ Indexing algorithmsInferencing stage (retrieval and generation):‚Ä¢ Query transformations (e.g., rephrasing, HyDE, or sub-queries)‚Ä¢ Retrieval parameters (alpha if you have hybrid search enabled)‚Ä¢ Advanced retrieval strategies (e.g., sentence-window or auto-merging retrieval)‚Ä¢ Re-ranking models‚Ä¢ LLMs‚Ä¢ Prompt engineeringRead more on Towards Data Science: https://lnkd.in/eGayVM55Which ones did I miss?

          ‚Ä¶see more
        


A Guide on 12 Tuning Strategies for Production-Ready RAG Applications
",,https://www.linkedin.com/feed/update/urn:li:activity:7138080837719224320?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7138080837719224320%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQGLRrqgiYLpiQ/articleshare-shrink_800/0/1704897877096?e=1705658400&v=beta&t=v_yguZCyRCycBNelkw8hWRp2nhsZfZXtMbKS65Xw6Nk
73,65a104f1a5b8f07200002183,44936593-5947-865c-4736-43d2fecaa537,https://media.licdn.com/dms/image/D5603AQGEADhHyEQ8rw/profile-displayphoto-shrink_100_100/0/1682553354695?e=1710374400&v=beta&t=kfjA-KO1Ea4gqAJ68vTh1_4ORnZzWv1qSW4bXFvg_tc,"Damien Benveniste, PhD",https://www.linkedin.com/in/ACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw,"
The ML Guy - Follow me to learn about Machine Learning Engineering, Machine Learning System Design, MLOps, and the latest techniques and news about the field. Join my AI newsletter and keep learning!
","
You should learn to deploy your Machine Learning models! The way to deploy is dictated by the business requirements. You should not start any ML development before you know how you are going to deploy the resulting model. There are four main ways to deploy ML models.#machinelearning #datascience #artificialintelligence

          ‚Ä¶see more
        


All the ways to deploy an ML model
",,https://www.linkedin.com/feed/update/urn:li:activity:7143835380025311233?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7143835380025311233%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5612AQHnZzzPxM54_Q/article-cover_image-shrink_720_1280/0/1703223196018?e=1710374400&v=beta&t=6pboNQZDtP5me-P7p7bLFiy4Zq7qUVh7Q6u_3_dBqi0
74,65a104f2a5b8f072000021a5,7967437d-ddda-67a5-b2e8-5ff46e5daccd,https://media.licdn.com/dms/image/D5603AQHxUzqt5ibu8Q/profile-displayphoto-shrink_100_100/0/1670820076513?e=1710374400&v=beta&t=jDLfZwZFFu2iGz5MnJjGW-UsIgg6W6Y2_uU05Hzvakw,Michael Galkin,https://www.linkedin.com/in/ACoAABQJ9wsBGHSNQWOUK2OVHWIhE26F7icbcLc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABQJ9wsBGHSNQWOUK2OVHWIhE26F7icbcLc,"
AI Research Scientist at Intel AI Lab | Graph ML & GNNs & Knowledge Graphs & ML
","
üéâ More Graph ML on Hugging Face Model Hub - ULTRA models are now available for KG reasoning and 0-shot inference with just 3 lines of code! To celebrate it, we also release a new checkpoint pre-trained on 50 graphs that works 30% better on larger datasets.Hub: https://lnkd.in/ggHCNKZP 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7137390270265917440?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7137390270265917440%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQGmVMDn83pX6Q/feedshare-shrink_480/0/1701686445841?e=1707955200&v=beta&t=xJOMEGbFaQWWhe0dNbqrVH594cmEwGkFMf7VrCwR8ts
75,65a104f1a5b8f0720000219c,dd1d3fcf-c260-6922-6737-5a695de47c80,https://media.licdn.com/dms/image/D4E03AQHtC2BUAB6jkA/profile-displayphoto-shrink_100_100/0/1694687456770?e=1710374400&v=beta&t=ndmP3__bJjjA60t62U8lCwf_bck4TDX4LIp-qSsOgAc,Prithivi Da,https://www.linkedin.com/in/ACoAAANONyEBI75vYtjMK4f9hcDMhgneli34DsA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAANONyEBI75vYtjMK4f9hcDMhgneli34DsA,"
Building a Memory Assistant for Philomaths. Sharing wisdom from a 2 decade experience in creative problem solving.
","
üöÄ ùóôùóπùóÆùòÄùóµùó•ùóÆùóªùó∏: ùóßùó∂ùóªùó∂ùó≤ùòÄùòÅ ùóÆùóªùó± ùóôùóÆùòÄùòÅùó≤ùòÄùòÅ ùó•ùó≤ùóøùóÆùóªùó∏ùó∂ùóªùó¥ ùóπùó∂ùóØùóøùóÆùóøùòÜ ùó∂ùóª ùóØùòÇùòÄùó∂ùóªùó≤ùòÄùòÄ (with super competitive performance).There are only zillion resources that shows reranking improves recall in  search & retrieval and RAG pipelines no matter it's a lexical search or semantic search or hybrid. But,ùóñùóµùóÆùóπùóπùó≤ùóªùó¥ùó≤ ùó∂ùòÄ: Most available reranking libraries are super heavy, or behind a paywall or tight-coupled with bigger vector database stacks. They are all great ü§ü....but unsuitable for most custom integrations and lighter server-less environments.ùó™ùóµùóÆùòÅ ùó∂ùó≥: We have an ultra-lite reranking library with - ùó°ùóº ùóßùóºùóøùó∞ùóµ ùóºùóø ùóßùóøùóÆùóªùòÄùó≥ùóºùóøùó∫ùó≤ùóøùòÄ dependency. - Super fast and ùó•ùòÇùóªùòÄ ùóºùóª ùóñùó£ùó®. - Models ùóÆùòÄ ùòÄùó∫ùóÆùóπùóπ ùóÆùòÄ ~ ùü∞ùó†ùóï. - Costs ùóüùóºùòÑùó≤ùòÄùòÅ $ ùóΩùó≤ùóø ùó∂ùóªùòÉùóºùó∞ùóÆùòÅùó∂ùóºùóª (best for Lambda & cousins)- Offers Competitive performance.- and you can lego into any pipeline ?Enter FlashRank !ùóßùóÆùó∏ùó≤ùóÆùòÑùóÆùòÜ:ùòôùò¶ùò≥ùò¢ùòØùò¨ùò™ùòØùò® ùò™ùò¥ ùòµùò©ùò¶ ùòßùò™ùòØùò¢ùò≠ ùò≠ùò¶ùò® ùò∞ùòß ùò©ùò¶ùò¢ùò∑ùò™ùò¶ùò≥ ùò≥ùò¶ùòµùò≥ùò™ùò¶ùò∑ùò¢ùò≠ ùò±ùò™ùò±ùò¶ùò≠ùò™ùòØùò¶ùò¥, ùò™ùò•ùò¶ùò¢ ùò™ùò¥ ùòµùò∞ ùò©ùò¢ùò∑ùò¶ ùòµùò©ùò¶ùòÆ ùò∏ùò™ùòµùò©ùò∞ùò∂ùòµ ùò¢ùò•ùò•ùò™ùòØùò® ùò¢ùòØùò∫ ùò∞ùò∑ùò¶ùò≥ùò©ùò¶ùò¢ùò• ùò¶ùò¥ùò±ùò¶ùò§ùò™ùò¢ùò≠ùò≠ùò∫ ùòßùò∞ùò≥ ùò∂ùò¥ùò¶ùò≥-ùòßùò¢ùò§ùò™ùòØùò® ùò¥ùò§ùò¶ùòØùò¢ùò≥ùò™ùò∞ùò¥. ùòçùò≠ùò¢ùò¥ùò©ùò≥ùò¢ùòØùò¨ ùò™ùò¥ ùò¥ùò∞ ùò¥ùòÆùò¢ùò≠ùò≠ ùò¢ùòØùò• ùòßùò¢ùò¥ùòµ ùò∫ùò∞ùò∂ ùò∏ùò∞ùòØùòµ ùò¶ùò∑ùò¶ùòØ ùò¨ùòØùò∞ùò∏ ùò™ùòµ'ùò¥ ùòµùò©ùò¶ùò≥ùò¶ :-). ùòïùò∞ùòµùò¶: ùòêùòµ ùò¢ùò≠ùò¥ùò∞ ùò¥ùò∂ùò±ùò±ùò∞ùò≥ùòµùò¥ ùò£ùò™ùò®ùò®ùò¶ùò≥ ùòÆùò∞ùò•ùò¶ùò≠ùò¥ (ùò¥ùò≠ùò∞ùò∏ùò¶ùò≥) ùòµùò∞ ùò¢ùò§ùò§ùò∞ùòÆùò∞ùò•ùò¢ùòµùò¶ ùò≠ùò¢ùò≥ùò®ùò¶ùò≥ ùò±ùò¢ùò¥ùò¥ùò¢ùò®ùò¶ùò¥ / ùò§ùò∞ùòØùòµùò¶ùòπùòµ ùò¥ùò™ùòªùò¶ùò¥.Repo: https://lnkd.in/eqX2kgiH____________Save for later with https://savelikeapro.aiEdited for typos.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7138036841391255552?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7138036841391255552%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQFdanKkKZzGqg/feedshare-shrink_480/0/1701835853156?e=1707955200&v=beta&t=CXun-K36LsWBI9ZIBDEKas4rpSn_YGa4RCE9eroy19w
76,65a104f1a5b8f0720000219d,dc3fe53f-e1a1-a994-61eb-753b16590290,https://media.licdn.com/dms/image/D4D03AQETmjbTZB_ebQ/profile-displayphoto-shrink_100_100/0/1674749455280?e=1710374400&v=beta&t=Ray2CyHD6noNSN-rQLdm5JoIpB8NeE1HCQkk8GkjhOM,Aladdin Persson,https://www.linkedin.com/in/ACoAACTlfREB2mnCzNgPDYFE-7yS7wO4tiR6QNM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACTlfREB2mnCzNgPDYFE-7yS7wO4tiR6QNM,"
Machine Learning Engineer | Master's in Data Science and AI
","
ü§ñ ùêáùê®ùê∞ ùêúùê°ùêöùê≠ùêÜùêèùêì ùê∞ùêöùê¨ ùê≠ùê´ùêöùê¢ùêßùêûùêùTraining a state-of-the-art LLM like GPT-4 involves four distinct steps. First, there's pretraining on a vast dataset‚Äîthink practically the whole internet for OpenAI. This phase focuses on learning to predict the next word, and is the same approach that was used for predecessors GPT-1, GPT-2, and GPT-3.üåü The biggest improvement going from GPT-3 to ChatGPT (GPT-3.5-Turbo) was supervised finetuning (SFT). By optimizing it for chat and making it into an assistant it made it a lot more intuitive and helpful in its responses. It's interesting how the difference between GPT-3 and ChatGPT that got the attention of the entire world is technically not that different, but the usefulness of the model is much better.Beyond this, there are two additional steps: reward modelling and reinforcement learning. I am not completely sure how much performance gain this step gets us, in comparison to the SFT process but this is part of the state of the art LLMs today. In this process, human judges compare responses to the same prompts and rank them‚Äîperhaps finding response B the best, C second best and A the worst of the three. From these rankings of different versions of responses to the same prompt, a reward function that measures the quality can be trained, which in turn can guide reinforcement learning to generate even better answers.When it comes to the time invested in training, pretraining is what takes basically all the training time‚Äîit takes an immense amount of time relative to supervised finetuning. With SFT and reward modeling, the real challenge lies in curating the dataset rather than the actual training in most cases and comparatively is a much smaller task. But as we've seen in chatGPT it makes a huge difference.Hope this post is interesting to understand LLM training. For a deeper dive, check out Andrej Karpathy's insightful video: https://lnkd.in/gtr-s6Tt#llm #chatgpt #machinelearning #ml #deeplearning #dl #ai

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7137772595415814144?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7137772595415814144%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQEVDhrSOgfRkA/feedshare-shrink_480/0/1701686238217?e=1707955200&v=beta&t=3girq81_2DxCA2LR2lLo1I-_h9hBGa85PdisgZMD9Ks
77,65a104f1a5b8f0720000219e,8b1059f2-f90b-4511-b844-31a180fd9d8d,https://media.licdn.com/dms/image/D5603AQF4voR_1_BQZg/profile-displayphoto-shrink_100_100/0/1687295026446?e=1710374400&v=beta&t=M5hMMaTPKE3EpNPLr3YcVe49d9NTq1lGxMx2kXluBRw,Nikita Gupta,https://www.linkedin.com/in/ACoAAAj0hSkBTfYXjqNrHUsALuhxj29aatN6aes?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAj0hSkBTfYXjqNrHUsALuhxj29aatN6aes,"
Co-Founder @Careerflow.ai | Keynote Speaker | Ex-Senior Technical Recruiter @Uber | Ex-Amazon | 255K+ Followers | TEDx Speaker | Resume and LinkedIn Coach | Career Coach | Entrepreneur | YouTuber
","
Spotify laid off 1500 employees today üò≠ üò¢I wanted to share an exciting list of resources for job seekers! üöÄüí•Reshare with your network to help more folksüëáüèªTop 10 websites for remote work opportunities üöÄ‚ö°Ô∏è Pangian - https://pangian.com‚ö°Ô∏è WeWorkRemotely - https://lnkd.in/dTwbuTCt‚ö°Ô∏è ARC - https://arc.dev‚ö°Ô∏è Remotive - Remote Jobs - https://remotive.com‚ö°Ô∏è JustRemote - https://justremote.co/‚ö°Ô∏è AngelList - https://angel.co/‚ö°Ô∏è Jobspresso - https://jobspresso.co/‚ö°Ô∏è DailyRemote - https://dailyremote.com/‚ö°Ô∏è Working Nomads - https://lnkd.in/dJKgGBTx‚ö°Ô∏è RemoteLeaf - https://remoteleaf.com/Top Job assistant platformüöÄ‚ö°Ô∏è Careerflow.ai: https://www.careerflow.ai/Top 10 websites for freelance/part-time jobsüöÄ‚ö°Ô∏è Freelancer.com - https://www.freelance.com/‚ö°Ô∏è Upwork - https://www.upwork.com/‚ö°Ô∏è Solid Gigs - https://solidgigs.com‚ö°Ô∏è Snagajob - https://www.snagajob.com/‚ö°Ô∏è LinkedIn - http://www.linkedin.com/‚ö°Ô∏è ServiceScape - https://lnkd.in/dg-5Q-WK‚ö°Ô∏è Craigslist - http://www.craigslist.org/‚ö°Ô∏è CoolWorks.com  - https://www.coolworks.com/‚ö°Ô∏è Contena - https://www.contena.co‚ö°Ô∏è Fiverr - https://www.fiverr.com/Top 11 websites to prep for coding interviews üöÄ‚ö°Ô∏è LeetCode - https://leetcode.com/‚ö°Ô∏è HackerRank - https://lnkd.in/d322VBBq‚ö°Ô∏è HackerEarth - https://lnkd.in/dXy7SAcf‚ö°Ô∏è Codewars - https://www.codewars.com‚ö°Ô∏è CodeChef - https://www.codechef.com/‚ö°Ô∏è CodingNinjas - https://lnkd.in/dAQiqPYk‚ö°Ô∏è Topcoder - https://www.topcoder.com/‚ö°Ô∏è Coderbyte - https://coderbyte.com/‚ö°Ô∏è Geektastic - https://geektastic.com‚ö°Ô∏è freeCodeCamp - https://lnkd.in/dGGmah9M‚ö°Ô∏è GeeksforGeeks - https://lnkd.in/dveifGFnTop 6 salary negotiation toolsüöÄ‚ö°Ô∏è Comparably - https://lnkd.in/ggZ4xhE7‚ö°Ô∏è Levels.fyi - http://www.levels.fyi/‚ö°Ô∏è Salary - https://www.salary.com/‚ö°Ô∏è Glassdoor - http://www.glassdoor.com/‚ö°Ô∏è Payscale - http://www.payscale.com/‚ö°Ô∏è PaycheckCity - https://lnkd.in/de6hBaxPTop 5 tools for Productivity and Collaboration tools‚ö°Ô∏è Grammarly - http://www.grammarly.com/‚ö°Ô∏è Todoist - http://www.todoist.com/‚ö°Ô∏è Notion - http://www.notion.so/‚ö°Ô∏è Calendly - http://www.calendly.com/‚ö°Ô∏è Overleaf - http://www.overleaf.com/Free AI Google 9 Generative AI Courses üöÄ‚ö°Ô∏èhttps://lnkd.in/gwUdaU-7Please share this with your network so more and more people can benefit from it! Let us help more folks get hired üí™Follow me and Careerflow.ai for job search tips!#newyears #humanresources #google #microsoft #amazon #apple #opentowork #networkingtips #linkedintips #networking #entrepreneurship #india #technology #careers #startups #interview #job #recruitment #careers #Socialmedia #jobinterviews #openfornewopportunities #hiringengineers #softwareengineerjobs #jobopportunites #jobseekers #linkedin #recruiters #jobs

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7137706911369498625?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7137706911369498625%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQESNehHcQYTyQ/feedshare-shrink_480/0/1701761939322?e=1707955200&v=beta&t=F_fECwyZxQ9vF0cvCNOuwnJp-vpK8u05dRAup_pmR3Y
78,65a104f1a5b8f0720000219f,379ec07f-7876-b636-dbe5-887e2ac319c3,https://media.licdn.com/dms/image/D4E03AQF9Mk0VO3GPrA/profile-displayphoto-shrink_100_100/0/1678539628962?e=1710374400&v=beta&t=xdY89-1thQXOUEZdOKdFw7yDjGOEi3J4fUMjF-5FQQk,Abonia Sojasingarayar,https://www.linkedin.com/in/ACoAABL7f-kBNdWLWZIatUeACOHl67S8wCwgZFk?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABL7f-kBNdWLWZIatUeACOHl67S8wCwgZFk,"
Machine Learning Scientist | Data Scientist | NLP Engineer | Computer Vision Engineer | AI Analyst | Technical Writer | Technical Book Reviewer
","
üîù Improve Information Retrieval in Large Language Models with Rerank RAG üîùRerank, is a method used in information retrieval to improve the quality of the data retrieved. It's like a helper that sorts and chooses the best options, enabling the RAG system to provide better and more accurate answers.‚û°Ô∏è Why Do We Need it?Rerank RAG is needed to improve the recall performance of Large Language Models. As we add more context, the recall performance for LLMs decreases, resulting in increased context window (context stuffing). Reranking helps to filter down the total number of documents into a fixed number, ensuring that the most relevant items are at the top and can be sent to the LLM.‚û°Ô∏è Rerankers listThere are several types of rerankers available, including ColBERT (Contextualized late interaction over BERT) based DrDecr model and others. These models are trained with a deep learning technique using a large dataset for ranking passages in response to a given query.üëâ Cohere's Reranker: This is a popular choice for reranking, especially with the CohereRerank and bge-reranker-large models. It has been shown to significantly improve performance across all embeddings, often providing the best or near-best results.üëâ OpenAI Reranker: This reranker shows top-tier performance, especially with the CohereRerank and bge-reranker-large models. It is particularly effective when combined with OpenAI embeddings.üëâ Custom Reranker: This is a fine-tuned reranker that can be trained with different strategies for selecting hard negatives. For example, it can be trained with 0 hard negatives, 5 hard negatives selected at random, or 5 hard negatives selected based on cosine similarity.üëâ Reranker from Reranker library: This is a lightweight package for training and deploying deep language model rerankers in information retrieval (IR), question answering (QA), and many other natural language processing (NLP) pipelines. It follows a training procedure using a localized contrastive estimation (LCE) loss.üéØ Advantages‚úÖ It improves the recall performance of LLMs, ensuring that the most relevant information is prioritized ‚úÖ It refines the results of the first-stage retriever, ensuring that the most relevant answers are brought up.‚úÖ It allows us to use better the sheer amount of information we can leverage in large documents.Image Source: Online#LLM #RAG #RErank #Informationretrival #GenAI

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7137719780681150465?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7137719780681150465%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHOghv5dHeKTQ/feedshare-shrink_480/0/1701709635964?e=1707955200&v=beta&t=zAzySoAezaX36sJtTTBMg8-2piSfb6TiYT6W4OaPmFg
79,65a104f1a5b8f072000021a0,0a9ce896-6970-30cf-ade7-e9743345515a,https://media.licdn.com/dms/image/D4D03AQFpramTnkoElw/profile-displayphoto-shrink_100_100/0/1670580633493?e=1710374400&v=beta&t=S032I_0r57qA_Thm98T7Xu_Nn46maV3uUmXnh4kYuiU,Bruno Neri,https://www.linkedin.com/in/ACoAAABlS2EBjKE-dekAzG21UIzH0d46NEotnuQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAABlS2EBjKE-dekAzG21UIzH0d46NEotnuQ,"
Technical Leader - Artificial Intelligence and Deep Learning Enthusiast - Senior Software Engineer at ALTEN Italia
","
""Fine-grained Expressivity of Graph Neural Networks"" by  Teresa Ningyuan Huang, Soledad Villar, et al.""Numerous recent works have analyzed the expressive power of message-passing graph neural networks (MPNNs), primarily utilizing combinatorial techniques such as the 1-dimensional Weisfeiler-Leman test (1-WL) for the graph isomorphism problem. However, the graph isomorphism objective is inherently binary, not giving insights into the degree of similarity between two given graphs. This work resolves this issue by considering continuous extensions of both 1-WL and MPNNs to graphons. Concretely, we show that the continuous variant of 1-WL delivers an accurate topological characterization of the expressive power of MPNNs on graphons, revealing which graphs these networks can distinguish and the level of difficulty in separating them. We identify the finest topology where MPNNs separate points and prove a universal approximation theorem. Consequently, we provide a theoretical framework for graph and graphon similarity combining various topological variants of classical characterizations of the 1-WL. In particular, we characterize the expressive power of MPNNs in terms of the tree distance, which is a graph distance based on the concept of fractional isomorphisms, and substructure counts via tree homomorphisms, showing that these concepts have the same expressive power as the 1-WL and MPNNs on graphons. Empirically, we validate our theoretical findings by showing that randomly initialized MPNNs, without training, exhibit competitive performance compared to their trained counterparts. Moreover, we evaluate different MPNN architectures based on their ability to preserve graph distances, highlighting the significance of our continuous 1-WL test in understanding MPNNs' expressivity.""Paper: https://lnkd.in/dw_Xgmta#graphneuralnetworks

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7137481449380675585?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7137481449380675585%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQEa0cbeOBh2AQ/feedshare-shrink_480/0/1701708184023?e=1707955200&v=beta&t=Fg6ws4nUUOoALG9IXNOmgvO5W2GmiOrKgDciLcCfXYU
80,65a104f1a5b8f072000021a1,439d1658-8104-f9f1-7d07-837871eec69e,https://media.licdn.com/dms/image/C4D03AQGML7n8UcfoFA/profile-displayphoto-shrink_100_100/0/1601728366460?e=1710374400&v=beta&t=dY_FzEfgGLodJIXZ8sulsUbkWPBh0eljVnNJm9XTSck,Younes Belkada,https://www.linkedin.com/in/ACoAACMyFoYBdOKfnKMQB-Tsxt1mWq2UaZZZqqM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACMyFoYBdOKfnKMQB-Tsxt1mWq2UaZZZqqM,"
Machine Learning Engineer @ Hugging Face
","
Blazing fast text generation using AWQ and fused modules! A great work from AWQ, AutoAWQ maintainers and open-source ML community now integrated into Hugging Face transformers library!Up to 3x speedup on a NVIDIA A100 GPU compared to native fp16 models that you can use right now on any AWQ model supported by TheBloke on HF Hub: https://lnkd.in/ePqExpdD Simply pass an `AwqConfig` with `do_fuse=True` to `from_pretrained` method! Read more about it here: https://lnkd.in/e9waaEuE

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7137766770915856386?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7137766770915856386%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQFvJb3k76tUgQ/feedshare-shrink_480/0/1701776210184?e=1707955200&v=beta&t=KaGXZ30FvqmDoz8GnEZC1keHe-8hWehHUscwPOervAI
81,65a104f2a5b8f072000021a2,865a4d0d-0227-6b34-6615-3d29f4cb12fa,https://media.licdn.com/dms/image/D4E03AQF6vorKIc_rDg/profile-displayphoto-shrink_100_100/0/1703628958212?e=1710374400&v=beta&t=mDh5ASm_Bz6tI7AUJ3L_iWFs4lPuSq8z7wpor2_Lz4c,Aniket Maurya,https://www.linkedin.com/in/ACoAABX5KEgBX_f0Ap7tJvvr9yXhqh9jp_rYCws?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABX5KEgBX_f0Ap7tJvvr9yXhqh9jp_rYCws,"
Developer Advocate @ Lightning AI ‚ö°Ô∏è | Creator of GradsFlow
","
TIL: Fast Feedforward Networks (FFFs) can be 220x faster than traditional feedforward networks and use just 1% of layer neurons for inference in vision transformers, while still preserving 94.2% of predictive performance. Check out the research paper here: https://lnkd.in/exNRR_7i #MachineLearning #NeuralNetworks #ArtificialIntelligence 

          ‚Ä¶see more
        


Fast Feedforward Networks
",,https://www.linkedin.com/feed/update/urn:li:activity:7133516219973816321?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7133516219973816321%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQF_3rg-SXhpgA/articleshare-shrink_800/0/1705009878887?e=1705658400&v=beta&t=HR7vfRrsAmleDa1OBFcrFQDZ2Bll7XiS8SuV7vsklyA
82,65a104f2a5b8f072000021a3,07170567-9c11-e815-2ec4-66f2808ede62,https://media.licdn.com/dms/image/C4E03AQHOLm0TKvS9Cw/profile-displayphoto-shrink_100_100/0/1655756384824?e=1710374400&v=beta&t=NISDlUj4YM4m_jF-QNP0N9ZEGCarbCPBEhh_q8HkhkA,Marcello Politi,https://www.linkedin.com/in/ACoAACjMJFMB41k9wwu8F5pCKDrVhQ7LidwZoEY?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACjMJFMB41k9wwu8F5pCKDrVhQ7LidwZoEY,"
Machine Learning Scientist @ Pi School | Event Manager @ Space Generation Advisory Council
","
Because of my job, recently I had to interview many people for Machine Learning positions. I noticed that a lot of candidates have worked on a variety of interesting projects, and they know how to use a lot of frameworks and libraries. But most of them always have ùê≠ùê´ùê®ùêÆùêõùê•ùêû ùêöùêßùê¨ùê∞ùêûùê´ùê¢ùêßùê† statistical questions, especially ùê°ùê≤ùê©ùê®ùê≠ùêûùê¨ùê¢ùê¨ ùê¨ùê≠ùêöùê≠ùê¢ùê¨ùê≠ùê¢ùêúùêöùê• ùê≠ùêûùê¨ùê≠ùê¢ùêßùê†. These types of tests are critical to figuring out the best model to put into production, ùê≤ùê®ùêÆ ùêúùêöùêß'ùê≠ ùê£ùêÆùê¨ùê≠ ùê´ùêûùê•ùê≤ ùê®ùêß ùêö ùêüùêûùê∞ ùê¶ùêûùê≠ùê´ùê¢ùêúùê¨ ùêüùê®ùê´ ùê¨ùê®ùê¶ùêû ùê´ùêöùêßùêùùê®ùê¶ ùê¨ùê©ùê•ùê¢ùê≠ ùê®ùêü ùê≠ùê°ùêû ùêùùêöùê≠ùêöùê¨ùêûùê≠.I found a paper where it is explained in a straightforward and simple way how and when to use these tests and wanted to share it with my network! üí™ #machinelearning #deeplearning #artificialintelligence #statistics

          ‚Ä¶see more
        


Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning
",,https://www.linkedin.com/feed/update/urn:li:activity:7135665777491259392?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7135665777491259392%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQHJUomdWwR5AQ/articleshare-shrink_800/0/1704988239461?e=1705658400&v=beta&t=GQEZjwksmC9czW4HWVH4go0VYH6QQFpjpWuFe4UsogI
83,65a104f2a5b8f072000021a4,ece0f550-f6f9-b36e-29dc-d7e867cc16f1,https://media.licdn.com/dms/image/C5603AQGui5p4Ri5tpQ/profile-displayphoto-shrink_100_100/0/1622144056265?e=1710374400&v=beta&t=CXt7TOeWFsWb4U8vSYjH9LPVrzM0K-YcEvwM6vIZsak,Dhruv Anand,https://www.linkedin.com/in/ACoAAAx-pOoBszcFhAafpwSxCcnmEIHDB9g_DGM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAx-pOoBszcFhAafpwSxCcnmEIHDB9g_DGM,"
Vector Search+LLMs architect | Founder, AI Northstar Tech | Ex-Google, FB | CS@CMU, IITK
","
Sharing a new Vector Database Feature Matrix!After receiving many questions over the past few months about the differences between Vector DBs and which one should be used in various scenarios, I've created a feature matrix that compares some objective features of different vector databases. This spreadsheet will help anyone looking for detailed information on various vector database options.Key Points:1. Comprehensive and Up-to-Date: Unlike various blogs and webpages online that are now outdated, I'll try to regularly update the matrix to ensure it reflects the latest releases.2. Open for Contributions: Vector database providers can request to add or correct their product information.3. Feedback Wanted: Please suggest additional attributes to include and other vector databases to feature. I've currently limited the set of attributes to basic objective measures. I'd love to know ideas around how to integrate developer experiences, ratings, benchmarks and other factors that people think about while choosing a vector DB.You can access the Google Sheet for it here: https://lnkd.in/daDKFnt5Bonus: VectorDB Guide MyGPT:I've also created a GPT that you can chat with, to help decide which vector DB makes sense for your project: https://lnkd.in/dbWnJYHgIf you're interested in having the design or DB choice for your Vector Search or LLM usecase vetted, feel free to ping me directly!PS: Inviting Vector DB folks from my network to contribute and verify:Jo Kristian Bergum (Vespa.ai), Andre Zayarni (Qdrant), Bob van Luijt(Weaviate), Kevin Butler (Pinecone), Zilliz, The Milvus Project, MongoDB, Owen Elliott (Marqo), Vectara, Supabase, Elastic, OpenSearch Project, Jeff Huber (Chroma)#VectorDatabases #VectorSearch #VectorEmbeddings #LLMs #RAG #RetrievalAugmentedGeneration

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7137357363879026688?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7137357363879026688%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQG79zH4Kpgf8g/feedshare-shrink_480/0/1701439386332?e=1707955200&v=beta&t=VYvSnWx4pLdGMKWTWLszt2NHkrxkpQo7mR5FOoViU4M
84,65a104f1a5b8f0720000219b,1f05cc1e-31b5-1ea0-39c2-34abeef77293,https://media.licdn.com/dms/image/C4D03AQE7iSxtcEqqZQ/profile-displayphoto-shrink_100_100/0/1594459905770?e=1710374400&v=beta&t=__M-yYdC_t66SS-2W5pANPQY0YiJtnZEVA6QE4aJoMU,Michael Bronstein,https://www.linkedin.com/in/ACoAAAAZEfYBuo_hRqA1P6ywF5ORzjVMwSzLhh0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAAZEfYBuo_hRqA1P6ywF5ORzjVMwSzLhh0,"
DeepMind Professor of AI, Oxford / Serial startupper
","
Can GNNs do a different type of message passing? In a new work with Ben Finkelshtein, ƒ∞smail ƒ∞lkan Ceylan, and Xingyue Huang, we show a new type of ""co-operative GNNs"" where every node can decide how to route its messages. Post: https://lnkd.in/eWNZSgHtPaper: https://lnkd.in/ejqYucxi 

          ‚Ä¶see more
        


Co-operative Graph Neural Networks
",,https://www.linkedin.com/feed/update/urn:li:activity:7138117151894196224?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7138117151894196224%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQG2UOoSJqj49g/articleshare-shrink_800/0/1704746152497?e=1705658400&v=beta&t=Nmn_zsCg3Ul60lmuw3lZc0IcEiInaMBUcpNx5ef2UD4
85,65a104f2a5b8f072000021a6,79c180f2-36f8-065b-2231-f2ba53011304,https://media.licdn.com/dms/image/C5603AQE7fjXsZ7wPWA/profile-displayphoto-shrink_100_100/0/1658593096462?e=1710374400&v=beta&t=W8qcjzwyAjI6vPbxZoV8hfGtcr21XMGiNAbu6tIMKn0,Ayush Chaurasia,https://www.linkedin.com/in/ACoAACRnolMBiOzNquvP9PNdm3VEWXLdR592cc4?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACRnolMBiOzNquvP9PNdm3VEWXLdR592cc4,"
Building @LanceDB | Co-author Ultralytics/YOLOv8
","
https://lnkd.in/dpRydE6y‚ùì  How do you go about improving and iterating upon your RAG systems?Here are 3 practical steps with guides and implementations:üí°  The simplest approach is to Re-rank the retrieved results using a Re-ranking Model. Here's the Guide along with code by Mahesh Deshwal üëâ https://lnkd.in/dzFXzFMfüí°  Another approach that should be explored next is FLARE. This technique queries the knowledge base every time the confidence of a part of the generation is less than a certain threshold. This bypasses the limitation of traditional RAG that only queries at the beginning and forms the final generation. This guide and code walkthrough by Akash Desai takes you through understanding and implementing it üëâ https://lnkd.in/dwKCdz64üí°  Finally, there's HyDE. This technique generates a hypothetical document to answer a query and encodes it into an embedding vector.This vector identifies a neighbourhood in the corpus embedding space and retrieves similar real documents based on vector similarity.And here's the guide with code by Akash Desai üëâ https://lnkd.in/d2gmtDJ5üïØ  But you'll also need a tool to compare and evaluate performance on different prompt. That's where you can use the next notebook in line that uses promptools by Hegel AI (YC S23) to evaluate promptsFind all of these curated examples with technical blogs here on LanceDB (YC W22)  - https://lnkd.in/dpRydE6y 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7135847420340359169?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7135847420340359169%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQH7QJncrv-uZA/feedshare-shrink_480/0/1701285074465?e=1707955200&v=beta&t=CfM6NL-1LE8ftdPQk_P18MXSF_nJQWRxdG44APb7ySs
86,65a104f2a5b8f072000021a7,ff8a777d-b8b5-7f45-ed48-5e6fb86a1958,https://media.licdn.com/dms/image/D5603AQE8TeENRxRByQ/profile-displayphoto-shrink_100_100/0/1680543445564?e=1710374400&v=beta&t=WAMISH15jy9fjUWYLao419e1ardhLWRheJTvDtJe_mU,Nathan Lambert,https://www.linkedin.com/in/ACoAAA5gPQwBYcNPOvXhgmD7ZRl_C4vL6hWnvjM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA5gPQwBYcNPOvXhgmD7ZRl_C4vL6hWnvjM,"
ML Scientist at AI2
","
A few more resources to share on model adaptation / rlhf before I forget.1. I gave an RLHF lecture at Stanford yesterday, here are the slides. The newer figures from other talks I've given (lmk if I should re-record it):* visuals on history of RLHF / related fields* figures on advanced RL methods (CAI / DPO / rejection sampling)Slides here: https://lnkd.in/g3gyuCRe2. Why you should revisit one of our recent experimental papers. If you're interested in anything in the bucket of LLM fine-tuning, which we are calling adaptation at AI2, the Tulu-2 paper is a must read. It is a clear resource on many trends in fine-tuning:* First to show that the RLHF method DPO scales to 70B parameters,* First paper to clearly compare PEFT fine-tuning to full-parameter fine-tuning,* Went deep on pushing the limits of CodeLlama even though the model is meh, because the code variant of llama 3 will surely be better,* Deeply understanding evaluation of instruction models, with a broader suite of evaluations before the open LLM leaderboard expanded,* Models that have great scores on the first run (very little hyperparam tuning)* a mini survey on instruction datasets to use.These lessons are going to be applied to our own fully open models OLMo, which is a new direction for the AI2 org. All of the models and code are available from day 1.Paper: https://lnkd.in/ghAB9gzP Artifacts: https://lnkd.in/gk5AwTmvBlog: https://lnkd.in/gHcdqY92Instruct code:  https://lnkd.in/g9nENNds Jax code (WIP): https://lnkd.in/gij5VWSxEnjoy!

          ‚Ä¶see more
        


[29 Nov 2023] RLHF Lecture @ Stanford
",,https://www.linkedin.com/feed/update/urn:li:activity:7136029436520398849?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7136029436520398849%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQEVGHygahkp5w/articleshare-shrink_800/0/1701361848004?e=1705658400&v=beta&t=iLWT77rigQCDEEaMq-IOefyQJQ-3lPw2II2q_AhQZRA
87,65a104f2a5b8f072000021a8,ae339f2d-df82-58d9-cce3-57e5bdd9529e,https://media.licdn.com/dms/image/D4E03AQFh6L32y18PAw/profile-displayphoto-shrink_100_100/0/1687119571913?e=1710374400&v=beta&t=haaUeeJhfZhTmEUwRGIj23AhHaRZGieNAKyHee2dScE,Maxime Labonne,https://www.linkedin.com/in/ACoAACHMnvUBcdKptayD76qA_A4NmTapmg0ti-Q?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACHMnvUBcdKptayD76qA_A4NmTapmg0ti-Q,"
Sr. Machine Learning Scientist @ JPMorgan
","
üß† NeuralHermes-2.5: Accidentally building a SOTA 7B LLMFor my next article, I fine-tuned the excellent OpenHermes 2.5-Mistral-7B model with Direct Preference Optimization (DPO). It outperforms the original model on several benchmark scores, which makes it one of the very best 7B LLMs.It is directly inspired by the RLHF process described by neural-chat-7b-v3-1's authors to improve performance. I used the same dataset and reformatted it to apply the ChatML template. This shows the untapped power of DPO to improve SFT models.I'm releasing the Google Colab notebook to fine-tune the model with DPO and build your own NeuralHermes-2.5. Training only requires one A100 for about just an hour. Feel free to play with the parameters to optimize them.ü§ó Model: https://lnkd.in/eXSTEvGsü§ó GGUF: https://lnkd.in/eJ3i8-4M (thanks to TheBloke)üíª Colab: https://lnkd.in/eMDAzKM7

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7135903533412806656?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7135903533412806656%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQHJUeR1EtNbzQ/feedshare-shrink_480/0/1701304005113?e=1707955200&v=beta&t=edE5Xdqv7EoLqjHh4P93HDhkCRxxWHldDnl3PH5dhDg
88,65a104f2a5b8f072000021a9,73bb5304-abd5-37c6-a856-b809f8a684cb,https://media.licdn.com/dms/image/D4D03AQHgrTcUNdC2Qg/profile-displayphoto-shrink_100_100/0/1695652685322?e=1710374400&v=beta&t=pnRcEu8wmjo524mWfZwHqI39ImCcQys_8vniM3SSUgE,Angelina Do,https://www.linkedin.com/in/ACoAACuU-ggBuzTCZ6SLcWGD98PeXfyfKJc5b8c?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACuU-ggBuzTCZ6SLcWGD98PeXfyfKJc5b8c,"
Talent Acquisition Partner ü§ù IT Recruiting Consulting
","
Neurons Lab is hiring!Don't miss üòé 
 

Neurons Lab Jobs
",,https://www.linkedin.com/feed/update/urn:li:activity:7135962304969416704?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7135962304969416704%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E22AQFaBXQKvLZ53g/feedshare-shrink_800/0/1701345846480?e=1707955200&v=beta&t=Xbw7nE9AJqLQEr_a-GL79sjEu8sGN8kBoeRzan6nS64
89,65a104f2a5b8f072000021aa,0e9a4e43-a74c-d577-4b1d-1b3f87649005,https://media.licdn.com/dms/image/D4D03AQGQNsTCZs4Org/profile-displayphoto-shrink_100_100/0/1674943970250?e=1710374400&v=beta&t=12FyAWDH6ZxxYnXI5xXgvTX_ofvRbLEpmcuLvXsAVFw,Gabriel Preda,https://www.linkedin.com/in/ACoAAAEUMPgBIgX93pwaqCb2TNc_MV98C_UycJQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAEUMPgBIgX93pwaqCb2TNc_MV98C_UycJQ,"
Principal Data Scientist at Endava ‚ãÑ 3 x Kaggle Grandmaster
","
Generative AI on Kaggle is really taking momentum.Here https://lnkd.in/dXeCprX5 is an example of Notebook showcasing the use of Kaggle Models (Llama v2 7b in this case) in combination with Langchain and a vector database to build a Retrieval Augmented Generation (RAG) system. For those of you interested to find more about how to use Kaggle Models to build prototypes for Gen AI applications, join Kaggle's Developer Relations Lead, Phil Culliton, who will present ""Prototyping useful applications on Kaggle"" at Google Cloud's Applied AI Summit (https://lnkd.in/dDZeen-H) on December 13, 2023.#artificialintelligence #kaggle #kagglemodels #ai #generatieveai #retrievalaugmentedgeneration #langchain #chromadb #vectordatabases  #llama2 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7135523078264004608?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7135523078264004608%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQENilkQb32fUQ/feedshare-shrink_480/0/1701241272149?e=1707955200&v=beta&t=yfrdeURE17Eiq_LAdbZIbwfI8cKkaSzpZJkj_6icb4U
90,65a104f2a5b8f072000021ab,f8a98f9b-bf1d-4f5f-bbdf-ac0e1be1a11f,https://media.licdn.com/dms/image/D4E35AQHCu9UlCSYmWQ/profile-framedphoto-shrink_100_100/0/1703699579103?e=1705658400&v=beta&t=jfrdKa7v-vpeO8FD7QTxkjESab4t5ATEX_Zh6QGOzdw,Mary-Anne Hartley,https://www.linkedin.com/in/ACoAADWEIkwBHzHyoXYCS6iHpiBFz9b8_KIT-5E?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADWEIkwBHzHyoXYCS6iHpiBFz9b8_KIT-5E,"
Professor @ Yale School of Medicine & EPFL School of Computer Science [MD PhD MPH]
","
ü¶ô‚õëÔ∏è Meet #Meditron!  Our new #opensource #openaccess 7- and 70-billion parameter #largelanguagemodel (#LLM) for medicine, built on the back of #llama2 (üôè Yann LeCun)Building LLMs is expensive üí®üí∏ üí∏ üí∏ , which prices out the voices of low-resource settings.Making Meditron an open-source, open-access  public good, will allow researchers to validate the tool in a range of challenging and under-represented healthcare settings for a fraction of the cost and #withoutreinventingthewheel üé°Check out the press release üëâ  https://lnkd.in/dab5GpPgüìú Paper: https://lnkd.in/dxKucqpeüîóÔ∏è Code: https://lnkd.in/d2NS_ZXvüîóÔ∏è Distributed trainer: https://lnkd.in/drG9sMMxü§ó Hugging Face hub: https://lnkd.in/d8z6Xnd4We are excited to continue working with the innovative team at the International Committee of the Red Cross - ICRC [Javier Elkin, PhD, Blaise Robert, Fabrice Lauper] and our dream team of clinical guideline experts [#KristinaKeitel Alix Miauton Rainer Tan...and so many more] as we work towards #representativevalidation through #openmodels. üí∞ Field studies cost money. Please reach out if you can recommend funders/donors interested in helping us scale this initiative of #LLMs4HumanitarianResponse. --Finally, I really can‚Äôt help but get sentimental ü•π about the phenomenally talented army of 30+ students and colleagues with whom I had the honor of working on this massive project. When you are making something to contribute to a public good, the energy is contagious  üå¨Ô∏èüåàZeming Chen Antoine Bonnet Alexandre Sallinen Martin Jaggi Antoine Bosselut Vinitra Swamy Matteo Pagliardini Angelika Romanou Syrielle Montariol Francesco Salvi ...and many more!‚ù§Ô∏è Thank you EPFL EssentialTech Centre Hugging Face Katie Link√âcole polytechnique f√©d√©rale de Lausanne EPFL School of Computer and Communication SciencesYale University School of Medicine Yale Biomedical Informatics & Data Science

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7135408165017243648?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7135408165017243648%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQEHh3SUhQd1lg/feedshare-shrink_480/0/1701213874456?e=1707955200&v=beta&t=-LYTioDzCd7f1xOEl31zRlngWi8iMT42DsbqXaMZXao
91,65a104f2a5b8f072000021ac,91a08768-0e2a-d5b5-8d1a-f6c312b1ba3a,https://media.licdn.com/dms/image/D4E03AQGrL9fScDpgcQ/profile-displayphoto-shrink_100_100/0/1680951340336?e=1710374400&v=beta&t=a68C7OOmGDhftectMoXnY4HrQnQk4fzDLEc_rFFDQFI,Victoria Slocum,https://www.linkedin.com/in/ACoAACtRH_gBtFB51x9Qf3FB7i_UJEjhXLQ-gAI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACtRH_gBtFB51x9Qf3FB7i_UJEjhXLQ-gAI,"
Machine Learning Engineer @ Weaviate
","
The HNSW (Hierarchical Navigable Small World) indexing algorithm allows for efficient nearest neighbor search in vector databases. It organizes vectors into a hierarchical graph structure, which helps quickly navigate through the dataset during search operations. How?- HNSW organizes vectors in a multi-layered graph structure.- Nodes in each layer maintain connections based on distances in the vector space, with the longest distances being on the top layer, and the shortest on the bottom.- Navigation happens hierarchically, starting from the top layer and descending to refine the search.- Higher layers are constructed by subsampling nodes from the lower layers. Nodes at each level maintain connections to a small set of nodes in the layer below, preserving the ‚Äúsmall-world‚Äù property and insuring that they can be reached efficiently from any other node in the network.Why?Speed: The hierarchical structure means the search algorithm can travel through the graph quicker than a flat structure.Scalability: Because the memory cache stores only the top layer, and then adds only the neighboring vectors in further layers, it's super memory efficient and scalable. Adaptability: HNSW is made to be very robust, handling imports and queries at the same time. With Weaviate's custom HNSW implementation, we've also used this quality to handle updates and deletes without needing to rebuild the entire index.More on this: https://lnkd.in/gqdfdDjU

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7135602013811216384?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7135602013811216384%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5605AQHCBxXoK0YQVQ/videocover-low/0/1701260081595?e=1705658400&v=beta&t=81NUXdx11wEuWKRVUtRd0tKt_d8XaSlO7PHkNPKVItg
92,65a104f2a5b8f072000021ad,f10b2d4e-f440-2ea9-586d-98b11ae8550b,https://media.licdn.com/dms/image/C4E03AQFS357V4nowiw/profile-displayphoto-shrink_100_100/0/1516363225459?e=1710374400&v=beta&t=0aHJGfWuTEIWoJefdG9SsTWjpcuB9cqC8MCPlIITvNY,Mahdi Namazifar,https://www.linkedin.com/in/ACoAAAIGb7gBqyUypz23M_t6gQMN9FF0JRrEpU8?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAIGb7gBqyUypz23M_t6gQMN9FF0JRrEpU8,"
Principal Scientist at Amazon AGI
","
Learning from human feedback is critical in training LLMs. RLHF is focused on using binary human feedback. However human feedback does not have to be limited to such binary feedback (preference). In our most recent paper we show learning from human feedback that is in natural language is highly efficient and effective. In this work that we call Critique and Revise (CnR) we show that with 1000 critique examples a 40b parameter LLM could be trained to improve the responses from even ChatGPT!

          ‚Ä¶see more
        


2311.14543.pdf
",,https://www.linkedin.com/feed/update/urn:li:activity:7135350570034364417?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7135350570034364417%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,
93,65a104f2a5b8f072000021ae,ae6115bb-9765-703a-5405-4319673a277d,https://media.licdn.com/dms/image/C4E03AQHVyH-IfD1KbQ/profile-displayphoto-shrink_100_100/0/1629877234109?e=1710374400&v=beta&t=0UZUl_dDUxLaZn-Hu-zToqEDe3rpL5cB2JkP5_jlNXc,"Sebastian Raschka, PhD",https://www.linkedin.com/in/ACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU,"
Machine learning and AI researcher since the early days ‚Ä¢ coding and working with LLMs at Lightning AI ‚Ä¢ ex-statistics professor at University of Wisconsin-Madison
","
""Simplifying Transformer Blocks"" ranks easily among my favorite research papers that I've read this year.Here, the authors look into how the standard transformer block, essential to LLMs, can be simplified without compromising convergence properties and downstream task performance.Based on signal propagation theory and empirical evidence, they find that many parts can be removed to simplify GPT-like decoder architectures as well as encoder-style BERT models:skip connections normalization layers (LayerNorm)projection and value parameterssequential attention and MLP sub-blocks (in favor of a parallel layout)The authors also did a great job referencing tons of related work motivating their experiments. I definitely recommend reading this paper just for the references alone: https://lnkd.in/g3Fc6q7Q#llms #AI #deeplearning

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7134889403964956672?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7134889403964956672%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQFzXByCwFJtSg/feedshare-shrink_480/0/1701090192918?e=1707955200&v=beta&t=JuMkjJDpUmp9C2bCvj-H4Jf9D7_pdMDy5VEQOy2mB20
94,65a1050ca5b8f072000021af,13f653a1-bff4-06dc-fcaa-fca6a3a1ded6,https://media.licdn.com/dms/image/D5603AQE8TeENRxRByQ/profile-displayphoto-shrink_100_100/0/1680543445564?e=1710374400&v=beta&t=WAMISH15jy9fjUWYLao419e1ardhLWRheJTvDtJe_mU,Nathan Lambert,https://www.linkedin.com/in/ACoAAA5gPQwBYcNPOvXhgmD7ZRl_C4vL6hWnvjM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA5gPQwBYcNPOvXhgmD7ZRl_C4vL6hWnvjM,"
ML Scientist at AI2
","
Chatting with a few researcher friends, we put together a hypothesis so coherent around Q* (OpenAI's rumored new super-powerful reasoning method) that I couldn't not share.The recipe, from four papers / ideas in LLMs:1. Tree of Thoughts reasoning: something to search over / generate data 2. Process reward models: rank all the steps of reasoning3. GPT4 to label all vertices of the tree (and create reward data)4. Q-learning to optimize your base model to incredible new abilitiesWho's going to be the first to implement this in open source?Read the full story here:

          ‚Ä¶see more
        


The Q* hypothesis: Tree-of-thoughts reasoning, process reward models, and supercharging synthetic data
",,https://www.linkedin.com/feed/update/urn:li:activity:7133823380625006592?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7133823380625006592%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQHapF4PwaYG9A/articleshare-shrink_800/0/1704949865386?e=1705658400&v=beta&t=qfEH3b_8wlgLWIXKdqRVBcNKTdRRWDOI0jNTYssJPKY
95,65a1050ca5b8f072000021b0,91152736-d329-6413-e468-cb145792f85d,https://media.licdn.com/dms/image/C5603AQGVJM12zNnoDQ/profile-displayphoto-shrink_100_100/0/1590996775671?e=1710374400&v=beta&t=NcFyJJBeMjtv87RWEVBsz0ws6bMGKRgSLw4snrac2ZU,Na Zhang,https://www.linkedin.com/in/ACoAAAf7Tp8B-IoQiWpFnfPSPa00MHADAPjq9sY?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAf7Tp8B-IoQiWpFnfPSPa00MHADAPjq9sY,"
Senior Manager, ML Science at Amazon
","
Hiring multiple Applied Scientist interns for summer 2024 in Amazon's Selling Partner Services Machine Learning Accelerator team. Ph.D. students (3rd or 4th year) in areas such as NLP, LLM, Vision Language, Deep Learning are welcome to apply directly. For you to be considered for my team's specific openings, please also send your resume with me. Our recruiting team will reach out if there is a fit. Due to high volume of messages received, I will only reply to those who I see a fit to the role we have. Thank you!

          ‚Ä¶see more
        


2024 Summer Applied Science Internship - Machine Learning - United States, PhD Student Science Recruiting
",,https://www.linkedin.com/feed/update/urn:li:activity:7133908415919132672?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7133908415919132672%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQGF1meJSijNmg/articleshare-shrink_800/0/1705045984354?e=1705658400&v=beta&t=ZedP84tBz0xJRiKAwf6NEDPmdfMluDTopGZ39QorifQ
96,65a1050ca5b8f072000021b1,dacff866-c48b-7aeb-54f1-afa1368d0df0,https://media.licdn.com/dms/image/C4D03AQF_BuEPwgrpnA/profile-displayphoto-shrink_100_100/0/1566531996331?e=1710374400&v=beta&t=KrwAo2KKVHsdnuQ8-iVbtQu34Ny5V9D_bCki-uBSqvg,Piero Alejandro Casusol Vargas,https://www.linkedin.com/in/ACoAACtlOEUB_4lHNecDmpnbgjA3uDoJG6IVjRo?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACtlOEUB_4lHNecDmpnbgjA3uDoJG6IVjRo,"
AI Developer / Data Scientist
","
In the world of AI, OpenAI's GPTs have been a game-changer, especially in simplifying the use of RAG (Retrieval-Augmented generation) systems. Prior to the advent of GPTs, deploying and maintaining RAG systems was a relativelly complex task, reserved for those with deep technical expertise.My latest article sheds light on this transformation. I take you through the journey of building a basic RAG system and then comparing it with a custom GPT. This exploration reveals how GPTs are revolutionizing the way we design systems to deliver tangible business value.https://lnkd.in/eDfDaDDB#GPTs #RAG #generativeai #ai #artificialintelligence

          ‚Ä¶see more
        


Implementing RAG with Vue3, FastAPI and Qdrant and how is this compared to OpenAI GPT‚Äôs
",,https://www.linkedin.com/feed/update/urn:li:activity:7133140158681346048?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7133140158681346048%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQEfHYgt_dDSQA/articleshare-shrink_800/0/1704310861207?e=1705658400&v=beta&t=gPWxNzH0Xxfy_BmyRx0GWOZv-Py1jOJeViorJF27F5E
97,65a1050ca5b8f072000021b2,d430c4e2-2775-d760-d51e-c9478dba9a17,https://media.licdn.com/dms/image/D4D03AQFpramTnkoElw/profile-displayphoto-shrink_100_100/0/1670580633493?e=1710374400&v=beta&t=S032I_0r57qA_Thm98T7Xu_Nn46maV3uUmXnh4kYuiU,Bruno Neri,https://www.linkedin.com/in/ACoAAABlS2EBjKE-dekAzG21UIzH0d46NEotnuQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAABlS2EBjKE-dekAzG21UIzH0d46NEotnuQ,"
Technical Leader - Artificial Intelligence and Deep Learning Enthusiast - Senior Software Engineer at ALTEN Italia
","
""The Bayesian Learning Rule"" by Mohammad Emtiyaz Khan et al.""We show that many machine-learning algorithms are specific instances of a single algorithm called the Bayesian learning rule. The rule, derived from Bayesian principles, yields a wide range of algorithms from fields such as optimization, deep learning, and graphical models. This includes classical algorithms such as ridge regression, Newton's method, and Kalman filter, as well as modern deep-learning algorithms such as stochastic gradient descent, RMSprop, and Dropout. The key idea in deriving such algorithms is to approximate the posterior using candidate distributions estimated by using natural gradients. Different candidate distributions result in different algorithms and further approximations to natural gradients give rise to variants of those algorithms. Our work not only unifies, generalizes, and improves existing algorithms, but also helps us design new ones.""Paper: https://lnkd.in/dUj3YpG2#machinelearning 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7132351600597024768?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7132351600597024768%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQGlfVChgQ43nQ/feedshare-shrink_480/0/1700485133085?e=1707955200&v=beta&t=xzTr-NTJQUy2GplwiapZmIDQS3EXge_vRjmmZY2_bnk
98,65a1050ca5b8f072000021b3,a31a0053-838a-a0c7-1dc1-3c6870a9f877,https://media.licdn.com/dms/image/C4D03AQFgT1ZKRV3P5w/profile-displayphoto-shrink_100_100/0/1517036059629?e=1710374400&v=beta&t=8QW7vtEZUiFdtf9B0P387hyJWUdNA34fRzARP14dVxQ,Deepak Gupta,https://www.linkedin.com/in/ACoAAATmxdkBAU5FyX-L-Cu0WAEnG1I5ebYLN1c?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAATmxdkBAU5FyX-L-Cu0WAEnG1I5ebYLN1c,"
Senior Manager, Applied Science at Amazon
","
Hi All - I am proud to share that our paper ""Efficient Expansion and Gradient Based Task Inference for Replay Free Incremental Learning "" has been accepted at WACV 2024. Thanks to my brilliant co-authors - Vinay Kumar Verma and Soumya RoyIn this paper, we propose a simple but highly efficient expansion-based model for continual learning. Our work proposes a simple filter and channelexpansion-based method that grows the model over the previous task parameters and not just over the global parameter. Therefore, it fully utilizes all the previously learned information without forgetting, which results in  better knowledge transfer

          ‚Ä¶see more
        


WACV 2024 Paper on Continual Learning
",,https://www.linkedin.com/feed/update/urn:li:activity:7133076070836109312?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7133076070836109312%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D1FAQEWiaTc07RdPg/feedshare-document-cover-images_480/0/1700657819997?e=1705658400&v=beta&t=DWRKLqSR8hKHAhywG6tnAcSsnxZfPWAZ02V9W2mgcvE
99,65a1050ca5b8f072000021b4,6aa151a6-36f9-2b7c-c8fc-d522d7ef081c,https://media.licdn.com/dms/image/D5635AQEBzEFRC2EzLg/profile-framedphoto-shrink_100_100/0/1704907585971?e=1705658400&v=beta&t=x71pDAJzCbSPZxvt91sIkpmEr_5_pGLZIt6VZgw5eV0,Aman Chadha,https://www.linkedin.com/in/ACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU,"
GenAI Leadership @ Amazon AWS ‚Ä¢ Stanford AI ‚Ä¢ EB-1 ""Einstein Visa"" Recipient/Mentor ‚Ä¢ Ex-Ô£ø, Amazon Alexa, Nvidia, Qualcomm ‚Ä¢ EMNLP 2023 Outstanding Paper Award
","
üìù GenAI Notebooks for Practical Use-cases: From Data to Model to Serving‚Ä¢ For data enthusiasts, developers, and AI aficionados looking to upskill, these free notebooks will help you learn how to supercharge your apps with #GenAI.‚Ä¢ Embark on a journey of learning in-demand skills related to data science and AI with these notebooks that cater to industrial use-cases.1. Build LLM Apps that Can See, Hear, Speak: https://lnkd.in/gaf2ab_W2. Retrieval Augmented Generation (RAG)-based Question-Answering Pipeline: https://lnkd.in/g_BCvzW23. Semantic Search with OpenAI Embeddings: https://lnkd.in/gdV94aWR4. A Simple Movie Recommender System: https://lnkd.in/gKghXp8s5. Ingesting Real-time Data from the International Space Station (ISS) using Kafka Pipelines and Query Tuning: https://lnkd.in/gF59-DTk6. Celebrity Image Matching with SQL: https://lnkd.in/gEZB-VdY7. Resume Evaluator: https://lnkd.in/gwa6QCx68. Comparative Analysis of Performance between MongoDB Atlas v/s SingleStore Kai: https://lnkd.in/gYQHkNVB9. Getting Started with Data Frames in SingleStoreDB: https://lnkd.in/gwHhYmyM10. Working with Numpy Vector Data: https://lnkd.in/gcJbwP5x#artificialintelligence #machinelearning #ai #ml

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7133322669839589376?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7133322669839589376%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHBe8cRlf8MXw/feedshare-shrink_480/0/1700716653926?e=1707955200&v=beta&t=5ncc3gHoyxN-WvTRPDAzDONDCEJH28ICGQGpdWL-04M
100,65a1050ca5b8f072000021b5,7b8b590e-964d-6e0c-82a5-240f3911c233,https://media.licdn.com/dms/image/C5603AQGqRZ2wBIapCQ/profile-displayphoto-shrink_100_100/0/1589738228802?e=1710374400&v=beta&t=xU4uvowOd9l3-rYyyxt20N8NCSIa2O37mL4Oq5j1zv8,Darien Schettler,https://www.linkedin.com/in/ACoAABJO87QBkQrt1OxOpzrZl3KuFt3m7nawIGs?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABJO87QBkQrt1OxOpzrZl3KuFt3m7nawIGs,"
| Generative AI Architect at VMware - Staff II (L6) | 2x Kaggle Grandmaster | TKS AI Mentor |
","
Day 7.5 - LLM-Focused Research Paper ChallengeSo today is a bit different, I wanted to share a Google Colab Notebook I worked on that explored RAG (Retrieval Augmented Generation) and the RAGAS framework that helps with the evaluation of said systems. Doing real implementations of things really helps me learn, and in this case, while it's not perfect, I wanted to share that.Colab Link (feel free to copy and play!):https://lnkd.in/eEu5xzAuI will be back to research papers tomorrow for day 8. Side note: I wrote a full post here and accidentally deleted it, so I'm going to keep this brief as it's getting late...The notebook I shared covers some educational content and then dives into setting up a RAG tool that we can then use and evaluate via RAGAS. One thing I did (I think it's neat) was to make the RAG tool dynamic in its sourcing. i.e. Instead of pulling from a static document source, it uses Wikipedia (realtime) and DuckDuckGo (realtime) to search your question before scraping, chunking, and embedding that into a vectorstore for subsequent retrieval and generation.At the end, I also created a basic little Agent that uses that RAG tool as well as a Review tool to make sure the RAG addressed the user's question. This is all a bit messy and I'm definitely feeling the time crunch lately, but I hope you find this a little helpful. RAGAS Note: While anecdotes are not evidence, I found the RAGAS tool to be hit or miss. There are some issues with Context Relevancy, but I noticed a Github issue addressing this. In general, it certainly seems like a good starting point and I can really appreciate the effort. I'm certain it will continue to improve and I will be staying appraised of the development of the project.Notion Page: https://lnkd.in/gWhgRrXW

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7132549898784104448?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7132549898784104448%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQFD5BmsCDWRug/feedshare-shrink_480/0/1700532410591?e=1707955200&v=beta&t=RWjbf1UxG1mMJKBfgUfRW48XA6JZ0MGFFpC74AatF74
101,65a1050ca5b8f072000021b6,ce3decdb-2d8e-33ed-1edf-335ffda771cc,https://media.licdn.com/dms/image/D5603AQGgKMh7qt3BaQ/profile-displayphoto-shrink_100_100/0/1684715779373?e=1710374400&v=beta&t=lU11cNYnEyhJCLyqUrMHfim2XPV-S6RRNUKfMouztSs,Sahar Mor,https://www.linkedin.com/in/ACoAAAghAr0B3tunEx7sW1oXU31EBb8i9l-v4ac?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAghAr0B3tunEx7sW1oXU31EBb8i9l-v4ac,"
I help researchers and builders make sense of AI | ex-Stripe | aitidbits.ai | Advisor
","
Stop compromising between speed and memory with LLMs. This new open-source package delivers both with up to 24x higher throughput.vLLM is an open-source package for high-throughput and memory-efficient inference.The secret sauce? PagedAttention - an attention algorithm inspired by the classic idea of virtual memory and paging in operating systems.Key features:1. Unmatched inference speed and efficient memory management thanks to PagedAttention2. Flexible integration with popular Hugging Face models (BLOOM, Vicuna, LLaMA 2, and more)3. Supports streaming outputsAchieve up to 24x higher throughput without making major changes to your architecture.GitHub repo (9k stars) https://lnkd.in/gmK6p74f‚ÄîJoin thousands of world-class researchers and engineers from Google, Stanford, OpenAI, and Meta staying ahead on AI http://aitidbits.ai

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7129852935919828992?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7129852935919828992%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQGkhm_AgCjkiw/feedshare-shrink_480/0/1698809405409?e=1707955200&v=beta&t=8ebvByoUjxQRJ1rEb6nW1TkY3tR7AXDK1xcZiLy-uJM
102,65a1050ca5b8f072000021b7,d3cdb905-3cf8-c0c5-0a23-acaee06f3c7c,https://media.licdn.com/dms/image/C4D03AQEmDwFNREkaIA/profile-displayphoto-shrink_100_100/0/1517524291944?e=1710374400&v=beta&t=9H8wRu-S3Mr0BN5zZEZBtWwefLpa0ZU_FPNQ9dTlNws,Robin Gras,https://www.linkedin.com/in/ACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ,"
Professor at University of Windsor, CSO and partner at Movyl Technologies and MVYL Associates
","
‚ÄúCapabilities like AutoGen are poised to fundamentally transform and extend what large language models are capable of. This is one of the most exciting developments I have seen in AI recently.‚Äù
 

AutoGen: Enabling next-generation large language model applications
",,https://www.linkedin.com/feed/update/urn:li:activity:7126564402278924288?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7126564402278924288%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQHuxpnMROLxCA/articleshare-shrink_800/0/1704271702848?e=1705658400&v=beta&t=dpxQsJ18lxOl9e-FbH8WHMG3AtudnA9Iqnzkkownx4s
103,65a1050da5b8f072000021b8,eef2eb7a-0188-aa76-6943-156c422882ee,https://media.licdn.com/dms/image/D5603AQGgKMh7qt3BaQ/profile-displayphoto-shrink_100_100/0/1684715779373?e=1710374400&v=beta&t=lU11cNYnEyhJCLyqUrMHfim2XPV-S6RRNUKfMouztSs,Sahar Mor,https://www.linkedin.com/in/ACoAAAghAr0B3tunEx7sW1oXU31EBb8i9l-v4ac?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAghAr0B3tunEx7sW1oXU31EBb8i9l-v4ac,"
I help researchers and builders make sense of AI | ex-Stripe | aitidbits.ai | Advisor
","
The death of data entry is near.The release of multimodal models like GPT-4V and LLaVA marks a new era in AI.These models can understand and process images, text, and more. In my latest blog post, I share a series of hands-on experiments using GPT-4V for document processing tasks like OCR, visual question answering, and converting images to structured JSON data.The results are mind-blowing. GPT-4V can extract fields from forms and tables, read handwritten text, and convert multi-page documents into structured data from medical forms, invoices, and research papers.I have been in the document processing space since 2016, when I joined an accounting AI startup, and later started my own Document Intelligence API venture in 2020. The space has undergone a massive transformation.What used to require teams of data scientists and millions in funding can now be achieved with off-the-shelf models. Of course, building production-level systems requires more validation and safety nets. But these experiments demonstrate how multimodal AI models like GPT-4V could revolutionize and potentially make obsolete an entire industry built around manual data processing.Blog post https://lnkd.in/gkZKpS5E

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7124765643026956288?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7124765643026956288%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQEduYp1ytKUlQ/feedshare-shrink_480/0/1698643156536?e=1707955200&v=beta&t=pZS0Q511_GeynA-WPsszT8ovhafIm-78KaY4NKrR6EE
104,65a1050da5b8f072000021b9,3404df2f-f754-3344-ff99-cc2b13604b84,https://media.licdn.com/dms/image/D4D35AQG2dF-l_p_oTw/profile-framedphoto-shrink_100_100/0/1701088205708?e=1705658400&v=beta&t=C-i12ak-Z9SHLoGkrrzXmSdlrLwBi4UFU5s87AxsiM8,Daniel Horak,https://www.linkedin.com/in/ACoAAAhMAhoBhfG2_BqRkYo8K0byhlFYMaVepsU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAhMAhoBhfG2_BqRkYo8K0byhlFYMaVepsU,"
Co-Founder | Building the future of corporate funding!
","
How Investors Assess Your Company üí°Are you considering equity financing to fund your business expansion?When assessing the potential of a business, investors look for certain indicators that signal its prospects.Some of the leading considerations include:Financial healthProfitabilityStrength of the management teamMarket opportunities and risksHowever, the final assessment can be quite specific to a single business while also dependent on external factors (e.g. the competition or the macroeconomic environment). In short: it can get complicated.Thus, you should understand how potential investors will assess you so you can:- Make any important business adjustments (if needed)- Position yourself optimally and inspire your marketing collateral- Intelligibly lead the stakeholder conversations while understanding your worthTo help you get started, check out the attached scorecard from the Eloquens.com team to help guide the information you should be armed with. üëáP.S. Are you looking for equity financing with added benefits like increased brand awareness and retention of company control? Check out CONDA Crowdinvesting - a digital investment alternative that helps businesses scale.#SMEs #Investors #Financing

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7127996304244232193?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7127996304244232193%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQGYgHcclV1TKg/feedshare-shrink_480/0/1699446749966?e=1707955200&v=beta&t=8kypcz919Z2v2PIt03vSbMlC3A_EeA69f5um4HT4fBc
105,65a1050da5b8f072000021ba,39b9083d-f434-9778-19a9-29f486a579bc,https://media.licdn.com/dms/image/D4D03AQFpramTnkoElw/profile-displayphoto-shrink_100_100/0/1670580633493?e=1710374400&v=beta&t=S032I_0r57qA_Thm98T7Xu_Nn46maV3uUmXnh4kYuiU,Bruno Neri,https://www.linkedin.com/in/ACoAAABlS2EBjKE-dekAzG21UIzH0d46NEotnuQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAABlS2EBjKE-dekAzG21UIzH0d46NEotnuQ,"
Technical Leader - Artificial Intelligence and Deep Learning Enthusiast - Senior Software Engineer at ALTEN Italia
","
""An Introduction to Transformers"" by Richard Turner""The transformer is a neural network component that can be used to learn useful representations of sequences or sets of data-points. The transformer has driven recent advances in natural language processing, computer vision, and spatio-temporal modelling. There are many introductions to transformers, but most do not contain precise mathematical descriptions of the architecture and the intuitions behind the design choices are often also missing. Moreover, as research takes a winding path, the explanations for the components of the transformer can be idiosyncratic. In this note we aim for a mathematically precise, intuitive, and clean description of the transformer architecture. We will not discuss training as this is rather standard. We assume that the reader is familiar with fundamental topics in machine learning including multi-layer perceptrons, linear transformations, softmax functions and basic probability.""Paper: https://lnkd.in/dUri_xhW#transformers 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7128074025636888577?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7128074025636888577%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQFHw7h7k0hhhw/feedshare-shrink_480/0/1699465279784?e=1707955200&v=beta&t=gTwGkTxo2vXAQP4LSxO1iGlrNMnkLfwKHgf6KBH2Fjg
106,65a1050da5b8f072000021bc,819b6085-11b3-c39a-59ab-3f6ec7f3f883,https://media.licdn.com/dms/image/D5603AQHxUzqt5ibu8Q/profile-displayphoto-shrink_100_100/0/1670820076513?e=1710374400&v=beta&t=jDLfZwZFFu2iGz5MnJjGW-UsIgg6W6Y2_uU05Hzvakw,Michael Galkin,https://www.linkedin.com/in/ACoAABQJ9wsBGHSNQWOUK2OVHWIhE26F7icbcLc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABQJ9wsBGHSNQWOUK2OVHWIhE26F7icbcLc,"
AI Research Scientist at Intel AI Lab | Graph ML & GNNs & Knowledge Graphs & ML
","
In our new Medium blog post with Xinyu Yuan, Zhaocheng Zhu, and special guest Bruno Ribeiro we explore - the theory of inductive reasoning - foundation models for KGs- and explain our recent ULTRA in more detail!https://lnkd.in/geygEayh

          ‚Ä¶see more
        


ULTRA: Foundation Models for Knowledge Graph Reasoning
",,https://www.linkedin.com/feed/update/urn:li:activity:7126280543498903552?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7126280543498903552%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQFyBdTbWWWF2Q/articleshare-shrink_800/0/1703949101178?e=1705658400&v=beta&t=mHaijbN7M5Fr5W6s6dCDBhNA_xzufZ66-Ip0YOe6yMg
107,65a1050da5b8f072000021bb,5459c688-6267-ab31-9d77-eff6bb07da84,https://media.licdn.com/dms/image/C5603AQHS6rJfWq9pew/profile-displayphoto-shrink_100_100/0/1517655569573?e=1710374400&v=beta&t=95Z2gfDdqgP3yTunJw8wBE5Z2tJoOyvUynu8y0Zsaso,Justin Basilico,https://www.linkedin.com/in/ACoAAAGqMQ8BOBFwt5lFsr3GtVfvv-cf7NI0DC0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAGqMQ8BOBFwt5lFsr3GtVfvv-cf7NI0DC0,"
Director - Machine Learning and Recommender Systems at Netflix
","
We're now accepting applications for Machine Learning research internships at Netflix Research for summer 2024, including in our personalization, recommendations, and search teams. Find out more and apply here: https://lnkd.in/gsY722K3 #netflix #machinelearning #research #personalization #recsys

          ‚Ä¶see more
        


Machine Learning Intern, Research
",,https://www.linkedin.com/feed/update/urn:li:activity:7125990296940662784?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7125990296940662784%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/C5627AQHih-g40m78ZA/articleshare-shrink_800/0/1703990282670?e=1705658400&v=beta&t=9C-4xGMKnsMaFw62jpMXDviTIZBv97f67saTcE61ko8
108,65a104d6a5b8f0720000215b,5c72ab9e-d36b-52b1-cc9c-edb58d6ad930,https://media.licdn.com/dms/image/D4D03AQH1jwTZYuaUcA/profile-displayphoto-shrink_100_100/0/1670679538725?e=1710374400&v=beta&t=sGtcG8jNPBO8khpCverWqJBUGeSdeP1vfkcLlKvRbOg,Pascal Biese,https://www.linkedin.com/in/ACoAACOuW9cBGe8UMxy2NSSkLE3bSdlcrAnh9YA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACOuW9cBGe8UMxy2NSSkLE3bSdlcrAnh9YA,"
Daily LLM Research Nuggets for 22k+ Experts üì≤ü§ó | AI/ML Engineer | NLP
","
30+ Strategies to Mitigate Hallucinations ‚öñ A major obstacle stands between the current capabilities of Large Language Models (LLMs) and their safe application in real-world settings‚Äîhallucination, the generation of plausible-sounding but factually inaccurate content. This challenge takes on critical significance when considering the deployment of LLMs in high-stakes domains like healthcare and finance.This latest paper delves into the issue of content hallucination in LLMs, offering an overview of more than 30 strategies devised to tackle this problem. As LLMs become more fluent, ensuring the factual integrity of their generated content is paramount for safe integration into sectors where accuracy is non-negotiable.The authors propose a comprehensive taxonomy of the various approaches, effectively mapping out the landscape of current interventions. Techniques range from Retrieval Augmented Generation (RAG) to advanced Knowledge Retrieval strategies and feedback mechanisms designed to keep model outputs in check.For the full taxonomy, check out the original paper below.[arXiv] https://lnkd.in/dvGxZqAj‚ÜìLiked this post? Get weekly AI highlights and papers-of-the-week directly to your inbox üëâ llmwatch.com

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7150079220990238721?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7150079220990238721%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQFj7lJNCNXVYg/feedshare-shrink_480/0/1704711727142?e=1707955200&v=beta&t=FOENGaiCD4o3DzTw-62KhQxbPs5hz24a7jNXCbqxBfU
109,65a1050da5b8f072000021be,58043343-c8b5-819f-4092-0948374235b7,https://media.licdn.com/dms/image/D5603AQEH_7ZzFaFU_g/profile-displayphoto-shrink_100_100/0/1683156131600?e=1710374400&v=beta&t=gIBhSzXj4Jf3JgPbrGnuZqlC6wXCYJ-8k5czwHsY_0Y,Yujian Tang,https://www.linkedin.com/in/ACoAABUawOcBrH3l91Q3Fay4MG8nNKONmcAUO-I?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABUawOcBrH3l91Q3Fay4MG8nNKONmcAUO-I,"
Developer Advocate at Zilliz (creators of Milvus, world's most popular open-source vector database)
","
Have you tried out any of the open source LLMs? They're pretty tough to run locally unless you have a LOT of compute and memory. The base 16GB Mac M1 can barely handle the 4-bit quantization of Llama2Yi Ding and I were talking about using Llama 2 with LlamaIndex and The Milvus Project to build RAG apps a couple weeks back and we found out the hard way üòÇ. As open source supporters we want to use some more open source tools to build retrieval apps on top of LLMs.Just today, I found out about LLMWare's models on Hugging Face by AI Bloks which are pretty cool and might be a viable solution for your open source LLM solution. Check it out!If you want to dive deeper into this stuff live, I'll be talking about more advanced RAG considerations tomorrow, 11/2, at Cloudera Evolve in NYC, on Deepchecks webinars on Monday 11/6, and again in Seattle on 11/7! RSVP links below :)

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7125557525210427392?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7125557525210427392%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQFu0Jh0_0Zl-Q/feedshare-shrink_480/0/1698865299561?e=1707955200&v=beta&t=QjmdhnBj4JaHcjHPn72XFZb916eB5too3i0pof2QEnM
110,65a1050da5b8f072000021bf,677784c2-da26-5375-e206-16f7084956ef,https://media.licdn.com/dms/image/D5603AQE8TeENRxRByQ/profile-displayphoto-shrink_100_100/0/1680543445564?e=1710374400&v=beta&t=WAMISH15jy9fjUWYLao419e1ardhLWRheJTvDtJe_mU,Nathan Lambert,https://www.linkedin.com/in/ACoAAA5gPQwBYcNPOvXhgmD7ZRl_C4vL6hWnvjM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA5gPQwBYcNPOvXhgmD7ZRl_C4vL6hWnvjM,"
ML Scientist at AI2
","
New paper! Why our current RLHF methods do not quite align with our actual goals, getting false refusals and hard to steer models: objective mismatch(s).The Alignment Ceiling: Objective Mismatch in Reinforcement Learning from Human Feedback, with Roberto Calandra - new position paper / sort of survey. RLHF design has three core components: evaluation metrics, reward model training, and policy model training. Each pair of these three carries heavy assumptions on ""how it should work"", resulting in many messy practices.1. Reward model training ‚ÜîÔ∏è policy model training: Reward hacking, overoptimization, etc (pretty well known).2. Reward model training ‚ÜîÔ∏è evaluation tools: Is our reward model even a good reward function?3. Policy model training ‚ÜîÔ∏è evaluation tools: Are we even correctly evaluating RLHF trained models?And of course, we propose plenty of areas for research to solve this: * reward model evaluation, * reward model training, * reward model dataset design, * value-guided sampling, * human-centric evaluation, * new RL optimizers, * and other topics.Yes, I've finally come full circle from my Ph.D. thesis.Read it here: https://lnkd.in/eMWD_9_P

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7125865944001716225?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7125865944001716225%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQHFclBUiL_LNw/feedshare-shrink_480/0/1698938831655?e=1707955200&v=beta&t=2zJpmjnTbZA52SdlE-d-OxtfRtV1kG3W2vVyfP7OgeU
111,65a1050da5b8f072000021c0,0995e55e-8fd8-4cc0-bcc4-e29b5af440da,https://media.licdn.com/dms/image/C4E03AQH1R8VSQ8zWeQ/profile-displayphoto-shrink_100_100/0/1529085386349?e=1710374400&v=beta&t=oVdg7onenlB6_-uCZkp0jDp8RKG_KW6_titqITHxExI,Mark Roy,https://www.linkedin.com/in/ACoAAAAenagBMCB87GJvsVYAWi-Yc5e12t5Urjo?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAAenagBMCB87GJvsVYAWi-Yc5e12t5Urjo,"
ML - GenAI - Lead Solution Architect - Amazon Bedrock
","
It‚Äôs fun seeing all the creative ways customers use Amazon Bedrock in real apps to add real value to real businesses. Sure, LLMs write good poems‚Ä¶ but isn‚Äôt it much more exciting that Bedrock helps customers integrate apps and dramatically improve productivity of their employees?Check out this cool post by SnapLogic, explaining how Bedrock and Anthropic Claude combine to easily create new integration pipelines, generate complex SQL queries and more. Every day brings a new story like this one. Bedrock is just getting started. Stay tuned. Clay Elmore, nice work!#genai #generativeai #aws #bedrock #amazonbedrock #claude #anthropic

          ‚Ä¶see more
        


SnapLogic Leverages Amazon Bedrock to Make Anthropic‚Äôs Model Claude Available in SnapGPT
",,https://www.linkedin.com/feed/update/urn:li:activity:7125657094241837056?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7125657094241837056%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQH7La3Ts2Y72w/articleshare-shrink_800/0/1704943419915?e=1705658400&v=beta&t=570HaI53Vnw6D2w3oheOIW9_VxkKNZ7r99YlIP-QRrk
112,65a1050da5b8f072000021c1,b5ce39f9-9dd5-08d9-d0b0-d9e4d04e99d8,https://media.licdn.com/dms/image/D5603AQE8TeENRxRByQ/profile-displayphoto-shrink_100_100/0/1680543445564?e=1710374400&v=beta&t=WAMISH15jy9fjUWYLao419e1ardhLWRheJTvDtJe_mU,Nathan Lambert,https://www.linkedin.com/in/ACoAAA5gPQwBYcNPOvXhgmD7ZRl_C4vL6hWnvjM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA5gPQwBYcNPOvXhgmD7ZRl_C4vL6hWnvjM,"
ML Scientist at AI2
","
""What should companies that care about Open LLMs do?""This is the most common question I get when advocating for openness, so I put together a short guide. Open LLM company playbookWhere does releasing model weights fit into company strategy? 3 requirements, 3 actions, and 3 benefits of being in the open LLM space.Read it here: https://lnkd.in/gvVTSq5vOr, in short...Prereq's:1. Have a niche 2. Train good models3. Have a technical team that interfaces with the communityActions:1.  Release model weights (duh)2. Get a specific data pipeline, don't release on-domain data3.  Extensively benchmark price and performance vs. closed modelsBenefits:1. Crowdsourced evaluations (capabilities and inference) improve models2. Crowdsourced use cases build product leads3. Good PR: Recruiting, values, vibes, etcPlus, some hot takes and examples of where this is going well (or not)!

          ‚Ä¶see more
        


Open LLM company playbook
",,https://www.linkedin.com/feed/update/urn:li:activity:7125477962761605120?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7125477962761605120%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQHKxcXdEqqUQw/articleshare-shrink_800/0/1704604926436?e=1705658400&v=beta&t=tXrZt1wDiZLosVx27apraSRxCDgIjpOMdfhMfHezY7Q
113,65a1050da5b8f072000021c2,420b1ab5-6e92-dade-a60f-e6f71500238f,https://media.licdn.com/dms/image/C4E03AQFMSYCZozCQAg/profile-displayphoto-shrink_100_100/0/1597352526698?e=1710374400&v=beta&t=Po9GOfRqQ1vLqgh84t9vy2OEZKLGqRHeMQHZF68vhCE,Jingjing Cannon,https://www.linkedin.com/in/ACoAAAUQxQ4BsHpWXvJzVSBF9zn3rvW73RVu5Ac?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAUQxQ4BsHpWXvJzVSBF9zn3rvW73RVu5Ac,"
Machine learning engineer
","
Happy Friday! I am hiring a Machine Learning Engineer III (Framingham, MA). I am looking for someone with working experience and expertise in NLP, LLMs and Generative AI; leadership skills and mentoring experience a big plus. Please apply through the link below:

          ‚Ä¶see more
        


Software Engineer III - Machine Learning job in Framingham, Massachusetts, United States | Technology jobs at Staples
",,https://www.linkedin.com/feed/update/urn:li:activity:7123691930307186689?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7123691930307186689%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQHsRpeVa2MTXA/articleshare-shrink_800/0/1704501853804?e=1705658400&v=beta&t=-AmIQvCggVdpTD-yp1NuCFICEa2MfVxe0_aLk7gnar4
114,65a1050da5b8f072000021c3,0c1f9c3f-54fb-5d6b-3a5c-8ab1b04f090b,https://media.licdn.com/dms/image/D5603AQFnPITypDbXvg/profile-displayphoto-shrink_100_100/0/1683560613868?e=1710374400&v=beta&t=XxcKRh4bn6MMMrGK3Id1FStwk9RPA2NRuBsPuj2x9iU,Tosan E.,https://www.linkedin.com/in/ACoAAAuDeV0BEoY0sgTtjteyrpBpPQ4dRLRJZCI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAuDeV0BEoY0sgTtjteyrpBpPQ4dRLRJZCI,"
Recruiting
","
Are you passionate about advancing the frontiers of Artificial Intelligence and Machine Learning? Ready to embark on a transformative journey that could redefine the future of AI? If so, we have some thrilling news to share!The Apple AIML Residency is thrilled to open its doors for applications for the 2024 cohort. This one-year program is tailor-made to offer a unique opportunity to dive into the world of interdisciplinary collaboration and apply it to create innovative, ML-based solutions to tackle the most complex and pressing challenges of our time.For more information about this program and to apply, go to the link attached.https://lnkd.in/gdeE4szG#apple #aiml #aimlresidency 

          ‚Ä¶see more
        


The 2024 AI/ML Residency Program Application is Now Open
",,https://www.linkedin.com/feed/update/urn:li:activity:7123333809080582144?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7123333809080582144%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQG33e34_xZd0A/articleshare-shrink_800/0/1704832858331?e=1705658400&v=beta&t=1WfYMKbhEz_xdCIRhi59fqLZCy2lj81bEwBKgyX-qb0
115,65a1050da5b8f072000021c4,e67edda4-61ac-f6a8-a85f-5f6df33b211a,https://media.licdn.com/dms/image/C4E03AQGfzEtRhrPHdw/profile-displayphoto-shrink_100_100/0/1619776973437?e=1710374400&v=beta&t=y9up1yBFMNfTMJvaDgcupbnl3OnJC7EgkzWAkOY4pyM,Sanyam Bhutani,https://www.linkedin.com/in/ACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0,"
Senior Data Scientist at H2O.ai | Kaggle Grandmaster
","
The definitive guide to RAG in production! üôèGoku Mohandas updated his guide to building RAG Applications for Production. The guide walks through an implementation from scratch, builds a scalable system. It now has a discussion on when to fine-tune embeddings, re-ranking retrieved context and effectively route requests.I think this is easily the most thorough discussion on an end-to-end RAG application. A perfect weekend study to follow along:https://lnkd.in/d--k3d3m

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7124059866867900416?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7124059866867900416%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQHZZe7IJS4naw/feedshare-shrink_480/0/1698508229845?e=1707955200&v=beta&t=VSPecwok3H1DjF8gNWk5rvAohVnHXE1nl6XIvUriZ3c
116,65a104d5a5b8f07200002152,2fd4bb90-07af-a43e-fe7d-f69423c7220f,https://media.licdn.com/dms/image/C4E03AQHXCHWaNFfffQ/profile-displayphoto-shrink_100_100/0/1520866735377?e=1710374400&v=beta&t=l1p1OlVSaho9plyRJ9ECfHeub8U66DxMtst_7E8RJF0,"Steven Murphy, PhD, ICD.D",https://www.linkedin.com/in/ACoAAA2s_-ABOCToivzxfqW9sV-oUlcP9UxtIJM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA2s_-ABOCToivzxfqW9sV-oUlcP9UxtIJM,"
President and Vice Chancellor, Ontario Tech University
","
So many Ontario Tech University alumni, faculty, students and staff are making the world a better place through technology. Hamayal Choudhry‚Äôs smart arm was born at Ontario Tech to provide a better prosthetic at a much more affordable price. Tech with a conscience isn‚Äôt a slogan: it‚Äôs impacting real people and our planet tangibly. The identified ‚Äòproblem‚Äô was an ethical one, and this happens everyday in research labs from engineering to social science and humanities to health sciences and more. Here‚Äôs to 2024 and making a world that needs it, a much better place! üëèüèªüëèüèªüëèüèªüçæüéâ

          ‚Ä¶see more
        


smartARM‚Äôs story begins at Ontario Tech University
",,https://www.linkedin.com/feed/update/urn:li:activity:7147985363670642688?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7147985363670642688%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5610AQGoLZ0P_uzy7w/image-shrink_1280/0/1704211530530?e=1705658400&v=beta&t=I8g-Ubwk5TFzvaMSoG4mDssIIbqC3NXAzzYG31ujlBU
117,65a1050da5b8f072000021c6,29834db9-fc1e-e560-8413-ac626633074c,https://media.licdn.com/dms/image/C4E03AQHX_QT1wNPm_Q/profile-displayphoto-shrink_100_100/0/1576101447245?e=1710374400&v=beta&t=aoMtcvN2ijjHmjnKpZhqr7TT9tW4qPATuYWd-3ZreyI,Dimitrios Adamos,https://www.linkedin.com/in/ACoAAAD3MmcBhHbO3d0Gj8sQd1p8WttgmHckZJQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAD3MmcBhHbO3d0Gj8sQd1p8WttgmHckZJQ,"
Co-Founder and CTO at Cogitat
","
Excited to share my interview with Interesting Engineering on applying graph theory and neural networks to decipher brain signals. It was a pleasure speaking about our work at Cogitat and the future of brain-computer interfaces. Read more through the link below:https://lnkd.in/dBM2Q2dQ#BCIs #Neurotech

          ‚Ä¶see more
        


Is graph theory the key to understanding the brain?
",,https://www.linkedin.com/feed/update/urn:li:activity:7123223894517329920?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7123223894517329920%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQFQ_cDak9wFVA/articleshare-shrink_800/0/1704361766250?e=1705658400&v=beta&t=WsKjbGSF36MKER5KUMGydphbGJC4u9N6Go9ezWplxLk
118,65a1050da5b8f072000021c5,c8895653-932a-0bbb-7a8c-56958c67d02c,https://media.licdn.com/dms/image/C4E03AQH7AuAk618FXQ/profile-displayphoto-shrink_100_100/0/1543476872462?e=1710374400&v=beta&t=eBwtv8HU2G_PuRPAHVpvJteD3_gA3OepacBOJs3ANT4,Francois Vanderseypen,https://www.linkedin.com/in/ACoAACmsd0UBQXqNzjQkUdxThMsgx01TOIkXCRg?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACmsd0UBQXqNzjQkUdxThMsgx01TOIkXCRg,"
Graph Analytics & Visualization Consulting
","
Graph Notebook developed by @AWS is a powerful library that expands the functionality of Jupyter notebooks by seamlessly integrating with Apache TinkerPop, openCypher, and RDF SPARQL. It enables users to effortlessly work with graph data and perform complex analysis and queries. Additionally, it offers seamless integration with @MemgraphDB, further enhancing its capabilities. Explore the power of graphs with Graph Notebook and take your data analysis to the next level. Find out more at https://buff.ly/3dWi0ZN. For more information on the @MemgraphDB integration, visit https://buff.ly/3FAlxJN. #Graphs

          ‚Ä¶see more
        


GitHub - aws/graph-notebook: Library extending Jupyter notebooks to integrate with Apache TinkerPop, openCypher, and RDF SPARQL.
",,https://www.linkedin.com/feed/update/urn:li:activity:7124379761803440128?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7124379761803440128%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E10AQH8qxvTu9pJhQ/image-shrink_800/0/1698584474524?e=1705658400&v=beta&t=eKMjA3SIiTs8idLBBqRaNz1BNzHrExUnHO32SjI3CS8
119,65a1050da5b8f072000021c7,14e0e319-f838-927c-cbc8-f5108bd5466c,https://media.licdn.com/dms/image/C5103AQFW70C9gBStrQ/profile-displayphoto-shrink_100_100/0/1579090487259?e=1710374400&v=beta&t=U9odD_ylZzk18D6KyxNuyZKCfrTD0AzN4j9aqBhhUAc,Mahesh Deshwal,https://www.linkedin.com/in/ACoAACwYL58B73jCm5A2kKR6ZSHR-JWI7qoHFOk?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACwYL58B73jCm5A2kKR6ZSHR-JWI7qoHFOk,"
Open Source Contributor | NLP | Computer Vision | Deep Learning || See, Read, Test and Share so just a curious person and definitely not an influencer.
","
Been working on LLM Evaluation so sharing a list of resources on how to Evaluate, Verify and Control LLM outputs that I've found so for.  Please feel free to add morewhich I might have missed. Ideas include:Prompting (CoT, ToT, Self Verification etc)Input / Output Guard RailsSome Dedicated Libraries like: ReLM, TruLens, FLARE etcSurvey paper and Research paper linksBlogs on the sameLink to the document: https://lnkd.in/drAX54-6#nlp #llm #evaluation #ai #machinelearning #deeplearning #hallucinations #RAG #datascience

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7123163857698643969?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7123163857698643969%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQEZ5ZV5eiCjgA/feedshare-shrink_480/0/1698290422231?e=1707955200&v=beta&t=HBqevm0KMe1yLeUsZkg_FiAPGPlPfay7PHcsSzOoWx0
120,65a1050da5b8f072000021c9,a7a7640e-4038-9e4f-bb71-a21b18f8df02,https://media.licdn.com/dms/image/D4E03AQFjkgmgFOF9nA/profile-displayphoto-shrink_100_100/0/1690223575085?e=1710374400&v=beta&t=xCL0YWmMyTjyjCWXe7ZV9wY-Lr1vCHJDZPmxnk_c0C8,Alfredo Canziani,https://www.linkedin.com/in/ACoAAAd1NJ8BzBDEWLqzwZZuAY1-4P31JA9h5wE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAd1NJ8BzBDEWLqzwZZuAY1-4P31JA9h5wE,"
Assistant Professor of Computer Science at NYU Courant Institute of Mathematical Sciences
","
Yesterday I wrote two pages of maths, with upper bounds for the computation of a gradient, using Cauchy-Schwarz inequality and other ‚Äòtricks‚Äô.Today I drew a picture, which summarises two pages of equations.Although the maths was necessary, the figure is what I see in my mind.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7122677074430943232?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7122677074430943232%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQGp03VD2vTY9Q/feedshare-shrink_480/0/1698178546590?e=1707955200&v=beta&t=Jv3bYD9KE7TLrULKSDQHB5cA_-ZnHe5LacZnZTZtm88
121,65a1050da5b8f072000021ca,9af3d962-bf82-a466-63e1-a758c1ae6926,https://media.licdn.com/dms/image/D4E03AQGBsq8i5cRzlg/profile-displayphoto-shrink_100_100/0/1673018883086?e=1710374400&v=beta&t=WW14M-llAzGJWQkJhb9_V1YAVbMG4nY-wOl3oLX1EQY,Christopher Kanan,https://www.linkedin.com/in/ACoAAAGvnywBFBNzDxBYFx02Z45eggAMwdmQi6E?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAGvnywBFBNzDxBYFx02Z45eggAMwdmQi6E,"
Professor | AI Expert
","
We won a new $2M NSF award to develop methods that are more sample efficient for deep learning on temporal prediction and control problems! My lab is collaborating with the labs of Dhireesha Kudithipudi, Itamar Lerner, and Garret Rose for this exciting project.

          ‚Ä¶see more
        


Human brain‚Äôs ‚Äòtemporal scaffolding‚Äô inspires new AI approaches
",,https://www.linkedin.com/feed/update/urn:li:activity:7122573990291742720?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7122573990291742720%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQHdIm0AModF4w/articleshare-shrink_800/0/1704240112136?e=1705658400&v=beta&t=gPSLUuPfppslFiNlHCyxD8tWLOHZVrYtJs_gn4ompBU
122,65a1050da5b8f072000021cb,f1c86961-b771-224f-0033-ed85eabd3ad6,https://media.licdn.com/dms/image/D5603AQHxUzqt5ibu8Q/profile-displayphoto-shrink_100_100/0/1670820076513?e=1710374400&v=beta&t=jDLfZwZFFu2iGz5MnJjGW-UsIgg6W6Y2_uU05Hzvakw,Michael Galkin,https://www.linkedin.com/in/ACoAABQJ9wsBGHSNQWOUK2OVHWIhE26F7icbcLc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABQJ9wsBGHSNQWOUK2OVHWIhE26F7icbcLc,"
AI Research Scientist at Intel AI Lab | Graph ML & GNNs & Knowledge Graphs & ML
","
üì£New paper alert!It‚Äôs time to announce ULTRA - a pre-trained foundation model for knowledge graph reasoning that works on _any_ graph and outperforms supervised SOTA models on 50+ graphs.Arxiv: https://lnkd.in/gNknJe_QCode: https://lnkd.in/g6pB_6xQFor years, ML on knowledge graphs implied training one model per dataset and those were fixed to a particular set of entities and relations, hence not transferable at all. The key problem: different, often non-overlapping sets of entities and relations (eg, Freebase and Wikidata)Since graph learning is a question of symmetries and invariances, we pose a question: what is the transferable invariance in seemingly different graphs even with different relations? We find the invariance in relation interactions in the graph of relations!Even though relations are different, their interactions remain the same - and we model 4 such interactions (edge types) in the graph of relations. Learning those means we can have a _single_ trained model working on _any_ multi-relational graph.Practically, ULTRA consists of 2 GNNs with the labeling trick (Neural Bellman-Ford nets in our case): given a query (h,r,?),  one produces relational features conditioned on the query relation and interaction graph, the 2nd one uses those for inductive reasoning on the main graphWe pre-train ULTRA on 3 standard KGs (from Freebase, Wordnet, and Wikidata) and evaluate on 50+ other graphs of various sizes. A single ULTRA outperforms supervised SOTA even in the 0-shot regime never seeing those graphs before. Fine-tuning bumps the performance by additional 10%! We can further increase the performance by adding more diverse graphs into the pre-training mix, and it seems a promising direction for deriving scaling laws for ULTRA-like foundation models.Cool fact: it can be shown that ULTRA is a distributionally double-equivariant (to nodes and relations permutations) model - thanks Bruno Ribeiro for noticing that! Double equivariance is a theoretical framework for inductive reasoning and (probably) is a necessary condition for designing inductive neural nets. Arxiv: https://lnkd.in/gSZKSXFEULTRA wouldn‚Äôt be possible without awesome Xinyu Yuan, Zhaocheng Zhu, Hesham Mostafa, and Jian Tang! We publish the code in the latest PyG 2.4 and Torch 2.1 and also release the pre-trained checkpoints so you can run it on your own graphs right away! 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7122276891549450240?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7122276891549450240%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQGZNnFGjD0s-g/feedshare-shrink_480/0/1698083133287?e=1707955200&v=beta&t=cq736z47B4tCA2R-CP2aCblW79E6h-82la1w9wVmBSA
123,65a1050da5b8f072000021cc,a88340d9-4c09-a04c-c4ef-46ae82dfbfa7,https://media.licdn.com/dms/image/C4E03AQGfzEtRhrPHdw/profile-displayphoto-shrink_100_100/0/1619776973437?e=1710374400&v=beta&t=y9up1yBFMNfTMJvaDgcupbnl3OnJC7EgkzWAkOY4pyM,Sanyam Bhutani,https://www.linkedin.com/in/ACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0,"
Senior Data Scientist at H2O.ai | Kaggle Grandmaster
","
Insanely detailed notes from Training LLMs! üôèStas Bekman has kindly shared his field notes from working on Large Language Model projects from the ground up. These are insanely detailed and cover a lot of gotchas and caveats for anyone interested in working on foundational models.While it seems like the main audience is large research labs, I still quite enjoyed learning new ideas from the notes. These are really well written, with documented code and also linked discussions that go into a lot of depth. A great read for anyone working on LLM training:https://lnkd.in/d_86B2DE

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7122202357156765696?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7122202357156765696%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQHK1vLy2BxBsw/feedshare-shrink_480/0/1698065365134?e=1707955200&v=beta&t=OmYI45c97wGm2kPKUxTVraOKK06Kyb4Wpl6g3e8WP1g
124,65a1050da5b8f072000021ce,2deaaab3-9a60-cba9-c846-09956f19aeaf,https://media.licdn.com/dms/image/D5635AQEqHNg0bHLTNQ/profile-framedphoto-shrink_100_100/0/1703368669246?e=1705658400&v=beta&t=N2iqdqk42LGWPrtGvRRulbc2WcnNs9B43yUoIHphqXA,Hossein Aboutalebi,https://www.linkedin.com/in/ACoAABe2oQ4BB37SPJffFoc1Wba-n1b2VHptzdw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABe2oQ4BB37SPJffFoc1Wba-n1b2VHptzdw,"
Working on Multimodal LLM
","
I'm thrilled to announce that our paper titled ""COVID-Net Biochem: An Explainability-driven Framework for Building Machine Learning Models to Predict the Survival and Kidney Injury of COVID-19 Patients Using Clinical and Biochemistry Data"" has been accepted by Nature Scientific Reports.In this research, we not only explored machine learning tools such as gradient-based decision trees and deep learning models like TabTransformer for predicting the vulnerability of COVID-19 patients to kidney failure but also introduced a mechanism to tailor features and model hyperparameters in line with expert domain knowledge. This ensures that the most relevant biomarkers are utilized, enhanced by the power of explainable AI tools.I'd like to extend my heartfelt gratitude to my supervisor Alexander Wong for his invaluable guidance throughout this project. It's my sincere hope that our contributions will pave the way for more transparent and responsible AI research in the medical domain. Access the paper here: https://lnkd.in/guTYp3Wq. #covid19 #AI #healthcare #deeplearning  #decisiontree #explainableAI 

          ‚Ä¶see more
        


COVID-Net Biochem: an explainability-driven framework to building machine learning models for predicting survival and kidney injury of COVID-19 patients from clinical and biochemistry data - Scientific Reports
",,https://www.linkedin.com/feed/update/urn:li:activity:7121282816859938816?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7121282816859938816%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQEZ3OanQgyMZA/articleshare-shrink_1280_800/0/1703915274299?e=1705658400&v=beta&t=Y99wyqcKdMF7rD3OWKGdCbfiv34K7Da-PbLuWjE9Mak
125,65a1050da5b8f072000021cd,7ac6df7f-a29b-d404-9e03-3c18f7eeac10,https://media.licdn.com/dms/image/C5603AQFvncvflX_kMQ/profile-displayphoto-shrink_100_100/0/1564316873635?e=1710374400&v=beta&t=DRxjFCzRMNJSc3QM233eAmSZ8rflNQHLrn8k0KQuOhg,Elvis S.,https://www.linkedin.com/in/ACoAACxhXeUBTYZYCwIa4nsvSBsETtrS0uhGNPc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACxhXeUBTYZYCwIa4nsvSBsETtrS0uhGNPc,"
Co-Founder at DAIR.AI | Prev: Meta AI, Galactica LLM, PapersWithCode, Elastic
","
I've been exploring RAG use cases more than anything these days.This has pushed me to explore new techniques (which I post daily), and ways to improve retriever-augmented systems and tools. While there are a lot of new approaches emerging, the tooling is still under heavy development, especially on the scale and affordability side of things. Combining LLMs (closed and open-source) with external data is a powerful approach to solving all kinds of problems and building useful agents, especially for enterprises where there is a ton of data available. So it's exciting to see Abacus AI expanding its offering to cheaper inference, LLMOps APIs, and vector store APIs.For the RAG use cases, it's important to have a scalable vector store for storing and retrieving embeddings so I think that's where Abacus AI can really help developers. The vector store can store billions of embeddings, has millisecond latencies, and can deliver 100% recall. They already offer a great no-code solution for building LLM-powered chat systems but offering these solutions in the form of APIs will enable interesting knowledge-intensive applications. Learn more here: https://lnkd.in/ebn2ttRM

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7121513773198139393?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7121513773198139393%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQF_n9OBz8G9Sg/feedshare-shrink_480/0/1697901194257?e=1707955200&v=beta&t=TINPK_4enQbnkxdKCJuVqumYRNvpLG14-lDwyqzPSUI
126,65a1050da5b8f072000021cf,c4d4e644-0e1d-764a-2673-93ba8598404c,https://media.licdn.com/dms/image/C4E03AQFaUJNosx6abA/profile-displayphoto-shrink_100_100/0/1597813815880?e=1710374400&v=beta&t=u8cwbKajIj5UIPhL3_9RVsE91lQw1q8adH0UXvrVScI,Mriganka Nath,https://www.linkedin.com/in/ACoAACmutM4Bt9gXvuU_dwLWH2CdGt0Ab6jK-FE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACmutM4Bt9gXvuU_dwLWH2CdGt0Ab6jK-FE,"
GSOC 22| Research Assistant @ CISPA | UdS
","
As I was learning about LLMs I wanted to make a short project on how to use LLMs as your personal chatbot. Here I show you how you can use LLMs to answer your queries related to a PDF. As someone who needs to read a lot of research papers, it is helpful.It follows the RAG pipeline making it possible that we also know the context used by the LLM to give the response and be doubly sure about it. More here https://t.co/p5lfxIlnrq. The step-by-step code is here https://lnkd.in/e9Q58V-t (powered by Kaggle Notebooks). Thanks to the open-source tools and community and special thanks to üöÄ Abhishek Thakur and Sanyam Bhutani for the inspiration and for making awesome content on LLMs. #LLMs #Kaggle #NLP If you are just a beginner in the field of LLMs and want to have an idea about it, maybe this could be useful https://lnkd.in/eMckcyEc

          ‚Ä¶see more
        


DIY PDF_Chatbot
",,https://www.linkedin.com/feed/update/urn:li:activity:7120786794610085888?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7120786794610085888%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQG0IBshuz05Xw/articleshare-shrink_1280_800/0/1704097534245?e=1705658400&v=beta&t=TdrX6YLKkfYUMyjdKyyK-Sr0KXoiR73aiESa-A62-A0
127,65a1050da5b8f072000021d0,2bd8de51-b134-0600-84f3-7be4a86870d7,https://media.licdn.com/dms/image/C5603AQGbEZgZKbSWNQ/profile-displayphoto-shrink_100_100/0/1600368657671?e=1710374400&v=beta&t=93xRczt-VMMORzGa9RULKnQyMbvCwknSuQnYX9EZGY4,Ping Li,https://www.linkedin.com/in/ACoAABK5BhYB5GTbY01Q7UvmNFL6r6fQLLjpuUA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABK5BhYB5GTbY01Q7UvmNFL6r6fQLLjpuUA,"
[ pltrees.github.io ] Engineer in Machine Learning, Ads, Search, Privacy, Recommendation, Statistics, at LinkedIn in Bellevue WA
","
Generative AI models, Langevin Dynamics This morning, I was organizing the previous work we did 2 years ago, on ""Stochastic Gradient Anisotropic Langevin Dynamics for Learning Energy-Based Models"" .  It reminds me of the long list of works on generative AI models the team did during 2018 - 2022.1.  On Random Deep Weight-Tied Autoencoders: Exact Asymptotic Analysis, Phase Transitions, and Implications to Training, ICLR 2019. https://lnkd.in/gSsPJskN 2. Graph to Graph: a Topology Aware Approach for Graph Structures Learning and Generation, AISTATS 2019. https://lnkd.in/gyrCxaWk 3.  Multi-Agent Discussion Mechanism for Natural Language Generation, AAAI 20194. Estimate the Implicit Likelihoods of GANs with Application to Anomaly Detection, WWW 20205. Meta-CoTGAN: A Meta Cooperative Training Paradigm for Improving Adversarial Text Generation, AAAI 2020 6. A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model, ICLR 2022. https://lnkd.in/g9vAG8_r7. Degenerate Swin to Win: Plain Window-based Transformer without Sophisticated Operations, https://lnkd.in/gi5b8pDc8. Flow-based Perturbation for Cause-effect Inference, CIKM 20229. Variational Flow Graphical Model, KDD 2022. https://lnkd.in/gHHttDys10. Causal Effect Prediction with Flow-based Inference, ICDM 202211. Learning Energy-Based Model with Variational Auto-Encoder as Amortized Sampler, AAAI 2021. https://lnkd.in/g_gDj-cK12. Patchwise Generative ConvNet: Training Energy-Based Models from a Single Natural Image for Internal Learning, CVPR 202113. Learning Deep Latent Variable Models by Short-Run MCMC Inference with Optimal Transport Correction, CVPR 202114.  Learning Energy-Based Generative Models via Coarse-to-Fine Expanding and Sampling, ICLR 202115. Learning Generative Vision Transformer with Energy-Based Latent Space for Saliency Prediction, NeurIPS 202116.  Causal Discovery with Flow-based Conditional Density Estimation, ICDM 202117. Likelihood-Based Generative Radiance Field with Latent Space Energy-Based Model for 3D-Aware Disentangled Image Representation, AISTATS 2023. 18. CoopInit: Initializing Generative Adversarial Networks via Cooperative Learning, AAAI 2023. https://lnkd.in/g8ub8cfr 19. A Tale of Two Latent Flows: Learning Latent Space Normalizing Flow with Short-run Langevin Flow for Approximate Inference, AAAI 2023. https://lnkd.in/gm-MNg85 20. Learning Latent Structural Relations with Message Passing Prior, WACV 2023.The team benefited a lot from Yann LeCun's inspiring talk at Baidu on energy-based generative AI models:https://lnkd.in/g9WReCTC https://lnkd.in/gnVvDavX Thanks again Yann. We are lucky to be in the great time of generative AI.I would like to thank the team members who worked on generative AI models: Jianwen Xie, Dingcheng Li, Hongliang Fei, Belhal Karimi, Shaogang Ren, HAIYAN YIN, Tan Y., Mingming Sun, Phan Minh N. and more. Thank you all for the hard work and great work.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7120751368885190656?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7120751368885190656%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQGdtEkE3Vvj3A/feedshare-shrink_480/0/1697719422957?e=1707955200&v=beta&t=h-4Iqxj3mWjHkEbJO8qVE5RpqmPe_9GGJ9xqqzjJ49s
128,65a1050da5b8f072000021d1,3d9e09f4-64cf-7b94-1fd5-9ccc6c1736af,https://media.licdn.com/dms/image/C560BAQEg7UfAyEoKWg/company-logo_100_100/0/1637414049335/nlplanet_logo?e=1713398400&v=beta&t=_QvY1xSefLEyzgG6cO_2hVnEPcwkGrAcB32ORRVOZbM,NLPlanet | Breaking Down Generative AI Daily,https://www.linkedin.com/company/nlplanet/,"
9K followers
","
Self-RAG: improving RAG through self-reflection üòÆü§î Despite being versatile, LLMs can produce factual inaccuracies due to their extensive knowledge. This can result in generated hallucinations, outdated information, and unclear source attributions.üîç Retrieval Augmented Generation (RAG) enhances LMs by adding a retrieval function to minimize issues in knowledge-intensive tasks like QA. Yet, it may retrieve and include irrelevant passages, leading to unhelpful response generation.üíÅ Self-RAG is an improvement of RAG. Self-RAG lets LMs retrieve and reflect on passages using ""reflection tokens"" in order to better cater responses to various task requirements.üöÄ Tests confirm Self-RAG outperforms leading LLMs and retrieval-augmented models across various tasks, including Open-domain QA, reasoning, and fact verification. It surpasses models like ChatGPT and retrieval-augmented Llama2-chat.‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚ÄîWant to stay at the forefront of Generative AI developments? Follow NLPlanet for daily insights into the most relevant news, guides, and research! üöÄ

          ‚Ä¶see more
        


Self-RAG: Learning to Retrieve, Generate and Critique through Self-Reflections
",,https://www.linkedin.com/feed/update/urn:li:activity:7120745750199775232?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7120745750199775232%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D22AQHKyaLvKxYsCQ/feedshare-shrink_800/0/1697718074680?e=1707955200&v=beta&t=3mUSaBMGLbWQYCXigSIlSdjFmXjWfYORbiRusf79wbg
129,65a1050da5b8f072000021d2,a5a7b4c8-3da7-6b48-701e-44622cfea8a3,https://media.licdn.com/dms/image/C4E03AQG_FvT0lgPNEQ/profile-displayphoto-shrink_100_100/0/1646334589594?e=1710374400&v=beta&t=PCl0rs-PUX83UaF9WwZiTWop7l1J47y2_yooHkMArGA,Glen Berseth,https://www.linkedin.com/in/ACoAABMXZX4Bh3XSdjWYEA2H-7N6_qXMPYf89fw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABMXZX4Bh3XSdjWYEA2H-7N6_qXMPYf89fw,"
Assistant Professor at UdeM and Mila - Quebec AI Institute
","
What else can a good RL agent do? We conduct 100+ experiments with different RL algorithms, pre-training methods, and molecular grammars to search the vast space of molecular graphs, because discovering useful drugs can provide significant value.

          ‚Ä¶see more
        


Searching for High-Value Molecules Using Reinforcement Learning and Transformers
",,https://www.linkedin.com/feed/update/urn:li:activity:7120857604003647488?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7120857604003647488%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E12AQFipvdD3FwiKg/article-cover_image-shrink_423_752/0/1697744122093?e=1710374400&v=beta&t=EUlUNPqwVcYOhCAzjc_F4mfDzoBODM_i5eMb0ITyReM
130,65a1050da5b8f072000021d3,4b1c3f3d-3a8b-524f-089c-d2a44371d93c,https://media.licdn.com/dms/image/C4E03AQHVyH-IfD1KbQ/profile-displayphoto-shrink_100_100/0/1629877234109?e=1710374400&v=beta&t=0UZUl_dDUxLaZn-Hu-zToqEDe3rpL5cB2JkP5_jlNXc,"Sebastian Raschka, PhD",https://www.linkedin.com/in/ACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU,"
Machine learning and AI researcher since the early days ‚Ä¢ coding and working with LLMs at Lightning AI ‚Ä¢ ex-statistics professor at University of Wisconsin-Madison
","
If you are interested in a 30 min intro to using and finetuning LLMs, my talk from the LLMs In Production Conference is now live. LinkedIn video only supports videos up to 15 min, but the full (higher-res) recording is freely available on the MLOps Community website here: https://lnkd.in/ggeeW6fA#LLMs #largelanguagemodels #AI

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7120841055201067009?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7120841055201067009%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5605AQGmoYjrGPy9rg/videocover-low/0/1697740699330?e=1705658400&v=beta&t=SlrgB7vuNu9lozHLfItccGH34WlAV8Tkaqu7eNP3TyM
131,65a1050da5b8f072000021d4,7bc57361-7242-c2ed-ea91-e3b19827fe6b,https://media.licdn.com/dms/image/D4E03AQHtC2BUAB6jkA/profile-displayphoto-shrink_100_100/0/1694687456770?e=1710374400&v=beta&t=ndmP3__bJjjA60t62U8lCwf_bck4TDX4LIp-qSsOgAc,Prithivi Da,https://www.linkedin.com/in/ACoAAANONyEBI75vYtjMK4f9hcDMhgneli34DsA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAANONyEBI75vYtjMK4f9hcDMhgneli34DsA,"
Building a Memory Assistant for Philomaths. Sharing wisdom from a 2 decade experience in creative problem solving.
","
üöÄ ~ùü∞ùü±ùó†ùóï ùòÅùó∂ùóªùòÜ ùó∫ùóºùó±ùó≤ùóπ ùóØùó≤ùóÆùòÅùòÄ ùó≤ùòÖùó∂ùòÄùòÅùó∂ùóªùó¥ ùó¶ùó≤ùóªùòÅùó≤ùóªùó∞ùó≤-ùóßùóøùóÆùóªùòÄùó≥ùóºùóøùó∫ùó≤ùóøùòÄ ùó≤ùó∫ùóØùó≤ùó±ùó±ùó≤ùóøùòÄ. Meet TaylorAI/gte-tinyùó¢ùó∏ ! ùó™ùóµùòÜ ùòÄùóµùóºùòÇùóπùó± ùòÜùóºùòÇ ùó∞ùóÆùóøùó≤?In Vector Search, Encoding user-queries is one of the performance hogs apart from the actual querying and filtering. Smaller, faster embedders means better user experience. This tiny model can be a drop-in replacement for the default embedder in almost all VectorDBs. It's not half bad as-is, A quick fine-tune on your data is all you need to get best in class retrieval performance. It will be dirt-cheap and lightning fast to fine-tune.ùó™ùóµùòÜ ùó∂ùòÅ'ùòÄ ùóÆ ùóØùó∂ùó¥ ùó±ùó≤ùóÆùóπ ?TaylorAI/gte-tiny, a tiny model in the MTEB leaderboard beats all the existing sentence-transformer all-mini series and all-mpnet series models that are used as default by almost all VectorDBs. For perspective, all-MiniLM-L6-V2 was ~80MB.ùóóùó≤ùòÅùóÆùó∂ùóπùòÄ- TaylorAI/gte-tiny- Embedding size 384d- BERT based (MPNET > BERT, need to play around more)- Distilled from thenlper/gte-small,- Very Comparable (only slightly worse) performance for the size.- Ranks 28th / 126 in the MTEB leaderboard. - ONNX version is even smaller. _____Save for later using https://savelikeapro.appLinks:Model: https://lnkd.in/eJWsfbiYMTEB leaderboard: https://lnkd.in/eY3aFH8a

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7120279840569597952?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7120279840569597952%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQEJFkfIsmhtNg/feedshare-shrink_480/0/1697523881905?e=1707955200&v=beta&t=MCR3LGN7YG27S15TLMt9tABwD5X355A3uNQx9Tvf6n0
132,65a1050da5b8f072000021d5,c03a1990-14bb-38e2-b859-2059f4a4e908,https://media.licdn.com/dms/image/C5603AQH0vt7JCOIZ2g/profile-displayphoto-shrink_100_100/0/1659622741519?e=1710374400&v=beta&t=oD7v-H5eftQLYDRlvUvk2VE7-lsZDVk9VuRckoG8nZk,Jim Fan,https://www.linkedin.com/in/ACoAAA1AILwBEWpiY_CZ_I03PL9inU_8YB3s5nQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA1AILwBEWpiY_CZ_I03PL9inU_8YB3s5nQ,"
NVIDIA Sr. Research Scientist & Lead of AI Agents. Stanford Ph.D. Creator of Voyager, Eureka, MineDojo (Best Paper). OpenAI's first intern. Sharing insights on the bleeding edge of AI research & industry.
","
New York Times featured our work - Voyager, the first LLM-powered AI agent that masters Minecraft! Voyager is a lifelong learning agent that plays Minecraft purely in-context. Voyager continuously improves itself by writing, refining, committing, and retrieving *code* from a skill library.GPT-4 unlocks a new paradigm: ‚Äútraining‚Äù is code execution rather than gradient descent. ‚ÄúTrained model‚Äù is a codebase of skills that Voyager iteratively composes, rather than matrices of floats. We are pushing no-gradient architecture to its limit.Voyager rapidly becomes a seasoned explorer. In Minecraft, it obtains 3.3√ó more unique items, travels 2.3√ó longer distances, and unlocks key tech tree milestones up to 15.3√ó faster than prior methods.We open-source everything. Let generalist agents emerge in Minecraft! Welcome you all to try today: voyager.minedojo.orgPaper: arxiv.org/abs/2305.16291Code: https://lnkd.in/g5yDhGPYThanks Cade Metz and Karen Weise  for the wonderful reporting!! Instead of replacing workers, I am confident that AI agents will empower them to be way more productive and effective. https://lnkd.in/g6vrYnF5

          ‚Ä¶see more
        


How ‚ÄòA.I. Agents‚Äô That Roam the Internet Could One Day Replace Workers
",,https://www.linkedin.com/feed/update/urn:li:activity:7119716684474589184?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7119716684474589184%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQHh1gH5tDPfhw/articleshare-shrink_800/0/1704845717290?e=1705658400&v=beta&t=ct0cr0LnhBybbhfrjESiwmPS3Yj5N661Shhpch2QfWs
133,65a1050da5b8f072000021d6,02df121c-6e33-60b7-42a5-07a9e8f3cdc4,https://media.licdn.com/dms/image/D4E03AQHR4OA6seOkhw/profile-displayphoto-shrink_100_100/0/1694675587202?e=1710374400&v=beta&t=O3s-HfiKp34rZAMMeLlSVRxzsMF0Knnsj6CmR6RpjfQ,Victor Mustar,https://www.linkedin.com/in/ACoAAAr0O_wBdWVz2R_Ige4Vdo7nobm4n42-3A8?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAr0O_wBdWVz2R_Ige4Vdo7nobm4n42-3A8,"
Head of Product Design at Hugging Face
","
üè† Do you want to run LLMs locally?Here is an awesome tool: Select a model, your vendor and your GPU and see if you can run a model locally üöÄ
 ",,https://www.linkedin.com/feed/update/urn:li:activity:7118520808410333185?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7118520808410333185%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQHLZBh5PrvOQw/feedshare-shrink_480/0/1697187615613?e=1707955200&v=beta&t=vDbodZM-0eqgHoze9obhgJb68P6ITrithd55SK3F8vA
134,65a1050da5b8f072000021c8,5b0edddc-5e1f-3fd4-6377-ff3b2b98fee2,https://media.licdn.com/dms/image/C5603AQFvncvflX_kMQ/profile-displayphoto-shrink_100_100/0/1564316873635?e=1710374400&v=beta&t=DRxjFCzRMNJSc3QM233eAmSZ8rflNQHLrn8k0KQuOhg,Elvis S.,https://www.linkedin.com/in/ACoAACxhXeUBTYZYCwIa4nsvSBsETtrS0uhGNPc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACxhXeUBTYZYCwIa4nsvSBsETtrS0uhGNPc,"
Co-Founder at DAIR.AI | Prev: Meta AI, Galactica LLM, PapersWithCode, Elastic
","
LLM CollectionBesides having a comprehensive list of prompting techniques for LLMs, we now track some of the most impactful LLMs to date. This is a great place to keep track of the latest general-purpose and domain-specific LLMs. More to come.Think of this as a living LLM survey. We are always open to feedback and improving the guide. You can directly add any missing LLMs as well.We are also working on another set of comprehensive guides on how to explore and build with these impactful LLMs. Currently, we have ChatGPT, GPT-4, and Flan, but more are coming soon (especially on the open-source side of things). Including Llama 2, Llama Code, T5-Flan, and Mistral to name a few.https://lnkd.in/e7UsZwPf

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7122961598092038145?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7122961598092038145%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQFrGq56q1p66w/feedshare-shrink_480/0/1698246382576?e=1707955200&v=beta&t=10NtDPfhh1REYnjw_uWoFdsLziQ-Hqvhz2YmldvTzgA
135,65a1050da5b8f072000021d8,f622b966-7d53-738a-8314-9483fb679f20,https://media.licdn.com/dms/image/C4E03AQEq-Kb5RAD1dw/profile-displayphoto-shrink_100_100/0/1527122932429?e=1710374400&v=beta&t=aQW0oQaH61QqRp9xeL7dLN5XxIRGrE_uK0WQqxKPrlc,Erfan Alimohammadi,https://www.linkedin.com/in/ACoAABnGfYMBPk-aSmofBDkvzH7e6i0QwrM_E4U?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABnGfYMBPk-aSmofBDkvzH7e6i0QwrM_E4U,"
Senior Data Scientist at Wisdomise | ACM-ICPC World Finalist 2017
","
I'm delighted that when you perform a Google search for ""Binance Futures Bot,"" my GitHub repository appears on the first page of search results.Link to my GitHub repository: https://lnkd.in/dzEmqm23#crypto #binance #trading #bitcoin

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7119151581052182528?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7119151581052182528%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQESzEB8KaLHug/feedshare-shrink_480/0/1697338003422?e=1707955200&v=beta&t=tCb6xEvRrstcbRvkofb86F7FLNDYV7IXRJCpREl-RL4
136,65a1050da5b8f072000021d9,4a75898c-d9cc-05cb-9524-812800e84eb5,https://media.licdn.com/dms/image/D5603AQGEADhHyEQ8rw/profile-displayphoto-shrink_100_100/0/1682553354695?e=1710374400&v=beta&t=kfjA-KO1Ea4gqAJ68vTh1_4ORnZzWv1qSW4bXFvg_tc,"Damien Benveniste, PhD",https://www.linkedin.com/in/ACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw,"
The ML Guy - Follow me to learn about Machine Learning Engineering, Machine Learning System Design, MLOps, and the latest techniques and news about the field. Join my AI newsletter and keep learning!
","
SHAP is certainly one of the most used techniques for explainable AI these days, but I think many people don't know why. Some researchers had a huge impact on the history of ML, and most people will never know about them.SHAP (SHapley Additive exPlanations) is a framework that provides explanations of predictions as a sum of the contributions of the underlying features used in the model. We have known about the Shapley value since 1951 (https://lnkd.in/e6jBm8YD), and since then, people have tried to use them as a way to measure feature attributions in Machine Learning models, but it was not until 2017 that a team from the University of Washington proposed a unified framework to apply those in any ML models.- Kernel SHAP is a black box method that builds on top of LIME (https://lnkd.in/gpjdUNxw). Let's say you want to explain a specific prediction p with the related features values x. The idea is to create many news samples around x by replacing some of the values with others pulled at random from the data set and to see the predictions of those new samples by the model. We can then use those samples and predictions to train a linear model and use the fitted weights to understand the local contributions of the different features. The difference between LIME and SHAP is the way the samples are weighted in the MSE loss function. LIME uses a Gaussian, whereas SHAP uses the Shapley weights.- Tree SHAP is the exact and faster estimate of those numbers by utilizing the structure of tree-based algorithms. In a tree, we can compute the exact predictions with a subset of the features by skipping the removed features and averaging the predictions of the resulting subtrees. We understand the contribution of a feature by measuring the variation of the predictions with and without it. In 2019, the same team proposed an algorithm to explore all the feature contributions of the feature power-set at once: https://lnkd.in/gDhHeQJP. - Linear SHAP is the exact analytic simplification of the original formula for linear models. For a model f(x) = w_1 * x_1 + w_2 * x_2 + ‚Ä¶, the contribution of the feature x_1 is simply w_1 * ( x_1 - E[x_1]).- Deep SHAP is an application of DeepLIFT (https://lnkd.in/gtRtxhZq) using the Shapley values as a measure of contribution. DeepLIFT is a way to decompose the predictions of Neural Networks as a linear combination of contributions of the underlying features. The idea is that we can backpropagate the contributions as we do the gradient.You can find the original SHAP papers here: https://lnkd.in/gWfEGkHt, https://lnkd.in/gDhHeQJP. SHAP is obviously, for most people, a Python package, and make sure to check it out if you haven't: https://lnkd.in/gNXF8_ab--üëâ Get a Free Machine Learning PDF (100+ pages) with 50+ tips by subscribing to my newsletter today: https://TheAiEdge.io--#machinelearning #datascience #artificialintelligence 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7116001905402630144?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7116001905402630144%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQG5R2dx2QSGdg/feedshare-shrink_480/0/1696550436859?e=1707955200&v=beta&t=xAN7yAWXw-838abnyHpwf6OEGyAdSSSGjBQfrjXb_6E
137,65a1050da5b8f072000021da,ee2aa8c8-a507-cf8e-719f-19d3c6873928,https://media.licdn.com/dms/image/D5603AQG9NK0CAgKtVg/profile-displayphoto-shrink_100_100/0/1687301791875?e=1710374400&v=beta&t=Bolt2zUMX7vi6uTl04U5LmzIk8J4LR-CV26o0v_KAIU,Lior S.,https://www.linkedin.com/in/ACoAADMTPYsBtfLtDZlCPxc0G4n0-rFYtqhC0yE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADMTPYsBtfLtDZlCPxc0G4n0-rFYtqhC0yE,"
I cover the latest breakthroughs in AI ‚Üí Ex-ML Engineer/Researcher ‚Üí Built the most read technical newsletter in AI
","
Impressive. MetaGPT is about to reach 30,000 stars on Github.It's a Multi-Agent Framework that can behave as an engineer,  product manager, architect, project managers.With a single line of text it can output the entire process of a software company along with carefully orchestrated SOPs:‚ñ∏ Data structures‚ñ∏ APIs‚ñ∏ Documents‚ñ∏ User stories‚ñ∏ Competitive analysis‚ñ∏ Requirements‚ÜìAre you technical? Check out https://AlphaSignal.ai to get a weekly summary of the latest research and breakthroughs in AI. Read by 150,000+ engineers and researchers.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7119376069719179264?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7119376069719179264%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQFSt05zGbUIqg/feedshare-shrink_480/0/1697391525203?e=1707955200&v=beta&t=ybZLyY-UtmfIWzDb4IBEkB1CZoOUM-WjJwBLawGDoF0
138,65a1050da5b8f072000021db,b7894f56-97ec-7baf-cc47-124942ac7e45,https://media.licdn.com/dms/image/C5603AQF9hcPUUohpZw/profile-displayphoto-shrink_100_100/0/1523832574043?e=1710374400&v=beta&t=lStXCR8PsZNYIbW47C7LYZzObALtwGOBj1QI2nUmZDM,Sumit Kumar,https://www.linkedin.com/in/ACoAAAOsZiMBFhI7v1j05VomMvU7TYU9n-m_KvY?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAOsZiMBFhI7v1j05VomMvU7TYU9n-m_KvY,"
Senior MLE @Meta, Ex- TikTok|Amazon|Samsung
","
I just published Vol. 21 of ""Top Information Retrieval Papers of the Week"" on Substack.My Substack newsletter features the 7-10 most notable research papers on information retrieval (including recommender systems, search & ranking, etc.) from each week, with a brief summary, and links to the paper/codebase.This week‚Äôs newsletter highlights the following research work:üìö Policy Gradient Training for Effective Text Retrieval with Large Language Models, from Cornellüìö Improving Task-Specific Dense Retrieval via Adaptive Residual Embeddings, from Microsoftüìö Exploiting Long-term User Behaviors for Query-dominant Interest Modeling in Personalized Search, from Kuaishouüìö Enabling Personalized Response Selection via Plug-and-Play Persona Prompting, from Naverüìö Explaining Recommendations through Personalized and Engaging Language Models, from Google Researchüìö A Unified Embedding Model for Diverse Retrieval Augmentation of Large Language Models, from BAAIüìö InstructRetro 48B: Pushing the Limit of Retrieval-Augmented Pretraining for Question Answering, from NVIDIAüìö Controlling Evolving Toxicity in Language Models through Retrieval, from Cohereüìö Improving Listwise Ranking in Language Models, from Comcast AIüìö Fine-Tuning LLaMA for Effective Multi-Stage Text Retrieval, from Microsoft#InformationRetrieval #ResearchPapers #CuratedContent #Newsletter  #substack

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7119322033645121536?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7119322033645121536%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQEjDkoyMVxcnw/feedshare-shrink_480/0/1697378642940?e=1707955200&v=beta&t=V7l9ilADVVfCF8ojM4VWm8m_O5TGouHxiChf4wEXyBA
139,65a1050da5b8f072000021dc,78af4b4e-a88b-0c1a-86b5-445c863ee699,https://media.licdn.com/dms/image/D560BAQGFpRpGKIeK6w/company-logo_100_100/0/1688581512782/pytorch_logo?e=1713398400&v=beta&t=PpzZq2REepkndNguYHvGhBbKkm4iNPBKoATlVMFfHc0,PyTorch,https://www.linkedin.com/company/pytorch/,"
228K followers
","
Today, we are releasing an AV-ASR recipe on TorchAudio, a library for audio and signal processing with PyTorch, enabling a broad set of applications and fostering further research into real-time speech recognition. üîäRead more: https://hubs.la/Q024_zPL0

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7117536653753163776?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7117536653753163776%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5610AQEeZh3cFvQ2Yw/image-shrink_480/0/1696952973713?e=1705658400&v=beta&t=JiXdurPWZ3nyR9ocEi8tNj29gPddWEM6jHH4q1DDFps
140,65a1050da5b8f072000021dd,7d03c2d5-7ee3-e53a-23a2-e73d7b8f5dc4,https://media.licdn.com/dms/image/D5603AQF1jz-pHuLrOA/profile-displayphoto-shrink_100_100/0/1695439999226?e=1710374400&v=beta&t=AJ8J2-1RoHXGBOgKPlITENJzKxSbMkOO6EHajL8Qe14,Soma Dhavala,https://www.linkedin.com/in/ACoAAACADkYBij00p7vwmP0tRP4LaOyqeAKuPZE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAACADkYBij00p7vwmP0tRP4LaOyqeAKuPZE,"
Director - ML
","
Duality between Attention in Transformers and a Neural Network is fascinating. Under this lens, we can interpret Attention as a kernel trick at play, where the infinite dimensional polynomials form the feature map in the primal formulation.It also means that we can derive different types of attention networks, all inspired by different kernels, possibly with different inductive biases.So, modern Deep Learning architectures are a composition of learnable kernel machines. My interpretation of the significance of this work!Paper: https://lnkd.in/gbgs3YwB

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7119524510776655872?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7119524510776655872%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHyW4mPmx5r3A/feedshare-shrink_480/0/1697426917171?e=1707955200&v=beta&t=_FMrtZHPMdxhIW61cseIfYK5npngrr_6gM5jXRWtCXA
141,65a10528a5b8f072000021de,f9f3bb9d-7b68-cd40-8d63-8e43af3e7c59,https://media.licdn.com/dms/image/D5603AQEMJUFRPHBXnA/profile-displayphoto-shrink_100_100/0/1669178612024?e=1710374400&v=beta&t=S5EQrr3TowkGUEDR6bUJKHkd5CIcwLOMYdmu3BGOrng,Xavier (Xavi) Amatriain,https://www.linkedin.com/in/ACoAAABxvO8BNIuBlB9QxS2rSSLpNQZRFLizDWg?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAABxvO8BNIuBlB9QxS2rSSLpNQZRFLizDWg,"
Leading Generative AI Engineering and Product Initiatives at LinkedIn
","
Interesting recent paper on LLM hallucinations that includes a new publicly available dataset as well as a new proposed metric (HVI). The ranking of known LLMs on the metric gives me pause on how practical it might be particularly since it seems smaller encoder/decoder models fare much better. Thoughts? (paper link: https://lnkd.in/gBxtwsXY)

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7119442371531997184?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7119442371531997184%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQGFnsWRNA2T9w/feedshare-shrink_480/0/1697407331895?e=1707955200&v=beta&t=UnHGyzvX5tuWn3ynUdBTTbCX9hGfJNl8_WtsxFqmzGE
142,65a10528a5b8f072000021df,4551676f-c966-a300-322f-a7e6a5bd7d14,https://media.licdn.com/dms/image/C4D03AQGdL59l00GaUA/profile-displayphoto-shrink_100_100/0/1621102404508?e=1710374400&v=beta&t=ZztfPNrjoNmlndU5gQYbW0JW1fgfJPsdQCR1dTJ1F6k,Florian PESCE,https://www.linkedin.com/in/ACoAACkZl2IB61R3UrcKXKc1BAtVJ80nuIWh0B4?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACkZl2IB61R3UrcKXKc1BAtVJ80nuIWh0B4,"
Machine Learning Engineer @ Apple | Multimodal Artificial Intelligence
","
Are you passionate about software engineering, machine learning engineering and/or machine learning research? Do you like the idea of working on state-of-art, privacy-preserving machine learning models and user experiences around AI which can impact millions of users? Are you interested in exploring four AI/ML roles and teams in your first year, before choosing your favorite position? Are you graduating from a BS or MS program in Spring 2024 and looking for a full-time position starting in Summer 2024?If these sound like a good fit to you, you should consider the Apple AI/ML Rotation Program! Link below

          ‚Ä¶see more
        


AIML Rotation Program - Summer 2024 - Careers at Apple
",,https://www.linkedin.com/feed/update/urn:li:activity:7117946646214148096?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7117946646214148096%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQGVcP6n174x4w/articleshare-shrink_800/0/1703954272681?e=1705658400&v=beta&t=XwPORE-otozfinOgVOUbMtyLN8IDmw2FXTa3SEdLxgI
143,65a10528a5b8f072000021e0,a69c06a8-bbf5-826e-87d8-1797b45db238,https://media.licdn.com/dms/image/C560BAQEg7UfAyEoKWg/company-logo_100_100/0/1637414049335/nlplanet_logo?e=1713398400&v=beta&t=_QvY1xSefLEyzgG6cO_2hVnEPcwkGrAcB32ORRVOZbM,NLPlanet | Breaking Down Generative AI Daily,https://www.linkedin.com/company/nlplanet/,"
9K followers
","
Lemur-70B is a new open-source LLM which outperforms other models on agent benchmarks üòÆüî• Lemur improves open source models by training on a 90B token corpus with a 10:1 ratio of code to text. It then fine-tunes on 300K examples covering both text and code domains to enhance natural language and coding skills.üìä Lemur's performance was validated across 8 language and code datasets, including MMLU, BBH, GSM8K, HumanEval, and Spider. It was also tested on 13 interactive agent datasets to evaluate its skills in tool usage, adaptation to feedback, and exploration of partially observable environments.üëÄ Lemur performance is similar to GPT-3.5-turbo on many code tasks.üòé Lemur outperforms other models on agent benchmarks. It excels in language and coding tasks, surpassing open source models, and is closing the performance gap with commercial models on agent abilities.‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚ÄîWant to stay at the forefront of Generative AI developments? Follow NLPlanet for daily insights into the most relevant news, guides, and research! üöÄ

          ‚Ä¶see more
        


Introducing Lemur: Open Foundation Models for Language Agents
",,https://www.linkedin.com/feed/update/urn:li:activity:7118852946720624640?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7118852946720624640%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D22AQHXQcxRZTYBCg/feedshare-shrink_800/0/1697184567201?e=1707955200&v=beta&t=QoqDou1FIhVf4DEQB6OKxGRKo0w4lJkT92WePq_Iotw
144,65a10528a5b8f072000021e1,86db9406-afb3-c1b7-e473-5c122d886101,https://media.licdn.com/dms/image/D4E03AQEvBTenWN3B6A/profile-displayphoto-shrink_100_100/0/1680492099214?e=1710374400&v=beta&t=Ie2zy0hTlNf_jCqdYshhj3oEVsArAuHfQem51IadrUM,Swarup Subudhi,https://www.linkedin.com/in/ACoAAA3UcsEBY4UVJ4RScQLP7m-ABwyqTEOVW0w?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA3UcsEBY4UVJ4RScQLP7m-ABwyqTEOVW0w,"
PhD Student at University of Maryland | Multiphysics Research (Fluids & Magnetism) | Additively Manufactured Electronics | Component Reliability
","
I'm excited to announce that our perspective article got published in the journal Frontiers in Sensors. This article talks about the state-of-the-art research on wearable Lab-on-a-Chip devices, and suggests new research directions in the domain of their long term reliability.Many thanks to my advisor Dr. Siddhartha Das .#perspective #labchipdevices #reliability #microfluidics #failuremodes #wearables

          ‚Ä¶see more
        


Reliability of lab-on-a-chip technologies for wearable electronics: a perspective
",,https://www.linkedin.com/feed/update/urn:li:activity:7119002875745161216?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7119002875745161216%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQFoaz6Wa3zotw/articleshare-shrink_480/0/1704643877852?e=1705658400&v=beta&t=3Le9eQ6e_7AfiEm-PQsArqhpxy9ylGNp43a49sB3QuU
145,65a10528a5b8f072000021e2,0697b6fc-d7c3-e717-5424-78c3028ca3e0,https://media.licdn.com/dms/image/D4E03AQFIWeYqBIWuWg/profile-displayphoto-shrink_100_100/0/1699242858702?e=1710374400&v=beta&t=W-WQLGihPIBU3f3FgsTMqZRRxaflIldstLb5Ejqxsho,"Shreyas Subramanian, PhD",https://www.linkedin.com/in/ACoAABLBC4wB267uuFCUMtQlhCU3h26SabT8xwk?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABLBC4wB267uuFCUMtQlhCU3h26SabT8xwk,"
Principal Data Scientist @ AWS | Author | Researcher | Inventor | Multiple hackathon winner | Intrapreneur
","
Recently popular LLMs like the Falcon 40B, Meta Llama2, Instruct GPT and many others have (at least) one thing in common: they all use a combination of the AdamW optimizer, with a Cosine scheduler decaying down to 10% of the starting Learning rate... But why? ü§î Vignesh Ganapathiraman and I have been working on a series of papers that we think will end up providing a better default optimizer-scheduler choice for training all kinds of models, including LLMs. Our paper on the ""GreedyLR"" scheduler also won the best presentation award at the recent IEEE Pattern Recognition and Machine Learning (PRML) conference. üî• üî• üî• Take a look at this Amazon Science blog that highlights our research on this topic so far - https://lnkd.in/eqYZksQtOur Amazon science page with recent articles:https://lnkd.in/eKkmtS4a Amazon Science #AmazonScience #amazonscience #aws #deeplearning #genAI #machinelearning

          ‚Ä¶see more
        


Shreyas Subramanian
",,https://www.linkedin.com/feed/update/urn:li:activity:7118634093486972928?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7118634093486972928%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQGYNfRT0WHqEQ/articleshare-shrink_800/0/1704236365785?e=1705658400&v=beta&t=AQIBYSQUSTyGVn30rjAdKRo7M1KZk90x-qG8iaAWyPI
146,65a10528a5b8f072000021e3,b8711e98-e7c6-3b53-14e5-0f39b4267667,https://media.licdn.com/dms/image/D4D03AQFpramTnkoElw/profile-displayphoto-shrink_100_100/0/1670580633493?e=1710374400&v=beta&t=S032I_0r57qA_Thm98T7Xu_Nn46maV3uUmXnh4kYuiU,Bruno Neri,https://www.linkedin.com/in/ACoAAABlS2EBjKE-dekAzG21UIzH0d46NEotnuQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAABlS2EBjKE-dekAzG21UIzH0d46NEotnuQ,"
Technical Leader - Artificial Intelligence and Deep Learning Enthusiast - Senior Software Engineer at ALTEN Italia
","
""Enhanced sampling of Crystal Nucleation with Graph Representation Learnt Variables"" by Pratyush Tiwary et al.""In this study, we present a graph neural network-based learning approach using an autoencoder setup to derive low-dimensional variables from features observed in experimental crystal structures. These variables are then biased in enhanced sampling to observe state-to-state transitions and reliable thermodynamic weights. Our approach uses simple convolution and pooling methods. To verify the effectiveness of our protocol, we examined the nucleation of various allotropes and polymorphs of iron and glycine from their molten states. Our graph latent variables when biased in well-tempered metadynamics consistently show transitions between states and achieve accurate free energy calculations in agreement with experiments, both of which are indicators of dependable sampling. This underscores the strength and promise of our graph neural net variables for improved sampling. The protocol shown here should be applicable for other systems and with other sampling methods.""Paper: https://lnkd.in/dgnZevin#graphneuralnetworks

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7118545835960770560?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7118545835960770560%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQGs4mSXpsQkWw/feedshare-shrink_480/0/1697193582733?e=1707955200&v=beta&t=L_S4JLdtUHkre3i6CVKajOHQl1hTJZxKmPNUsjaoldU
147,65a10528a5b8f072000021e4,7f8a74ea-0e68-4cc0-0d3d-9cf37502c188,https://media.licdn.com/dms/image/C4D03AQEmDwFNREkaIA/profile-displayphoto-shrink_100_100/0/1517524291944?e=1710374400&v=beta&t=9H8wRu-S3Mr0BN5zZEZBtWwefLpa0ZU_FPNQ9dTlNws,Robin Gras,https://www.linkedin.com/in/ACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ,"
Professor at University of Windsor, CSO and partner at Movyl Technologies and MVYL Associates
","

 

GPT-4 Architecture: Unravelling the Deep Technical Weave
",,https://www.linkedin.com/feed/update/urn:li:activity:7118941929483948032?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7118941929483948032%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQFbYmmabKe5fA/articleshare-shrink_800/0/1704111601104?e=1705658400&v=beta&t=ygm_DEM4pFgLFLJfvVRFto2sSPWpHv-uZMk2SLbyar0
148,65a10528a5b8f072000021e5,3397891c-d53f-9668-0025-73a39da2068a,https://media.licdn.com/dms/image/D4E03AQHtC2BUAB6jkA/profile-displayphoto-shrink_100_100/0/1694687456770?e=1710374400&v=beta&t=ndmP3__bJjjA60t62U8lCwf_bck4TDX4LIp-qSsOgAc,Prithivi Da,https://www.linkedin.com/in/ACoAAANONyEBI75vYtjMK4f9hcDMhgneli34DsA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAANONyEBI75vYtjMK4f9hcDMhgneli34DsA,"
Building a Memory Assistant for Philomaths. Sharing wisdom from a 2 decade experience in creative problem solving.
","
ùóôùó¶ùóóùó£ ùòÉùòÄ ùóóùóóùó£: ùó™ùóµùóÆùòÅ ùóÆùóøùó≤ ùòÅùóµùó≤ùòÜ ùóÆùóªùó± ùó™ùóµùòÜ ùó∞ùóµùóºùóºùòÄùó≤ ùóºùóªùó≤ ùóºùòÉùó≤ùóø ùóºùòÅùóµùó≤ùóø?ùóóùóóùó£ (ùóóùó∂ùòÄùòÅùóøùó∂ùóØùòÇùòÅùó≤ùó±ùóóùóÆùòÅùóÆùó£ùóÆùóøùóÆùóπùóπùó≤ùóπ):Scales the training across multiple GPUs or nodes by distributing mini-batches of data to different GPUs and then aggregating the gradients to perform the weight update. Each GPU retains a copy of the entire model, so the maximum model size you can train is limited by the memory capacity of a single GPU you have.ùóôùó¶ùóóùó£ (ùóôùòÇùóπùóπùòÜ ùó¶ùóµùóÆùóøùó±ùó≤ùó± ùóóùóÆùòÅùóÆ ùó£ùóÆùóøùóÆùóπùóπùó≤ùóπùó∂ùòÄùó∫):Targets training very large models that don't fit into the memory of a single GPU by sharding (splitting) the model's parameters across multiple GPUs.Instead of every GPU having a copy of the entire model, each GPU holds only a shard (portion) of the model. During the forward and backward passes, FSDP uses various techniques to swap in/out shards as necessary to compute the result and gradient.ùóôùó¶ùóóùó£ ùòÄùóºùòÇùóªùó±ùòÄ ùóπùó∂ùó∏ùó≤ ùó†ùóºùó±ùó≤ùóπ ùó£ùóÆùóøùóÆùóπùóπùó≤ùóπùó∂ùòÄùó∫, ùó°ùóº?There are some overlaps but they are not the same.Model Parallelism typically involves dividing the model into larger chunks or segments and placing each on a different GPU. For example, in a deep neural network, you might place the first few layers on GPU 1, the next set of layers on GPU 2, and so on.In FSDP the model is divided into finer-grained shards, and these shards are distributed across GPUs. Instead of segregating whole layers or sections to specific GPUs, parameters are more evenly divided and distributed and there is more.ùó¶ùó∞ùó≤ùóªùóÆùóøùó∂ùóºùòÄTraining a moderately large language model (like BERT-Large)Model Size: BERT-Large has 340 million parameters. While this is large, it can still fit on data center GPUs with substantial memory (e.g., NVIDIA V100 or A100, Largest A100s have 80GB as of this writing.) ? Go for DDP.Training a gigantic language model, (Look at the image below the model is > 80GB and cannot fit into a single A100 ) Go for FSDP.FSDP is better than DDP in scenarios where memory usage is a concern and when there is a need to optimize computational efficiency. By sharding model parameters and offloading computations to CPUs, FSDP can reduce memory consumption and improve training speed.ùóüùó∂ùó∫ùó∂ùòÅùóÆùòÅùó∂ùóºùóªùòÄ:However, it's important to note that FSDP has some limitations. It may not be suitable for all types of AI algorithms, and further development is needed to support a wider range of models. Additionally, FSDP may require additional configuration and setup compared to DDP.‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïêSave for later using https://SaveLikeAPro.app‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïêùó•ùó≤ùó≥ùó≤ùóøùó≤ùóªùó∞ùó≤ùòÄ:1. Facebook Engineering Blog: [FSDP: Fully Sharded Data Parallelism](https://lnkd.in/eWfrs8iv)2. PyTorch Tutorials: [FSDP Tutorial](https://lnkd.in/e53Hi8sa)

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7118825212392939520?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7118825212392939520%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQFB_FXNn_hEXA/feedshare-shrink_480/0/1697260190868?e=1707955200&v=beta&t=EndpmYSgwIZqfiSjpP5CdU2TQE-br6E-jZO8-Nop5KA
149,65a10528a5b8f072000021e6,23558be9-c338-c1b3-57bd-cfd9927917a2,https://media.licdn.com/dms/image/C4D03AQEmDwFNREkaIA/profile-displayphoto-shrink_100_100/0/1517524291944?e=1710374400&v=beta&t=9H8wRu-S3Mr0BN5zZEZBtWwefLpa0ZU_FPNQ9dTlNws,Robin Gras,https://www.linkedin.com/in/ACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ,"
Professor at University of Windsor, CSO and partner at Movyl Technologies and MVYL Associates
","
EIPE-text: Evaluation-Guided Iterative Plan Extraction for Long-Form Narrative Text Generationpaper page: https://lnkd.in/eTFATpFm""Plan-and-Write is a common hierarchical approach in long-form narrative text generation, which first creates a plan to guide the narrative writing. Following this approach, several studies rely on simply prompting large language models for planning, which often yields suboptimal results. In this paper, we propose a new framework called Evaluation-guided Iterative Plan Extraction for long-form narrative text generation (EIPE-text), which extracts plans from the corpus of narratives and utilizes the extracted plans to construct a better planner. EIPE-text has three stages: plan extraction, learning, and inference. In the plan extraction stage, it iteratively extracts and improves plans from the narrative corpus and constructs a plan corpus. We propose a question answer (QA) based evaluation mechanism to automatically evaluate the plans and generate detailed plan refinement instructions to guide the iterative improvement. In the learning stage, we build a better planner by fine-tuning with the plan corpus or in-context learning with examples in the plan corpus. Finally, we leverage a hierarchical approach to generate long-form narratives. We evaluate the effectiveness of EIPE-text in the domains of novels and storytelling. Both GPT-4-based evaluations and human evaluations demonstrate that our method can generate more coherent and relevant long-form narratives.""

          ‚Ä¶see more
        


Paper page - EIPE-text: Evaluation-Guided Iterative Plan Extraction for Long-Form Narrative Text Generation
",,https://www.linkedin.com/feed/update/urn:li:activity:7118576262750560256?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7118576262750560256%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQGUmy0ZuMP6Sg/articleshare-shrink_800/0/1704412474080?e=1705658400&v=beta&t=ZluU2d-KhL4eXExbswPzHO2l4V_onZikvbQz0LTOe-0
150,65a10528a5b8f072000021e7,ecf4626d-f92f-e8c7-70a3-1ca59093d1ff,https://media.licdn.com/dms/image/C5603AQHz5yBZgyaMpg/profile-displayphoto-shrink_100_100/0/1613872098784?e=1710374400&v=beta&t=gt4ypfC__UeZTT0ez7Bp89CDqDVJKUIZaZBs7eoBOr0,Bhavdeep Singh Sachdeva,https://www.linkedin.com/in/ACoAABDiGX8Bihj_BMK6Ru5MfG_7yYEx-6ED0TY?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABDiGX8Bihj_BMK6Ru5MfG_7yYEx-6ED0TY,"
Research Scientist
","
This excellent blog post by Chip Huyen on ""Open Challenges in LLM research"" lists building LLMs for non-English languages as an important challenge that needs to be solved!The AYA project by Cohere For AI is dedicated towards addressing this problem!

          ‚Ä¶see more
        


Open challenges in LLM research
",,https://www.linkedin.com/feed/update/urn:li:activity:7118095964283834368?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7118095964283834368%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQG4QiqOBNWamA/articleshare-shrink_800/0/1704615427136?e=1705658400&v=beta&t=th__KPFUJ0AU54qwz0jYE-3AOWO8rt44FTtqXsdW2S0
151,65a10528a5b8f072000021e8,e3982a8c-c680-d23b-6462-8d6f8139e718,https://media.licdn.com/dms/image/C4D03AQEmDwFNREkaIA/profile-displayphoto-shrink_100_100/0/1517524291944?e=1710374400&v=beta&t=9H8wRu-S3Mr0BN5zZEZBtWwefLpa0ZU_FPNQ9dTlNws,Robin Gras,https://www.linkedin.com/in/ACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ,"
Professor at University of Windsor, CSO and partner at Movyl Technologies and MVYL Associates
","

 

TimeGPT: The First Foundation Model for Time Series
",,https://www.linkedin.com/feed/update/urn:li:activity:7118214419444027392?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7118214419444027392%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQHtv7K287VRWg/articleshare-shrink_800/0/1705038053425?e=1705658400&v=beta&t=IlW8FIM9m4vy4j7EzGodXaGZd1F1g5fRSCLwTZwcIDg
152,65a10528a5b8f072000021e9,addff342-6f7e-0b91-bd63-bc54587e6133,https://media.licdn.com/dms/image/D5635AQEBzEFRC2EzLg/profile-framedphoto-shrink_100_100/0/1704907585971?e=1705658400&v=beta&t=x71pDAJzCbSPZxvt91sIkpmEr_5_pGLZIt6VZgw5eV0,Aman Chadha,https://www.linkedin.com/in/ACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU,"
GenAI Leadership @ Amazon AWS ‚Ä¢ Stanford AI ‚Ä¢ EB-1 ""Einstein Visa"" Recipient/Mentor ‚Ä¢ Ex-Ô£ø, Amazon Alexa, Nvidia, Qualcomm ‚Ä¢ EMNLP 2023 Outstanding Paper Award
","
üìù Announcing our new papers at EMNLP 2023!üîπThe Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations‚Ä¢ Vipula Rawte, Swagata Chakraborty, Agnibh Pathak, Anubhav Sarkar, S.M Towhidul Islam Tonmoy, Aman Chadha, Amit Sheth, Prof. (Dr.) Amitava Das‚Ä¢ We delve into the issue of hallucinations in LLMs with a comprehensive categorization based on degree, orientation, and type, introduce the HILT dataset with 75K samples from 15 LLMs, and present the Hallucination Vulnerability Index (HVI) for ranking LLMs by hallucination tendencies.‚Ä¢ https://lnkd.in/gwPnbJYVüîπCounter Turing Test (CT^2): AI-Generated Text Detection is Not as Easy as You May Think - Introducing AI Detectability Index (ADI)‚Ä¢ Megha Chakraborty, S.M Towhidul Islam Tonmoy, S M Mehedi Zaman, Shreya Gautam, Tanay Kumar, Krish Sharma, Niyar R Barman, Chandan Gupta, Vinija Jain, Aman Chadha, Amit Sheth, Prof. (Dr.) Amitava Das‚Ä¢ We unveil the Counter Turing Test (CT^2) benchmark for assessing AI-generated text detection methods and propose the AI Detectability Index (ADI) to rank 15 LLMs by their detectability.‚Ä¢ https://lnkd.in/grZVBzAjüîπFACTIFY3M: A benchmark for multimodal fact verification with explainability through 5W Question-Answering‚Ä¢ Megha Chakraborty, Khushbu Pahwa, Anku Rani, Shreyas Chatterjee, Dwip Dalal, Harshit Dave, Ritvik G, Preethi Gurumurthy, Adarsh Mahor, Samahriti Mukherjee, Aditya Pakala, Ishan Paul, Janvita Reddy, Arghya Sarkar, Kinjal Sensharma, Aman Chadha, Amit Sheth, Prof. (Dr.) Amitava Das‚Ä¢ We introduce FACTIFY3M, a comprehensive multimodal dataset for fact verification featuring 3M samples, textual claims and associated images, visual paraphrases, and 5W QA pairs, aiming to address the growing societal challenge of disinformation.‚Ä¢ https://lnkd.in/gFKVzErxüîπAre Personalized Stochastic Parrots More Dangerous? Evaluating Persona Biases in Dialogue Systems‚Ä¢ Elaine (Yixin) Wan, Jieyu Zhao, Aman Chadha, NANYUN PENG, Kai-Wei Chang‚Ä¢ We examine ""persona biases"" in dialogue systems, highlighting the sensitivity of LLMs to persona-based prompts, propose the UniversalPersona dataset to evaluate biases, reveal significant biases in models like ChatGPT, and ultimately emphasize the need for safer persona use in LLMs.‚Ä¢ https://lnkd.in/grFdVZKvüîπCONFLATOR: Incorporating Switching Point based Rotatory Positional Encodings for Code-Mixed Language Modeling‚Ä¢ Mohsin Mohammad, Sai Teja Kandukuri, Neeharika Gupta, Parth Patwa, Anubhab Chatterjee, Vinija Jain, Aman Chadha, Prof. (Dr.) Amitava Das‚Ä¢ We introduce CONFLATOR, a language modeling approach for code-mixing that emphasizes switching points using a rotary positional encoding, outperforming the state-of-the-art in sentiment analysis and translation tasks for Hinglish.‚Ä¢ https://lnkd.in/gwgj_rak#artificialintelligence #machinelearning #ai #research

          ‚Ä¶see more
        


EMNLP 2023 Papers
",,https://www.linkedin.com/feed/update/urn:li:activity:7118078536787136513?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7118078536787136513%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D561FAQGuDA0vh9TJ7g/feedshare-document-cover-images_480/0/1697081323802?e=1705658400&v=beta&t=XP1K13zPERstkkUH12I5tcM_m0zMqYIrARmFjS8Syz4
153,65a10528a5b8f072000021ea,31712502-0ec5-cdf6-5304-53400f5d0fed,https://media.licdn.com/dms/image/D4E03AQGM0Y967bzwYw/profile-displayphoto-shrink_100_100/0/1673958730736?e=1710374400&v=beta&t=D7vfK8Xc4FuC4GIIHDiKOT2J7OcBvz88MsJvG0D0Df8,David Mataciunas,https://www.linkedin.com/in/ACoAAAsf8pgBPeN60A0rc0301Fe7tNkiA88zbVQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAsf8pgBPeN60A0rc0301Fe7tNkiA88zbVQ,"
Technical Data Analyst / ML Engineer @ Sunrise | Chairman of the Board of AI Association of Lithuania | Startup Mentor
","
State of AI Report 2023 is HERE!!!! ü§Øü§ØOne of the best reports about AI has been released!! Huge kudos to Air Street Capital & Nathan Benaich for an amazing job üöÄExecutive summary of report:Research üöÄüöÄ GPT-4 lands and demonstrates a capabilities chasm between proprietary and next-best open source alternatives, while also validating the power of reinforcement learning from human feedback. üöÄ Efforts grow to clone or beat proprietary model performance with smaller models, better datasets, longer context‚Ä¶powered by LLaMa-1/2.üöÄ It‚Äôs unclear how long human-generated data can sustain AI scaling trends (some estimate that data will be exhausted by LLMs by 2025) and what the effects of adding synthetic data are. Videos and data locked up in enterprises are likely up next. üöÄ LLMs and diffusion models continue to offer gifts to the life science community by producing new breakthroughs for molecular biology and drug discovery. üöÄ Multimodality becomes the new frontier and excitement around agents of all flavors grows substantially. Industry üõ∏üõ∏ NVIDIA rips into the $1T market cap club with voracious demand for its GPUs from nation states, startups, big tech and researchers alike.üõ∏ Export controls rate limit advanced chip sales to China, but major chip vendors create export control-proof alternatives. üõ∏ Led by ChatGPT, GenAI apps have a breakout year across image, video, coding, voice or CoPilots for everyone, driving $18B of VC and corporate investments. Politics ü™êü™ê The world has divided into clear regulatory camps, but progress on global governance remains slower. The largest AI labs are stepping in to fill the vacuum.ü™ê The chip wars continue unabated, with the US mobilising its allies, and the Chinese response remaining patchy.ü™ê AI is forecast to affect a series of sensitive areas, including elections and employment, but we‚Äôre yet to see a significant effect.Safety ü¶æü¶æ The existential risk debate has reached the mainstream for the first time and intensified significantly.ü¶æ Many high-performing models are easy to ‚Äòjailbreak‚Äô. To remedy RLHF challenges, researchers are exploring alternatives, e.g. self-alignment and pretraining with human preferences.ü¶æ As capabilities advance, it‚Äôs becoming increasingly hard to evaluate SOTA models consistently. Vibes won‚Äôt suffice.#ai #stateofai #llm #future

          ‚Ä¶see more
        


State of AI report
",,https://www.linkedin.com/feed/update/urn:li:activity:7118127095762890752?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7118127095762890752%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D1FAQGzYK8UpcVVfw/feedshare-document-cover-images_480/0/1697093326585?e=1705658400&v=beta&t=AXZPDJokn2crhwKT2tZQDwm_Lt7kKATsp7t_qiOix2k
154,65a10528a5b8f072000021eb,8b12c1f7-1e0b-bdbd-d642-9f7507c7bec1,https://media.licdn.com/dms/image/C5603AQGCA0jXW9wIGQ/profile-displayphoto-shrink_100_100/0/1603913066364?e=1710374400&v=beta&t=M64xWhgI7OO0_FX5ZHok8lecx-QinGmoDc29X_wdRmI,Chip Huyen,https://www.linkedin.com/in/ACoAAAIQAJQBE3ykLNnsOPVvxwuuVCOir2zAjOQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAIQAJQBE3ykLNnsOPVvxwuuVCOir2zAjOQ,"
Real-time ML @ Claypot AI | ML Sys @ Stanford | Hiring strong streaming engineers
","
New blog post: Multimodality and Large Multimodal Models (LMMs)Link: https://lnkd.in/gJAsQjMcBeing able to work with data of different modalities -- e.g. text, images, videos, audio, etc. --  is essential for AI to operate in the real world.Many use cases are impossible without multimodality, especially those in industries that deal with multimodal data such as healthcare, robotics, e-commerce, retail, gaming, etc.Not only that, data from new modalities can help boost model performance. Shouldn‚Äôt a model that can learn from both text and images perform better than a model that can learn from only text or only image?OpenAI noted in their GPT-4V system card that ‚Äúincorporating additional modalities (such as image inputs) into LLMs is viewed by some as a key frontier in AI research and development.‚ÄùThis post covers multimodal systems, including LMMs (Large Multimodal Models). It consists of 3 parts.* Part 1 covers the context for multimodality, including use cases, different data modalities, and types of multimodal tasks.* Part 2 discusses how to train a multimodal system, using the examples of CLIP, which lays the foundation for many LMMs, and Flamingo, whose impressive performance gave rise to LMMs.* Part 3 discusses some active research areas for LMMs, including generating multimodal outputs and adapters for more efficient multimodal training.Even though we‚Äôre still in the early days of multimodal systems, there‚Äôs already so much work in the space. At the end of the post, I also compiled a list of models and resources for those who are interested in learning more about multimodal.As always, feedback is appreciated!#llm #lmm #multimodal #genai #largemultimodalmodel

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7117734420760952833?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7117734420760952833%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQGG9rrqKsxWfQ/feedshare-shrink_480/0/1697000126303?e=1707955200&v=beta&t=oX8tUIQLy1PnSaSPHvKWBgFGgqaJgyj1wPHkMQYgPo0
155,65a10528a5b8f072000021ec,8a0e30b7-54c5-4ea3-6985-a61a867fdea1,https://media.licdn.com/dms/image/C4D03AQFcFViXg1T69g/profile-displayphoto-shrink_100_100/0/1516303645074?e=1710374400&v=beta&t=B8NcAcO7HYN5DPDIEZpJtUtwghc43sWTR9AiLdRXUaU,"Bojan Tunguz, Ph.D.",https://www.linkedin.com/in/ACoAAACtHQMBTsH6C8rrVqP5YOv1H9T55PU6NPA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAACtHQMBTsH6C8rrVqP5YOv1H9T55PU6NPA,"
Machine Learning at NVIDIA | Physicist | Quadruple Kaggle Grandmaster
","
Automated AI agents stand to turbocharge the digital economy. My latest blog post.Agents are Coming: https://lnkd.in/gpRCZrMF#AI #AGI #ChatBots 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7116444471445135360?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7116444471445135360%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQE2hDZcGaGsYQ/feedshare-shrink_480/0/1696692578687?e=1707955200&v=beta&t=1JOb07u-KX7n3IVnycbgm05tcw-gBwPbFVMaQeDlhMs
156,65a10528a5b8f072000021ed,827e389b-b1ab-d178-ee40-dabc95e10c2c,https://media.licdn.com/dms/image/C4E03AQGT5NwZ4L3-nQ/profile-displayphoto-shrink_100_100/0/1609312296918?e=1710374400&v=beta&t=RX-cE_-LuAO1Ts2ng0RA3f0NOTvyqvjfYra3rqeY02s,Md Tahmid Rahman Laskar,https://www.linkedin.com/in/ACoAABQ2JxABpGZaEvVRONVp_2ABhssVPJCNebo?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABQ2JxABpGZaEvVRONVp_2ABhssVPJCNebo,"
Applied Scientist (NLP & ML) @ Dialpad
","
Happy to inform that one of our papers from the NLP team at Dialpad on building a real-world business meeting summarization system using Large Language Models (LLMs) has been accepted at the Industry Track of EMNLP 2023. We benchmarked various LLMs to study their pros and cons in the context of business meeting summarization which paved the way to build the real-time call summary generation system for Dialpad‚Äôs Ai Recap (https://lnkd.in/g6D7qFCd).I also have two other papers accepted at EMNLP 2023 (one on Poem Summarization in the main conference, and another on Query-Focused Summarization in the Findings of EMNLP) based on my academic collaboration with my alma maters Islamic University of Technology and York University.Looking forward to the EMNLP 2023 in Singapore this December.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7117568403493588992?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7117568403493588992%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHcM5L9PRNSHQ/feedshare-shrink_800/0/1696960544076?e=1707955200&v=beta&t=Xk4qOh97vsTN976hoVEWq1o9P4g0MaJ_FyGGRCFQgsE
157,65a10528a5b8f072000021ee,2364df9b-71a1-c6cf-96be-3c5a36aaf8e7,https://media.licdn.com/dms/image/C5603AQH0vt7JCOIZ2g/profile-displayphoto-shrink_100_100/0/1659622741519?e=1710374400&v=beta&t=oD7v-H5eftQLYDRlvUvk2VE7-lsZDVk9VuRckoG8nZk,Jim Fan,https://www.linkedin.com/in/ACoAAA1AILwBEWpiY_CZ_I03PL9inU_8YB3s5nQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA1AILwBEWpiY_CZ_I03PL9inU_8YB3s5nQ,"
NVIDIA Sr. Research Scientist & Lead of AI Agents. Stanford Ph.D. Creator of Voyager, Eureka, MineDojo (Best Paper). OpenAI's first intern. Sharing insights on the bleeding edge of AI research & industry.
","
Let's reverse engineer Disney's adorable, lifelike robot! I couldn't find a whitepaper, but this is how I think it's trained: 1. The emotional behaviors are curated by Disney animation artists, keyframe by keyframe. But it cannot be ""rendered"" directly on the robot because it doesn't take into account the complex real-world physics.2. Reinforcement learning (RL) is a great tool for training low-level robot controllers. RL needs a reward function to optimize, and it's typically a task reward (e.g. walk in a straight line as fast as possible). The problem is that RL doesn't know what counts as ""natural behavior"", and often produces weird-looking body postures that somehow still maximize the reward. This is a human alignment problem just like ChatGPT.3. Enters Adversarial Motion Prior (AMP): a technique that learns the human preference by training a classifier on what we consider ""emotional & cute"". In GAN literature, this is called a discriminator. Disney artists are good at creating such a dataset. You can then add AMP as an auxiliary reward in simulation to nudge the robot towards desired behaviors. AMP was developed by Peng et al. 2021 and Escontrela et al. 2022.https://lnkd.in/gasRtsWA4. Add lots of data augmentation to make the controller robust to physical disturbances. In RL, it's called ""domain randomization"". This is a very powerful technique that bridges the gap between simulator and reality. Previously, OpenAI used domain randomization to train a 5-finger robot hand to manipulate a Rubik's Cube: https://lnkd.in/gK2T5dTsIEEE news article gave hints about the pipeline: https://lnkd.in/gpiqrFut

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7117563997435936769?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7117563997435936769%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5605AQGfjm9zzMi-ZQ/videocover-low/0/1696959480837?e=1705658400&v=beta&t=FWnxf9K-_k0_jM_PyxVW8W83EAqpDmU1Mt7pmzYcglw
158,65a10528a5b8f072000021ef,ae161a9a-8743-5743-73eb-37a51f7529ac,https://media.licdn.com/dms/image/D4D03AQHI9V5qRZLPxg/profile-displayphoto-shrink_100_100/0/1704471436964?e=1710374400&v=beta&t=0SFabtfQZmowTM1efId8aLycAwuRJ-0S47Lq9GpPpJ0,Dylan Castillo,https://www.linkedin.com/in/ACoAABZFzAwBy8HvvEMBpnGeWGhAVWoi6hof2mg?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABZFzAwBy8HvvEMBpnGeWGhAVWoi6hof2mg,"
AI Engineer | Taking AI projects from zero to one
","
Most paid courses about LLMs simply rehash free materials that can easily be found online.Before you waste your $$$ on them, here are some beginner-friendly FREE resources that I can vouch for:1Ô∏è‚É£ A Hacker's Guide to Language Models by Jeremy Howard: https://lnkd.in/dcXMg8zJ2Ô∏è‚É£ ChatGPT Prompt Engineering for Developers: https://lnkd.in/dk8utYMr 3Ô∏è‚É£ OpenAI Cookbook: https://lnkd.in/djp2zHGE4Ô∏è‚É£ GPT Best Practices: https://lnkd.in/d66v_q8t5Ô∏è‚É£ Lilian Weng's Prompt Engineering guide: https://lnkd.in/dwvdZEkG6Ô∏è‚É£ Chip Huyen's Building LLM applications for production https://lnkd.in/dSffDGfVThis list is biased towards OpenAI's models and practical approaches. If you want theory-heavy or OSS-focused materials, these won't be that useful.

          ‚Ä¶see more
        


A Hackers' Guide to Language Models
",,https://www.linkedin.com/feed/update/urn:li:activity:7117426046404063233?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7117426046404063233%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQG0vCEc2YWjSQ/articleshare-shrink_800/0/1704312131279?e=1705658400&v=beta&t=bnvDu3PeSos5MzZTHBuXSL3vSczme938fU0g6_RSPqQ
159,65a10528a5b8f072000021f0,867a9466-a496-adba-398a-eaa82e8ebcf4,https://media.licdn.com/dms/image/D4E03AQGM0Y967bzwYw/profile-displayphoto-shrink_100_100/0/1673958730736?e=1710374400&v=beta&t=D7vfK8Xc4FuC4GIIHDiKOT2J7OcBvz88MsJvG0D0Df8,David Mataciunas,https://www.linkedin.com/in/ACoAAAsf8pgBPeN60A0rc0301Fe7tNkiA88zbVQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAsf8pgBPeN60A0rc0301Fe7tNkiA88zbVQ,"
Technical Data Analyst / ML Engineer @ Sunrise | Chairman of the Board of AI Association of Lithuania | Startup Mentor
","
Want to understand how #ChatGPT and Transformers work? Financial Times released a transformers guide with great visualization to explain this in simple words. Article in the comments‚¨áÔ∏è#ai #transformers #future

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7117038295762497537?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7117038295762497537%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQFkXnjcXOcs6A/feedshare-shrink_480/0/1696834156800?e=1707955200&v=beta&t=_RxFcDCVMi6lYX_iAJxEv8ZxKMgnqiG3wS8AyNXmNhs
160,65a10528a5b8f072000021f1,fdbb75b7-6a96-eb2a-9207-7c3f929d3cca,https://media.licdn.com/dms/image/C560BAQGgJ6XIqm5uFw/company-logo_100_100/0/1671049348505/microsoftresearch_logo?e=1713398400&v=beta&t=I6qz1r1FIDjkwjUVlMI7INP5kg_djUG_Mm_cElw-tXg,Microsoft Research,https://www.linkedin.com/company/microsoftresearch/,"
215K followers
","
Microsoft Research is announcing a contingent Pre-Doctoral Research Assistant Position in Biomedical ML. Recent college graduates wishing to gain research experience prior to pursuing a Ph.D. at the intersection of ML and biological and medical imaging or multi-omics are encouraged to apply by Nov 13th: https://msft.it/60419qTSH

          ‚Ä¶see more
        


Pre-Doctoral Research Assistant Position in Biomedical ML
",,https://www.linkedin.com/feed/update/urn:li:activity:7117479148607995904?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7117479148607995904%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5610AQGcQBkEm6ElQw/image-shrink_800/0/1696939261276?e=1705658400&v=beta&t=NS6yRru9Lh75z6U6kfQSZvTzQ2UlNLJ39_Fqr9NSzw4
161,65a10528a5b8f072000021f2,d607498d-15fe-09bf-ed77-4b4911314183,https://media.licdn.com/dms/image/D4E03AQHtC2BUAB6jkA/profile-displayphoto-shrink_100_100/0/1694687456770?e=1710374400&v=beta&t=ndmP3__bJjjA60t62U8lCwf_bck4TDX4LIp-qSsOgAc,Prithivi Da,https://www.linkedin.com/in/ACoAAANONyEBI75vYtjMK4f9hcDMhgneli34DsA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAANONyEBI75vYtjMK4f9hcDMhgneli34DsA,"
Building a Memory Assistant for Philomaths. Sharing wisdom from a 2 decade experience in creative problem solving.
","
Rag-fusion: Takes RAG to next frontier. Why ?It tackles the constraints inherent in RAG by generating multiple user queries and reranking the results.Utilises Reciprocal Rank Fusion and custom vector score weighting for comprehensive, accurate results.Blog: https://lnkd.in/em8vsxTmRepo: https://lnkd.in/evdYGPct_________Save for later using https://savelikeapro.app

          ‚Ä¶see more
        


GitHub - Raudaschl/rag-fusion
",,https://www.linkedin.com/feed/update/urn:li:activity:7117380747178426368?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7117380747178426368%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQHHOTFj9iIvnw/articleshare-shrink_800/0/1704134319741?e=1705658400&v=beta&t=pfj5tJAMTRxtuGcYx_WyEKwIlSQBueHM-soCbZ7ExVQ
162,65a10528a5b8f072000021f3,b0f6fab8-c4d7-e5ae-6c10-30fdca350b44,https://media.licdn.com/dms/image/C4E03AQGY_MdIED_pjg/profile-displayphoto-shrink_100_100/0/1659451623932?e=1710374400&v=beta&t=8eSqImt6h2RqD8j5-Qw-SlmD4I4dwaU90bOacY5yQOs,Suneel Patel,https://www.linkedin.com/in/ACoAAAf3wo0BK1dahQlGfk0TF5QwqntX5WMV2iM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAf3wo0BK1dahQlGfk0TF5QwqntX5WMV2iM,"
Sr. Data Scientist at TaskUs
","
If you struggle to deploy your AI/ML/DL Model in production environment and want to use docker. Sharing a good resource for beginner level clarity how to use docker.Article - Docker For Data Science Project...https://lnkd.in/dRizCbB9Source -  Youssef Hosni#docker #datascience #deployment #endtoendproject #data #ai #ml #dl 

          ‚Ä¶see more
        


Docker for Data Science Projects: A Beginner-Friendly Introduction
",,https://www.linkedin.com/feed/update/urn:li:activity:7116610939105214464?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7116610939105214464%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQEDibEyqu_rrQ/articleshare-shrink_1280_800/0/1704378655225?e=1705658400&v=beta&t=V7tFsQ0TGOTLqWJr9Ap7ynruOjvtpIMm8ts9Evbxziw
163,65a10528a5b8f072000021f4,01c34310-3212-6022-8d49-6ba86f27da9d,https://media.licdn.com/dms/image/C4E03AQHVyH-IfD1KbQ/profile-displayphoto-shrink_100_100/0/1629877234109?e=1710374400&v=beta&t=0UZUl_dDUxLaZn-Hu-zToqEDe3rpL5cB2JkP5_jlNXc,"Sebastian Raschka, PhD",https://www.linkedin.com/in/ACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU,"
Machine learning and AI researcher since the early days ‚Ä¢ coding and working with LLMs at Lightning AI ‚Ä¢ ex-statistics professor at University of Wisconsin-Madison
","
In this issue of Ahead of AI, I explore the current endeavors of major tech companies. It appears that every one of these entities is either training or developing LLMs, with a noticeable shift of their core operations towards AI -- thus the title ""LLM Businesses and Busyness.""For those particularly interested in open-source and freely accessible LLMs, fear not. This edition will also spotlight some innovative LLMs that have garnered attention due to their small nature and exceptional benchmark results.Given that LoRA is a favored technique in research for efficient finetuning, I will also delve into two new intriguing variants that were proposed last month. To conclude, I'll highlight the recent launches of some major open-source initiatives.#LLMs #largelanguagemodels #AI

          ‚Ä¶see more
        


Ahead of AI #12: LLM Businesses and Busyness
",,https://www.linkedin.com/feed/update/urn:li:activity:7116737745254813696?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7116737745254813696%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5612AQGtYjf4FHtrSQ/article-cover_image-shrink_720_1280/0/1696691152180?e=1710374400&v=beta&t=6m8xYZWNvO0TXdlJm_vPCYW71TKkvXD8uR6zv5E1Kz0
164,65a10528a5b8f072000021f5,a6564daa-efb3-5ea4-d6c7-f7772cefcd26,https://media.licdn.com/dms/image/C560BAQGgJ6XIqm5uFw/company-logo_100_100/0/1671049348505/microsoftresearch_logo?e=1713398400&v=beta&t=I6qz1r1FIDjkwjUVlMI7INP5kg_djUG_Mm_cElw-tXg,Microsoft Research,https://www.linkedin.com/company/microsoftresearch/,"
215K followers
","
HoloAssist is a new multimodal dataset consisting of 166 hours of interactive task executions with 222 participants. Discover how it offers invaluable data to advance the capabilities of next-gen AI copilots for real-world tasks: https://msft.it/60459Ua6W 

          ‚Ä¶see more
        


HoloAssist: A multimodal dataset for AI copilots in the physical world
",,https://www.linkedin.com/feed/update/urn:li:activity:7115765358682144769?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7115765358682144769%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5610AQFo3YCj10AqKQ/image-shrink_800/0/1696530661443?e=1705658400&v=beta&t=rXd6_yQOQsE76lL1VW3wCYszEWBjiYFCKR95iv3Dg8E
165,65a10528a5b8f072000021f6,d3a5c15a-ca5e-f882-5f16-e07c7dc38106,https://media.licdn.com/dms/image/C560BAQEg7UfAyEoKWg/company-logo_100_100/0/1637414049335/nlplanet_logo?e=1713398400&v=beta&t=_QvY1xSefLEyzgG6cO_2hVnEPcwkGrAcB32ORRVOZbM,NLPlanet | Breaking Down Generative AI Daily,https://www.linkedin.com/company/nlplanet/,"
9K followers
","
Can pause tokens help LLMs in ""thinking before speaking""? ü§îüëÄ This study tests the idea of letting language models arrange more hidden vectors before generating the next token. They use a learnable pause token to allow extra calculations before giving an answer.üî¨ Tests were done on decoder-only models with different parameter sizes.üìä Significant score gains were observed on reasoning tasks, such as the QA task of SQuAD, CommonSenseQA, and the reasoning task of GSM8k.‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚ÄîWant to stay at the forefront of Generative AI developments? Follow NLPlanet for daily insights into the most relevant news, guides, and research! üöÄ

          ‚Ä¶see more
        


Think before you speak: Training Language Models With Pause Tokens
",,https://www.linkedin.com/feed/update/urn:li:activity:7115953871436341248?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7115953871436341248%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D22AQFW3uA7u5JVsA/feedshare-shrink_800/0/1696493527240?e=1707955200&v=beta&t=9MIZn9qhMgsNwwx79fIsRmVWkzAlA-K2b3i0j5fUGX0
166,65a10528a5b8f072000021f7,33f60179-7398-55b5-d799-485ace6e7ed9,https://media.licdn.com/dms/image/C4E0BAQEH4nbL2sl5gA/company-logo_100_100/0/1635539130887/facebookai_logo?e=1713398400&v=beta&t=sFixUTJyqFvVkiEiDy7X9VTcRcgGTR2jo-a3QyjRJ70,AI at Meta,https://www.linkedin.com/company/aiatmeta/,"
672K followers
","
Today we're officially opening applications for Llama Impact Grants.Full details & application ‚û°Ô∏è https://bit.ly/45lqz7zFrom now until November 15, organizations across the globe can submit proposals for how they'd like to utilize Llama 2 to address challenges across three different tracks: education, environment & open innovation. The goal of the program is to identify and support the most compelling applications of Llama 2 for societal benefit.Following a two-phase proposal review process, three $500,000 grants will be awarded to winning teams to implement their solutions.We can't wait to see what you'll build!

          ‚Ä¶see more
        


Llama Impact Grants | AI at Meta
",,https://www.linkedin.com/feed/update/urn:li:activity:7116105835797254144?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7116105835797254144%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5622AQG3F02H7UwcUw/feedshare-shrink_800/0/1696611837150?e=1707955200&v=beta&t=gn-X9a-PxOW7yRrZ4M40EVfebQ0VMzD60tX-lyJ2hqs
167,65a10529a5b8f072000021f8,605c3bcd-3ab0-9392-b4e1-f961c9215136,https://media.licdn.com/dms/image/C4D03AQHBLoV7GRUP2w/profile-displayphoto-shrink_100_100/0/1642552032280?e=1710374400&v=beta&t=6fHP9zlPn3MfDX75uR_yOGRirqSCpNHqYVzC4P-vK0s,Yann LeCun,https://www.linkedin.com/in/ACoAAAADFk0BbiOeu2Wrer11SaPH_5m1GM8pG6Q?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAADFk0BbiOeu2Wrer11SaPH_5m1GM8pG6Q,"
VP & Chief AI Scientist at Meta
","
decoding speech from magnetoencephalography signals.
 

Decoding speech perception from non-invasive brain recordings - Nature Machine Intelligence
",,https://www.linkedin.com/feed/update/urn:li:activity:7115981398166908928?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7115981398166908928%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5622AQGhLJKQkmDrHw/feedshare-shrink_2048_1536/0/1696525825724?e=1707955200&v=beta&t=xGSyTfC5q-PGraJSq_HTBaUawTN4BSohgfqXKFPERLQ
168,65a10529a5b8f072000021f9,a1b84443-7e84-c5d5-07f5-bf5abb02101a,https://media.licdn.com/dms/image/D5603AQGJYhJyVo8iPw/profile-displayphoto-shrink_100_100/0/1663082443585?e=1710374400&v=beta&t=jOo61H1qgMruiGbJNZqeBy1_GDlP_1aDvIp0Rod6pcU,Deval Pandya,https://www.linkedin.com/in/ACoAAALBmRMBtHZNBY1FcCSxb3UxnOVPiqCGpmg?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAALBmRMBtHZNBY1FcCSxb3UxnOVPiqCGpmg,"
Responsible AI | Climate Change | Empathy
","
Amazing opportunity to work with the best and the brightest and contribute to designing a better future for people and the planet!
 

Job Board
",,https://www.linkedin.com/feed/update/urn:li:activity:7116100680406224896?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7116100680406224896%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5622AQH2EJG6Af2ejQ/feedshare-shrink_800/0/1696606369421?e=1707955200&v=beta&t=VmyOR_GP46ox2FsG9oYY85lXe2nLJ4TdMowusCpx2ZE
169,65a10529a5b8f072000021fa,2347a1ee-e83b-28bb-f7ef-4734ec744f08,https://media.licdn.com/dms/image/D4D03AQGiM7ZrUwqu_Q/profile-displayphoto-shrink_100_100/0/1675971026692?e=1710374400&v=beta&t=ZxyOG4FoSseA2EWLlzTMnbmhB6JtuO_GJ2MbbYjK918,Ishaan Jaffer,https://www.linkedin.com/in/ACoAACWY5pEBKzknX7d4_HZgChhe63kyRKsiUmg?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACWY5pEBKzknX7d4_HZgChhe63kyRKsiUmg,"
Building LiteLLM (YC W23) 4.1k+ stars | Use 100+ LLMs
","
üí•Excited to announce LiteLLM now powers Microsoft LMOps https://lnkd.in/gSGyjpbR for calling 100+ LLMs for completion ‚ö°Ô∏èNew repo using LiteLLM: https://lnkd.in/g34aAiJx s/o to Kasper Junge for this PR üå¥Improvement to LiteLLM proxy - pass keys, env variables in request body h/t to Joseph Ucuzoglu for this requestü¶ô Improvement to Ollama - fix when api_base not set h/t to Prasad Chalasani for this issueüõ†Ô∏è Fixes to passing request_timeout for Anthropic LLMs üîé Support for tracking user ids for completion calls using the LLMonitor callback 

          ‚Ä¶see more
        


GitHub - microsoft/LMOps: General technology for enabling AI capabilities w/ LLMs and MLLMs
",,https://www.linkedin.com/feed/update/urn:li:activity:7115914121706962944?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7115914121706962944%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQFVf2gAAYgjmA/articleshare-shrink_800/0/1703848792163?e=1705658400&v=beta&t=92K73pVhQ3YLK-nLqWZPIkJcBk12wNSSgxB-Lv6ctHo
170,65a10529a5b8f072000021fb,f26d0ae8-62a6-c8e1-fa88-26bd0bd9937b,https://media.licdn.com/dms/image/D4E35AQEYNkhtesIo_A/profile-framedphoto-shrink_100_100/0/1702485367945?e=1705658400&v=beta&t=WQHkQz0l1z5bd3L3a-K9q54909iPNSWVJXIcUrOKuB4,Cheng Zhang,https://www.linkedin.com/in/ACoAAAYXsfsBxiHYVH5aS0af8RDvShNPljqKBU4?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAYXsfsBxiHYVH5aS0af8RDvShNPljqKBU4,"
Principal Research Manager at Microsoft Research | ex-Disney Research | PhD in Machine Learning | Award winner | D&I advocate
","
Since the beginning of this year, I have been contemplating ways to make foundation models causal. I am so excited to share our latest work, titled  Towards Causal Foundation Model: on Duality between Causal Inference and Attention Our research has uncovered a connection between causal inference and self-attention. This discovery enables transformers to directly answer causal inference questions! As a result, our method can be used to do causal inference even when presented with an unseen dataset in a foundation model setting. Thank you Jiaqi (Vicky) Zhang Chao Ma Joel Jennings who are the heroes behind this work. Thanks the Causica team in Microsoft Research. I cannot wait to see our new research making real-world impact in collabration with  Colleen Tyler Lisa Parks Maria Defante Shiv Kunderu Nitin Agarwal #machinelearning #AI #Attention #Causality #CausalMachineLearning#foundationmodel #transformer #ZeroShot #Microsoft #MicrosoftResearch #CausalFoundationModel #CausalInference #DeepLearning #DecisionOptmization #AIforGrowth 

          ‚Ä¶see more
        


2310.00809.pdf
",,https://www.linkedin.com/feed/update/urn:li:activity:7115408059035738113?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7115408059035738113%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,
171,65a10529a5b8f072000021fc,230a8f11-19df-88b2-8797-0ca3d51defec,https://media.licdn.com/dms/image/C560BAQEg7UfAyEoKWg/company-logo_100_100/0/1637414049335/nlplanet_logo?e=1713398400&v=beta&t=_QvY1xSefLEyzgG6cO_2hVnEPcwkGrAcB32ORRVOZbM,NLPlanet | Breaking Down Generative AI Daily,https://www.linkedin.com/company/nlplanet/,"
9K followers
","
SkyPilot: an open-source framework for running LLMs efficiently and batch jobs on any cloud üòÆüî• As of now, SkyPilot supports a wide array of providers such as AWS, Azure, GCP, Lambda Cloud, IBM, Samsung, OCI, Cloudflare, and any Kubernetes cluster.üíª SkyPilot ensures maximum GPU availability for your tasks, allowing provisioning in all zones, regions, or clouds you have access to. It also offers automatic failover for added security, preventing any issues from hampering job execution.üí∞ SkyPilot excels in cost savings. Managed Spot saves 3-6x with spot VMs, offering auto-recovery. Optimizer saves 2x by selecting cheapest options. Autostop prevents waste by managing idle clusters.‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚ÄîWant to stay at the forefront of Generative AI developments? Follow NLPlanet for daily insights into the most relevant news, guides, and research! üöÄ

          ‚Ä¶see more
        


GitHub - skypilot-org/skypilot: SkyPilot: Run LLMs, AI, and Batch jobs on any cloud. Get maximum savings, highest GPU availability, and managed execution‚Äîall with a simple interface.
",,https://www.linkedin.com/feed/update/urn:li:activity:7114866723924697088?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7114866723924697088%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQFjK52_u30YCw/articleshare-shrink_800/0/1704495447550?e=1705658400&v=beta&t=Nrni9MCo7iJIWF5JyVdS539kxy3jIw6TrPYWLRyWDVU
172,65a10529a5b8f072000021fd,794a9f29-ce12-1419-e208-416d6a5000d5,https://media.licdn.com/dms/image/D5603AQGvhhCjW5El4Q/profile-displayphoto-shrink_100_100/0/1701211615166?e=1710374400&v=beta&t=N2Hd_lnU2BgySFWeE-6AiCgE0tz06UjB1cdTy7J3Mjs,Ethan Mollick,https://www.linkedin.com/in/ACoAAAAGUakBGLMO02LmS5BwXexrsKODQQpx2qI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAAGUakBGLMO02LmS5BwXexrsKODQQpx2qI,"
Associate Professor at The Wharton School
","
Fascinating, I have been waiting for a paper to test this: How good is GPT-4 as a peer reviewer?A study on 4,800 real Nature + ICLR papers finds AI reviewers overlap with human ones as much as humans overlap with with each otherPlus, 57% of authors find them helpful and 83% said it beats at least one of their real human reviewers (no surprise, given how we feel aboug peer review). Given that it is stronger in some areas than othets, GPT-4 is a flawed but useful tool for authors. Curious how future AIs do‚Ä¶ https://lnkd.in/es5EHFff

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7115306117517168640?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7115306117517168640%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQFVvuYijqY1uA/feedshare-shrink_480/0/1696421172489?e=1707955200&v=beta&t=yvyJ6S1GKPlBcn__1YfHGep6cxWR3EDj5yAwjqhnBOg
173,65a10529a5b8f072000021fe,e1be5fc6-7b11-9fff-890f-4307d4210ad0,https://media.licdn.com/dms/image/D5603AQGcNOmlWJaw3Q/profile-displayphoto-shrink_100_100/0/1689228899278?e=1710374400&v=beta&t=FTjavpluSNdk1bMK4oYMHxF6Erb2UvjMbLuSUDwnepg,Sayon Mondal,https://www.linkedin.com/in/ACoAAAOSQvMBsLl5VklVsW9GF0nMiKupi271CLA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAOSQvMBsLl5VklVsW9GF0nMiKupi271CLA,"
Corporate Strategy | Global GTM | User Experience | Service Design | Stock Investor
","
An awesome collection of Design articles..
 ",,https://www.linkedin.com/feed/update/urn:li:activity:7115203784363978752?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7115203784363978752%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQHDpZuDTiyCxw/feedshare-shrink_2048_1536/0/1696099275236?e=1707955200&v=beta&t=iD7g6JUIiz3G8-b9Zs04N3_zdSCgajaRRMXffxf-TRo
174,65a10529a5b8f072000021ff,c4733ee2-0913-7ed5-7dcd-8deb44a97c5f,https://media.licdn.com/dms/image/D5603AQF6Aon5GU1gQw/profile-displayphoto-shrink_100_100/0/1679883134942?e=1710374400&v=beta&t=5XCOy_u-_M2mkmOLl4UVBg_ryAs3QdllGHUlrlra9iw,Jinen Setpal,https://www.linkedin.com/in/ACoAACkVI5wBUocPA6zbGw4-tecX8hYDAsT2i1E?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACkVI5wBUocPA6zbGw4-tecX8hYDAsT2i1E,"
Research in Interpretable Model Optimization. http‚Äés://jinensetpal.github.io/
","
Our research from the Alexa Prize TaskBot Challenge 2 was published today!! Thanks Amazon Science for the opportunity to deliver the bleeding edge directly to the Alexa userbase. It was incredible fun!Publication: https://lnkd.in/d5XzKA32 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7115034079472816128?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7115034079472816128%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQGMwMKcA4ifPg/feedshare-shrink_480/0/1696356314963?e=1707955200&v=beta&t=riSw9D9m1wmHtO2RPsDNnSyEkAF8iIfCQHSOj4a4zyY
175,65a10529a5b8f07200002200,f52fa26e-6b50-9e4a-9ddd-a9093a118ea7,https://media.licdn.com/dms/image/D4D03AQG4xJZLKNN8EA/profile-displayphoto-shrink_100_100/0/1697049214527?e=1710374400&v=beta&t=gxyPdmwMAtuCcxeevLC8Usy54dL9U6kJn9xnsn83W_w,Avi Chawla,https://www.linkedin.com/in/ACoAACSeHjUBR43YlMI3pOJvMZLrV0e9i43SNCQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACSeHjUBR43YlMI3pOJvMZLrV0e9i43SNCQ,"
Follow me to learn about Data Science, Machine Learning Engineering and best practices in the field. Author of Daily Dose of Data Science Series.
","
Loss functions of common ML algorithms in a single frame...Loss functions are a key component of ML algorithms. Therefore, knowing which loss functions are (typically) best suited for specific ML algorithms is extremely crucial.--üëâ Get a Free Data Science PDF (550+ pages) with 320+ posts by subscribing to my daily newsletter today: https://bit.ly/DailyDS.--üëâ Over to you: Can you tell which loss function is used in KMeans?#machinelearning .

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7114548403035873280?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7114548403035873280%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQEpdpiTrAUgnA/feedshare-shrink_480/0/1696190714955?e=1707955200&v=beta&t=91kwHF13uWz04TIPorztKoJqBBs5TPNnDeJRAN0hwLw
176,65a10529a5b8f07200002201,4342df00-a7b1-3528-cc01-7dc68e1a1a8b,https://media.licdn.com/dms/image/D4E03AQHtC2BUAB6jkA/profile-displayphoto-shrink_100_100/0/1694687456770?e=1710374400&v=beta&t=ndmP3__bJjjA60t62U8lCwf_bck4TDX4LIp-qSsOgAc,Prithivi Da,https://www.linkedin.com/in/ACoAAANONyEBI75vYtjMK4f9hcDMhgneli34DsA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAANONyEBI75vYtjMK4f9hcDMhgneli34DsA,"
Building a Memory Assistant for Philomaths. Sharing wisdom from a 2 decade experience in creative problem solving.
","
Microsoft‚Äôs Phi1.5 just trolled LLaMa 2 ?‚Üí Open source (non-commercial only license)‚Üí 5.4x smaller than Smallest LLaMa. ‚Üí Yet performance matched ‚Üí Safer and less biased. Checkout out the paper Textbooks Are All You Need II: phi-1.5 paper : https://lnkd.in/eKc-u3HH_____________Save for later using https://savelikeapro.ai

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7114934618557931520?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7114934618557931520%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQH3rD6oBLOisw/feedshare-shrink_480/0/1696324699329?e=1707955200&v=beta&t=MhXW7eHh0oD-hLHv1JpOc2A6IlMk0fcuLQPIBbXEu9c
177,65a10529a5b8f07200002202,7b49e363-d911-94b7-a384-c349cb230bb7,https://media.licdn.com/dms/image/C4D03AQHHMFwUJI538w/profile-displayphoto-shrink_100_100/0/1622601163637?e=1710374400&v=beta&t=BQiEO_aSp5DrKwjXAnb93mimxSSLOQrqh1cuDExDh1k,Ida Momennejad,https://www.linkedin.com/in/ACoAAAIp6g4B_Iw2S70z8yh2Pn3Dw9ef8iyW9Tg?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAIp6g4B_Iw2S70z8yh2Pn3Dw9ef8iyW9Tg,"
Principal Researcher at Microsoft Research
","
 üì¢ üì¢ Delighted to share our #neurips2023 paper with colleagues at Microsoft Microsoft Research Evaluating Cognitive Maps & Planning in LLMs with CogEvalhttps://lnkd.in/e-V2VYMvTLDR: We tested planning in 8 LLMs (GPT-4, 3.5, 3, LLama2, Alpaca, Claude-v1, Bard, Cohere.) and identified failures like hallucinating invalid paths/falling in loops that don't support emergent zero-shot planning in LLMs.More:Recently an influx of studies claims emergent cognitive abilities in LLMs & doomers warn of AI planning a takeover.  Such claims often lack systematic evaluation involving multiple tasks, control conditions, iterations, stats, etc.But can LLMs really plan?! We make 2 contributions to address this.1-We propose CogEval: a cognitive science-inspired protocol for systematic evaluation of cognitive capacities in LLMs.Inspired by cognitive science, CogEval operationalizes a capacity w multiple tasks, iterations, domains, & can be applied to various abilities.2- We applied CogEval to evaluate LLM's ability to use cognitive maps for planning, which we operationalize with 15 tasks in 5 groups: multistep traversal, reward revaluation, transition revaluation, detour, shortcut. We made task prompts for 6 graphs based on previous human studies, 2 spatial & 1 social domains.Results: *  Zero-shot performance was low for all LLMs, w GPT-4 performing better than others.*  Performance was lowest on tasks that required flexible planning & adapting to local changes.*  Performance was broadly worse for larger graphs, but size was not key. Performance on a 15node graph with dense community structure & 3 bottleneck (D) was far worse compared to a 16node graph w more bridge ties (E), & a 12-node (C) was easier than a 7node tree (B).*   Next we identified three categories of failure modes in shortest-path planning of GPT-4/3.5 on a graph inspired by @AnnaSchapiro's work. LLMs:1-GPT-4 hallucinated paths that didn't exist >20% of the time2- sometimes even 1-step paths failed3- GPT4's shortest path had loops* GPT-4 did better when asked to list edges but couldn't use this information for planning valid trajectories.* Adding explicit breadth first search and depth first search instructions marginally but not consistently improve performance on some but not all 1-step traversals &didn't improve performance on flexible planning tasks that require adapting to local changes.Taken together these failure modes, esp hallucinations & 1-step errors, suggest GPT-4 can't use cognitive maps for zero-shot planning.Summary:1- We propose CogEval, a cog-sci-inspired protocol for systematic evaluation of abilities in LLMs2- Evidence speaks against emergent zero-shot planning in LLMs.Work highlights importance of methods in evaluating emergent cognitive ability in LLMs.Many thanks to coauthors: Hosein Hasanbeig, PhD, Felipe Vieira Frujeri, Hiteshi Sharma, Hamid Palangi, Robert Ness, Jonathan Larson. Follow ups soon!

          ‚Ä¶see more
        


Evaluating Cognitive Maps and Planning in Large Language Models with CogEval
",,https://www.linkedin.com/feed/update/urn:li:activity:7114672014681890816?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7114672014681890816%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQHsVHb898XgYA/articleshare-shrink_800/0/1703846914820?e=1705658400&v=beta&t=58DGiSIrlKNu1HwN4C3yRiGA9ZcCrfHw6rh9eUZuOlU
178,65a10529a5b8f07200002203,f6ee591b-ae03-1721-b110-530ac4a7c298,https://media.licdn.com/dms/image/C560BAQGcYjh_E6yyxg/company-logo_100_100/0/1658966385693/fiddler_ai_logo?e=1713398400&v=beta&t=1JCZhb1FaB2U938qhDanlf7-KpKSq7YdBweGF9I9XnE,Fiddler AI,https://www.linkedin.com/company/fiddler-ai/,"
11K followers
","
RLHF is a critical part of #LLM training. Sebastian Raschka, PhD breaks down how its done and the difference in approaches between ChatGPT and Llama2: https://lnkd.in/dPgP_Rxt#LLMOps #MLOps #MachineLearning #ML #DataScience #DataScientist #DataEngineer #DataEngineering #AI #ArtificialIntelligence

          ‚Ä¶see more
        


LLM Training: RLHF and Its Alternatives
",,https://www.linkedin.com/feed/update/urn:li:activity:7111741071197433856?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7111741071197433856%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQGbL4zVSWEwTw/articleshare-shrink_800/0/1703873127026?e=1705658400&v=beta&t=v4uo5JEvrG2Oku0esuPm_KbABnSbAMRYttC_kqBuI5I
179,65a10529a5b8f07200002204,22bb227f-34da-bc3d-aa1a-4c8a77be53cf,,Xiang Song,https://www.linkedin.com/in/ACoAAAhX1OgBxHyjSFy6ufvF_D8Y25ot1gxWyqU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAhX1OgBxHyjSFy6ufvF_D8Y25ot1gxWyqU,"
Senior Applied Scientist at Amazon Web Services (AWS)
","
We have released GraphStorm v0.2: https://lnkd.in/g77XTisM.Key features:- Support multi-task learning for node classification tasks - Enable NCCL backend - Publish GraphStorm doc on https://lnkd.in/gd5nKCjq.- Support using multiple language models available in Huggingface including bert, roberta, albert, etc, in graph aware LM fine-tuning, GNN-LM co-training and GLEM. - More models including: Heterogeneous Graph Transformer (HGT), GraphSage and GLEM.- Distributed graph processing support. (experimental)- Support using NVidia WholeGraph to speedup node feature fetching during distributed GNN training.  (experimental)- Support for distilling a GNN model into a Huggingface DistilBertModel. (experimental)

          ‚Ä¶see more
        


Release GraphStorm v0.2 release ¬∑ awslabs/graphstorm
",,https://www.linkedin.com/feed/update/urn:li:activity:7114720652183437313?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7114720652183437313%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQEzIzBwPG1YeQ/articleshare-shrink_800/0/1704755024976?e=1705658400&v=beta&t=-oo_q5VKtr8tLVvFMTCOikEeYbzZXR_ivyRwDWD11qs
180,65a10529a5b8f07200002205,3e5c626f-6650-e836-75b0-71fe971103e3,https://media.licdn.com/dms/image/D4D03AQFpramTnkoElw/profile-displayphoto-shrink_100_100/0/1670580633493?e=1710374400&v=beta&t=S032I_0r57qA_Thm98T7Xu_Nn46maV3uUmXnh4kYuiU,Bruno Neri,https://www.linkedin.com/in/ACoAAABlS2EBjKE-dekAzG21UIzH0d46NEotnuQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAABlS2EBjKE-dekAzG21UIzH0d46NEotnuQ,"
Technical Leader - Artificial Intelligence and Deep Learning Enthusiast - Senior Software Engineer at ALTEN Italia
","
""Sheaf Hypergraph Networks"" by Iulia Duta, Giulia Cassara, Fabrizio Silvestri, Pietro Lio""Higher-order relations are widespread in nature, with numerous phenomena involving complex interactions that extend beyond simple pairwise connections. As a result, advancements in higher-order processing can accelerate the growth of various fields requiring structured data. Current approaches typically represent these interactions using hypergraphs. We enhance this representation by introducing cellular sheaves for hypergraphs, a mathematical construction that adds extra structure to the conventional hypergraph while maintaining their local, higher-order connectivity. Drawing inspiration from existing Laplacians in the literature, we develop two unique formulations of sheaf hypergraph Laplacians: linear and non-linear. Our theoretical analysis demonstrates that incorporating sheaves into the hypergraph Laplacian provides a more expressive inductive bias than standard hypergraph diffusion, creating a powerful instrument for effectively modeling complex data structures. We employ these sheaf hypergraph Laplacians to design two categories of models: Sheaf Hypergraph Neural Networks and Sheaf Hypergraph Convolutional Networks. These models generalize classical Hypergraph Networks often found in the literature. Through extensive experimentation, we show that this generalization significantly improves performance, achieving top results on multiple benchmark datasets for hypergraph node classification.""Paper: https://lnkd.in/dUcCUuYv#machinelearning

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7114518557152940032?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7114518557152940032%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQH96Ib4u0yEZQ/feedshare-shrink_480/0/1696233403730?e=1707955200&v=beta&t=P1yEIemPQOTR167-3_ti59DdKtz1qmlbnF323HnTAuo
181,65a10529a5b8f07200002206,167f01ba-fbe7-4fd1-07c4-5979914e6161,https://media.licdn.com/dms/image/D5603AQElCAER7UR04g/profile-displayphoto-shrink_100_100/0/1683841857079?e=1710374400&v=beta&t=deo4IY-h4UGS9am1H8WQqjC_wCJPXVGUoWSmN2HQlk8,Pranab Ghosh,https://www.linkedin.com/in/ACoAAAAFAIMBeKbCX4rT80h_x-oJ-IobwmJLuBE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAAFAIMBeKbCX4rT80h_x-oJ-IobwmJLuBE,"
AI Consultant || MIT || Entrepreneur || Open Source Project Owner || Blogger
","
Transformer may be the reigning king in LLM, but they fail for Time Series Forecasting. They perform worse than an embarrassingly simple linear neural model called DLinear. In this study 6 Transformer based models were pitted against DLinear for various datasets. In more than 90% of the cases DLinear performed better across all Transformers and datasets.In DLinear, the time series is decomposed into the trend and remaining components. For each component a one layer linear neural network is trained. For forcasing, the output from the 2 linear models are added for the final forecast. The models are trained for specific look back window size and forecast horizon window size.In ML we should always use the appropriate model for the task in hand and not blindly  use the latest shiny object. The model should be aligned with the inductive bias in the data. There should be just enough complexity in the model based on the task.#deeplearning #transformer #timeseries #forecasting #llm #machinelearning

          ‚Ä¶see more
        


Are Transformers Effective for Time Series Forecasting?
",,https://www.linkedin.com/feed/update/urn:li:activity:7114284056472690688?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7114284056472690688%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQEpmxRn0l0C-w/articleshare-shrink_800/0/1704899192776?e=1705658400&v=beta&t=vF-qNh1Y40qhmPiXaESUKfPGephR_liNWy23pYBfnSQ
182,65a10529a5b8f07200002207,ef98dec6-37d9-efe6-7982-289337e93fa2,https://media.licdn.com/dms/image/D5603AQG9NK0CAgKtVg/profile-displayphoto-shrink_100_100/0/1687301791875?e=1710374400&v=beta&t=Bolt2zUMX7vi6uTl04U5LmzIk8J4LR-CV26o0v_KAIU,Lior S.,https://www.linkedin.com/in/ACoAADMTPYsBtfLtDZlCPxc0G4n0-rFYtqhC0yE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADMTPYsBtfLtDZlCPxc0G4n0-rFYtqhC0yE,"
I cover the latest breakthroughs in AI ‚Üí Ex-ML Engineer/Researcher ‚Üí Built the most read technical newsletter in AI
","
You can now can generate 3D assets in 2 minutes without the use of neural networks. DreamGaussian is a new model that uses Gaussian splatting (GS), popularized by NeRF, on text-to-3D and image-to-3D tasks.The result: 3D assets can now be generated in 2 minutes instead of 20 minutes.The authors also created an algorithm to convert 3D Gaussians into textured meshes and applies a fine-tuning stage to refine the details.This is faster than Zero-1-to-3 and comparable to inference-only methods like One-2-3-45, Point-E, and Shap-E, which take between 30 to 75 seconds.https://lnkd.in/gQuPfZiC‚ÜìAre you technical? Check out https://AlphaSignal.ai to get a weekly summary of the latest research and breakthroughs in AI. Read by 140,000+ engineers and researchers.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7114284116472188928?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7114284116472188928%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5605AQGYfUzx2eCfqw/videocover-low/0/1696177502736?e=1705658400&v=beta&t=yiBPNuUUMewJ_u0Q3ZAyThwjQtXlAwVHw0ftNAI-Yus
183,65a10529a5b8f07200002208,5b0cb801-537d-12be-4c04-4fd4a203dc7d,https://media.licdn.com/dms/image/C4E03AQGCmz60TR4U_A/profile-displayphoto-shrink_100_100/0/1548387165698?e=1710374400&v=beta&t=HBx2vUOpilvOTIG2cAztZlGw5XYBFYfm_Zv7qdfxDBY,Russell Jurney,https://www.linkedin.com/in/ACoAAABfD7wB1ProJaev__Cskc2izd0_t4nIhDI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAABfD7wB1ProJaev__Cskc2izd0_t4nIhDI,"
Graph AI meets LLMs
","
A sweet tutorial on full-stack Anthropic conversational app building. I am very much in love with full-stack tutorials. It used to be the case that both machine learning documentation and blog posts would just train and score and not... predict! hahahaha No inference, just create the potential and shelf it. I couldn't figure out how to do it! Now people are more practical.https://lnkd.in/gbhaPk6T#anthropic #llm #llms #chatbot #chatbots

          ‚Ä¶see more
        


Anthropic's Claude and LangChain Tutorial: Bulding Search Powered Personal Assistant App tutorial
",,https://www.linkedin.com/feed/update/urn:li:activity:7114080439434149888?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7114080439434149888%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQF3yZmYKep1CQ/articleshare-shrink_800/0/1703768061334?e=1705658400&v=beta&t=xCNstF55yJRbJVqdvBw1DES2DrrMpeFHZR6mO9bFozc
184,65a10529a5b8f07200002209,3cb7cea7-c754-1e4b-24bf-31aba9fba49b,https://media.licdn.com/dms/image/C4E03AQFGE8y2NeGRBA/profile-displayphoto-shrink_100_100/0/1640628826402?e=1710374400&v=beta&t=kWRx_HJ-xJfP7xxmdqwvn88MjDc7DDPs5cTcD6UGcng,Shannon Lord üá®üá¶,https://www.linkedin.com/in/ACoAABfDkt4BFjgZm0NSBytQHTjuTz8Pr_O0UtY?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABfDkt4BFjgZm0NSBytQHTjuTz8Pr_O0UtY,"
Executive Director, Digital Strategy & Enterprise Architecture
","
https://lnkd.in/gQizECD8Industry Minister Fran√ßois-Philippe Champagne will announce new government measures September 27, 2023, designed to help Canada take the lead in the area of artificial intelligence.#ai #artificialintelligence #gcdigital [Edit]  Links to AI Voluntary Code of ConductEN:  https://lnkd.in/gFnYHdDhFR:  https://lnkd.in/gZUBuCYr

          ‚Ä¶see more
        


Ottawa unveils new AI code of conduct for Canadian companies | CBC News
",,https://www.linkedin.com/feed/update/urn:li:activity:7112756619712630784?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7112756619712630784%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQHY6JFqnrjhPA/articleshare-shrink_1280_800/0/1703870456399?e=1705658400&v=beta&t=cdfOshqpq6mZyL8XhwuKoWEjiul417CK3OOozP27rgI
185,65a10544a5b8f0720000220b,3d287af0-cdbe-7633-50a0-d2ce2b0c22c0,https://media.licdn.com/dms/image/C4E03AQGCmz60TR4U_A/profile-displayphoto-shrink_100_100/0/1548387165698?e=1710374400&v=beta&t=HBx2vUOpilvOTIG2cAztZlGw5XYBFYfm_Zv7qdfxDBY,Russell Jurney,https://www.linkedin.com/in/ACoAAABfD7wB1ProJaev__Cskc2izd0_t4nIhDI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAABfD7wB1ProJaev__Cskc2izd0_t4nIhDI,"
Graph AI meets LLMs
","
Graph databases and vector databases are merging from both ends... in the next 12 months, you'll see both teams unite :)How are they merging?* From vectors to graphs: A-KNN has long been a primary knowledge graph construction technique. Check out YangDB and the OpenSearch security analytics plugin! Lots of teams are building out graph databases on top of Elasticsearch/OpenSearch that incorporate their vector search support. Large datasets and complex queries are not economical on any other platform. Transformation via Python on data lakes or streaming systems to/from the graph DB makes the final portion of interactive queries simple, and cheap. This what Ben Lorica ÁΩóÁëûÂç° and Leo Meyerovich mean regarding graph intelligence, which isn't necessarily graph DB-centric. They're a place to land data, not always the core of graph VA and graph AI.* From graphs to vectors: PySpark/GraphFrames has enabled this for years [ we do this at Graphlet AI: https://graphlet.ai ], Neo4j supports vector search, Redis has both vector and search engines, and you've been able to store and query embeddings in TigerGraph for years using a C++ UDF to compute cosine similarity, although their embedding features have gotten much better than that since I used it :)I expect new models of vector/graph combined uses to emerge. One I am writing up presently are what I call _semantic motif search_, where you use embeddings as part of pattern recognition against a null model of your expected result in a random graph model to highlight important features of a network. The use of embeddings on top of property graphs in motif search is - I think - a new concept I plan to write up. Matching ""Russ H Jurney"" to ""Russell Jurney"" in a money laundering risk motif search of a business graph is incredibly powerful and useful.More on motifs as soon as I write about the terminology of graph intelligence :)> Graph databases and vector databases are rapidly merging. All major graph databases have in the last twelve months become GNN feature factories [my term!] that take existing embeddings as input and build their own contextual representations by distributing them across their neighborhoods and summarizing them in context. I‚Äôll write more on this as soon as I make more progress on my full-stack graph ML class on October 9‚Äì13, 2023.https://lnkd.in/g8mJsUvc#graph #graphs #graphdatabases #machinelearning #ml #vector #vectors #vectorsearch #label #labels #labeling #datalabeling #data #database #embedding #embeddings #representationlearning #dl #deeplearning #python

          ‚Ä¶see more
        


Knowledge Graph Construction
",,https://www.linkedin.com/feed/update/urn:li:activity:7113304682525065216?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7113304682525065216%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,
186,65a10544a5b8f0720000220c,d6afd821-b5a4-bd53-d68e-9b7b2d974df3,https://media.licdn.com/dms/image/C5103AQHSreRrerpnNA/profile-displayphoto-shrink_100_100/0/1579845531664?e=1710374400&v=beta&t=4iXVD_8jc_kzA_CtRxkDydQsUmyT7EJ_Yrbvy7h6KbU,Vikas Agrawal,https://www.linkedin.com/in/ACoAAAOI8jABu7-wqmxKN6aMAKwuIskrGHFPzug?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAOI8jABu7-wqmxKN6aMAKwuIskrGHFPzug,"
Consulting Data Scientist at Oracle
","
While Large Language Models (LLMs) have shown exceptional performance in various tasks, their (arguably) most prominent drawback is generating inaccurate or false information with a confident tone. In this paper Tom Mitchell (Carnegie Mellon University) and Amos Azaria have tried to show how an LLM's internal state can be used to reveal the truthfulness of a statement at a rate better (60%-80%) than few shot prompting based Socratic method (56%). They utilize the LLM's hidden layer activations to determine the veracity of statements. Please share what other approaches you think might be useful in comments. Related publications will be very valuable as well. It appears that there is significant room left for hybrid neuro-symbolic approaches, Cyc like common sense reasoning approaches, and checking complex relationships or facts in output against enterprise knowledge bases or in simpler cases with triple store type knowledge graphs. https://lnkd.in/gzB2wxpuPS: Tom Mitchell's paper has been critiqued in https://lnkd.in/g5n-kpT7  Still No Lie Detector for Language Models: Probing Empirical and Conceptual Roadblocks B.A. Levinstein, Daniel A. Herrmann where the authors have tried to replicate the work and have provided further explanation about the limitations of these techniques in getting at facts in the real world. An LLM does not possess the ability to ""know"" when it is lying (because it doesn't have self-awareness, consciousness, or intentions, and so we do not need to anthromorphise it). There is no concept of truth or lying for an LLM. It simply processes input and generates responses based on its training data and algorithms. It's essential for users to critically evaluate the information provided by such models and not assume they are infallible sources of truth.""Gary Marcus Walid Saba Rajeshwari Ganesan Sarabjot Singh Kiran R, Ph.D. Vijay Srinivas Agneeswaran, Ph.D Ricardo Baeza-Yates Marko Grobelnik Goda Ramkumar Ganesh Mani Raghav Bali Dr. Sunil Kumar Vuppala Hari Koduvely (PhD) Sudalai Rajkumar - SRK Rohan Rao Pramod Agrawal Dr.Srinivas Padmanabhuni Sundaresan Poovalingam Balaraman Ravindran Favio Vazquez Mathangi Sri Ramachandran Ujjyaini Mitra Alok Ranjan Sayak Paul Dat Tran Rahee Walambe Pavel Pleskov Ratnakar Pandey Vijay Gabale Xander Steenbrugge Timnit Gebru

          ‚Ä¶see more
        


The Internal State of an LLM Knows When its Lying
",,https://www.linkedin.com/feed/update/urn:li:activity:7113093926441402368?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7113093926441402368%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQF-AN5e0rLM9A/articleshare-shrink_800/0/1704560389394?e=1705658400&v=beta&t=WKhMkyyl4yTa-KJ4sxlsotRzzuXOZHqvqB9ACxX1Po4
187,65a10544a5b8f0720000220d,fc45c4e1-830c-9a1d-a4cb-115753b0bf93,https://media.licdn.com/dms/image/C4E03AQGCmz60TR4U_A/profile-displayphoto-shrink_100_100/0/1548387165698?e=1710374400&v=beta&t=HBx2vUOpilvOTIG2cAztZlGw5XYBFYfm_Zv7qdfxDBY,Russell Jurney,https://www.linkedin.com/in/ACoAAABfD7wB1ProJaev__Cskc2izd0_t4nIhDI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAABfD7wB1ProJaev__Cskc2izd0_t4nIhDI,"
Graph AI meets LLMs
","

 ",,https://www.linkedin.com/feed/update/urn:li:activity:7112484694071406592?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7112484694071406592%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQHho0r709KIog/feedshare-shrink_480/0/1693901443373?e=1707955200&v=beta&t=La-rdI6cfVXgSi666xszjLQKVztbj855aa_t3_k9aDM
188,65a10544a5b8f0720000220e,ba20b5e9-5ed6-84bb-a561-e19253282d25,https://media.licdn.com/dms/image/D4E03AQGNmuDAfXmcog/profile-displayphoto-shrink_100_100/0/1670548971455?e=1710374400&v=beta&t=IYtmV2v6VRPLYrNIQpqy0oW6pILs7PD8j-Uo2OZyqRQ,Petar Veliƒçkoviƒá,https://www.linkedin.com/in/ACoAABAXWYMBZm8zSP1Sk3mgaiuWFpjBXdy_U_o?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABAXWYMBZm8zSP1Sk3mgaiuWFpjBXdy_U_o,"
Staff Research Scientist at Google DeepMind | Affiliated Lecturer at University of Cambridge | Associate at Clare Hall | ELLIS Scholar in Geometric Deep Learning
","
We have a paper accepted at NeurIPS 2023 on affinity-aware graph neural networks! üéâ Our work strikes a sweet-spot in GNN design: it is theoretically expressive (provably more powerful than 1-WL, incorporating non-local graph structural information), empirically strong (state-of-the-art result on large-scale quantum chemistry tasks), and scalable (time complexity O(n log n) for a graph of n nodes).Check it out here: arxiv.org/abs/2206.11941This is joint work with a great team from Google AI and Google DeepMind: Ameya Velingker, Ali Kemal Sinop, Ira Ktena, PhD and Sreenivas Gollapudi.

          ‚Ä¶see more
        


Affinity-Aware Graph Networks
",,https://www.linkedin.com/feed/update/urn:li:activity:7112447061907644416?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7112447061907644416%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQEW18jcUBXzsg/articleshare-shrink_800/0/1704214724331?e=1705658400&v=beta&t=wSKfsHlMvlJD6oityeRAS4mo0uLTgkzMKbXNvy1B6i8
189,65a10544a5b8f0720000220f,e76846d2-b24b-ab32-e0c8-5f67569e4ccc,https://media.licdn.com/dms/image/C4E03AQHVyH-IfD1KbQ/profile-displayphoto-shrink_100_100/0/1629877234109?e=1710374400&v=beta&t=0UZUl_dDUxLaZn-Hu-zToqEDe3rpL5cB2JkP5_jlNXc,"Sebastian Raschka, PhD",https://www.linkedin.com/in/ACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU,"
Machine learning and AI researcher since the early days ‚Ä¢ coding and working with LLMs at Lightning AI ‚Ä¢ ex-statistics professor at University of Wisconsin-Madison
","
Another month, another round of interesting research papers ranging from large language modeling to computer vision. One recent focus is on refining Large Language Models (LLMs). For instance, introducing models like Platypus and the Reinforced Self-Training (ReST) method are the latest attempts to improve alignment with human preferences. In addition, Self-Alignment with Instruction Backtranslation and OctoPack leverage existing knowledge structures, be it instructions or code, to improve model performances. A recurring theme is to make models more efficient and accessible. There's LongLoRA with another sparse attention mechanism for LLMs and simpler, more fundamental ideas like replacing softmax with ReLU in vision transformers to boost computational efficiency and pave the way for better parallelization.But this is only a snapshot of what has happened this month. I hope you get something useful out of the subset of the 22 research highlights I compiled in this month's ""Research Highlights in Three Sentences or Less"": https://lnkd.in/gMsXk_ny#LLMs #AI #Transformers

          ‚Ä¶see more
        


Research Highlights in Three Sentences or Less (August-September 2023)
",,https://www.linkedin.com/feed/update/urn:li:activity:7111325767573127168?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7111325767573127168%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQElx9oS4sSJFg/articleshare-shrink_800/0/1704813069308?e=1705658400&v=beta&t=f8Ds-DGyeywb19ZSE-sgbNA-G6Z525mOnNqA-dM2O6U
190,65a10544a5b8f07200002210,71069098-9950-9a2c-8311-3f3556022d0c,https://media.licdn.com/dms/image/D4D03AQF6sQxl1QrPoA/profile-displayphoto-shrink_100_100/0/1698769693482?e=1710374400&v=beta&t=FSjSjYdS86NhX3mTnCWbiPuDqeM0I0Jy3-QmCHjjo-g,Hanan Gani,https://www.linkedin.com/in/ACoAACDnxLEBIa73Ne05WNE-USo4NCbOpgvpgeE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACDnxLEBIa73Ne05WNE-USo4NCbOpgvpgeE,"
Grad Student at MBZUAI | Attending @NeurIPS‚Äô23
","
#NeurIPS 2023: Excited to share that our paper titled ‚ÄúAlign Your Prompts: Test-Time Prompting with Distribution Alignment for Zero-Shot Generalization‚Äù has been accepted to #NeurIPS 2023.Thanks to all the coauthors Jameel Hassan Noor Hussein Muhammad Uzair Khattak Muzammal Naseer Salman Khan Fahad Khan More details about the paper will be released soon.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7110894272417030145?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7110894272417030145%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQFyKgttD8MLUg/feedshare-shrink_480/0/1695369307421?e=1707955200&v=beta&t=dP1A3zTOpIObCb8oY5UzzH40q7cCR3LIvon4XIgiwlY
191,65a10544a5b8f07200002211,91373f1e-2f6e-3cb6-b55d-9ac16c762d39,https://media.licdn.com/dms/image/D5635AQEqNZJ4r9wPoQ/profile-framedphoto-shrink_100_100/0/1687929327882?e=1705658400&v=beta&t=DMqllWhaCDU0oTqTBxNE-2fgSduZYEZ0ng7RAi6WcHg,Pei Chen,https://www.linkedin.com/in/ACoAABzxHdwBbt0scuWm1fMODfZA849LHauz1x4?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABzxHdwBbt0scuWm1fMODfZA849LHauz1x4,"
CS PhD@TAMU | NLP, LLMs, KGs | Pretraining & Inference & Prompting & Information Extraction | Research Intern@AWS AI, Tencent AI, Chinese Academy of Sciences
","
I'm pleased to announce that our paper about LM pretraining , ""HYTREL: Hypergraph-enhanced Tabular Data Representation Learning"" is accepted to NeurIPS 2023 as a #spotlight!1.  arXiv link: https://lnkd.in/gFxVFi9N2. Code: https://lnkd.in/gHbVAiadMany thanks to all  collaborators!Currently, I am actively look a full-time position. If you know any opening that is related to NLP or LLM, please don‚Äôt hesitate to let me know!In this research, we propose a novel tabular language model (TaLMs) that models tables as hyper-graphs and maximally preserves the table structure information. #foundationmodels #languagemodel #table  #nlp #amazonscience #tamu Key Takeaways:1. Hyper-graphs can maximally preserve the table structure information.2. We use Set Transformer instead of plain Transformer model that exists in current popular language models, aiming at preserve table and hypergraph structures.3. We pretrain HYTREL with two objectives: one table-content based ELECTRA objective and one table-structure based Contrastive objective. Our empirical results show that both pre-trainings can achieve superior performance than strong baselines on four table understanding tasks. 4. Further analysis shows that modeling the table structure can reduce pre-training overheads, as compared with baseline models. Suggestions and comments are welcomed! See you in New Orleans!!!

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7110812847252664320?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7110812847252664320%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQFRhmikLRvv6g/feedshare-shrink_800/0/1695349894586?e=1707955200&v=beta&t=wI5TyjVrTihgWQAOkeoqZgxVK7CThRAyxLl7-aQK03w
192,65a10544a5b8f07200002212,2de836ab-71a8-16b5-a9bc-6b1df62fb741,https://media.licdn.com/dms/image/C4E03AQHv_YBMv3y7FA/profile-displayphoto-shrink_100_100/0/1568691788629?e=1710374400&v=beta&t=J3PxW32L3BSyaaNG3rV4KR-wsdb_TWFIyjL4db0f3bc,Nabiha Asghar,https://www.linkedin.com/in/ACoAAANGh7sBYJ0HIZq8X8cPlN79d2CKlmXR6Y8?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAANGh7sBYJ0HIZq8X8cPlN79d2CKlmXR6Y8,"
LLMs & Graph ML @ Microsoft
","
New Paper by Meta AI -- ""Chain-of-Verification Reduces Hallucination in LLMs"" - Reduces longform hallucinations via LLM double-checking its own work with shortform questions- Important not to reattend to the original hallucinations or they get copiedhttps://lnkd.in/g5MsQPMU#genai #llm #ml 

          ‚Ä¶see more
        


Chain-of-Verification Reduces Hallucination in Large Language Models
",,https://www.linkedin.com/feed/update/urn:li:activity:7110502753365364736?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7110502753365364736%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQE710qsR-0uSA/articleshare-shrink_800/0/1703902970986?e=1705658400&v=beta&t=Vcm6qbneFSOhDjP1cZnw4zHifQE3I0X1zFlHgBa78W8
193,65a10544a5b8f07200002213,5434213e-8522-9179-9732-b65f22950950,https://media.licdn.com/dms/image/C5603AQGOg53LhVKcMg/profile-displayphoto-shrink_100_100/0/1634181027164?e=1710374400&v=beta&t=xbAuSltqPyCgLI8ejViTew8K0qVdvl9WHdiugPK8oFQ,Devashish K.,https://www.linkedin.com/in/ACoAAAFofR8B_DN53-Hjj1iXu4ICczFB3VMqGhw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAFofR8B_DN53-Hjj1iXu4ICczFB3VMqGhw,"
Science Leader at Amazon
","
üöÄ Day 5: Dive into LLM Papers üöÄPaper: Orca: Progressive Learning from Complex Explanation Traces of GPT-4."" üß†üìöMeet Orca, a 13-billion parameter AI model üêã that's changing the game in imitating the reasoning process of Large Language Models. ü§ØOrca learns from rich signals from GPT-4, including explanation traces, step-by-step thought processes. The paper shows that instruction fine tuning using  Chain of Thought prompt improves the performance much faster and with much smaller dataset sizes. A 13B model trained in this fashion is able to beat larger models at reasoning tasks. ü§ñüìù Orca achieves parity with ChatGPT on the BBH benchmark and shines in professional and academic exams like SAT, LSAT, GRE, and GMAT, even in zero-shot settings without CoT! ü§ØüìöHuggingFace has multiple models which have been further instruction fine tuned using Orca style instructions.ü§óüåüüí° #AI #Innovation #Orca #gpt4 Read the full paper here:  https://lnkd.in/ggTT2ycX üëâüìñ

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7110238127222374401?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7110238127222374401%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQGNmu4c68Kn7A/feedshare-shrink_480/0/1695212870399?e=1707955200&v=beta&t=t-XzCdysFVr0TUPEkCT9FSXbNTdy4zVmQU4THpoKVUg
194,65a10544a5b8f07200002214,ce77de8f-d563-2f36-6172-1c2469708c89,https://media.licdn.com/dms/image/C5603AQH0vt7JCOIZ2g/profile-displayphoto-shrink_100_100/0/1659622741519?e=1710374400&v=beta&t=oD7v-H5eftQLYDRlvUvk2VE7-lsZDVk9VuRckoG8nZk,Jim Fan,https://www.linkedin.com/in/ACoAAA1AILwBEWpiY_CZ_I03PL9inU_8YB3s5nQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA1AILwBEWpiY_CZ_I03PL9inU_8YB3s5nQ,"
NVIDIA Sr. Research Scientist & Lead of AI Agents. Stanford Ph.D. Creator of Voyager, Eureka, MineDojo (Best Paper). OpenAI's first intern. Sharing insights on the bleeding edge of AI research & industry.
","
DeepMind's paper turns textual LLMs into general-purpose compressor API, even for images & audio. Now it can be compared directly to gzip, PNG, LZMA2, etc.We already know that learning & generalization are closely linked to compression, but it's fascinating to see this quantified in real experiments on LLMs.Chinchilla is converted to a compressor by a clever arithmetic coding scheme (fig on the right). It's a really compelling study that can be easily replicated and investigated deeper without much compute.Paper: Language Model is CompressionArxiv: https://lnkd.in/gVATYRDv

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7110303722739572738?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7110303722739572738%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQEzhPog9ZwZfw/feedshare-shrink_480/0/1695228510041?e=1707955200&v=beta&t=lKtweK9F3MJxp9MPP_N7LYReSTuadceJgUDYAlZy_0I
195,65a10544a5b8f07200002215,171259b2-ea84-860a-301a-26742774381f,https://media.licdn.com/dms/image/D4E03AQHlDrrMgdW81w/profile-displayphoto-shrink_100_100/0/1680035432469?e=1710374400&v=beta&t=-vUIbi1Q6d_yibA5oKRnwxnsXbcTPzU3lNUaMV75mFM,Matthew Hepburn,https://www.linkedin.com/in/ACoAAAPwt64BGmrsa6RrMPuzKHxkX5S7BEIlIgY?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAPwt64BGmrsa6RrMPuzKHxkX5S7BEIlIgY,"
Principal Product Marketing Manager, Amazon Science
","
Hope everyone‚Äôs having a great time at RecSys this week! Check out Amazon‚Äôs papers here: https://lnkd.in/efGm98TW#RecommenderSystems #MachineLearning #AmazonScience

          ‚Ä¶see more
        


RecSys 2023
",,https://www.linkedin.com/feed/update/urn:li:activity:7109787311277502464?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7109787311277502464%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQGVViR5XuJTNw/articleshare-shrink_800/0/1704911417495?e=1705658400&v=beta&t=8bMyJUmOXTdhpigaNr1EiDqBRB1SOW-5DOjiNzudjzI
196,65a10544a5b8f07200002216,5d923270-5f77-3986-4c41-a46c1e3eb351,https://media.licdn.com/dms/image/C4E03AQFtC3ZH506r6A/profile-displayphoto-shrink_100_100/0/1517578865199?e=1710374400&v=beta&t=rX1ZuyXupewBHqElwttuauoBaZe3YSd11eKwaSHFoPw,Vassilis N. Ioannidis,https://www.linkedin.com/in/ACoAABf7POQBHkJ5L-wLdfUUB4BQ8j9af1ruBGE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABf7POQBHkJ5L-wLdfUUB4BQ8j9af1ruBGE,"
Team Leader @ Amazon Search AI | AWS AI | MERL | PhD
","
Can we combine the power of language models with GNNs? Yes!Check our poster in ECML-PKDD in Turin at the Graph Neural Networks 1 session https://2023.ecmlpkdd.org/  presented by Costas Mavromatis.Our GraDBERT achieves top-4 (top-1 originally üòÄ ) in the ogbn-arxiv leaderboard and top-2 in the ogbn-products leaderboard. Our model is optimized to achieve superior performance in text graph. Dive into the code for the distillation supervision . #gnnupdates #gnn #largelanguagemodels #bert #transformers #graphneuralnetworks #knowledgegraphs 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7109944330429071360?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7109944330429071360%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQFP2WW3XZOayQ/feedshare-shrink_480/0/1695142823645?e=1707955200&v=beta&t=TijZ_HA9VvfkrNWUYC7jOzr8EXKRj_RRx3jbpuGuhlM
197,65a10544a5b8f07200002217,9ccad400-3d4f-2325-ae59-c2d833f69d28,https://media.licdn.com/dms/image/C4D03AQGsBskbBZ3fQQ/profile-displayphoto-shrink_100_100/0/1614534462823?e=1710374400&v=beta&t=qNMq_bYgWNgoA2VAF7eQmC7A48grXKS--I4WZpVpkU0,Leonie Monigatti,https://www.linkedin.com/in/ACoAABdZ4YQB5f0bhOeOvQJ3YEUtKThe0GEP4tc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABdZ4YQB5f0bhOeOvQJ3YEUtKThe0GEP4tc,"
Developer Advocate @ Weaviate | Kaggle Notebooks Grandmaster
","
Nice explanation of Retrieval Augmented Generation (RAG) by Ajay Chintala!https://lnkd.in/eGUaCRrb

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7109536574748418048?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7109536574748418048%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQGJJeIqFh8WtQ/feedshare-shrink_480/0/1695041591700?e=1707955200&v=beta&t=H7TVPhGMDwx6iw0aWL4NjXeth74VvZe0zcrrM3o9b78
198,65a10544a5b8f07200002218,ce33843e-f4bf-f323-4768-4394aca93ddb,https://media.licdn.com/dms/image/C5603AQH0vt7JCOIZ2g/profile-displayphoto-shrink_100_100/0/1659622741519?e=1710374400&v=beta&t=oD7v-H5eftQLYDRlvUvk2VE7-lsZDVk9VuRckoG8nZk,Jim Fan,https://www.linkedin.com/in/ACoAAA1AILwBEWpiY_CZ_I03PL9inU_8YB3s5nQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA1AILwBEWpiY_CZ_I03PL9inU_8YB3s5nQ,"
NVIDIA Sr. Research Scientist & Lead of AI Agents. Stanford Ph.D. Creator of Voyager, Eureka, MineDojo (Best Paper). OpenAI's first intern. Sharing insights on the bleeding edge of AI research & industry.
","
A neural network can *smell* like humans do for the first time!üëÉüèΩDigital smell is a modality that AI community has long ignored, but maybe one day useful for robot chef üë©üèΩ‚Äçüç≥? Here's how to do smell2text:1. Collected 5,000 molecules and ask humans to label ""creamy, chocolate, alcoholic, beefy, spicy, citrus"", etc. This dataset is one of its kind and a huge contribution from the paper.2. Train a graph neural network (GNN) to map the molecule to label. Each molecule is a graph of atoms described by valence, degree, hydrogen count, hybridization, formal charge, and atomic number.3. The GNN predictions match well with expert humans on novel smells.4. The embeddings give us a ""Principal Odor map (POM)"" that faithfully represents hierarchies and distances among odorants.Next step: we need text2smell, a generative model that synthesizes odorant molecules given a natural language description. It'll be epic.Science Paper, ""A principal odor map unifies diverse tasks in olfactory perception""https://lnkd.in/gqfVEtWYOpen access PDF: https://lnkd.in/giBPz3YM

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7107379430406201344?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7107379430406201344%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQFBamRl9mRDlg/feedshare-shrink_480/0/1694531303642?e=1707955200&v=beta&t=MDc_N68UWn2ZY0yUlkxqAjBWsvY7shaHC_7AVYbbfsY
199,65a10544a5b8f07200002219,dce0994e-c2d2-9676-b128-bb25a96eaa17,https://media.licdn.com/dms/image/C5603AQH0vt7JCOIZ2g/profile-displayphoto-shrink_100_100/0/1659622741519?e=1710374400&v=beta&t=oD7v-H5eftQLYDRlvUvk2VE7-lsZDVk9VuRckoG8nZk,Jim Fan,https://www.linkedin.com/in/ACoAAA1AILwBEWpiY_CZ_I03PL9inU_8YB3s5nQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA1AILwBEWpiY_CZ_I03PL9inU_8YB3s5nQ,"
NVIDIA Sr. Research Scientist & Lead of AI Agents. Stanford Ph.D. Creator of Voyager, Eureka, MineDojo (Best Paper). OpenAI's first intern. Sharing insights on the bleeding edge of AI research & industry.
","
This is the way to unlock the next trillion high-quality tokens, currently frozen in textbook pixels that are not LLM-ready.Nougat: an open-source OCR model that accurately scans books with heavy math/scientific notations. It's ages ahead of other open OCR options. Meta is doing extraordinary open-source AI, sometimes without as much fanfare as Llama.My first serious AI research project (back at Columbia, 2012) was to convert chemical engineering PDFs into NLP-ready corpus. I still remember the immense pain of Tesseract, a much older OCR system (https://lnkd.in/gq4G47hx).Now Nougat runs a powerful Swin Transformer backbone and blows the benchmarks out of the water. We're talking about double-digit improvements across all metrics.Now, textbooks are all we need for the next GPT!Website: https://lnkd.in/gtCF2QZ4Open-source code: https://lnkd.in/ggTgzX3NPaper ""Nougat: Neural Optical Understanding for Academic Documents"": https://lnkd.in/gBXZDyyk

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7108088453996675072?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7108088453996675072%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQFX02Ji_zolcQ/feedshare-shrink_480/0/1694700347993?e=1707955200&v=beta&t=Hrms_i2wi38GPJdK7Enk_LmfzdrmWPmW5I-N5pk0LiI
200,65a10544a5b8f0720000221a,73be26c9-297e-86d5-5aa1-48574ea95e8e,https://media.licdn.com/dms/image/C4E03AQGCmz60TR4U_A/profile-displayphoto-shrink_100_100/0/1548387165698?e=1710374400&v=beta&t=HBx2vUOpilvOTIG2cAztZlGw5XYBFYfm_Zv7qdfxDBY,Russell Jurney,https://www.linkedin.com/in/ACoAAABfD7wB1ProJaev__Cskc2izd0_t4nIhDI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAABfD7wB1ProJaev__Cskc2izd0_t4nIhDI,"
Graph AI meets LLMs
","
A cool contest to train an LLM on one A100 GPU with 40GB VRAM for n 24 hours‚Ä¶
 

NeurIPS Large Language Model Efficiency Challenge:1 LLM + 1GPU + 1Day
",,https://www.linkedin.com/feed/update/urn:li:activity:7108463866832949248?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7108463866832949248%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,
201,65a10544a5b8f0720000221b,a2d27c8c-cf4c-dae4-d412-bcab19785ab3,https://media.licdn.com/dms/image/C4E03AQHYIRnlC55JsA/profile-displayphoto-shrink_100_100/0/1517498131850?e=1710374400&v=beta&t=_rRA1ULYJfpxcc570qKmzA5BDGAiL737HWLZNnnL7bo,Belhassen Bayar,https://www.linkedin.com/in/ACoAABOpPKgB_NP_a_WsGKQ3fy3A95C0h5zrVLo?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABOpPKgB_NP_a_WsGKQ3fy3A95C0h5zrVLo,"
Senior Applied Scientist at Amazon
","
I'm happy to share that two papers from my team at Prime Video & Amazon Studios got accepted for ""ACM RecSys 2023 Workshop on Context-Aware Recommender Systems"".In these papers, we address most common challenges (e.g., data sparsity and cold-start scenarios, popularity bias in multi-territory settings, etc) encountered by researchers and engineers while building a Video Recommender System.#AmazonScience #amazonprimevideo  Amazon SciencePhani deep Farnoosh Javadi Ainur Yessenalina Zhen WenLinks:- https://lnkd.in/emYGbVeU- https://lnkd.in/euwk6h3jMain contributions & summary of our work are shared below:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~1) Design Principles of Robust Multi-Armed Bandit Framework in Video Recommendations- Current multi-armed bandit approaches in recommender systems (RS) have focused more on devising effective exploration techniques, while not adequately addressing common exploitation challenges related to distributional changes and item cannibalization. Little work exists to guide the design of robust bandit frameworks that can address these frequent challenges in RS. In this paper, we propose a new design principles to (i) make bandit models robust to time-variant metadata signals, (ii) less prone to item cannibalization, and (iii) prevent their weights fluctuation due to data sparsity.2) Multi-task learning for reduced popularity bias in multi-territory video recommendations- Various data imbalances that naturally arise in a multi-territory personalized recommender system can lead to a significant item bias for globally prevalent items. A locally popular item can be overshadowed by a globally prevalent item. Moreover, users‚Äô viewership patterns/statistics can drastically change from one geographic location to another which may suggest to learn specific user embeddings. In this paper, we propose a multi-task learning (MTL) technique, along with an adaptive upsampling method to reduce popularity bias in multi-territory recommendations.

          ‚Ä¶see more
        


Design principles of robust multi-armed bandit framework in video recommendations
",,https://www.linkedin.com/feed/update/urn:li:activity:7108479539474743296?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7108479539474743296%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQFVInfQSsyRFg/articleshare-shrink_800/0/1704895115950?e=1705658400&v=beta&t=PW9X9jfOao4kj_gT_YO_NUKKgwpu7i965A7C_0eJnH4
202,65a10544a5b8f0720000221c,2351a011-2d5c-61bf-d6d6-f8b2d3231b99,https://media.licdn.com/dms/image/C5603AQEGK_kIML5FYw/profile-displayphoto-shrink_100_100/0/1595864198140?e=1710374400&v=beta&t=6CC4QiBsF-0SuD53fsfS3gV_mVcn3rXMzcrbPHGnAqE,Prakhar Mishra,https://www.linkedin.com/in/ACoAAA7J_U4BNtFcrfzwXdbfaajkC_m2PB-8EsU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA7J_U4BNtFcrfzwXdbfaajkC_m2PB-8EsU,"
AI/ML Engineer @ UnitedHealth Group | MS in Data Science
","
Language Models like GPT-3 and similar models can be likened to an ‚Äúocean of knowledge‚Äù in the sense that they have been trained on vast amount of text data from internet, making them repository of information and language understanding.It‚Äôs essential that we tailor their capabilities to specific tasks, domain, and ensuring they align to our goals and requirements. üéØ The other day, while scrolling my feed, I found this nice article on ‚Äú3 methods for improving LLMs‚Äù, thought of sharing it across  as an easy read over a cup of coffee ‚òïÔ∏è üìöüí´Below image from the blog succinctly summarises the blog. Article link in the comments.#machinelearning #datascientists #naturallanguageprocessing #llms #languagemodels #technology #education  #science #research #artificialintelligence

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7109055211637268480?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7109055211637268480%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQEozOaYT1THoA/feedshare-shrink_480/0/1694930841083?e=1707955200&v=beta&t=Wq0Sl73qY25dm6AKAQT3FrRCrcPYANG7wREbJSrLtZ4
203,65a10544a5b8f0720000221d,eeba7d31-284e-febb-873e-4d122f4d8eeb,https://media.licdn.com/dms/image/C4E03AQEfiaN-GeJgXg/profile-displayphoto-shrink_100_100/0/1658874676127?e=1710374400&v=beta&t=34vmAAUwC5FcMQgZ_ytOUJlGJSkqjhvJInStPH_kFJI,Prof. (Dr.) Amitava Das,https://www.linkedin.com/in/ACoAAASyXFMBWUjysXb27JPr-oSePSpdbaibkaI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAASyXFMBWUjysXb27JPr-oSePSpdbaibkaI,"
Faculty AIISC@USC | Advisory Scientist Wipro AI | Adjunct Faculty IIT Patna
","
DEFACTIFY 3.0 @AAAI 2024‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚ÄîAnnouncing 3rd iteration of DEFACTIFY workshop @AAAI 2024. This year we are announcing two new shared tasks - FACTIFY5WQA‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚ÄîIn this task, we will release a 5W framework (who, what, when, where, and why) for question-answer-based fact explainability. We will be releasing data from our ACL 2023 paper - https://lnkd.in/dPenvZZGDE:HATE‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚ÄîWe present a first-of-its-kind task: a challenge focused on the automatic blurring of offensive segments within a hateful image, while Facebook and Twitter commonly employ blanket blurring.cc------Co-organizers - Amit Sheth (USC), Asif Ekbal (IIT Patna), Aman Chadha (Amazon, Stanford) Artificial Intelligence Institute of South Carolina #aiiscAssociation for the Advancement of Artificial Intelligence (AAAI)Students organizers-------------------------Megha Chakraborty, Anku Rani, Parth Patwa, Shreyash Mishra, Suryavardan Suresh, S.M Towhidul Islam Tonmoy

          ‚Ä¶see more
        


DEFACTIFY 3.0
",,https://www.linkedin.com/feed/update/urn:li:activity:7108287040458231808?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7108287040458231808%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D1FAQEhg6-gIHqFVQ/feedshare-document-cover-images_480/0/1694747647772?e=1705658400&v=beta&t=bPWHY87T-G5QbOVcw-XSEQxgW7vWcJu1h_a8pd6Vn0s
204,65a10544a5b8f0720000221e,7df0b2d4-6df7-10bc-c67b-3c9e928dc09f,https://media.licdn.com/dms/image/D5603AQHA9XKI42dJ6Q/profile-displayphoto-shrink_100_100/0/1680169524636?e=1710374400&v=beta&t=76m2CkeMtcrx3TxA6-_-9lNyLbxkxxsiAfoRhaM5ZoU,Houyu Zhang,https://www.linkedin.com/in/ACoAAC1jOCABCK8Ike7-6JtIoAPv9zFK-TBMpv4?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAC1jOCABCK8Ike7-6JtIoAPv9zFK-TBMpv4,"
Applied Scientist @ Amazon Search M5 | CS @ Brown
","
Check out our work from KDD'23 for LM+Graph pre-training!#AmazonScience
 

Graph-aware language model pre-training on a large graph corpus can help multiple graph applications
",,https://www.linkedin.com/feed/update/urn:li:activity:7105963018647212032?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7105963018647212032%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQH9pPUK241lOA/articleshare-shrink_800/0/1704007221686?e=1705658400&v=beta&t=OsntfpRYGejdwpbB2VqFwBdGXCVNGMdrbui0rU243lk
205,65a10544a5b8f0720000221f,292d67b8-ba7f-d516-1c11-b759d1163d33,https://media.licdn.com/dms/image/C4E03AQHVyH-IfD1KbQ/profile-displayphoto-shrink_100_100/0/1629877234109?e=1710374400&v=beta&t=0UZUl_dDUxLaZn-Hu-zToqEDe3rpL5cB2JkP5_jlNXc,"Sebastian Raschka, PhD",https://www.linkedin.com/in/ACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU,"
Machine learning and AI researcher since the early days ‚Ä¢ coding and working with LLMs at Lightning AI ‚Ä¢ ex-statistics professor at University of Wisconsin-Madison
","
I recently wrote about the new reinforcement learning with AI feedback (RLAIF) paper to collect and extend datasets for LLM training. Next to RLAIF, here are two additional interesting ideas to create datasets for instruction finetuning: HIR and Backtranslation.1) Self-Alignment with Instruction BacktranslationInstead of collecting datasets for instruction finetuning written by humans or using an LLM to generate instruction-response pairs (i.e., distillation), this paper proposes a third approach. Here, starting with a pretrained LLM, the researchers generate instructions for unlabeled text, such as websites. LLMs finetuned with this so-called instruction backtranslation approach outperform LLMs trained on distillation data, such as Alpaca.2) The Wisdom of Hindsight makes Language Models Better Instruction Followers This paper shows that supervised approaches to LLM finetuning can indeed work well. Here, researchers propose a relabeling-based supervised approach for finetuning that outperforms RLHF on 12 BigBench tasks.How does the proposed HIR (Hindsight Instruction Labeling) work? In a nutshell, the method HIR consists of two steps, sampling and training. In the sampling step, prompts and instructions are fed to the LLM to collect the responses. Based on an alignment score, the instruction is relabeled where appropriate in the training phase. Then, the relabeled instructions and the original prompts are used to finetune the LLM. Using this relabeling approach, the researchers effectively turn failure cases (cases where the LLM creates outputs that don't match the original instructions) into useful training data for supervised learning.#LLMs #AI #Transformers

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7108065056969428994?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7108065056969428994%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQEU0UjktmyUnA/feedshare-shrink_480/0/1694694769761?e=1707955200&v=beta&t=r72lz5vxEIh9Q583bousV3axZX4Dm7z5A41Cix8GByA
206,65a10544a5b8f07200002220,1a725905-edbc-6534-03b5-3b8e85fd8b32,https://media.licdn.com/dms/image/C4D03AQEmDwFNREkaIA/profile-displayphoto-shrink_100_100/0/1517524291944?e=1710374400&v=beta&t=9H8wRu-S3Mr0BN5zZEZBtWwefLpa0ZU_FPNQ9dTlNws,Robin Gras,https://www.linkedin.com/in/ACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ,"
Professor at University of Windsor, CSO and partner at Movyl Technologies and MVYL Associates
","

 

World scale inverse reinforcement learning in Google Maps
",,https://www.linkedin.com/feed/update/urn:li:activity:7107701450159308800?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7107701450159308800%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQGIuKgHVgb6OQ/articleshare-shrink_800/0/1704295856217?e=1705658400&v=beta&t=mJWRlYb4WdTRNslAalxQMQQoa1u_62JhsGX9h5CRDDY
207,65a10544a5b8f07200002221,b3a1cac8-36a8-447b-7aca-a97d311a2d52,https://media.licdn.com/dms/image/C4D03AQEmDwFNREkaIA/profile-displayphoto-shrink_100_100/0/1517524291944?e=1710374400&v=beta&t=9H8wRu-S3Mr0BN5zZEZBtWwefLpa0ZU_FPNQ9dTlNws,Robin Gras,https://www.linkedin.com/in/ACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ,"
Professor at University of Windsor, CSO and partner at Movyl Technologies and MVYL Associates
","
NExT-GPT: Any-to-Any Multimodal LLMpaper page: https://lnkd.in/egc33yev""While recently Multimodal Large Language Models (MM-LLMs) have made exciting strides, they mostly fall prey to the limitation of only input-side multimodal understanding, without the ability to produce content in multiple modalities. As we humans always perceive the world and communicate with people through various modalities, developing any-to-any MM-LLMs capable of accepting and delivering content in any modality becomes essential to human-level AI. To fill the gap, we present an end-to-end general-purpose any-to-any MM-LLM system, NExT-GPT. We connect an LLM with multimodal adaptors and different diffusion decoders, enabling NExT-GPT to perceive inputs and generate outputs in arbitrary combinations of text, images, videos, and audio. By leveraging the existing well-trained highly-performing encoders and decoders, NExT-GPT is tuned with only a small amount of parameter (1%) of certain projection layers, which not only benefits low-cost training and also facilitates convenient expansion to more potential modalities. Moreover, we introduce a modality-switching instruction tuning (MosIT) and manually curate a high-quality dataset for MosIT, based on which NExT-GPT is empowered with complex cross-modal semantic understanding and content generation. Overall, our research showcases the promising possibility of building an AI agent capable of modeling universal modalities, paving the way for more human-like AI research in the community.""

          ‚Ä¶see more
        


Paper page - NExT-GPT: Any-to-Any Multimodal LLM
",,https://www.linkedin.com/feed/update/urn:li:activity:7107707339213787136?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7107707339213787136%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQFzCfrLu1q2Zw/articleshare-shrink_800/0/1704372202343?e=1705658400&v=beta&t=GgfXjmP7O6DsAZTz1QFLVjY4b_DgxeEkOYrUyWg2LzY
208,65a10544a5b8f07200002222,03952f41-9325-1d32-6a81-2809be600ae6,https://media.licdn.com/dms/image/C5603AQGgg073ELAVbg/profile-displayphoto-shrink_100_100/0/1592234000524?e=1710374400&v=beta&t=9nrxRBMHL9tPISkGhvB3DM5CTqfDr0Z8IewBew3jIs8,Udit Gupta,https://www.linkedin.com/in/ACoAACKCeEUBxrwdrRRPbfOuFTl3ufE9qWi3IJQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACKCeEUBxrwdrRRPbfOuFTl3ufE9qWi3IJQ,"
Data Scientist - III @ Zendrive | Master's in Computational and Data Science, IISc
","
üöÄ GPT-InvestAR: A Remarkable Success in Just One Week! üìàIn less than a week since GPT-InvestAR was released, the response has been nothing short of phenomenal and I'm deeply grateful for the support from the #AI and #Finance communities.üìù Featured in a Blog Post:To my surprise, someone in the community has taken the time to write a detailed blog post about GPT-InvestAR. You can check it out here: https://lnkd.in/d4CG-nv6It's incredibly gratifying to see the impact that this work is having on others.üåü GitHub Repo Buzz:The GitHub repository has been buzzing with activity! It's been viewed a whopping 6000 times, and has already garnered 92 stars and 17 forks. The enthusiasm and engagement from the open-source community is truly remarkable. Explore the code and get involved: https://lnkd.in/d4Wsc6HYüí° A Learning Opportunity:If you haven't had the chance to dive into GPT-InvestAR yet, this is a great opportunity. It can act as a starting point for understanding how Large Language Models (LLMs) work with supplementary data and are utilised for downstream tasks.üåê Continuing the Journey:Given the resounding success it has witnessed, I'm motivated to keep improving. I'm eager to explore the latest technologies and advanced ML approaches to further enhance this framework.Thank you all for your support and enthusiasm.üí° #AIinFinance #DataScience #InvestmentStrategies #OpenSource #LLM

          ‚Ä¶see more
        


GPT-InvestAR: LLMs for better investment
",,https://www.linkedin.com/feed/update/urn:li:activity:7107736506265387009?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7107736506265387009%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQETMbju15ufSg/articleshare-shrink_800/0/1704470986697?e=1705658400&v=beta&t=74Mb7JAyVYRXLJN-xu5spffS73ivfSKEkZEWPEd9gZU
209,65a10544a5b8f07200002223,8a30d254-4db2-0caa-9b51-7d50f3971785,https://media.licdn.com/dms/image/C5603AQEGK_kIML5FYw/profile-displayphoto-shrink_100_100/0/1595864198140?e=1710374400&v=beta&t=6CC4QiBsF-0SuD53fsfS3gV_mVcn3rXMzcrbPHGnAqE,Prakhar Mishra,https://www.linkedin.com/in/ACoAAA7J_U4BNtFcrfzwXdbfaajkC_m2PB-8EsU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA7J_U4BNtFcrfzwXdbfaajkC_m2PB-8EsU,"
AI/ML Engineer @ UnitedHealth Group | MS in Data Science
","
ùêÄùê´ùêû ùê≤ùê®ùêÆ ùê•ùê®ùê®ùê§ùê¢ùêßùê† ùê≠ùê® ùê´ùêûùêùùêÆùêúùêû ùêÖùêöùêúùê≠ùêÆùêöùê• ùêáùêöùê•ùê•ùêÆùêúùê¢ùêßùêöùê≠ùê¢ùê®ùêß ùê¢ùêß ùê≤ùê®ùêÆùê´ ùêãùêãùêåùê¨ ùê®ùêÆùê≠ùê©ùêÆùê≠ ùê∞ùê¢ùê≠ùê°ùê®ùêÆùê≠ ùê¶ùêÆùêúùê° ùê°ùêöùê¨ùê¨ùê•ùêû? üßêùêÉùê®ùêãùêÄ ùê≠ùê® ùê´ùêûùê¨ùêúùêÆùêû!! - Decoding Method that improves Factuality in Pre-trained Large Language Models. Does not require any external knowledge or additional fine-tuning. Massachusetts Institute of Technology Microsoft - (released a week back)ùêéùêõùê¨ùêûùê´ùêØùêöùê≠ùê¢ùê®ùêßùê¨:  (fig. 2 in the https://lnkd.in/dru_tbSx)1.  LMs progressively incorporate more factual information along the layers (ùòûùò©ùò¶ùòØ ùòµùò©ùò¶ ùòØùò¶ùòπùòµ-ùò∏ùò∞ùò≥ùò• ùò±ùò≥ùò¶ùò•ùò™ùò§ùòµùò™ùò∞ùòØ ùò≥ùò¶ùò≤ùò∂ùò™ùò≥ùò¶ùò¥ ùòßùò¢ùò§ùòµùò∂ùò¢ùò≠ ùò¨ùòØùò∞ùò∏ùò≠ùò¶ùò•ùò®ùò¶, ùòìùòìùò¢ùòîùòà ùò¢ùòØùò• ùò∞ùòµùò©ùò¶ùò≥ùò¥ ùò¥ùò¶ùò¶ùòÆ ùòµùò∞ ùò§ùò©ùò¢ùòØùò®ùò¶ ùòµùò©ùò¶ ùò±ùò≥ùò¶ùò•ùò™ùò§ùòµùò™ùò∞ùòØùò¥ ùò¢ ùò≠ùò∞ùòµ ùò™ùòØ ùòµùò©ùò¶ ùò©ùò™ùò®ùò©ùò¶ùò≥ ùò≠ùò¢ùò∫ùò¶ùò≥ùò¥.)2. Function words, such as was, the, to, and Input tokens usually come out from early layers of the transformers. ùêñùê®ùê´ùê§ùê¢ùêßùê†:1. For every token that is predicted next, it calculates the contrast (JS Divergence) between the distribution of the Last layer (mature layer) and Intermediate layers (pre-mature layers).2. Increased contrast indicates the progression of information. The pre-mature layer with the highest contrast w.r.t to the mature layer is chosen. 3. The final distribution for the next word is calculated by subtracting the log probabilities of the premature layer outputs from those of the mature layer. ùêàùêß ùê®ùêßùêû ùê•ùê¢ùêßùêû:The word that experiences the greatest probability increase across the layers will have a peak in the final distribution.Very interesting idea. Want to read more? Recommend you go through the paper: https://lnkd.in/dru_tbSxCode link in comments.#naturallanguageprocessing #largelanguagemodels #ai #machinelearning #deeplearning #education #science #technology #research #datascientist #llm

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7107964867873009664?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7107964867873009664%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQGiYRtVGa9zhA/feedshare-shrink_480/0/1694670883138?e=1707955200&v=beta&t=5sbBP2cDyCHK0Vv6QJf7qfP-Klu5ADdVWpWEZVH1ayU
210,65a10544a5b8f07200002224,b542ad58-1293-374b-6a93-d82650a3294e,https://media.licdn.com/dms/image/D5603AQHvmYJmMHtysQ/profile-displayphoto-shrink_100_100/0/1672934103495?e=1710374400&v=beta&t=6iI7YLcwsn8GqhICUaTHb6MOmcMXwOMNixRp5b3jxFY,Amit Sheth,https://www.linkedin.com/in/ACoAAAAAZ2YB886_WgrdhXkhRpqDG83-3hw8Npk?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAAAZ2YB886_WgrdhXkhRpqDG83-3hw8Npk,"
Founding Director, Artificial Intelligence Institute at University of South Carolina
","
Delighted to share this:A Survey of Hallucination in Large Foundation ModelsOverview of recent efforts to identify, elucidate, and tackle the problem of #hallucination. Challenges and solutions related to hallucination in Large Foundational Models. #llm  #foundationmodels Vipula RawteProf. (Dr.) Amitava Das Amit Shethhttps://lnkd.in/gcZVPsD5Check out what other readers have to say about this work: https://lnkd.in/gfvxJ3Kb ; https://lnkd.in/g4H8Y-v3

          ‚Ä¶see more
        


A Survey of Hallucination in Large Foundation Models
",,https://www.linkedin.com/feed/update/urn:li:activity:7107759437515259905?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7107759437515259905%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQFKUp0REtOF9w/articleshare-shrink_800/0/1703998951935?e=1705658400&v=beta&t=nOMIYTCsTMtIW-5_iwqwwSlqONS1y3gh-DJGEv-THWQ
211,65a10544a5b8f07200002225,bf6e0d44-3306-3bc2-7f0b-350425fbd065,https://media.licdn.com/dms/image/D4E03AQHtC2BUAB6jkA/profile-displayphoto-shrink_100_100/0/1694687456770?e=1710374400&v=beta&t=ndmP3__bJjjA60t62U8lCwf_bck4TDX4LIp-qSsOgAc,Prithivi Da,https://www.linkedin.com/in/ACoAAANONyEBI75vYtjMK4f9hcDMhgneli34DsA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAANONyEBI75vYtjMK4f9hcDMhgneli34DsA,"
Building a Memory Assistant for Philomaths. Sharing wisdom from a 2 decade experience in creative problem solving.
","
ùóßùó∂ùóªùòÜ ~ùü±ùü¨ùó∫ùóØ ùó∫ùóºùó±ùó≤ùóπùòÄ ùó≥ùóºùóø ùó¢ùó≥ùó≥ùóπùó∂ùóªùó≤ ùó¶ùóΩùó≤ùó≤ùó∞ùóµ-ùòÅùóº-ùóßùó≤ùòÖùòÅ ùòÅùóµùóÆùòÅ ùó≥ùó∂ùòÅùòÄ ùó∂ùóª ùòÜùóºùòÇùóø ùóΩùóµùóºùóªùó≤ùòÄ ùóºùóø ùó±ùó≤ùòÉùó∂ùó∞ùó≤ùòÄ.‚Üí Open source‚Üí 20+ languages, accents & dialects‚Üí Zero-latency w/streaming API,‚Üí Speaker identification.‚Üí Supports Python, Java, Node, Rust, Go...‚Üí Versatile: Devices or Server or Serverless.Repo: https://lnkd.in/e5gnBukx_________________________Save-for-later using SaveLikeAPRO, https://savelikeapro.app.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7107588729073979392?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7107588729073979392%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQHK09d3Aq_tlA/feedshare-shrink_480/0/1694577539620?e=1707955200&v=beta&t=pSPDmcdBnBwiI2BdCBpFg7ybTyPXCXjWKWZjRT1QrU8
212,65a10544a5b8f07200002226,cf53a86c-2651-567d-57e9-2cca61443032,https://media.licdn.com/dms/image/C4E03AQGaJicfkdx0OA/profile-displayphoto-shrink_100_100/0/1621628083925?e=1710374400&v=beta&t=dCq_JLW2qmUQT5QYTGVPNi3F2JpNOfG-SGxWiIli7z4,Matt Payne,https://www.linkedin.com/in/ACoAACMNIUkBR6vQlxXWze4xhzbN-CSqpPpr1MI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACMNIUkBR6vQlxXWze4xhzbN-CSqpPpr1MI,"
Building Machine Learning & Ai software tools for organizations to automate business processes and enhance product capabilities. | Primarily focused on generative ai | ex - Capital One | Focused on Width.ai & Pumice.ai
","
Some of my best work I've put out recently. Broke down how you can use the ReAct prompting framework to improve your generative ai implementations, and shared our SOTA banking chatbot that uses ReAct. The key benefit this provides is an awesome framework for managing interacting with both the Vector DB for non-dynamic data and external API services for real time data. Take a look:

          ‚Ä¶see more
        


ReAct Prompting: How We Prompt for High-Quality Results from LLMs | Chatbots & Summarization | Width.ai
",,https://www.linkedin.com/feed/update/urn:li:activity:7105238564988145664?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7105238564988145664%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQH8Q5VRJF-W1A/articleshare-shrink_800/0/1703931713188?e=1705658400&v=beta&t=MC0oLruvPHB1V0PbA84iXqVHyDuVtC-DJiUK42z2_Lg
213,65a10544a5b8f07200002227,08c91b1c-41e2-92f9-b856-6e312ac2d81b,https://media.licdn.com/dms/image/C4E03AQGCmz60TR4U_A/profile-displayphoto-shrink_100_100/0/1548387165698?e=1710374400&v=beta&t=HBx2vUOpilvOTIG2cAztZlGw5XYBFYfm_Zv7qdfxDBY,Russell Jurney,https://www.linkedin.com/in/ACoAAABfD7wB1ProJaev__Cskc2izd0_t4nIhDI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAABfD7wB1ProJaev__Cskc2izd0_t4nIhDI,"
Graph AI meets LLMs
","
Whoah!
 ",,https://www.linkedin.com/feed/update/urn:li:activity:7104985418525261824?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7104985418525261824%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E10AQFwzfSiBGNXsQ/image-shrink_480/0/1692597026293?e=1705658400&v=beta&t=3AYC7KhPaukYP9CPKbMlUzUuaI1qoy-6jJfzVMxrQcE
214,65a10544a5b8f07200002228,e855ffa6-389a-564c-36a9-e875a2d06e49,https://media.licdn.com/dms/image/D4E03AQGM0Y967bzwYw/profile-displayphoto-shrink_100_100/0/1673958730736?e=1710374400&v=beta&t=D7vfK8Xc4FuC4GIIHDiKOT2J7OcBvz88MsJvG0D0Df8,David Mataciunas,https://www.linkedin.com/in/ACoAAAsf8pgBPeN60A0rc0301Fe7tNkiA88zbVQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAsf8pgBPeN60A0rc0301Fe7tNkiA88zbVQ,"
Technical Data Analyst / ML Engineer @ Sunrise | Chairman of the Board of AI Association of Lithuania | Startup Mentor
","
Google DeepMind is back with another breakthrough: Reinforced Self-Training (ReST) for language modeling. Here's the more details:üéØ ùêéùêõùê£ùêûùêúùê≠ùê¢ùêØùêû:ùêñùê°ùêöùê≠? Aligning large language models (LLMs) with our human way of thinking and communicating. üß†ùêñùê°ùê≤? To make our interactions with machines feel more natural and intuitive. Imagine chatting with a machine and feeling like it really ""gets"" you. ü§ùüîß ùêåùêûùê≠ùê°ùê®ùêù:ùêèùê´ùê®ùêúùêûùê¨ùê¨: ReST takes an initial LLM and generates samples. Using these samples, it refines and sharpens the model's responses and understanding. üîÑùêáùê¢ùê†ùê°ùê•ùê¢ùê†ùê°ùê≠: It's like giving continuous feedback to a buddy, helping them improve their language skills over time. üó£Ô∏è‚û°Ô∏èüìö‚è≥ ùêÑùêüùêüùê¢ùêúùê¢ùêûùêßùêúùê≤:ùêÄùê©ùê©ùê´ùê®ùêöùêúùê°: The beauty of ReST is in its offline data processing. This means it can keep reusing and learning from the same data, making the most of every piece. üîÑùêÅùêûùêßùêûùêüùê¢ùê≠: Faster improvements, less data waste, and more robust results. üöÄüåè ùêÄùê©ùê©ùê•ùê¢ùêúùêöùê≠ùê¢ùê®ùêß:ùêÖùê®ùêúùêÆùê¨: The spotlight is on machine translation. üó£Ô∏èüåêùêàùê¶ùê©ùêöùêúùê≠: ReST doesn't just translate words; it captures the essence, context, and nuance. So, if you've ever scratched your head over a weird machine translation, ReST is on its way to make things clearer. üéâLove our content? ü•∞ Help spread the word! Hit üëç, share with friends üîÑ, and don't forget to üîî for our latest!#ai #technology #innovation #data

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7104401014283190272?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7104401014283190272%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQEec6IeZ1WKiQ/feedshare-shrink_480/0/1693821193985?e=1707955200&v=beta&t=pwNbIVkrFEpUEwrNFSB25sa6GPvQNOBAO1dp1jVmevU
215,65a10544a5b8f07200002229,89d55b71-88be-cbb1-d896-6ad55ee46898,https://media.licdn.com/dms/image/C4E03AQHFGmCDjxWzjg/profile-displayphoto-shrink_100_100/0/1643009949453?e=1710374400&v=beta&t=Y-TD5POX9mxNGlhJ75MxqyDwLAWDdj0WXndZhwyg9Cc,Sayak Paul,https://www.linkedin.com/in/ACoAABxMXFAB6ootaAI0HGnHMWCg8Rzpqvyoviw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABxMXFAB6ootaAI0HGnHMWCg8Rzpqvyoviw,"
ML @ Hugging Face ü§ó
","
Inspired by OpenAI's Jason Wei, today, I am sharing a Google Doc answering some FAQs at length. I envision this document to be always in WIP mode. I don't consider myself to be someone accomplished enough to have the need to author a document like this. But, if my answers help elevate someone, I would be happy. Link to the doc:https://bit.ly/sayak-faqs

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7104108951226515456?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7104108951226515456%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHlir9026fXtA/feedshare-shrink_480/0/1693751560943?e=1707955200&v=beta&t=s1MmdGYy_7BaZVnKk6uPE-B7uFgO5w_tSVCSvIiFnSE
216,65a10544a5b8f0720000222a,cef9d046-b6b7-1916-d781-2f351175c039,https://media.licdn.com/dms/image/C4E03AQGfzEtRhrPHdw/profile-displayphoto-shrink_100_100/0/1619776973437?e=1710374400&v=beta&t=y9up1yBFMNfTMJvaDgcupbnl3OnJC7EgkzWAkOY4pyM,Sanyam Bhutani,https://www.linkedin.com/in/ACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0,"
Senior Data Scientist at H2O.ai | Kaggle Grandmaster
","
My favourite Channel to learn ML in 2023! üôèRob Mulla is the best teacher to learn Machine Learning from no matter where you are in your journey. His videos are the best combination of both breadth of topics and depth of knowledge. The videos span a large span of topics and every video covers them in the depth you would expect from a Quadruple Kaggle Grandmaster. I'm a fan of his no-nonsense and dive straight into explaining concepts via code style.Happy learning:https://lnkd.in/dYJQ9ffz

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7104083904499789824?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7104083904499789824%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQHOUwUZ8Ior-w/feedshare-shrink_480/0/1693745589612?e=1707955200&v=beta&t=nvekPfj0Euv-1tlUKqeJ5E0Ce24wOIDfXZPrgr9o5Og
217,65a10544a5b8f0720000222b,bd1ef30f-b5f2-0bac-68ec-c948e85547fa,https://media.licdn.com/dms/image/C4E03AQGCmz60TR4U_A/profile-displayphoto-shrink_100_100/0/1548387165698?e=1710374400&v=beta&t=HBx2vUOpilvOTIG2cAztZlGw5XYBFYfm_Zv7qdfxDBY,Russell Jurney,https://www.linkedin.com/in/ACoAAABfD7wB1ProJaev__Cskc2izd0_t4nIhDI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAABfD7wB1ProJaev__Cskc2izd0_t4nIhDI,"
Graph AI meets LLMs
","
I‚Äôm writing a three part series using the included prompts to reproduce and extend InstructGLM - a new model that uses instruction fine tuning to teach an LLM node features as well as topology.
 

LLMs-represent->Knowledge Graphs
",,https://www.linkedin.com/feed/update/urn:li:activity:7103564079251783680?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7103564079251783680%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5612AQFQbAD0C6XmCQ/article-cover_image-shrink_600_2000/0/1693620121041?e=1710374400&v=beta&t=WZ0hw_dAw-DndQv8BgSRgUAvu-znxEW28DAWVI-9k10
218,65a10544a5b8f0720000222c,df0c5a6c-f5bc-53e2-cbe4-f67a068bdbb6,https://media.licdn.com/dms/image/C4E03AQHVyH-IfD1KbQ/profile-displayphoto-shrink_100_100/0/1629877234109?e=1710374400&v=beta&t=0UZUl_dDUxLaZn-Hu-zToqEDe3rpL5cB2JkP5_jlNXc,"Sebastian Raschka, PhD",https://www.linkedin.com/in/ACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU,"
Machine learning and AI researcher since the early days ‚Ä¢ coding and working with LLMs at Lightning AI ‚Ä¢ ex-statistics professor at University of Wisconsin-Madison
","
A while back, I wrote an article titled ""Fine-Tuning Large Language Models: An Introduction to the Core Ideas and Approaches."" It covered various techniques for interacting with and customizing large language models (LLMs), such as in-context learning and indexing, fine-tuning for classification, parameter-efficient fine-tuning, supervised instruction fine-tuning, and reinforcement learning with human feedback.As a follow-up, if you're looking for an insightful read over the long weekend, I highly recommend the recently uploaded survey ""Instruction Tuning for Large Language Models"" by Zhang et al. This survey contains succinct summaries of various dataset construction techniques, including unnatural instructions, self-instruct, evol-instruct, and super-natural instructions, as well as curated datasets like LIMA and OpenAssistant conversations.Moreover, the survey also explores various LLMs that have been fine-tuned on instruction datasets, such as InstructGPT, BLOOMZ, Nous-Hermes, Guanaco, and more.#LLMs #AI #Transformers

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7103730546198904832?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7103730546198904832%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQFFIqbxa9sh3A/feedshare-shrink_480/0/1693661342609?e=1707955200&v=beta&t=BtXeYjGVtMuV14I7Y1QOuLDq6UOkMW3RGBzfjmjPhak
219,65a10544a5b8f0720000222d,bcef8d43-a434-513a-1688-b480f3d2c7e8,https://media.licdn.com/dms/image/C4E03AQHXPJjrhZpyIA/profile-displayphoto-shrink_100_100/0/1639252923491?e=1710374400&v=beta&t=CZIcq4nMhapEZQJfh5Xb9_7WJSZ4Er1Axe0he9o9_F4,Ravi Theja Desetty,https://www.linkedin.com/in/ACoAAAUWtEABhvXgvUh2Me4HrSvlTbb9ZrN2G_o?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAUWtEABhvXgvUh2Me4HrSvlTbb9ZrN2G_o,"
LlamaIndex || LLM || GenAI || Open Source
","
üöÄ Automatic Knowledge Transfer (KT) Generation for Code Bases with LlamaIndex!üë©‚Äçüíª Navigating roles as a new hire, aiming for a seamless handover during notice periods, or adapting to shifting projects as developers and product specialists can make the KT process daunting and stress-inducing.ü§î Amid these challenges in the fast-paced software realm, is there a silver lining that can offer clearer, more efficient communication?üèÜ Thrilled to unveil our (Vibhav Agarwal) award-winning solution from the Google Cloud, Searce Inc, and Lifesight GenAI hackathon. Our solution is a four-stage process:1Ô∏è‚É£ Code Parsing.2Ô∏è‚É£ Summary and Explanation Generation.3Ô∏è‚É£ Video Creation.4Ô∏è‚É£ Integration of Code and Video.üìù Blog Post: https://lnkd.in/gSHUx7GZüíª Code: https://lnkd.in/gVPkqCeaüé• Watch the demo featuring Jerry Liu as he delves into the LlamaIndex codebase: https://lnkd.in/gW77eZZk

          ‚Ä¶see more
        


LlamaIndex: Automatic Knowledge Transfer (KT) Generation for Code Bases
",,https://www.linkedin.com/feed/update/urn:li:activity:7102865445241712640?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7102865445241712640%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQFf2pCchz2Z7g/articleshare-shrink_800/0/1704408284488?e=1705658400&v=beta&t=JsEKJw6V9M00VtPm_yXUxPBPQeLkUWps3PCiWHgDL6E
220,65a10544a5b8f0720000222e,a23ae5bd-463a-9ba5-cc9e-9a00dddd4a2d,https://media.licdn.com/dms/image/C5603AQGNiPgtzhytNA/profile-displayphoto-shrink_100_100/0/1661100392803?e=1710374400&v=beta&t=GW7z3ILL8k5xz1b9nGGMDJ_LvUChugJhs_eOqURVGa4,Vasudev Lal,https://www.linkedin.com/in/ACoAAAE8L6cBrBiAuir2A_RG-u5PJWjLWG_jZAs?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAE8L6cBrBiAuir2A_RG-u5PJWjLWG_jZAs,"
AI/ML Research Scientist at Intel Labs
","
Here's something that combines Chip Huyen's #3 (multimodality) and #6 (Develop GPU alternatives)For multimodal transformer training (eg BridgeTower model, AAAI-23 Oral), Intel's Gaudi-2 AI accelerator beats H100:https://lnkd.in/gpC9uU5Z

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7103259220317282304?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7103259220317282304%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHKw2Qa1ED0WQ/feedshare-shrink_480/0/1692204407678?e=1707955200&v=beta&t=ea7K6pr7vDEPC_iF_k6DXEbqX6Nk5zBl-dl7dUEJ04U
221,65a10544a5b8f0720000222f,a00c2ef0-f2f1-bca8-9814-05f7bef3a619,https://media.licdn.com/dms/image/D5635AQEBzEFRC2EzLg/profile-framedphoto-shrink_100_100/0/1704907585971?e=1705658400&v=beta&t=x71pDAJzCbSPZxvt91sIkpmEr_5_pGLZIt6VZgw5eV0,Aman Chadha,https://www.linkedin.com/in/ACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU,"
GenAI Leadership @ Amazon AWS ‚Ä¢ Stanford AI ‚Ä¢ EB-1 ""Einstein Visa"" Recipient/Mentor ‚Ä¢ Ex-Ô£ø, Amazon Alexa, Nvidia, Qualcomm ‚Ä¢ EMNLP 2023 Outstanding Paper Award
","
ü§ñ Reinforcement Learning with Human Feedback (RLHF) and Reinforcement Learning with AI Feedback (RLAIF): http://rlhf.aman.ai- RLHF is one of the most effective techniques to align LLM behavior with human preferences. It has been pivotal for the optimal performance of current LLMs, resulting in more accurate and contextually appropriate responses. - On the other hand, RLAIF involves an LLM providing feedback to another LLM based on certain criteria. This could potentially enable faster training, better scalability, and remove annotation bottlenecks by leveraging the insights of one AI to refine another.- Here are primers for RLHF and RLAIF.üîπ RLHF- Refresher: Basics of RL- Training Process (Pretraining Language Models, Training a Reward Model, Fine-tuning the LM with RL)- Bias Concerns and Mitigation Strategiesüîπ RLAIF- Overview: Anthropic‚Äôs Constitutional AI paper- Using AI feedback instead of human feedback to steer LLMs.- Architecture: Supervised Learning and Reinforcement LearningNotes written in collaboration with Vinija Jain.#artificialintelligence #machinelearning #ai

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7101407760352768000?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7101407760352768000%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQEwkzt1DP6jJg/feedshare-shrink_480/0/1693107546093?e=1707955200&v=beta&t=LJKYtFza8Bt7_GmViqCTzmyrHE1wZUyw5KGfXAmKpQE
222,65a10544a5b8f07200002230,f74f4970-f4b1-bcf3-3025-d0711d4445df,https://media.licdn.com/dms/image/D5635AQGcqj5DCJEmjw/profile-framedphoto-shrink_100_100/0/1691025528105?e=1705658400&v=beta&t=BrKZB-w_ckKRtCDIIXUv1oINAN6TB8XHPrJ8SleK20A,Ajay Y.,https://www.linkedin.com/in/ACoAAAJc7nwBhT2mSOLJVqC0QAtuqukXlfdywUs?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAJc7nwBhT2mSOLJVqC0QAtuqukXlfdywUs,"
Co-Founder at Simplified | Forbes 30 under 30
","
7 AI tools that can help you crack interviews and find a high paying job (USD): 1. Pyjama Jobs: This remote job board employs an algorithm that matches you exclusively with relevant jobs, facilitating immediate viewing and communication between you and recruiters.Link: pyjamahr.com2. InterviewIQ: Enhance your interview skills with real-time AI feedback, offering insights into your communication style, body language, and content to improve your chances of success.Link: interviewiq.com.au3. Woo: AI-powered platform that anonymously matches tech professionals with potential employers based on their skills, experience, and desired working conditions.Link: tech.woo.io4. JobScan: Utilize AI algorithms to match your resume with job descriptions, increasing the likelihood of getting noticed by applicant tracking systems and landing interviews.Link: jobscan.co5. SalaryWizard AI: Optimize your salary negotiation strategies with AI-generated insights and personalized tips, helping you secure the compensation you deserve.Link: https://lnkd.in/gCNbud6V6. SkillMentor: Receive AI-curated learning paths to upskill and stay competitive in your industry, helping you fill in knowledge gaps and stay relevant.Link: mentorindia.com7. MarketWatch Insights: Utilize AI-driven market trends and salary data to identify high-demand skills and industries, guiding your job search toward lucrative opportunities.Link: https://lnkd.in/g_4wa5-4#recruiting #careers #USD

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7103362446085541888?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7103362446085541888%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHOcMC-MWJL3g/feedshare-shrink_480/0/1693573579600?e=1707955200&v=beta&t=0QtWbpMmEQt4rPT7aTv_txQJOI9Rit80Q8AKvpDb_ZI
223,65a10544a5b8f07200002231,d523cb18-8179-bc4e-a2b7-5e0cbf8fb9c1,https://media.licdn.com/dms/image/D4D03AQFYouPze-Z_FQ/profile-displayphoto-shrink_100_100/0/1697588413972?e=1710374400&v=beta&t=E747SFntX-oCLKL7kdd0duSjLLVAc-lUA5XiE3QZlFI,Philipp Schmid,https://www.linkedin.com/in/ACoAAC32gzIBgoSQxlj2vNU5Zs9xZMxtINv3MvA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAC32gzIBgoSQxlj2vNU5Zs9xZMxtINv3MvA,"
Technical Lead & LLMs at Hugging Face ü§ó | AWS ML HERO ü¶∏üèª‚Äç‚ôÇÔ∏è
","
Not, Yet another RoPE extensioN method! üôÑ But listen, ‚ÄúYaRN‚Äù allows you to scale LLMs like llama 2 to over 100k context! ü§Ø Yesterday, a team of researchers, including EleutherAI, and Nous Research, presented a new method to efficiently extend the context window of models trained with Rotary Position Embeddings (RoPE) like LLaMA, GPT-NeoX, and PaLM families. üÜï In the paper they successfully extended the context length of llama 2 13B to 128k training only for additional 400 steps! ü§ØüöÄYaRN allows you to extend the context using only 0.1% of original pre-training data with negligible performance loss on standardized benchmarks compared to the original model. ü§Ø Models are available on Hugging Face ü§óüëâ https://lnkd.in/evhfz6pcThe code and the Paper can be found in the GitHub repository:üëâ https://lnkd.in/e2myD2eJ

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7103271115103330304?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7103271115103330304%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQF-f0AC7BiH8g/feedshare-shrink_480/0/1693551805646?e=1707955200&v=beta&t=gn_35LmZCT7rDs3KMTbeWkH6eo4TtwGZBjdO9Z5CRu8
224,65a10544a5b8f07200002232,365acefe-c48a-273f-b40e-3315da337aae,https://media.licdn.com/dms/image/C5603AQGL-jtAfNfY5Q/profile-displayphoto-shrink_100_100/0/1517359397526?e=1710374400&v=beta&t=WWcd_C4Np63Xlcd_FwhBZtqpXYj0p9p5vcVCS7VcTUo,"Mike Tamir, PhD",https://www.linkedin.com/in/ACoAAA4nX3ABkkBcWs4lpNTpQrM0ucxXVDOJgOs?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA4nX3ABkkBcWs4lpNTpQrM0ucxXVDOJgOs,"
Distinguished ML Scientist @Shopify, Data Science Faculty at UC Berkeley
","
ETH Z√ºrich DLSC: Course Introduction https://bit.ly/44X8H3y#AI #MachineLearning #DeepLearning #LLMs #DataScience

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7103395186055016448?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7103395186055016448%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5610AQEkLfBEn2iY8A/image-shrink_480/0/1693581362119?e=1705658400&v=beta&t=euS4nHdByWU1A7tZ-Y1bF_TssvSG4GFbOEm0srQp9I8
225,65a10544a5b8f07200002233,8a8166d7-2225-f782-bef1-a650e444d31c,https://media.licdn.com/dms/image/C4D03AQEmDwFNREkaIA/profile-displayphoto-shrink_100_100/0/1517524291944?e=1710374400&v=beta&t=9H8wRu-S3Mr0BN5zZEZBtWwefLpa0ZU_FPNQ9dTlNws,Robin Gras,https://www.linkedin.com/in/ACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ,"
Professor at University of Windsor, CSO and partner at Movyl Technologies and MVYL Associates
","

 

Researchers from Virginia Tech and Microsoft Introduce Algorithm of Thoughts: An AI Approach That Enhances Exploration of Ideas And Power of Reasoning In Large Language Models (LLMs)
",,https://www.linkedin.com/feed/update/urn:li:activity:7103365559379013632?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7103365559379013632%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQHtNsUSHMTM7g/articleshare-shrink_800/0/1704725399852?e=1705658400&v=beta&t=4YtrStLJ3cTFq-1_0YhFpXe3Lz7sq09UVcrekHGlFQg
226,65a10544a5b8f07200002234,75eee83a-4202-13a1-469b-e1e8ec345726,https://media.licdn.com/dms/image/D4E03AQGM0Y967bzwYw/profile-displayphoto-shrink_100_100/0/1673958730736?e=1710374400&v=beta&t=D7vfK8Xc4FuC4GIIHDiKOT2J7OcBvz88MsJvG0D0Df8,David Mataciunas,https://www.linkedin.com/in/ACoAAAsf8pgBPeN60A0rc0301Fe7tNkiA88zbVQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAsf8pgBPeN60A0rc0301Fe7tNkiA88zbVQ,"
Technical Data Analyst / ML Engineer @ Sunrise | Chairman of the Board of AI Association of Lithuania | Startup Mentor
","
LLM Autonomous Agents Explained! üìöLarge Language Models play a small, but vital role in the world of autonomous agents.The magic lies in the system's intricate engineering and design üîßThis paper by offers a comprehensive look at the architecture and links to other related studies.Key components of these agent structures include:Profile: Defining their character üìùMemory: Essential for long-term functionality üîçPlanning: Important for practical systems üó∫Ô∏èAction: The foundation of behavior üèÉThe paper also gives a concise summary of its practical applications.Rather than following a chronological approach like many reviews, this offers a straightforward overview.A quick look at the diagrams and figures will help. But reading in full is recommended! üëç#ai #largelanguagemodels #gpt4 #innovation

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7102598348322271232?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7102598348322271232%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQGHISlEamGsTA/feedshare-shrink_480/0/1693391405462?e=1707955200&v=beta&t=dqhp5MNNFCxjDHYp3-PMyftzX_DdqhNBwdBMs1I6YDk
227,65a10544a5b8f07200002235,31b2adae-b21c-57f7-e253-6040d2cd10cf,https://media.licdn.com/dms/image/C4D03AQEmDwFNREkaIA/profile-displayphoto-shrink_100_100/0/1517524291944?e=1710374400&v=beta&t=9H8wRu-S3Mr0BN5zZEZBtWwefLpa0ZU_FPNQ9dTlNws,Robin Gras,https://www.linkedin.com/in/ACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ,"
Professor at University of Windsor, CSO and partner at Movyl Technologies and MVYL Associates
","

 

Consciousness in AI - Insights
",,https://www.linkedin.com/feed/update/urn:li:activity:7102286486980448259?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7102286486980448259%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E1FAQHCx4BMy5IOVg/feedshare-document-cover-images_480/0/1693145971778?e=1705658400&v=beta&t=B13PmNXNW_H3lDhV_GNGkUU4rVZTmGnjU9VeG_UoJII
228,65a10544a5b8f07200002236,fe8ff98d-1007-f48f-f7b2-eab59b70d392,https://media.licdn.com/dms/image/C4E03AQGfzEtRhrPHdw/profile-displayphoto-shrink_100_100/0/1619776973437?e=1710374400&v=beta&t=y9up1yBFMNfTMJvaDgcupbnl3OnJC7EgkzWAkOY4pyM,Sanyam Bhutani,https://www.linkedin.com/in/ACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0,"
Senior Data Scientist at H2O.ai | Kaggle Grandmaster
","
LLamaIndex: Super intuitive framework for LLM Apps! üêêFor the last two weeks, I have been playing around with LlamaIndex to test Large Language Model application ideas. The entire ecosystem: documentation, tutorials and examples are refreshingly approachableConnecting your own data with LLMs is a superpower to make these models really performant and really useful, this is exactly where the framework shines. I actually found the documentation and the framework to be very intuitive and easy to build with. Over the next few days, I will share more cool snippets and tutorials. If you haven't yet, check out the framework, it's quite refreshing:https://lnkd.in/dNMEWAyw

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7102272779290316800?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7102272779290316800%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQGnpgQY05mNJw/feedshare-shrink_480/0/1693313783556?e=1707955200&v=beta&t=hncIoBwSdhbAh45cXk8ghjEr3LO9St5rW_uZXTNzxFo
229,65a10544a5b8f07200002237,191990ef-80cc-92d2-8e54-b249341bdaf6,https://media.licdn.com/dms/image/C4E03AQHVyH-IfD1KbQ/profile-displayphoto-shrink_100_100/0/1629877234109?e=1710374400&v=beta&t=0UZUl_dDUxLaZn-Hu-zToqEDe3rpL5cB2JkP5_jlNXc,"Sebastian Raschka, PhD",https://www.linkedin.com/in/ACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU,"
Machine learning and AI researcher since the early days ‚Ä¢ coding and working with LLMs at Lightning AI ‚Ä¢ ex-statistics professor at University of Wisconsin-Madison
","
All this happened on the Code LLM open source front since last week:1) Researchers release the Lemur suite, a code LLM based on Llama 2.HumanEval score: 61.6% pass@1 for 70B Lemur-Chat model2) Meta releases the Code Llama suite, code LLMs based on Llama 2.HumanEval score: 53.7% pass@1 for CodeLlama-34B-Python model3) Phind's finetuned Code Llama.HumanEval score: 69.5% pass@1 for finetuned CodeLlama-34B-Python model4) The WizardCoder-34B finetuned Code Llama.HumanEval score: 73.2% pass@1 for WizardCoder-Python-34B-V1.0 model*Note that there are a few claims that the WizardCoder model had a test data leakage. Also, the HumanEval dataset is not ideal. But it's still impressive how fast things are moving!#llms #ai #opensource

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7102269345979928576?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7102269345979928576%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQEqEv4sZbJenw/feedshare-shrink_480/0/1693312964628?e=1707955200&v=beta&t=n0_MBQVkeX6TGSvSIGYHj8fSFZsFwjjxuHpXKH2t1sQ
230,65a10544a5b8f07200002238,96374828-a5b6-b9af-df03-34e784956f58,https://media.licdn.com/dms/image/D4E03AQGM0Y967bzwYw/profile-displayphoto-shrink_100_100/0/1673958730736?e=1710374400&v=beta&t=D7vfK8Xc4FuC4GIIHDiKOT2J7OcBvz88MsJvG0D0Df8,David Mataciunas,https://www.linkedin.com/in/ACoAAAsf8pgBPeN60A0rc0301Fe7tNkiA88zbVQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAsf8pgBPeN60A0rc0301Fe7tNkiA88zbVQ,"
Technical Data Analyst / ML Engineer @ Sunrise | Chairman of the Board of AI Association of Lithuania | Startup Mentor
","
üìå Exploring LLM Research Challenges:üìö Hallucinationsüìñ Context Length & Constructionüìä Multimodality‚öôÔ∏è Faster & Cheaper LLMsüîß New Model Architectureüí° GPU Alternativesüåê LLM Agentsüåç LLMs for Non-English Languages - Join Cohere For AI Aya project and help us to solve this problem (more information in the comments) ‚¨á#ai #largelanguagemodels #innovation #data

          ‚Ä¶see more
        


LLM Research
",,https://www.linkedin.com/feed/update/urn:li:activity:7100035010132369409?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7100035010132369409%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E1FAQHjMaHv0741Cg/feedshare-document-cover-images_480/0/1692780173303?e=1705658400&v=beta&t=mp_d3gvvlHmAyWbCv4_4CVE0A4bZYGz-qD6ajE5Fb10
231,65a10544a5b8f07200002239,0d8cc34a-01be-4d1d-1a1a-59ca95c019c9,https://media.licdn.com/dms/image/D5635AQFcoKsERaUVzg/profile-framedphoto-shrink_100_100/0/1701941987794?e=1705658400&v=beta&t=PE_tPIPCVh-_SFHNuGGpXn25FlBVgpq0Ac7eNgA-4ok,Piotr Skalski,https://www.linkedin.com/in/ACoAAB5YNAMBHK3pXNcx81VZMKBhebx9gEOGUDA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAB5YNAMBHK3pXNcx81VZMKBhebx9gEOGUDA,"
Computer Vision Engineer, Growth @ Roboflow | Open Source
","
Top Modern Computer Vision Tutorials üî•üî•üî•41 notebooks, 32 YouTube videos, and 37 blog posts covering 21 models. Recently, we have added:- RTMDet Object Detection (MMDetection)- Fast Segment Anything Model (FastSAM)- YOLO-NAS Object DetectionI'm working on a traffic analysis tutorial with YOLOv8 and Supervision! Leave a star to stay up to date! ‚≠ê‚Æë üîó GitHub repository: https://lnkd.in/deQexCeS#opensource #github #computervision #tutorials

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7102237501351768064?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7102237501351768064%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQE5Bc9GyEhrog/feedshare-shrink_480/0/1693305372903?e=1707955200&v=beta&t=FPLD3IwOeF5c0GeIdJuXlxU7nChmLEDvB22q3sJytD8
232,65a10544a5b8f0720000223a,7e161a12-cb8a-a1f4-1194-b0c7b192027f,https://media.licdn.com/dms/image/D560BAQFbVTDw-oWXmw/company-logo_100_100/0/1681327675102?e=1713398400&v=beta&t=Ir5hx7xUuaUo5T2BZZ9XorhXXE6Rv1XeKkDVGjYlWDo,LlamaIndex,https://www.linkedin.com/company/llamaindex/,"
67K followers
","
We're excited to present a brand-new integration üî•: LlamaIndex data agents ü§ñ + Metaphor üîéThis integration gives data agents access to a search tool designed for LLMs - unlike Bing/Google search, Metaphor is specifically designed for LLM use.This allows LLM agents to dynamically retrieve data to answer any question over any data. Unlike RAG over a static knowledge source, this tool gives agents research/lookup capabilities. Big thanks to Jeffrey Wang for the review help.Colab notebook: https://lnkd.in/g_bDk6MKFull blog: https://lnkd.in/gXyNP2x2

          ‚Ä¶see more
        


LlamaIndex + Metaphor: Towards Automating Knowledge Work with LLMs
",,https://www.linkedin.com/feed/update/urn:li:activity:7099427438283165696?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7099427438283165696%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQGafJiKxrfjzA/articleshare-shrink_800/0/1704764423416?e=1705658400&v=beta&t=p5-MIkYsCYxa54oypGp8d1YFFEGFS_9jGKw7jBgUGMg
233,65a10544a5b8f0720000223b,00deb8a5-c0aa-ff59-c6bc-16a4f46aba83,https://media.licdn.com/dms/image/C5603AQG-dM4ML4UxFA/profile-displayphoto-shrink_100_100/0/1557023095050?e=1710374400&v=beta&t=LQ_tNrPtF7gFIxFApoMUaL1VAONTORvd7GgrPHM-uKY,Eric Vyacheslav,https://www.linkedin.com/in/ACoAACgVdBIBnVU5t_1PfWzjEm4SjOgQ1yY3Tsc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACgVdBIBnVU5t_1PfWzjEm4SjOgQ1yY3Tsc,"
AI/ML Engineer | Ex-Google | MIT Alumni
","
ü§Ø  This library has 163k stars on GitHub and it contains an implementation in Python of every single algorithm you can think of. From machine learning to blockchain and data structures.Data TransformationsDecision TreeDimensionality ReductionForecastingRunGradient DescentK Means ClustK Nearest NeighboursKnn SklearnLinear Discriminant AnalysisLinear RegressionLocal Weighted LearningLocal Weighted LearningLogistic RegressionLstmLstm PredictionMultilayer Perceptron ClassifierPolynomial RegressionScoring FunctionsSelf Organizing MapSequential Minimum OptimizationSimilarity SearchSupport Vector MachinesWord Frequency FunctionsXgboost ClassifierXgboost Regressor https://lnkd.in/gp4mHB5W ‚ÜìAre you technical? Check out https://AlphaSignal.ai to get a weekly summary of the latest research and breakthroughs in AI. Read by 120,000+ engineers and researchers.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7101956760734756864?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7101956760734756864%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5610AQEzk8LXmvWkfg/image-shrink_480/0/1693238414777?e=1705658400&v=beta&t=nKbmO1YbmfPM-AIC-2JrAd3XcDVlmqfQjgfBkU2eIaM
234,65a1055fa5b8f0720000223c,4795924e-8ddb-b207-5ad1-cdfd9adc83fe,https://media.licdn.com/dms/image/C4E03AQFqUHVisQctPA/profile-displayphoto-shrink_100_100/0/1574887699985?e=1710374400&v=beta&t=rHhvG7eAzKJe-_mPlb3InF4vnwlC9mzGfZ_TAvMnCHc,Weijie Xu,https://www.linkedin.com/in/ACoAABn5D3oBzd3ipxPC5Wx0GaVBwYZ2bWaU21I?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABn5D3oBzd3ipxPC5Wx0GaVBwYZ2bWaU21I,"
Applied Scientist II Amazon
","
üìö Favorite Paper of the week: ""TabDDPM: Modelling Tabular Data with Diffusion Models"" by Artem Babenko, Ivan Rubachev, Dmitry Baranchuk, Akim Kotelnikovüîë Quick Insight: The paper Introduces TabDDPM, a universal diffusion model for any tabular dataset, they demonstrate its superiority over existing GAN/VAE alternatives. The model also shows promise for privacy-oriented setups where data cannot be shared publicly.üí° Applications in People Analytics:In the people analytics realm, sharing valuable datasets can be risky due to privacy leaks. Experts can leverage TabDDPM to distribute synthetic data that retains utility without compromising privacy.üîó Full paper: https://lnkd.in/gnn6GuBG#AIResearch #DataModeling #TabularData #DiffusionModels #DataAnalytics #DataPrivacy #PredictiveAnalytics #BusinessIntelligence

          ‚Ä¶see more
        


TabDDPM: Modelling Tabular Data with Diffusion Models
",,https://www.linkedin.com/feed/update/urn:li:activity:7102024552410480640?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7102024552410480640%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,
235,65a1055fa5b8f0720000223d,59db84d7-0515-4726-2634-9cd34dcf2999,https://media.licdn.com/dms/image/C4E03AQGfzEtRhrPHdw/profile-displayphoto-shrink_100_100/0/1619776973437?e=1710374400&v=beta&t=y9up1yBFMNfTMJvaDgcupbnl3OnJC7EgkzWAkOY4pyM,Sanyam Bhutani,https://www.linkedin.com/in/ACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0,"
Senior Data Scientist at H2O.ai | Kaggle Grandmaster
","
Strong LLM blog recommendation! üôèEugene Yan's blogs are the best at combining knowledge of industrial patterns, experiments and cutting edge ideas. He has written about various Large Language Model patterns, best practises and really cool weekend experiments.I have been a big subscriber of Eugene's works for a long time, for anyone interested in remotely experimenting with the LLM world, his write-ups is your best gateway blog that very clearly mixes code with best practises.I have read every single one of them, my favourites are the personal writing and ""board committee"" experiments:https://eugeneyan.com

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7101911444295757824?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7101911444295757824%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQHIEQZDHyfiIg/feedshare-shrink_480/0/1693227633775?e=1707955200&v=beta&t=rZccmqX9nhxVsJmDJr6nCSqoJgjtBH58Q7o35cqMZQc
236,65a1055fa5b8f0720000223e,3d273747-c8d3-46b3-2bb1-6f29159d1e8f,https://media.licdn.com/dms/image/D560BAQFbVTDw-oWXmw/company-logo_100_100/0/1681327675102?e=1713398400&v=beta&t=Ir5hx7xUuaUo5T2BZZ9XorhXXE6Rv1XeKkDVGjYlWDo,LlamaIndex,https://www.linkedin.com/company/llamaindex/,"
67K followers
","
We've partnered with Wey Gu to create the world‚Äôs most comprehensive short course on using LLMs with Knowledge Graphs. ‚úÖ Key query techniques: text2cypher, graph RAG‚úÖ Automated KG construction‚úÖ vector db RAG vs. KG RAGAll this content is contained in a single Colab notebook: https://lnkd.in/gJ3D5Kr6There's also a full 1.5 hour video tutorial: https://lnkd.in/gDtzGwx5 It's a must watch if you're exploring how to use graph-based data structures in your LLM application! 

          ‚Ä¶see more
        


Google Colaboratory
",,https://www.linkedin.com/feed/update/urn:li:activity:7101315253833011200?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7101315253833011200%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQE9Psmxkm3_-A/articleshare-shrink_480/0/1704120609467?e=1705658400&v=beta&t=mjQV6XApcHf3VweBgkEPZq3M7-wypb6DlSZ6EF8CHvo
237,65a1055fa5b8f0720000223f,348e9492-1bfe-4a5d-eb48-fd9be1ab2040,https://media.licdn.com/dms/image/C4D0BAQG1yEbzvWYiXw/company-logo_100_100/0/1642603423308/towards_data_science_logo?e=1713398400&v=beta&t=y8CIwK9dQB-BTSDO6I7B3oL7VUGVvPS986H7M3mioNE,Towards Data Science,https://www.linkedin.com/company/towards-data-science/,"
601K followers
","
In a new tutorial, Nicol√≤ Cosimo Albanese introduces the fundamentals of reinforcement learning, before turning to a full Python implementation of a dynamic-pricing problem.
 

Dynamic Pricing with Reinforcement Learning from Scratch: Q-Learning
",,https://www.linkedin.com/feed/update/urn:li:activity:7101146113855946752?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7101146113855946752%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5610AQGKYKjyJi-kUw/image-shrink_800/0/1693045141459?e=1705658400&v=beta&t=1LM24OzH1x6ZAs_xNR0dB0Nhmc3kM4WW-iLeZLPKSwk
238,65a1055fa5b8f07200002240,4ef4be96-6007-d29e-e728-9deefdf54a6a,https://media.licdn.com/dms/image/C4E03AQHVyH-IfD1KbQ/profile-displayphoto-shrink_100_100/0/1629877234109?e=1710374400&v=beta&t=0UZUl_dDUxLaZn-Hu-zToqEDe3rpL5cB2JkP5_jlNXc,"Sebastian Raschka, PhD",https://www.linkedin.com/in/ACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU,"
Machine learning and AI researcher since the early days ‚Ä¢ coding and working with LLMs at Lightning AI ‚Ä¢ ex-statistics professor at University of Wisconsin-Madison
","
Llama 2, CodeLlama, and leaked GPT-4 details. I promised a more detailed write-up on Llama 2 a few weeks back. And there was also the new Code Llama that was just released this week. Coincidentally, OpenAI also announced its new finetuning API this week, designed to train the GPT 3.5-turbo on custom data sets. This is an interesting opportunity to look at the GPT-4 performance (or behavior) changes and its leaked model details!So, here's my new write-up on the noteworthy developments around LLMs this summer so far: https://lnkd.in/grgZuJsF#AI #LLMs #deeplearning

          ‚Ä¶see more
        


Ahead of AI #11: New Foundation Models
",,https://www.linkedin.com/feed/update/urn:li:activity:7101176181495894016?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7101176181495894016%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQHLHbvukPZaSw/articleshare-shrink_800/0/1703899563826?e=1705658400&v=beta&t=hTwfXag_aP0jcqmWnbRl_rQHxM7XSu8UjzAaqtkayuE
239,65a1055fa5b8f07200002241,a15ef552-8d02-7e4f-b1e5-1c84460c7596,https://media.licdn.com/dms/image/C4E03AQGfzEtRhrPHdw/profile-displayphoto-shrink_100_100/0/1619776973437?e=1710374400&v=beta&t=y9up1yBFMNfTMJvaDgcupbnl3OnJC7EgkzWAkOY4pyM,Sanyam Bhutani,https://www.linkedin.com/in/ACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0,"
Senior Data Scientist at H2O.ai | Kaggle Grandmaster
","
Notes from CS 324 are a self-contained LLM Book! üôèStanford University had released lecture notes of their Large Language Model course. These notes are actually an incredibly organised self-contained book covering the foundations of Large Language ModelsMy favourite part is these are structured as an onion, going from an overview and slowly going a level further with every page. These also have the best notes I have read on Mixture of ExpertsThis is a great read for your weekend, I'm working on creating a set companion notebooks to the course:Note: The course was hosted in Winter 2022 so it lacks the latest shiny materials but it's still really high quality for the foundational ideas https://lnkd.in/d8B3m8c7

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7101186900811522048?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7101186900811522048%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQFtdZtyud_G9w/feedshare-shrink_480/0/1693054889661?e=1707955200&v=beta&t=-43Juy0AdEJe9RutVeFxuqDK7u8lmqMlVOjff9Jk-nA
240,65a1055fa5b8f07200002242,3ace24d4-7760-7799-2520-0e1c1cbfcda0,https://media.licdn.com/dms/image/D560BAQFbVTDw-oWXmw/company-logo_100_100/0/1681327675102?e=1713398400&v=beta&t=Ir5hx7xUuaUo5T2BZZ9XorhXXE6Rv1XeKkDVGjYlWDo,LlamaIndex,https://www.linkedin.com/company/llamaindex/,"
67K followers
","
One major way to improve your RAG system is to fine-tune your embedding model ‚öôÔ∏èWe‚Äôve created a full repo/guide (courtesy of Simon Suo) on fine-tuning embedding models over any unstructured text (no labels needed) üåüWe squeezed out 5-10% improvement üìà in retrieval evaluation metrics from the Hugging Face `bge` model. Best of all, it's super easy and lightweight to run. Just follow our comprehensive notebooks, plugin your own dataset, and have it run on your local machine! Check it out üëá:Repo: https://lnkd.in/gdQxu2fKBlog: https://lnkd.in/gNbkYpD3

          ‚Ä¶see more
        


GitHub - run-llama/finetune-embedding: Fine-Tuning Embedding for RAG with Synthetic Data
",,https://www.linkedin.com/feed/update/urn:li:activity:7100874973212250113?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7100874973212250113%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQGwQq89Qgh5Kw/articleshare-shrink_800/0/1703894395931?e=1705658400&v=beta&t=KoghfiwWkFVEyusjTQ4zj7HlAjyO5Vs4MhLFoj0wjy0
241,65a1055fa5b8f07200002243,427fc6be-24dd-ae8f-04d6-6b8e64c86a4b,https://media.licdn.com/dms/image/C4D03AQEmDwFNREkaIA/profile-displayphoto-shrink_100_100/0/1517524291944?e=1710374400&v=beta&t=9H8wRu-S3Mr0BN5zZEZBtWwefLpa0ZU_FPNQ9dTlNws,Robin Gras,https://www.linkedin.com/in/ACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ,"
Professor at University of Windsor, CSO and partner at Movyl Technologies and MVYL Associates
","
AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework - Microsoft 2023 - Outperforms ChatGPT+Code Interpreter!Paper: https://lnkd.in/e2NrNwvwGithub: https://lnkd.in/eM__6FEGAbstract:""This technical report presents AutoGen, a new framework that enables development of LLM applications using multiple agents that can converse with each other to solve tasks. AutoGen agents are customizable, conversable, and seamlessly allow human participation. They can operate in various modes that employ combinations of LLMs, human inputs, and tools. AutoGen's design offers multiple advantages: a) it gracefully navigates the strong but imperfect generation and reasoning abilities of these LLMs; b) it leverages human understanding and intelligence, while providing valuable automation through conversations between agents; c) it simplifies and unifies the implementation of complex LLM workflows as automated agent chats. We provide many diverse examples of how developers can easily use AutoGen to effectively solve tasks or build applications, ranging from coding, mathematics, operations research, entertainment, online decision-making, question answering, etc.""

          ‚Ä¶see more
        


AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework
",,https://www.linkedin.com/feed/update/urn:li:activity:7100488088899969024?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7100488088899969024%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQHW80LGN6sWog/articleshare-shrink_800/0/1704063285620?e=1705658400&v=beta&t=YuHTR834_atWtHFhV2XiP669OhJFfhd61-J3YFB6SdY
242,65a1055fa5b8f07200002244,8e0e5508-7658-55d3-6d34-75e228f08688,https://media.licdn.com/dms/image/D4E03AQHSyjIkQ1gA3Q/profile-displayphoto-shrink_100_100/0/1703169868998?e=1710374400&v=beta&t=KPsVOo3REmKitTD9MzqgsI54Pz6jAo2o5HJvqZckTCU,David Scharbach,https://www.linkedin.com/in/ACoAAAXOhSoBu8sPAnQ4bjbJdxBFI31RXUxDPns?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXOhSoBu8sPAnQ4bjbJdxBFI31RXUxDPns,"
Distracted Father, Founder of Toronto Machine Learning Series (TMLS) & MLOps World; Machine Learning in Production
","
Where do I draw inspiration, find great content for the conference, and learn from some of the best ML Teams? In a large part, from this group of company blogs. I love when companies are able to share their work. It help promotes an ethos of open-door knowledge exchange, and for companies that aren't at the mature stages of their AI development, these can help team leads save a lot of time, energy, and resources. Feel free to check them out here! ‚úÖ https://lnkd.in/g-g2Zxv5Thanks to the teams that share their work in these blogs, including many of whom will be visiting Austin for the 4th Annual MLOps World  (alongside Generative AI World) You can also hold your spot for that here: üìå https://lnkd.in/guvFg4W3?Toronto Machine Learning Society (TMLS) IMPULSE Data & AI - Inteligencia Artificial Aplicada (IAA) 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7099777944352407552?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7099777944352407552%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQGNHlMH1A_4WA/feedshare-shrink_480/0/1692718968782?e=1707955200&v=beta&t=yCf7g9nZ9o2En7ZsQ8BwV3peWjFP6_nyNuGgOGsXq8I
243,65a1055fa5b8f07200002245,cd0da694-f146-eea8-893b-d2eda21cdf38,https://media.licdn.com/dms/image/C4D03AQEmDwFNREkaIA/profile-displayphoto-shrink_100_100/0/1517524291944?e=1710374400&v=beta&t=9H8wRu-S3Mr0BN5zZEZBtWwefLpa0ZU_FPNQ9dTlNws,Robin Gras,https://www.linkedin.com/in/ACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ,"
Professor at University of Windsor, CSO and partner at Movyl Technologies and MVYL Associates
","
Graph of Thoughts: Solving Elaborate Problems with Large Language Models - ETH Z√ºrich 2023Paper: https://lnkd.in/eP_jScbvGithub: https://lnkd.in/e9WGGSBdAbstract:""We introduce Graph of Thoughts (GoT): a framework that advances prompting capabilities in large language models (LLMs) beyond those offered by paradigms such as Chain-of-Thought or Tree of Thoughts (). The key idea and primary advantage of GoT is the ability to model the information generated by an LLM as an arbitrary graph, where units of information (""LLM thoughts"") are vertices, and edges correspond to dependencies between these vertices. This approach enables combining arbitrary LLM thoughts into synergistic outcomes, distilling the essence of whole networks of thoughts, or enhancing thoughts using feedback loops. We illustrate that GoT offers advantages over state of the art on different tasks, for example increasing the quality of sorting by 62% over , while simultaneously reducing costs by >31%. We ensure that GoT is extensible with new thought transformations and thus can be used to spearhead new prompting schemes. This work brings the LLM reasoning closer to human thinking or brain mechanisms such as recurrence, both of which form complex networks.""

          ‚Ä¶see more
        


Graph of Thoughts: Solving Elaborate Problems with Large Language Models
",,https://www.linkedin.com/feed/update/urn:li:activity:7100114870791991296?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7100114870791991296%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQHv032heCb3gg/articleshare-shrink_800/0/1704240773135?e=1705658400&v=beta&t=Z2TOKDuRavy9exnYZyA4qKAieJ-szYsW-fGCfXESFSc
244,65a1055fa5b8f07200002246,43a43a88-a919-cfec-bc9a-b30064e6a720,https://media.licdn.com/dms/image/C4E03AQHVyH-IfD1KbQ/profile-displayphoto-shrink_100_100/0/1629877234109?e=1710374400&v=beta&t=0UZUl_dDUxLaZn-Hu-zToqEDe3rpL5cB2JkP5_jlNXc,"Sebastian Raschka, PhD",https://www.linkedin.com/in/ACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU,"
Machine learning and AI researcher since the early days ‚Ä¢ coding and working with LLMs at Lightning AI ‚Ä¢ ex-statistics professor at University of Wisconsin-Madison
","
This morning, OpenAI announced its new finetuning service for ChatGPT. This is super interesting for those interested in developing LLMs on custom data. However, it will be interesting to see how it fares against open-source solutions -- we have seen a lot of innovations in the latter space with respect to finetuning (Llama-Adapters, LoRA, QLoRA, and more).Also, the recent open-source Llama 2 model compares very favorably to ChatGPT / GPT 3.5, as shown below. We live in interesting times!#LLMs #largelanguagemodels #AI

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7100098535890575361?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7100098535890575361%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQE_IMtS9oEj3A/feedshare-shrink_480/0/1692795403365?e=1707955200&v=beta&t=qFQ6qqSn9GLlWfqvNEjMQBQ915F6Nqry2u1Bkbh4UsI
245,65a1055fa5b8f07200002247,d7a44e76-27f1-795b-9df6-e3549512a8a3,https://media.licdn.com/dms/image/C4D03AQEmDwFNREkaIA/profile-displayphoto-shrink_100_100/0/1517524291944?e=1710374400&v=beta&t=9H8wRu-S3Mr0BN5zZEZBtWwefLpa0ZU_FPNQ9dTlNws,Robin Gras,https://www.linkedin.com/in/ACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ,"
Professor at University of Windsor, CSO and partner at Movyl Technologies and MVYL Associates
","
'A survey of several prominent theories of consciousness, including recurrent processing, global workspace, higher-order, predictive processing, and attention schema theories. They claim there are ‚Äúno obvious barriers to building conscious AI systems‚Äù.'

          ‚Ä¶see more
        


Consciousness in Artificial Intelligence: Insights from the Science of Consciousness
",,https://www.linkedin.com/feed/update/urn:li:activity:7099859831074758658?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7099859831074758658%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQFCYbHMnCR6eg/articleshare-shrink_800/0/1704901540357?e=1705658400&v=beta&t=ssijmAl6fsawLa0-otnkja6Xx7-70c12x0S6NgMl88w
246,65a1055fa5b8f07200002248,0d6f4594-7748-94fa-d2d8-1bf10a5072ad,https://media.licdn.com/dms/image/D5603AQHnUq3f5MxrKw/profile-displayphoto-shrink_100_100/0/1665422397012?e=1710374400&v=beta&t=ayeu8e9S2xLdiSXsGyO0hSfPdklShXuW9YdYBBM_QTk,Kelvin Mu,https://www.linkedin.com/in/ACoAAALsEl4B_UhGvbEEUNcJrunJGHDf47nwq5o?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAALsEl4B_UhGvbEEUNcJrunJGHDf47nwq5o,"
Early Stage Investor @ Translink Capital
","
Dear friends, I‚Äôm starting a recurring weekly post summarizing the key developments in AI over the past week. Here is issue No. 1. üîô ùêìùê°ùêû ùêÅùêöùêúùê§ùê∞ùêöùê´ùêù ùêèùêöùê¨ùê¨: ùêëùêûùêØùêûùê´ùê¨ùê¢ùêßùê† ùêìùê°ùê´ùê®ùêÆùê†ùê° ùê≠ùê°ùêû ùêÄùêà ùêñùêûùêûùê§ Week 1 | August 13-20, 2023  Industry:‚Ä¢ Google Gemini is rumored to launch this fall. Gemini be a multi-modal, multi-functional product aimed to ""surpass the competition"" (https://lnkd.in/g6icTqWQ)‚Ä¢ OpenAI is using GPT-4 to build an AI-powered content moderation system (https://lnkd.in/gbKHJkB5)‚Ä¢ Meta preparing to launch a code copilot product (https://lnkd.in/gmXcwnw2)‚Ä¢ Former Google Brain David Ha and Stability Head of Research Llion Jones  launches AI company  (https://lnkd.in/gzpZy-zC) Financing and M&A:‚Ä¢ AI-Privacy platform DynamoFL raised $15 million in a series A‚Ä¢ OpenAI acquired 8-member creative app studio Global Illumination. This is OpenAI's first announced acquisition‚Ä¢ Anthropic has raised another $100 million in funding‚Ä¢ Voiceflow raised $15 million to boost its conversational AI agent platform‚Ä¢ Databricks is in talks to raise more cash. The company reported a $380m operating loss in its most recent fiscal year Research and Innovation:‚Ä¢ Meta AI Agents Learn To Move By Copying Toddlers (https://lnkd.in/gxcfxyMn)‚Ä¢ There's been a lot of buzz on liquid neural networks lately, which are modeled under properties of liquid. They are supposedly more adaptive, less computationally expensive, and more explainable than traditional NNs. Here is a very high-level summary from TechCrunch: https://lnkd.in/gmyjmf7E  Other Interesting Resources:‚Ä¢ Interesting article on the history of open source LLMs (https://lnkd.in/gQ44jZ3P‚Ä¢ Interesting article from Chip Huyen on top 10 open challenges in LLM research (https://lnkd.in/gMETN-Z3‚Ä¢ CB insights State of AI report 2023 (https://lnkd.in/gxExZSPb)‚Ä¢ McKinsey‚Äôs State of AI in 2023 (https://lnkd.in/g8uSN_Fr) * This post was made possible from friends at Ben's Bites, CBInsight.com, Lastweekin.ai, The Gradient, The Information, TLDR, thesequence.substack.com and others #artificialintelligence #generativeai #startups #venturecapital #VC #AI #ML #machinelearning #deeplearning

          ‚Ä¶see more
        


Google's next big swing at AI rumored to launch this fall
",,https://www.linkedin.com/feed/update/urn:li:activity:7099374586168803328?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7099374586168803328%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQGunhj4oPG90g/articleshare-shrink_800/0/1704738811554?e=1705658400&v=beta&t=fTIpQIDMZpJtMWdzv7QRAC1Lih91IQDZbLfcV7bQWMY
247,65a10560a5b8f07200002249,efbd8c28-87ae-e6c8-0f5a-a430b68bc48c,https://media.licdn.com/dms/image/D4E0BAQEXph-zwTAZww/company-logo_100_100/0/1703827334751?e=1713398400&v=beta&t=UJmJA5Vc-8Tp3vkq9921qjq3m9JJceDrBndMHxRt06o,AWS Machine Learning,https://www.linkedin.com/company/aws-machine-learning/,"
358K followers
","
Here's a fantastic bite-size video series on generative AI from #AWS developer advocate Mike Chambers. ü™Ñ https://go.aws/44Y1sbEIn this series of videos, you will see how large language models work and what they are capable of.üåü The Power of the LLMüåü How LLMs Worküåü Prompt Engineering and In Context Learningüåü Fine-tuning an LLM using PEFTüåü How to Chat with your Live Dataüåü Deploy LLMs Quickly & Start Building TodayHappy learning!#GenerativeAI #MachineLearning #LLMs #Developer

          ‚Ä¶see more
        


Introduction to Large Language Models (LLMs)
",,https://www.linkedin.com/feed/update/urn:li:activity:7094316277959118849?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7094316277959118849%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E10AQEIhoOT2dmIOw/image-shrink_800/0/1691416803218?e=1705658400&v=beta&t=qtQp5VxS5Q3Jt3iRyJHDdhD0OZqbnK9n_a7REX3rn4o
248,65a10560a5b8f0720000224a,2122a438-7715-2e2d-36df-687e913d57d4,https://media.licdn.com/dms/image/C4D03AQEmDwFNREkaIA/profile-displayphoto-shrink_100_100/0/1517524291944?e=1710374400&v=beta&t=9H8wRu-S3Mr0BN5zZEZBtWwefLpa0ZU_FPNQ9dTlNws,Robin Gras,https://www.linkedin.com/in/ACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ,"
Professor at University of Windsor, CSO and partner at Movyl Technologies and MVYL Associates
","

 

Google DeepMind Researchers Propose 6 Composable Transformations to Incrementally Increase the Size of Transformer-based Neural Networks while Preserving Functionality
",,https://www.linkedin.com/feed/update/urn:li:activity:7099033000503296000?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7099033000503296000%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E10AQG0Co9CyxvxTA/image-shrink_800/0/1692532802475?e=1705658400&v=beta&t=tf1fhpQDPZkxaQt3WkNCs9GRdU-dRbmtzfJV26_Ql1Y
249,65a10560a5b8f0720000224b,781640ae-e184-2eda-dfcb-bf16bdd1704a,https://media.licdn.com/dms/image/C4D03AQEmDwFNREkaIA/profile-displayphoto-shrink_100_100/0/1517524291944?e=1710374400&v=beta&t=9H8wRu-S3Mr0BN5zZEZBtWwefLpa0ZU_FPNQ9dTlNws,Robin Gras,https://www.linkedin.com/in/ACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ,"
Professor at University of Windsor, CSO and partner at Movyl Technologies and MVYL Associates
","
Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning (UMASS Lowell, March 2023)Paper: https://lnkd.in/eiid4iAxAbstract:""This paper presents a systematic overview and comparison of parameter-efficient fine-tuning methods covering over 40 papers published between February 2019 and February 2023. These methods aim to resolve the infeasibility and impracticality of fine-tuning large language models by only training a small set of parameters. We provide a taxonomy that covers a broad range of methods and present a detailed method comparison with a specific focus on real-life efficiency and fine-tuning multibillion-scale language models.""

          ‚Ä¶see more
        


Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning
",,https://www.linkedin.com/feed/update/urn:li:activity:7099030916458532864?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7099030916458532864%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/C5627AQFyO6K4A-YXdw/articleshare-shrink_800/0/1704152467652?e=1705658400&v=beta&t=FkH5xrHfSWfGqiZAGHioHqKxNMg_9ErOHD7BpNlOe8I
250,65a10560a5b8f0720000224c,ceb97e4e-1158-0707-a96f-50e83736927e,https://media.licdn.com/dms/image/C4D03AQEF92abeIXmPA/profile-displayphoto-shrink_100_100/0/1661925873538?e=1710374400&v=beta&t=Z3Mey1dzVajA_qo8nZvrelfmBMF6e-QdTgNsHQ64VbY,Naman Agarwal,https://www.linkedin.com/in/ACoAAA3nzA8BMLhd0-VfzyANQTI3l4Dk_5RVLhw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA3nzA8BMLhd0-VfzyANQTI3l4Dk_5RVLhw,"
Engineering @ Rippling
","

 

Inside Rippling‚Äôs real-time reporting engine | Rippling
",,https://www.linkedin.com/feed/update/urn:li:activity:7094549761738850305?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7094549761738850305%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQEjlS_1nQWqvw/articleshare-shrink_800/0/1704757555004?e=1705658400&v=beta&t=NhB2dZDRAO2_cWcfmkF8iP8ZuZm0uPfNj6OsKckP20k
251,65a10560a5b8f0720000224d,c4140d3e-277c-11de-49fc-419fd53f502d,https://media.licdn.com/dms/image/C4E03AQFf1dY4fISOAg/profile-displayphoto-shrink_100_100/0/1577125270265?e=1710374400&v=beta&t=Xbzt8yxz-XMa9P5uFmuE_LY5zzfZOtLTrHf-OngcVRI,"Nowel Pitt, MBA",https://www.linkedin.com/in/ACoAAAGoHcsBgsxRvvj3nOVrcAt0AN9H8kY8hZU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAGoHcsBgsxRvvj3nOVrcAt0AN9H8kY8hZU,"
Global Account Manager @ NVIDIA | MBA
","
üöÄ NVIDIA NeMo is revolutionizing enterprise AI:1. Tailored LLM development for specific business needs.2. Simplified data curation for robust model training.3. Cutting-edge training techniques for optimized performance.4. Versatile model customization options for precise applications.5. Enhanced security with long-term support.Unlock the full potential of generative AI with NeMo! #NVIDIANeMo #EnterpriseAI #llm

          ‚Ä¶see more
        


Unlocking the Power of Enterprise-Ready LLMs with NVIDIA NeMo | NVIDIA Technical Blog
",,https://www.linkedin.com/feed/update/urn:li:activity:7098496151661793280?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7098496151661793280%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQFRS8gNx9uesQ/articleshare-shrink_800/0/1704574354756?e=1705658400&v=beta&t=PMZzUqeU6sw2PchHPOCE26xoQK_zDKD0o2gjSWa5noI
252,65a10560a5b8f0720000224e,fb26ce46-682b-f8d2-1ec1-becb4f8d727a,https://media.licdn.com/dms/image/C5603AQHq_R7a3rNrdg/profile-displayphoto-shrink_100_100/0/1516249239907?e=1710374400&v=beta&t=_FtWbWc5ZFSxG8yww4FsRg8HXI4opsmmeiednHI6Wwc,"Craig Brown, PhD",https://www.linkedin.com/in/ACoAAABg0RkBBwrY20r_Pc7Awl6C_sazWbUgfjo?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAABg0RkBBwrY20r_Pc7Awl6C_sazWbUgfjo,"
SME - Leadership, Architecture, Solutions (Cloud, Big Data, Data Science, Data Analytics, Machine Learning, Artificial Intelligence)
","
If you did not already know: GridNet This paper presents GridNet, a new Convolutional Neural Network (CNN) architecture for semantic image segmentation (full scene labelling). Classical neural networks are implemented as one stream from the input to the output with subsampling operators applied in the stream in order to reduce the feature maps size and to increase the receptive field for the final prediction. However, for semantic image segmentation, where the task consists in providing a semantic class to each pixel of an image, feature maps reduction is harmful because it leads to a resolution loss in the output prediction. To tackle this problem, our GridNet follows a grid pattern allowing multiple interconnected streams to work at different resolutions. We show that our network generalizes many well known networks such as conv-deconv, residual or U-Net networks. GridNet is trained from scratch and achieves competitive results on the Cityscapes dataset. ‚Ä¶ Circumcentered-Reflection Method The elementary Euclidean concept of circumcenter has recently been employed to improve two aspects of the classical Douglas‚ÄìRachford method for projecting onto the intersection of affine subspaces. The so-called circumcentered-reflection method is able to both accelerate the average reflection scheme by the Douglas‚ÄìRachford method and cope with the intersection of more than two affine subspaces. We now introduce the technique of circumcentering in blocks, which, more than just an option over the basic algorithm of circumcenters, turns out to be an elegant manner of generalizing the method of alternating projections. Linear convergence for this novel block-wise circumcenter framework is derived and illustrated numerically. Furthermore, we prove that the original circumcentered-reflection method essentially finds the best approximation solution in one single step if the given affine subspaces are hyperplanes. ‚Ä¶ TextNet Reading text from images remains challenging due to multi-orientation, perspective distortion and especially the curved nature of irregular text. Most of existing approaches attempt to solve the problem in two or multiple stages, which is considered to be the bottleneck to optimize the overall performance. To address this issue, we propose an end-to-end trainable network architecture, named TextNet, which is able to simultaneously localize and recognize irregular text from images. Specifically, we develop a scale-aware attention mechanism to learn multi-scale image features as a backbone network, sharing fully convolutional features and computation for localization and recognition. In text detection branch, we directly generate text proposals in quadrangles, covering oriented, perspective and curved text regions. To preserve text features for recognition, we introduce a perspective RoI transform layer, which can align quadrangle proposals into small feature maps. Furthermore, in order to‚Ä¶

          ‚Ä¶see more
        


If you did not already know
",,https://www.linkedin.com/feed/update/urn:li:activity:7098758668514443264?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7098758668514443264%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5610AQEQc9XY40zlwA/image-shrink_800/0/1692475953853?e=1705658400&v=beta&t=oNrU5_5iNdT_b1Aur11_XTzpOuhjkm3i9eM4WovjBJo
253,65a10560a5b8f0720000224f,4c5528c9-1e62-8af2-69ad-19d52f32427a,https://media.licdn.com/dms/image/D4E0BAQEXph-zwTAZww/company-logo_100_100/0/1703827334751?e=1713398400&v=beta&t=UJmJA5Vc-8Tp3vkq9921qjq3m9JJceDrBndMHxRt06o,AWS Machine Learning,https://www.linkedin.com/company/aws-machine-learning/,"
358K followers
","
Calling all #GenerativeAI builders, we want you on Twitch! If you‚Äôve got a cool demo that shows us something new, exploring the capabilities of foundation models on AWS using open-source techniques, we want to hear about it. Selected speakers will join us on the weekly Twitch show to dive deep into what they built. Submit your ideas here: üëâ https://go.aws/3KEjKX4#AWS #Developer #MachineLearning 

          ‚Ä¶see more
        


Build On Generative AI - Call For Content
",,https://www.linkedin.com/feed/update/urn:li:activity:7096928477643173889?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7096928477643173889%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E10AQHuCooW-UXE4Q/image-shrink_800/0/1692039602649?e=1705658400&v=beta&t=YWNMT8czaUA063TcdRGTwARfXnIH2dZYWFbCaM0agZQ
254,65a10560a5b8f07200002250,764047f3-582c-7865-70f8-32043db77f90,https://media.licdn.com/dms/image/D5603AQGEADhHyEQ8rw/profile-displayphoto-shrink_100_100/0/1682553354695?e=1710374400&v=beta&t=kfjA-KO1Ea4gqAJ68vTh1_4ORnZzWv1qSW4bXFvg_tc,"Damien Benveniste, PhD",https://www.linkedin.com/in/ACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw,"
The ML Guy - Follow me to learn about Machine Learning Engineering, Machine Learning System Design, MLOps, and the latest techniques and news about the field. Join my AI newsletter and keep learning!
","
Did you know that LLama 2 is probably the best choice if you need a large context window? At first glance, LLama 2 has a context window size of 4096, which seems smaller than ChatGPT's 16K, GPT-4's 32K, and Claude 2's 100K, but the magic in the open source!4096 tokens, that is about 3000 words. Not bad but it limits the possible applications. The typical Transformer architecture is composed of Embeddings to encode the text input, multiple transformer blocks, and a prediction head specific to the learning task the LLM is used for. To encode the text, we use a text embedding matrix T that has the size of the token vocabulary and a positional embedding P that encodes the position of the token in the input sequence. That position embedding size defines the context size. That embedding can be learned or it can be a simple sin function of the position index. Typically they are added together T + P such that the same word is encoded differently at positions i and j. The great thing about LLama 2 is that it uses Rotary Positional Embeddings (RoPE) as opposed to the typical sin function encoding. Each Attention layer is modified using that embedding and it ensures the computed attention between input tokens to be only dependent on the distance between those tokens. If token T1 is at position i and a token T2 at position j, the attention A(T1, T2) = f(j - i) is a function of j - i. The attention is not dependent on the specific token's locations but on their relative positions. The technique they use at Meta to extend the context window is to interpolate at non-integer positions. Basically, if the original window size is L, you can extend it to L' (with L' > L) by rescaling the integer positionsi' = i * L / L' As an example, if you wanted to have a text input of 16,384 tokens (so 4x the window size of LLama 2) into LLama 2, you would just need to divide every integer position by 4: i' = i / 4. To be clear, if you look at the implementation of LLama 2 available on GitHub (line 50 in model.py today https://lnkd.in/gGvUye6K), you would just need to replace the following line of code  t = torch.arange(end, device=freqs.device) byt = torch.arange(end, device=freqs.device) / 4How simple is that? Because the model was not trained for that position embedding, you would need to fine-tune a bit the model to adapt it to that new context window and position embedding. When we think that LLama 2 will most likely be used to be fine-tuned on private data, that is the icing on the cake to be able to dynamically adapt the context window to our needs as we fine-tune it.You can look at the method here: https://lnkd.in/gPUzdBPi. They were able to extend LLama's context window by 16 times while keeping the performance at the same level! ----Receive 50 ML lessons (100 pages) when subscribing to our newsletter: TheAiEdge.io#machinelearning #datascience #artificialintelligence

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7094338916111044608?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7094338916111044608%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQFJUBhoiXbVgA/feedshare-shrink_480/0/1691384876462?e=1707955200&v=beta&t=De8qcY0YDHRjgFJV4_PxFzSB2fRFa202al3YYpyGyCM
255,65a10560a5b8f07200002251,d2c9d609-933a-3af7-8f32-1e0e8d66cf37,https://media.licdn.com/dms/image/D5635AQEBzEFRC2EzLg/profile-framedphoto-shrink_100_100/0/1704907585971?e=1705658400&v=beta&t=x71pDAJzCbSPZxvt91sIkpmEr_5_pGLZIt6VZgw5eV0,Aman Chadha,https://www.linkedin.com/in/ACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU,"
GenAI Leadership @ Amazon AWS ‚Ä¢ Stanford AI ‚Ä¢ EB-1 ""Einstein Visa"" Recipient/Mentor ‚Ä¢ Ex-Ô£ø, Amazon Alexa, Nvidia, Qualcomm ‚Ä¢ EMNLP 2023 Outstanding Paper Award
","
üìù LLM Primers | ChatGPT, GPT-4, Prompt Engineering, LLaMA, RLHFLLMs are probably the hottest topic in AI right now; they‚Äôre currently experiencing a significant surge in prominence ‚Äî whether it‚Äôs core NLP tasks, or visual language models (VLMs), or even in the area of personalization ranking. Here is a primer that covers LLM-related topics: üîπ Overview of LLMs: http://llm.aman.ai- Embeddings - How do LLMs work?- LLM Training Steps- Computing Similarity between Embeddings (Dot Product Similarity, Geometric Intuition, Cosine Similarity, Cosine Similarity vs. Dot Product Similarity)- Retrieval/Knowledge-Augmented LLMs (Process, Summary, LLM Knobs, Token Sampling, Prompt Engineering, Token Healing)- ü§ó Open LLM Leaderboard- Extending Prompt Context (Summary of All Tricks, Large Prompt Context Models)- List of Popular LLMs- List of Popular VLMs- LangChain, LangFlow, Flowise, Ragas, and LLaMA2-Accessory (Examples, Resources)Here are some more primers on recent LLMs and related concepts to get you up to speed: üîπ ChatGPT: http://chatgpt.aman.aiüîπ Prompt Engineering: http://prompt.aman.aiüîπ Reinforcement Learning from Human Feedback (RLHF): http://rlhf.aman.aiüîπ LLaMA: http://llama.aman.aiüîπ Toolformer: http://toolformer.aman.aiüîπ Visual ChatGPT: http://vchatgpt.aman.aiüîπ GPT-4: http://gpt-4.aman.aiNotes written in collaboration with Vinija Jain.#artificialintelligence #machinelearning #ai #ml #nlp

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7098506365307912192?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7098506365307912192%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQE4aLzJjJlrzA/feedshare-shrink_480/0/1692409320089?e=1707955200&v=beta&t=VfxxkPlXSZJSAC5WozTD_prgi88NVFekRCgmRIQ1qM8
256,65a10560a5b8f07200002252,c72c0230-39dd-cc89-20af-911be7dd9c00,https://media.licdn.com/dms/image/D4E03AQHlDrrMgdW81w/profile-displayphoto-shrink_100_100/0/1680035432469?e=1710374400&v=beta&t=-vUIbi1Q6d_yibA5oKRnwxnsXbcTPzU3lNUaMV75mFM,Matthew Hepburn,https://www.linkedin.com/in/ACoAAAPwt64BGmrsa6RrMPuzKHxkX5S7BEIlIgY?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAPwt64BGmrsa6RrMPuzKHxkX5S7BEIlIgY,"
Principal Product Marketing Manager, Amazon Science
","

 

A quick guide to Amazon's papers at Interspeech 2023
",,https://www.linkedin.com/feed/update/urn:li:activity:7098353074674495490?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7098353074674495490%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQFETWHub1nUXA/articleshare-shrink_800/0/1704149202929?e=1705658400&v=beta&t=rV2n3Qj7J9D0saHziFApU0tsF-l3tUajSfZG7FRYD_g
257,65a10560a5b8f07200002253,b9a8d2de-60b7-3e32-1594-e260fe2080a5,https://media.licdn.com/dms/image/D4E03AQHlDrrMgdW81w/profile-displayphoto-shrink_100_100/0/1680035432469?e=1710374400&v=beta&t=-vUIbi1Q6d_yibA5oKRnwxnsXbcTPzU3lNUaMV75mFM,Matthew Hepburn,https://www.linkedin.com/in/ACoAAAPwt64BGmrsa6RrMPuzKHxkX5S7BEIlIgY?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAPwt64BGmrsa6RrMPuzKHxkX5S7BEIlIgY,"
Principal Product Marketing Manager, Amazon Science
","
Assessing the absolute utility of query results, rather than just their relative utility, improves learning-to-rank models: https://lnkd.in/eDn2jiQw#AmazonScience #MachineLearning

          ‚Ä¶see more
        


Leveraging transformers to improve product retrieval results
",,https://www.linkedin.com/feed/update/urn:li:activity:7092907593689358336?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7092907593689358336%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQG-V34pAxnsmw/articleshare-shrink_800/0/1704155772655?e=1705658400&v=beta&t=-VVa3aLpFGRhS421Ed3VOwx163GiDY5KUAJOhDG9hDc
258,65a10560a5b8f07200002254,743f7b24-13fb-1c18-8e4c-476d8f783867,https://media.licdn.com/dms/image/D5635AQEmf57V-uRIAg/profile-framedphoto-shrink_100_100/0/1678175910308?e=1705658400&v=beta&t=U8Jrif2y1kgkrWphZOqNZhIYFm_rq2Cei56oUn2-E8o,Razu Ahmmedüí≠,https://www.linkedin.com/in/ACoAAD3qvNMBbgxj2tSvYYf3xJW69Cub-Vm1YQA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAD3qvNMBbgxj2tSvYYf3xJW69Cub-Vm1YQA,"
Digital Marketing Specialist || Social Media Virtual Assistant || Strategic Planning Specialist || Business Consulting || Helping Digital Brands Grow Profitably || If You Need Any Help Feel Free Contact Meüìß
","
Looking for a #REMOTE_JOB that allows you to work from anywhere? üåéA remote job will let you better appreciate what it's like to live in freedom.As you start the process of looking for a remote job, adopt the proper strategy and an optimistic outlook.Visit these remote employment websites to find the work-from-home opportunity that's perfect for you!1. MAGAS2. FlexJobs2. Uplers4. Remote Workmate5. We Work Remotely6. FindAsync - Async Remote Jobs7. Pangaia CBD8. JustRemote9. Remotive - Remote Jobs10. RemoteWriters.org11. Indeed12. Upwork13. Working Nomads14. Remote.co15. Crossover 16. INSIDEA17. Remote Jobs18. Remote Circle19. Outsourcely20. Dynamite Jobs21. Authentic Brands Group22. WorkWave23. 100 Telecommute Jobs24. Fiverr25. Werk26. Remoters.me 27. Remote4U28. DailyRemote29. Freelancer.com30. People Per Job31. Pepechat LLC¬Æ 32. PeoplePerHourWant to boost up your Business Sales to 5X?Dm Me Let's Discuss About your business Razu Ahmmed ( Digital Marketing & Social Media Marketing )#remoteopportunity #remotejobs #remotework #softwaredevelopment #linkedinnetworking #opportunity #talent #jobs #workfromhome #email #job #fiverr #work #change #like #help #digitalmarketingcompany #designer #video #mindset #ui #ux #humanresourcesmanagement #socialmediamarketing

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7094351713079336962?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7094351713079336962%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQGMcq-HEv0w8Q/feedshare-shrink_480/0/1691425253328?e=1707955200&v=beta&t=M01kusfo8pJ5okVNl3bXfqb1k4ywgcDtOpoKNOov1Os
259,65a10560a5b8f07200002255,0305ae40-291d-56e3-d806-ca9f7860342a,https://media.licdn.com/dms/image/C4D03AQHXpcuUsXJtpg/profile-displayphoto-shrink_100_100/0/1629852928423?e=1710374400&v=beta&t=GOd9J3OEuKjSs21woxS5tu8Ad-Hm628uJAuRhoogsL4,Dmitry Krotov,https://www.linkedin.com/in/ACoAAAY0h0sBodGmUBnq3ZOtpJdnalY9V1W0y1Q?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAY0h0sBodGmUBnq3ZOtpJdnalY9V1W0y1Q,"
Research Staff Member | MIT-IBM Watson AI Lab & IBM Research
","
What could be the computational function of astrocytes in the brain? We hypothesize that they may be the biological cells that could implement the Transformer's attention operation commonly used in AI. Please check out our paper in PNAS (much improved compared to an earlier preprint): https://lnkd.in/dinYWSsq.Also, here is a nice article summarizing our work: https://lnkd.in/dMv8eSx2

          ‚Ä¶see more
        


AI models are powerful, but are they biologically plausible?
",,https://www.linkedin.com/feed/update/urn:li:activity:7097722091617067008?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7097722091617067008%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQHvI5pzBgdEsA/articleshare-shrink_800/0/1704946029828?e=1705658400&v=beta&t=OfD0YAdOcCM6hDMT19OJ88iChF3OxFpxWDf0t1ZaZnU
260,65a10560a5b8f07200002256,e8a455c1-8997-bb94-d0a0-4ce063ad627d,https://media.licdn.com/dms/image/C4E03AQEtNDjzPJfNUg/profile-displayphoto-shrink_100_100/0/1516331573954?e=1710374400&v=beta&t=e98YkeLxIuVA2cRsmSRXoTVs06IHXZDR3t1RXAFPLgU,Manaranjan Pradhan,https://www.linkedin.com/in/ACoAAAHiLwABGm-7fNMG3Sj5K7pW06yaSrnOKzU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAHiLwABGm-7fNMG3Sj5K7pW06yaSrnOKzU,"
Author | AI and Data Enthusiast
","
I am releasing a complete course (free) on ML Foundation with 20 hours of recorded videos (youtube videos), several notebooks and exercises for those who wish to start with foundations of machine learning. These content has already been delivered in several corporates, colleges and to more than 1000 learners.I will keep adding more advanced topics in future. But if you want to start learning, this could be a good starting point.https://lnkd.in/gaXSqGGm Happy learning and please share your feedback.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7097880511246712832?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7097880511246712832%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQGPFaicEsk-_w/feedshare-shrink_480/0/1692266583374?e=1707955200&v=beta&t=JabrRGhnDbshU44H-z59dwHte-ANgOPM5xqfgLuKD2U
261,65a10560a5b8f07200002257,54f05ea7-750f-d247-0033-05b28bd6fa08,https://media.licdn.com/dms/image/D5603AQF36E6WYkbyzQ/profile-displayphoto-shrink_100_100/0/1684770674826?e=1710374400&v=beta&t=CBvJ7_jKqLgag88ZQze7LlDUg2Nil5U6heHTyD4ViTM,Kourosh Hakhamaneshi,https://www.linkedin.com/in/ACoAABL3tmEBb4cN7VJlMZ229OA8g5USo_tvda8?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABL3tmEBb4cN7VJlMZ229OA8g5USo_tvda8,"
AI lead @Anyscale, PhD UC Berkeley
","
üöÄ Exploring Llama-2‚Äôs Quality: Can we replace generalist GPT-4 endpoints with specialized OSS models? Dive deep with our technical blogpost to understand the nuances and insights of fine-tuning OSS models.üîó Link: https://lnkd.in/gnvZAAG4We experimented with three unique LLM tasks: 1Ô∏è‚É£ Functional representations from unstructured text 2Ô∏è‚É£ SQL generation 3Ô∏è‚É£ Grade-school math questionsResults? Llama-7B fine-tuned impressively for the first two, outperforming GPT-4! But math reasoning? That‚Äôs a different ball game with a much bigger gap to bridge.This post isn't just about outcomes. We delve deep into:- Problem formulation üß†- Data preparation üìä- Evaluation setup üéØ- Setting the right baselines & measuring progress ‚è≥Had a blast collaborating with Rehaan Ahmad on this one! All of our experiments were built on top of Ray and Anyscale. Wanna fine-tune Llama-2 on your data?Checkout Anyscale Endpoints: https://lnkd.in/gKsxJJuh üé∏üî•

          ‚Ä¶see more
        


Fine-Tuning Llama-2: A Comprehensive Case Study for Tailoring Models to Unique Applications
",,https://www.linkedin.com/feed/update/urn:li:activity:7095762273352249344?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7095762273352249344%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQHXV96Ms0kyaA/articleshare-shrink_800/0/1691761257447?e=1705658400&v=beta&t=n1KAUOnFef53h19WzLE-EP48ll5V_VZwaxrTklbiU6Y
262,65a10560a5b8f07200002258,d5f79a3e-b8c4-2be3-db42-2918ad1476da,https://media.licdn.com/dms/image/C4E0BAQEH4nbL2sl5gA/company-logo_100_100/0/1635539130887/facebookai_logo?e=1713398400&v=beta&t=sFixUTJyqFvVkiEiDy7X9VTcRcgGTR2jo-a3QyjRJ70,AI at Meta,https://www.linkedin.com/company/aiatmeta/,"
672K followers
","
Responsible innovation can‚Äôt happen in isolation. Opening up our research and resulting models helps ensure that everyone has equal access. We've publicly released AudioCraft ‚Äî a one-stop code base for generative audio supporting generation of high-quality music & sound effects from text, and compression ‚Äî for research use.AudioCraft is an important step forward in generative AI research. We believe the simple approach we developed for audio generation will have a meaningful impact on future technologies and how we interact with them. The models are available for research purposes so that researchers and practitioners can train their own models with their own datasets for the first time. We can't wait to hear what people create with AudioCraft.

          ‚Ä¶see more
        


GitHub - facebookresearch/audiocraft: Audiocraft is a library for audio processing and generation with deep learning. It features the state-of-the-art EnCodec audio compressor / tokenizer, along with MusicGen, a simple and controllable music generation LM with textual and melodic conditioning.
",,https://www.linkedin.com/feed/update/urn:li:activity:7095809848231014400?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7095809848231014400%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQFMYOGjOqt_XQ/articleshare-shrink_800/0/1704203033609?e=1705658400&v=beta&t=5u0FUdNQHmNOshYgFYlRcXN8EVtaIclwZsvsdqPnCP8
263,65a10560a5b8f07200002259,88ccb7f0-a784-f51e-0b44-abf9f8f4d69b,https://media.licdn.com/dms/image/D4D03AQEYCGSc8lLDSQ/profile-displayphoto-shrink_100_100/0/1671090632152?e=1710374400&v=beta&t=9iah2MKct2J-3DkN-Cjn0e3-RunycdfVosVphuQuhv4,üöÄ Abhishek Thakur,https://www.linkedin.com/in/ACoAAAL1AE0BCC3EHeSe-q9ul8j33fC3gKHb1lc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAL1AE0BCC3EHeSe-q9ul8j33fC3gKHb1lc,"
AutoTrain @ Hugging Face | World's First 4x Kaggle GrandMaster | 140k+ LinkedIn | 100k+ YouTube
","
Here's how to finetune Llama-v2 in Kaggle notebook, utlizing 2 GPUs for FREE! https://lnkd.in/dgryMxfr Have fun! üí•
 ",,https://www.linkedin.com/feed/update/urn:li:activity:7095359336868159488?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7095359336868159488%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQHRhaDS2D1RvA/feedshare-shrink_480/0/1691665490364?e=1707955200&v=beta&t=uR4kz06CUaTaQXrVIZXPtn6iqApA4-vfWW13eM-2Slk
264,65a10560a5b8f0720000225a,f5171d01-2785-fc21-a551-e1dd41ea5371,https://media.licdn.com/dms/image/C4E0BAQH5ZTUMjFXhyg/company-logo_100_100/0/1630610511047/amazon_science_logo?e=1713398400&v=beta&t=q-4oOXo0BordU6VXkJqpj4R0M28LwU_BopSbigIgG8s,Amazon Science,https://www.linkedin.com/company/amazonscience/,"
327K followers
","
To enable multimodal models to answer questions with information drawn from multimedia content, Amazon intern and Virginia Tech PhD student Qing Guo leverages her background as a PhD student in statistics.#ConvAI #Statistics #VirginiaTech

          ‚Ä¶see more
        


Amazon intern Qing Guo explores the interface between statistics and machine learning
",,https://www.linkedin.com/feed/update/urn:li:activity:7097243250725392384?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7097243250725392384%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQH8mU8FWJKo5w/articleshare-shrink_800/0/1704151065757?e=1705658400&v=beta&t=Fx779XD8rYap7LgNrF30p5HR0jE1RyifoMVbSKt6YmI
265,65a10560a5b8f0720000225b,87b70d0c-331d-3cb3-f265-6cdd51696d69,https://media.licdn.com/dms/image/D5603AQE0z6HKVvqnIA/profile-displayphoto-shrink_100_100/0/1667801774000?e=1710374400&v=beta&t=a0JrYPQgEr9CYjkvMCqWYv3bnFCs155R-bqXPmU8Hv8,Yifan G.,https://www.linkedin.com/in/ACoAAB96w1gBtZovOHI0AGTR-_1eikCRkDlTP4E?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAB96w1gBtZovOHI0AGTR-_1eikCRkDlTP4E,"
Senior Applied Scientist | Build LLM for Amazon Search
","
Congrats to the team!
 

Teaching language models to reason consistently
",,https://www.linkedin.com/feed/update/urn:li:activity:7097666514748678144?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7097666514748678144%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQFitLBkhpjUaQ/articleshare-shrink_800/0/1704847040901?e=1705658400&v=beta&t=jMXogs9_IDevaGChPM0f_FBkFayqf5Ve7F7NmnyQXN0
266,65a10560a5b8f0720000225c,a790448a-ab29-c16c-cd2f-5b6d5afd7c3e,https://media.licdn.com/dms/image/D4D03AQHIxHD2V_Bekw/profile-displayphoto-shrink_100_100/0/1703234305642?e=1710374400&v=beta&t=8m_Ue-GlOGDOb1NdzB0MFK_nRnnZTEhxKVMcaqmw2gg,Stefano Fiorucci,https://www.linkedin.com/in/ACoAAA_fVEkBpNHvi7ZCcl22Pca9yX3bBM20SHA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA_fVEkBpNHvi7ZCcl22Pca9yX3bBM20SHA,"
Contributing to Haystack, the LLM Framework üèóÔ∏è | NLP Engineer, Craftsman and Explorer üß≠
","
‚ú® Strategic Passage Ranking for RAGWith the release of powerful Large Language Models, ùêëùêûùê≠ùê´ùê¢ùêûùêØùêöùê• ùêÄùêÆùê†ùê¶ùêûùêßùê≠ùêûùêù ùêÜùêûùêßùêûùê´ùêöùê≠ùê¢ùê®ùêß has emerged as the forefront paradigm for tackling Question Answering on unseen data.In essence, RAG involves two steps:1Ô∏è‚É£ Use a Retriever üîé to gather textual passages relevant to the user's question2Ô∏è‚É£ Augment the prompt, by injecting the passages üìÑüìÑ into the LLM context, to make the model use this information‚ö†Ô∏è Challenges of long contextsThe recent ""Lost in the Middle"" paper (https://lnkd.in/d_RS8seJ) highlighted two aspects that can potentially hinder the effectiveness of RAG:üîπ Although some LLMs can take long contexts as input, their performance substantially decreases as the input context grows longer.üîπ LLMs struggle to focus on relevant passages in the middle of a long context. Hence, the order of passages matters!ü•áü•àü•â Ranking can helpTo address these challenges, Vladimir Blagojevic recently designed two novel Rankers for the Haystack LLM framework (https://lnkd.in/dbC9TaqS).(In general, a Ranker is a component that assesses and orders textual passages according to a given criterion).- Diversity Ranker üé®: this Ranker uses embeddings to sort relevant textual passages, progressively prioritizing those that contain different information not yet considered.- LostInTheMiddle Ranker üîÄ: by alternating the placement of the best passages at the beginning and end of the context window, this Ranker facilitates the LLM‚Äôs attention mechanism in accessing and utilizing these passages.üåü Check out Vladimir's insightful blog post: https://lnkd.in/dBb9cizJIn addition to in-depth explanations, it contains some suggestions for using these new Rankers in Haystack and a case study.#largelanguagemodels #llm #rag #questionanswering #haystack

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7096746266197467136?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7096746266197467136%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQHwTMp4H3px8g/feedshare-shrink_480/0/1691960403719?e=1707955200&v=beta&t=2eWZfWxM1TB77pw5BNb9lR4mfAGt3AOW2zhzpU3vwUQ
267,65a10560a5b8f0720000225d,210b996e-7f4c-242d-30c7-ef7ff9507009,https://media.licdn.com/dms/image/D5603AQGNiuOdOwGOXA/profile-displayphoto-shrink_100_100/0/1664778459905?e=1710374400&v=beta&t=xBgaXiEzd_m7LRcAM3FAiTW3npUaSw7mDRGAhH05ro0,Vinija Jain,https://www.linkedin.com/in/ACoAAA4CfZwBGeQakt2b0sUVu1GdoGrJgBGwpJU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA4CfZwBGeQakt2b0sUVu1GdoGrJgBGwpJU,"
Machine Learning Leader at Amazon | Stanford AI | EMNLP Outstanding Paper Award Recipient
","
üêô Multi-armed bandit‚û¢ Multi-armed bandit algorithms are used in industrial recommendation systems by companies like Netflix and DoorDash for their remarkable capabilities in:- Dynamically adapting to changing conditions- Optimizing the exploration-exploitation trade-off- Handling large datasets- Personalizing recommendations- Enhancing overall user experiences‚û¢ The article (http://mab.vinija.ai) reviews those concepts as well as a few commonly used bandit algorithms with code.‚û¢ This is written in collaboration with Aman Chadha, please feel free to reach out to us for any comments or suggestions!

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7095263183648534528?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7095263183648534528%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHmb12yU0CagQ/feedshare-shrink_480/0/1691642564828?e=1707955200&v=beta&t=fPij6bpFzxTekfo4UYyT8R5lJqtBUwJxZGaUI1agHqU
268,65a10560a5b8f0720000225e,c689716e-5c4b-f338-4088-75d211c4cbc3,https://media.licdn.com/dms/image/C5603AQGCA0jXW9wIGQ/profile-displayphoto-shrink_100_100/0/1603913066364?e=1710374400&v=beta&t=M64xWhgI7OO0_FX5ZHok8lecx-QinGmoDc29X_wdRmI,Chip Huyen,https://www.linkedin.com/in/ACoAAAIQAJQBE3ykLNnsOPVvxwuuVCOir2zAjOQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAIQAJQBE3ykLNnsOPVvxwuuVCOir2zAjOQ,"
Real-time ML @ Claypot AI | ML Sys @ Stanford | Hiring strong streaming engineers
","
Never before had I seen so many smart people working on the same goal: making LLMs better. After talking to many people working in both industry and academia, I noticed the 10 major research directions that emerged.Link: https://lnkd.in/gxiimJdgThe first two directions, hallucinations and context learning, are probably the most talked about today.I‚Äôm the most excited about numbers 3 (multimodality), 5 (new architecture), and 6 (GPU alternatives).Some of the directions are harder than others. For example, I think that number 10, building LLMs for non-English languages, is more straightforward with enough time and resources.  Number 1, reducing hallucination, will be much harder, since hallucination is just LLMs doing their probabilistic thing.Number 4, making LLMs faster and cheaper, will never be completely solved. There is already so much progress in this area, and there will be more, but we will never run out of room for improvement.Number 5 and number 6, new architectures and new hardware, are very challenging, but are inevitable with time. Because of the symbiosis between architecture and hardware ‚Äì new architecture will need to be optimized for common hardware, and hardware will need to support common architecture ‚Äì they might be solved by the same company.Some of these problems won‚Äôt be solved using only technical knowledge. For example, number 8, improving learning from human preference, might be more of a policy problem than a technical problem. Number 9, improving the efficiency of the chat interface, is more of a UX problem. We need more people with non-technical backgrounds to work with us to solve these problems.I referenced a lot of papers here, but I have no doubt that I still missed a ton. If there‚Äôs something you think I missed, please let me know.What research direction are you most excited about? What do you see as promising solutions? I‚Äôd love to hear from you.#llm #airesearch #generativeai 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7097619722363408385?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7097619722363408385%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHKw2Qa1ED0WQ/feedshare-shrink_480/0/1692204407678?e=1707955200&v=beta&t=ea7K6pr7vDEPC_iF_k6DXEbqX6Nk5zBl-dl7dUEJ04U
269,65a10560a5b8f0720000225f,7f129fea-d188-5577-e1cf-f53eb1296215,https://media.licdn.com/dms/image/C4E03AQHVyH-IfD1KbQ/profile-displayphoto-shrink_100_100/0/1629877234109?e=1710374400&v=beta&t=0UZUl_dDUxLaZn-Hu-zToqEDe3rpL5cB2JkP5_jlNXc,"Sebastian Raschka, PhD",https://www.linkedin.com/in/ACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU,"
Machine learning and AI researcher since the early days ‚Ä¢ coding and working with LLMs at Lightning AI ‚Ä¢ ex-statistics professor at University of Wisconsin-Madison
","
The NeurIPS 2023 LLM Efficiency Challenge is a super exciting opportunity for developing & benchmarking new research directions for param-efficient LLMs. If you are looking for something to tinker with this weekend, I just put together a Starter Guide: https://lnkd.in/g2TEhagDI am really excited for the research community to develop (more) efficient methods for finetuning LLMs. And I hope you find this competition as useful and exciting as I do. Please spread the word about this competition ‚Äî the more people participate, the more we can advance the efficient LLM research field.#llm #ai #largelanguagemodels 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7095771182259458049?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7095771182259458049%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQGOBRZ5rBnLxA/feedshare-shrink_480/0/1691763681556?e=1707955200&v=beta&t=Xch7UcC-dH3DlAYbVenfkDT0JGhZVZTZ2IVlK0oWk_Q
270,65a10560a5b8f07200002260,96c083c9-1cb5-8240-beec-15a10ed449f2,https://media.licdn.com/dms/image/D4E03AQHtC2BUAB6jkA/profile-displayphoto-shrink_100_100/0/1694687456770?e=1710374400&v=beta&t=ndmP3__bJjjA60t62U8lCwf_bck4TDX4LIp-qSsOgAc,Prithivi Da,https://www.linkedin.com/in/ACoAAANONyEBI75vYtjMK4f9hcDMhgneli34DsA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAANONyEBI75vYtjMK4f9hcDMhgneli34DsA,"
Building a Memory Assistant for Philomaths. Sharing wisdom from a 2 decade experience in creative problem solving.
","
What is ""ùóóùó∂ùóπùóÆùòÅùó≤ùó± ùóîùòÅùòÅùó≤ùóªùòÅùó∂ùóºùóª"" & how has it made The 1 BILLION tokens in context possible?Dilation is originally a concept used by CNNs to increase the receptive field of pixels (Look at the image below)ùó£ùóµùóÆùòÄùó≤ ùü≠: ùó™ùóµùòÜ ùó©ùó∂ùòÄùó∂ùóºùóª ùóßùóøùóÆùóªùòÄùó≥ùóºùóøùó∫ùó≤ùóøùòÄ ùóªùó≤ùó≤ùó±ùó≤ùó± ùó±ùó∂ùóπùóÆùòÅùó∂ùóºùóª?Self-attention: Considers all pairs of patches, allowing it to capture long-range dependencies.Enables modeling complex relationships in data but suffers from quadratic complexity. So came NA (Neighborhood Attention): Focuses on local neighborhoods within the data, reducing complexity. More scalable but may lose long-range context due to its localized focus. The came DiNaT (Dilated Neighborhood Attention Transformer): Combines Neighborhood Attention with dilation to increase the receptive field without increasing complexity. Attempts to capture long-range context with linear complexity while maintaining a neighborhood focus. An extension of NA with a larger receptive field, designed for vision tasks.ùó£ùóµùóÆùòÄùó≤ ùüÆ: ùó™ùóµùòÜ ùóüùóÆùóªùó¥ùòÇùóÆùó¥ùó≤ ùóßùóøùóÆùóªùòÄùó≥ùóºùóøùó∫ùó≤ùóøùòÄ ùóªùó≤ùó≤ùó±ùó≤ùó± ùóóùó∂ùóπùóÆùòÅùó∂ùóºùóª ùó≥ùóøùóºùó∫ ùó©ùó∂ùòÄùó∂ùóºùóª ùóßùóøùóÆùóªùòÄùó≥ùóºùóøùó∫ùó≤ùóøùòÄ?Dilated Attention in LONGNET- ùóîùóΩùóΩùóπùó∂ùó∞ùóÆùòÅùó∂ùóºùóª: Designed for sequence modeling, scaling Transformers to extremely long sequences (e.g., 1 billion tokens).- ùóñùóºùóªùó∞ùó≤ùóΩùòÅ: Expands the attentive field exponentially as the distance grows, allowing the model to capture long-range dependencies in sequences.- ùóñùóºùó∫ùóΩùóπùó≤ùòÖùó∂ùòÅùòÜ: Also maintains linear complexity, enabling the model to handle extremely long sequences without sacrificing performance.- ùóúùóªùòÅùó≤ùó¥ùóøùóÆùòÅùó∂ùóºùóª: Serves as a drop-in replacement for standard attention in Transformer models and can be applied to general language tasks.______________________Save it for later using SaveLikeAPRO 

          ‚Ä¶see more
        


How Dilated Attn works ?
",,https://www.linkedin.com/feed/update/urn:li:activity:7093140271386742785?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7093140271386742785%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E1FAQG83mEXBCZqFA/feedshare-document-cover-images_480/0/1691136179998?e=1705658400&v=beta&t=13mPRzXKvcRnOxxqok7Gy0fYuDvIiSHItZEeZ1wojI4
271,65a10560a5b8f07200002261,e60cda83-0502-14a8-f764-54644bf76077,https://media.licdn.com/dms/image/D5603AQHLwo7d_7vKNg/profile-displayphoto-shrink_100_100/0/1701769075230?e=1710374400&v=beta&t=5lLKLNjyNpB7kY5aOz9Dm0z5VoirsZxlX5i9xuqm5w0,Steve Nouri,https://www.linkedin.com/in/ACoAAAj_qcABebPCFHyk-0_-nNFZsxiGnzK5i6c?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAj_qcABebPCFHyk-0_-nNFZsxiGnzK5i6c,"
Generative AI Founder | Advisor @ Fortune 500 | 1.5 Million Followers | Keynote Speaker | Top Voice DS & AI
","
Google just released 10 FREE courses to master Generative AI. ( 4 New Coursesüî•)1. Introduction to Generative AIThis is an introductory-level microlearning course aimed at explaining what Generative AI is, how it is used, and how it differs from traditional machine-learning methods.2. Introduction to Large Language ModelsThis is an introductory-level microlearning course that explores what large language models (LLM) are, the use cases where they can be utilized, and how you can use prompt tuning to enhance LLM performance3. Introduction to Responsible AIThis is an introductory-level microlearning course aimed at explaining what responsible AI is, why it's important, and how Google implements responsible AI in its products. It also introduces Google's 7 AI principles4. Generative AI FundamentalsEarn a skill badge by completing the Introduction to Generative AI, Introduction to LLM, and Introduction to Responsible AI courses.5. Introduction to Image GenerationThis course introduces diffusion models, a family of machine learning models that recently showed promise in the image generation space.Diffusion models draw inspiration from physics, specifically thermodynamics.6. Encoder-Decoder ArchitectureLearn about the main components of the encoder-decoder architecture and how to train and serve these models.7. Attention MechanismYou will learn how attention works, and how it can be used to improve the performance of a variety of machine-learning tasks, including machine translation, text summarization, and question-answering.8. Transformer Models and BERT ModelYou learn about the main components of the Transformer architecture, such as the self-attention mechanism, and how it is used to build the BERT model.9. Create Image Captioning ModelsThis course teaches you how to create an image captioning model by using deep learning. You learn about the different components of an image captioning model, and how to train and evaluate your model.10. Introduction to Generative AI StudioIn this course, you learn what Generative AI Studio is, its features and options, and how to use it by walking through demos of the product. In the end, you will have a quiz to test your knowledge.https://lnkd.in/g2w9Q-qWClick Follow Steve Nouri  and dont miss my future posts about Generative AI#artificialintelligence #generativeai 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7094241373414977536?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7094241373414977536%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQGw-vwotvh4zA/feedshare-shrink_480/0/1691398947411?e=1707955200&v=beta&t=nQAr6umPlPcyCM7SVtOnXOiyL3_p2t2ixYLem6dbi7U
272,65a10560a5b8f07200002262,04d51567-a945-7817-ca91-f38205669cbb,https://media.licdn.com/dms/image/C4E03AQGfzEtRhrPHdw/profile-displayphoto-shrink_100_100/0/1619776973437?e=1710374400&v=beta&t=y9up1yBFMNfTMJvaDgcupbnl3OnJC7EgkzWAkOY4pyM,Sanyam Bhutani,https://www.linkedin.com/in/ACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0,"
Senior Data Scientist at H2O.ai | Kaggle Grandmaster
","
Terrific summary of LLMs for developers! üôèSimon Willison has given one of the best talks summarising the world of Large Language Models aimed at developers.This one has no usual fluff and gives a direct summary of the origin, current applications and pitfalls. I‚Äôd recommend starting with the companion blog and then watching the talk:https://lnkd.in/esnpXQnM

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7094301648679772160?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7094301648679772160%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQE6C_xE9-bKgg/feedshare-shrink_480/0/1691413317385?e=1707955200&v=beta&t=XPB8Xn4AaccKBGi-cETq9GX0FX0rT9XJWegwK_D5WAA
273,65a10560a5b8f07200002263,38f3fb4f-d6da-c305-e92c-58dcde1ba4a0,https://media.licdn.com/dms/image/C4E03AQGfzEtRhrPHdw/profile-displayphoto-shrink_100_100/0/1619776973437?e=1710374400&v=beta&t=y9up1yBFMNfTMJvaDgcupbnl3OnJC7EgkzWAkOY4pyM,Sanyam Bhutani,https://www.linkedin.com/in/ACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0,"
Senior Data Scientist at H2O.ai | Kaggle Grandmaster
","
A masterclass in creating Synthetic Datasets using LLMs! üêêToolLLM paper has been incredibly popular for creating the largest API following dataset to fine tune models along with backbones. I think there is an underrated side to the paper as well of using Large Language Models effectively for data creation. Like always, here is my summary:- The paper aims to improve API following capabilities of open source models- It creates 16,000 synthetic examples and improves LLaMA-1 model to get performant at ChatGPT levels- The authors start by collecting a large set of API examples along with documentation- The low quality ones are filtered out by removing examples that don't work or are too slow- ChatGPT is used to annotate and provide reasoning for the examples- The authors create a new depth based technique that is more effective for API following which is key for making the step above- Depth First Search Strategy is much more useful here compared to Chain of Thought or ReAct techniques - The open source models are fine-tuned on the instructions annotated above- Finally a retrieval model is trained to fetch the most useful APIs to call during inference- The last part is helpful to make the fine tuned models useful in the real world by telling it which APIs to call for particular tasksThe paper also proposes an end to end automated evaluation for this technique. For me the way of smartly creating synthetic dataset was a masterclass of itself. Here's the link to the paper, although I would recommend playing with the GitHub instead:https://lnkd.in/dih5RnMv

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7093939150998974464?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7093939150998974464%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQHo7XYJEz2t0w/feedshare-shrink_480/0/1691326890618?e=1707955200&v=beta&t=INq2-Uab_28Wf-ruKmeBCdZaEJWSgPQXn60QX7JJesA
274,65a10560a5b8f07200002264,a35a8681-7fb1-1ecd-de10-40465210faf5,https://media.licdn.com/dms/image/C4E03AQGfzEtRhrPHdw/profile-displayphoto-shrink_100_100/0/1619776973437?e=1710374400&v=beta&t=y9up1yBFMNfTMJvaDgcupbnl3OnJC7EgkzWAkOY4pyM,Sanyam Bhutani,https://www.linkedin.com/in/ACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0,"
Senior Data Scientist at H2O.ai | Kaggle Grandmaster
","
The most detailed and practical writeup on applying LLMs! üôèEugene Yan is known as the best NLP writer in the field for a reason. He has written what is definitely the best overview of patterns on building Large Language Models in the real world. This reads like a survey paper but for the industryEugene has identified 7 key patterns based on performance and cost tradeoffs. I would recommend dropping everything this weekend and reading this comprehensive post:https://lnkd.in/d-Mq84-u

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7093214689798557696?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7093214689798557696%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQFGRHtwQGUoKA/feedshare-shrink_480/0/1691154166698?e=1707955200&v=beta&t=ck8makY4DOPWonCO4Rng0zSQakCZ8e51L8gQrHigpW4
275,65a10560a5b8f07200002265,0f14fba3-037e-81fd-a10e-1565aaf25428,https://media.licdn.com/dms/image/C4D03AQFTwrdIn8d-mA/profile-displayphoto-shrink_100_100/0/1604245712566?e=1710374400&v=beta&t=l4-FrAa7wImnnZDPnH93cJEv7BZODxi5FSckrSiPUPI,Giannis Tolios,https://www.linkedin.com/in/ACoAAA4S6wIBSZyJZDZq6NnoXsAqh64btIYNPTE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA4S6wIBSZyJZDZq6NnoXsAqh64btIYNPTE,"
Data Scientist | Book Author at Leanpub | Contributor at Towards Data Science | Passionate about Climate Change Mitigation
","
ùó¢ùóΩùòÅùó∂ùó∫ùó∂ùòáùó≤ ùòÜùóºùòÇùóø ùó†ùóü ùó†ùóºùó±ùó≤ùóπùòÄ ùòÑùó∂ùòÅùóµ ùòÄùó∞ùó∂ùó∏ùó∂ùòÅ-ùóºùóΩùòÅùó∂ùó∫ùó∂ùòáùó≤!üí°Most machine learning models let you tweak them to achieve optimal performance, a technique known as hyperparameter tuning. The scikit-learn library supports various hyperparameter tuning methods, such as grid search. Unfortunately, those techniques can become time consuming as they aren't optimized. In contrast, the scikit-optimize library uses bayesian optimization to model the hyperparameter space, thus quickly finding optimal combinations. Check the links below for more information, and follow me for regular content!ùòÄùó∞ùó∂ùó∏ùó∂ùòÅ-ùóºùóΩùòÅùó∂ùó∫ùó∂ùòáùó≤ ùóöùó∂ùòÅùóµùòÇùóØ ùóøùó≤ùóΩùóºùòÄùó∂ùòÅùóºùóøùòÜ: https://lnkd.in/dZcdzTRSùóñùóµùó≤ùó∞ùó∏ ùóÆùóª ùóîùó∫ùóÆùòáùó∂ùóªùó¥ ùóïùóºùóºùó∏ ùóÆùóØùóºùòÇùòÅ ùó†ùóÆùòÅùóµ ùó≥ùóºùóø ùó†ùóüüìö: https://amzn.to/3DuARqxùóüùó≤ùóÆùóøùóª ùó†ùóü ùóÆùóªùó± ùóßùó∂ùó∫ùó≤ ùó¶ùó≤ùóøùó∂ùó≤ùòÄ ùóôùóºùóøùó≤ùó∞ùóÆùòÄùòÅùó∂ùóªùó¥ ùòÑùó∂ùòÅùóµ ùó£ùòÜùóñùóÆùóøùó≤ùòÅüìö: https://lnkd.in/dyByK4F#python #datascience #machinelearning #deeplearning #linkedin

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7092143266778759168?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7092143266778759168%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQGnnhg527UL5w/feedshare-shrink_480/0/1690898718992?e=1707955200&v=beta&t=LWD9Bir1Qyeb7GR6a03gMAyA6FmyLeSzDCkKghFuTuI
276,65a10560a5b8f07200002266,ea141660-569f-ab15-ed6b-9412e239d4f8,https://media.licdn.com/dms/image/D5603AQGEADhHyEQ8rw/profile-displayphoto-shrink_100_100/0/1682553354695?e=1710374400&v=beta&t=kfjA-KO1Ea4gqAJ68vTh1_4ORnZzWv1qSW4bXFvg_tc,"Damien Benveniste, PhD",https://www.linkedin.com/in/ACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw,"
The ML Guy - Follow me to learn about Machine Learning Engineering, Machine Learning System Design, MLOps, and the latest techniques and news about the field. Join my AI newsletter and keep learning!
","
The history of YOLO is not as straightforward as we could think! It started at V1 and it ended up at V8, we should have all the intermediary versions in between, right? Not exactly!The first version of YOLO was published in 2015 (https://lnkd.in/ghxcPp83) by Joseph Redmon and a few other people. It introduced for the first time the possibility of detecting objects in real time. Redmon and Ali Farhadi developed further YOLO V2 in 2016 (https://lnkd.in/gJASkpy3) and YOLO V3 in 2018 (https://lnkd.in/gTrejZ3j). Among other things, YOLO V2 introduced anchor boxes, the Darknet-19 architecture, and fully convolutional predictions. V3 used the Darknet-53 architecture and multi-scale predictions.In 2020 Redmon announced that he stopped doing CV research due to the military applications and that was when other teams started to take over his legacy! Honestly, I am kind of glad because the later articles were much easier to read. In 2020, Alexey Bochkovskiy et al. published the V4 paper (https://lnkd.in/gs9t7XnB) with more emphasis on optimizing the network hyperparameters and an IOU-based loss function. A few months later, Ultralytics entered the game and published YOLOv5 (https://lnkd.in/gyPX7FmF) with a better algorithm for anchor finding. They also previously implemented their own V3 version. The same team as V4 published YOLOR (https://lnkd.in/gq__-v5j) in 2021 focusing on multi-task learning: classification, detection, and pose estimation. YOLOX was developed later this year by Megvii Technology (https://lnkd.in/gZDJu7hY) reintroducing the anchor-free process. Interestingly enough, V7 was published in 2022 before V6 by the V4 team focusing on small optimizations. V6 was introduced in 2022 by Meituan (https://lnkd.in/gw9E7T8s) focusing on model compression strategies such as quantization and distillation. DAMO-YOLO (https://lnkd.in/grG9PRei) was developed by Alibaba later that year using neural architecture search. YOLOv8 (https://lnkd.in/gR7dxU-C) was published earlier this year by Ultralytics improving on V5.There are actually a few other models labeled with ""YOLO"" that were created by other teams but I am going to stop here today! You can read more about it here: https://lnkd.in/ggRZjKjT----Make sure to checkout my ML newsletter: TheAiEdge.io#machinelearning #datascience #artificialintelligence

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7092164578863714305?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7092164578863714305%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHTcI9TKgZ1jQ/feedshare-shrink_480/0/1690867978374?e=1707955200&v=beta&t=q7uybDS5QhTJpxC0wCPOu4syl1st9YxJQxBs2vVvDGY
277,65a10560a5b8f07200002267,af34d099-115c-deca-c497-fa6a24c3aa74,https://media.licdn.com/dms/image/C4E03AQGfzEtRhrPHdw/profile-displayphoto-shrink_100_100/0/1619776973437?e=1710374400&v=beta&t=y9up1yBFMNfTMJvaDgcupbnl3OnJC7EgkzWAkOY4pyM,Sanyam Bhutani,https://www.linkedin.com/in/ACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0,"
Senior Data Scientist at H2O.ai | Kaggle Grandmaster
","
Annotated PyTorch papers! üî•labml.ai has one of the best resources for learning how to really implement ideas in PyTorch. This is a no-nonsense website with a side-by-side implementation of Neural Network concepts in PyTorch.I've found myself going back to the Transformers section every few months and I can't recommend it enough for anyone who writes code using PyTorch:https://nn.labml.ai

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7091766788929069056?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7091766788929069056%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQGL1nr0VgTLZA/feedshare-shrink_480/0/1690808959594?e=1707955200&v=beta&t=ARjeXklvQbi5IobDB24rtv8yL0LCqSS9yRp6uYCMVJ4
278,65a10560a5b8f07200002268,9323d019-b464-e1ac-c1e7-11cdc6760cc3,https://media.licdn.com/dms/image/C5103AQGaPB2H0KYHLw/profile-displayphoto-shrink_100_100/0/1549280612864?e=1710374400&v=beta&t=lk7pk4XVMPmv0bE30cageNy4vjTC59iUPYVBrugu6iA,Avinash P.,https://www.linkedin.com/in/ACoAAAnitZwBU5IfQKzxtJdu6hxmNebFn10SPjs?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAnitZwBU5IfQKzxtJdu6hxmNebFn10SPjs,"
GenAI | LLM | Nvidia | ex-TomTom
","
üé© 12 Generative Ai courses - 12 Generative Ai experts to follow üöÄ #generativeai #LLM #NLP #VISION #TRANSFORMERS #people Free Generative AI Courses by GoogleLink - https://lnkd.in/dwBbUMmDGenerative AI with Large Language ModelsLink - https://lnkd.in/dy-wqBWPGenerative AI - From Big Picture, to Idea, to ImplementationLink - https://lnkd.in/d24V-6nUGenerative AI Crash Course with Hands-on ImplementationsLink - https://lnkd.in/ddnzhNViHow Diffusion Models WorkLink - https://lnkd.in/daazSr7kStable DiffusionLink - https://lnkd.in/dB4q-JW5Building Systems with the ChatGPT APILink - https://lnkd.in/dsNcRgvmOpen AI's Generative Pre-trained Transformer (GPT3 + GPT4)Link - https://lnkd.in/drvBPtcpLangChain for LLM Application DevelopmentLink - https://lnkd.in/de7__v9WChatGPT Prompt Engineering for DevelopersLink - https://lnkd.in/dRijqy_NThe Fundamentals of ChatGPT: AI Language ModelLink - https://lnkd.in/dz2UYc6xBuild, Train, and Deploy ML Pipelines using BERTLink - https://lnkd.in/djSY8jJaAlso follow these amazing people for GenAI updates1. Akshay Pachaar2. Aishwarya Srinivasan3. Sebastian Raschka, PhD4. Clem Delangue ü§ó5. Johnny Crupi6. Saachi Grover7. Jerry Kurian8. Sid Rath9. Ahmad Al-Dahle10. Nilesh Chopda11. Madhur Jain12. Pankaj Kumar Madhukar

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7091335235384033280?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7091335235384033280%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQHIxWms0heMlQ/feedshare-shrink_2048_1536/0/1690706069878?e=1707955200&v=beta&t=zCoaTAbzJnPdsDr-4LIz4Mz7a-r9Xld5vcZwJWwOQmU
279,65a10560a5b8f07200002269,881982fd-8149-9b10-40e8-995f7f587bbe,https://media.licdn.com/dms/image/C560BAQEg7UfAyEoKWg/company-logo_100_100/0/1637414049335/nlplanet_logo?e=1713398400&v=beta&t=_QvY1xSefLEyzgG6cO_2hVnEPcwkGrAcB32ORRVOZbM,NLPlanet | Breaking Down Generative AI Daily,https://www.linkedin.com/company/nlplanet/,"
9K followers
","
An educational implementation of LLaMA 2 inference in pure C by Andrej Karpathy ü¶ôüòÆ Andrej Karpathy released code that allows you to train a Llama 2 LLM architecture from scratch in PyTorch, save weights to raw binary file, and load them into single C file for inference.‚ö°Ô∏è Not for production-grade use, but it's simple and efficient for running reasonably sized models at interactive rates. A great educational resource!üöÄ This project is in its early stages and serves as a weekend project and a proof-of-concept. It demonstrates the potential of running Llama 2 models in C without dependencies. The concise code consists of a 500-line C file, making it easier for developers to use.

          ‚Ä¶see more
        


GitHub - karpathy/llama2.c: Inference Llama 2 in one file of pure C
",,https://www.linkedin.com/feed/update/urn:li:activity:7089680710801776640?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7089680710801776640%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQHC510hBzunvA/articleshare-shrink_800/0/1704330331019?e=1705658400&v=beta&t=LG7EzuhPyA-BL4Qc6fveGpq0m2yognQ6AjPQ-K5Segs
280,65a10560a5b8f0720000226a,12ebfcce-5f89-e898-9058-86af28b1a30f,https://media.licdn.com/dms/image/D5603AQGNiuOdOwGOXA/profile-displayphoto-shrink_100_100/0/1664778459905?e=1710374400&v=beta&t=xBgaXiEzd_m7LRcAM3FAiTW3npUaSw7mDRGAhH05ro0,Vinija Jain,https://www.linkedin.com/in/ACoAAA4CfZwBGeQakt2b0sUVu1GdoGrJgBGwpJU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA4CfZwBGeQakt2b0sUVu1GdoGrJgBGwpJU,"
Machine Learning Leader at Amazon | Stanford AI | EMNLP Outstanding Paper Award Recipient
","
üìä GNN for Recommender Systems‚û¢ Graph Neural Networks (GNNs) are a type of neural network architecture designed for processing graph-structured data. Graphs are a versatile data structure that can represent complex relationships, and GNNs extend traditional neural networks to operate directly on graphs.‚û¢ GNNs can aggregate information from neighboring nodes, capture local and global graph structures, and make predictions based on graph-structured data.‚û¢ They have been successfully applied to various applications, such as node classification, link prediction, and recommendation systems.‚û¢ Popular GNN architectures include Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs), GraphSAGE, and GGNNs.‚û¢ GNNs are used in several industry applications such as Maps for Google/Uber, and Social Network for LinkedIn, Instagram, and Facebook.‚û¢ In this article, http://gnn.vinija.ai, we will look at GNN‚Äôs in more detail as well as their application within industry for recommender systems.‚û¢ This is written in collaboration with Aman Chadha, please feel free to reach out to us for any comments or suggestions!

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7090923561019736064?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7090923561019736064%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHNDWPpblB7IA/feedshare-shrink_480/0/1690607918873?e=1707955200&v=beta&t=meRehOaztmvTbKGpCyhUXBLTcgw4UVnV6B68tJbffFU
281,65a10560a5b8f0720000226b,8f4ad3bc-1ad4-baba-641b-610e84235285,https://media.licdn.com/dms/image/C5103AQHA5gQgdWjT5A/profile-displayphoto-shrink_100_100/0/1516702664219?e=1710374400&v=beta&t=0ISAapciYG3gLs_0ziTlP-hfdQWIvniEJaaQkZ-CnZA,George Karniadakis,https://www.linkedin.com/in/ACoAAAtbsJgBhSmN8hWuMMX7feYTA3M5Ff2jbJ0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAtbsJgBhSmN8hWuMMX7feYTA3M5Ff2jbJ0,"
Charles Pitts Robinson and John Palmer Barstow Professor of Applied Mathematics & Engineering, Brown University
","
BEATING THE-CURSE-OF-DIMENSIONALITY (for good!). Thanks to a simple but brilliant idea of Kenji Kawaguchi and Zheyuan Hu, we have a true breakthrough of machine learning! They introduced a type of batching in the dimension space - Stochastic Dimension Gradient Descent or SDGD - which we combine with PINNs so we can now solve notoriously hard equations in 100,000 dimensions in a couple of hours on a single GPU. The method is agnostic to equations (no tranfosrmations, no gimmicks!). For example, we solve the Hamilton-Jacobi-Bellman (HJB, see below in the table), Black-Scholes-Barenblantt (BSB), Fokker-Planck,  Allen-Cahn, the sine-Gordon, semi-linear heat, and Schroendiger equations in 100,000. The BSB takes less than 40 minutes on a single GPU. In the table, you can see that we go from 250 to 100,000 dimensions and the cost goes up only by a factor of 4!!! SDGD is based on rigorous theory and it is a generalization of SGD - stochastic gradient descent. All theoretical results for convergence and all the computatioanl results are in a new paper here:   https://lnkd.in/euFeR3xP#neuralnetworks #machinelearning #neuralnetworks #deeplearning #optimization #controls #finance #multiphysics #quantum #stochasticity

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7089722114768789504?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7089722114768789504%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQE9Wk3FcBXaPA/feedshare-shrink_480/0/1690321472165?e=1707955200&v=beta&t=_kNk3r7ZCqUKk9ahdPDFZLjJc61bqdn2F8z5lnuMlRY
282,65a1057ba5b8f0720000226c,7683f82f-38f9-c184-2128-7ede8f79ed16,https://media.licdn.com/dms/image/D5635AQEBzEFRC2EzLg/profile-framedphoto-shrink_100_100/0/1704907585971?e=1705658400&v=beta&t=x71pDAJzCbSPZxvt91sIkpmEr_5_pGLZIt6VZgw5eV0,Aman Chadha,https://www.linkedin.com/in/ACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU,"
GenAI Leadership @ Amazon AWS ‚Ä¢ Stanford AI ‚Ä¢ EB-1 ""Einstein Visa"" Recipient/Mentor ‚Ä¢ Ex-Ô£ø, Amazon Alexa, Nvidia, Qualcomm ‚Ä¢ EMNLP 2023 Outstanding Paper Award
","
üìö Distilled Notes for NLP from Stanford University | http://nlp.aman.ai- NLP is one of the most popular #AI domains, widely used from language translation to auto-complete to voice assistants.- Presenting notes from Stanford‚Äôs CS224n Natural Language Processing taught by Christopher Manning.- Written in collaboration with Vinija Jain.What‚Äôs included:üîπ NLP Overview: Word Vectors, Word2Vec (CBOW, Skip-gram)üîπ NLP Tasks: Named Entity Recognition (NER), Dependency Parsingüîπ Neural Networks: RNNs, LSTMs, CNNs, Regularization, Dropoutüîπ Language Models (LMs): n-gram LMs, Neural LMs, Evaluating LMs with Perplexity, Contextual Embeddings, ELMO, GPT-3üîπ Machine Translation: seq2seq, Neural Machine Translation (NMT)üîπ Attention: The Bottleneck Problem, seq2seq with Attention, Self Attention, Multi-Headed Attentionüîπ Knowledge Graphs: Entity Linking, ERNIE, KGLMüîπ Transformer: Encoder, Decoder, BERT#artificialintelligence #machinelearning #ai #ml 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7088717491522187264?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7088717491522187264%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQFEcYEw43m7FQ/feedshare-shrink_480/0/1690081947558?e=1707955200&v=beta&t=DVOrUtxXgeVAXmq4EO37vC5zidQQQNApp7emjY1FvrU
283,65a1057ba5b8f0720000226d,4e906c05-dba0-2758-1d2a-d6df77a4acf4,https://media.licdn.com/dms/image/D5603AQGNiuOdOwGOXA/profile-displayphoto-shrink_100_100/0/1664778459905?e=1710374400&v=beta&t=xBgaXiEzd_m7LRcAM3FAiTW3npUaSw7mDRGAhH05ro0,Vinija Jain,https://www.linkedin.com/in/ACoAAA4CfZwBGeQakt2b0sUVu1GdoGrJgBGwpJU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA4CfZwBGeQakt2b0sUVu1GdoGrJgBGwpJU,"
Machine Learning Leader at Amazon | Stanford AI | EMNLP Outstanding Paper Award Recipient
","
 ü™∑ Large Language Model, Prompt Engineering, LangChain, and LangFlow‚û¢ LLMs are currently experiencing a significant surge in prominence. With that, comes a need for understanding prompt engineering techniques as well as familiarity with tools such as LangChain and LangFlow to leverage LLMs efficiently.‚û¢ The articles here (http://llm.vinija.ai and http://prompt.vinija.ai) are a deep dive into these concepts.‚û¢ This is written in collaboration with Aman Chadha, please feel free to reach out to us for any comments or suggestions!#artificialintelligence #machinelearning #ai #ml

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7088719751987810304?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7088719751987810304%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQE1SGIj60nYUQ/feedshare-shrink_480/0/1690082489599?e=1707955200&v=beta&t=xa_o5wUwSOVfIiVbdgIMQJzfddSB7G7nIK7240flEck
284,65a1057ba5b8f0720000226e,a5f30a55-e51d-5425-3ae3-2847fc6b279d,https://media.licdn.com/dms/image/D4D03AQEYCGSc8lLDSQ/profile-displayphoto-shrink_100_100/0/1671090632152?e=1710374400&v=beta&t=9iah2MKct2J-3DkN-Cjn0e3-RunycdfVosVphuQuhv4,üöÄ Abhishek Thakur,https://www.linkedin.com/in/ACoAAAL1AE0BCC3EHeSe-q9ul8j33fC3gKHb1lc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAL1AE0BCC3EHeSe-q9ul8j33fC3gKHb1lc,"
AutoTrain @ Hugging Face | World's First 4x Kaggle GrandMaster | 140k+ LinkedIn | 100k+ YouTube
","
üö® NEW TUTORIAL ALERT üö®The EASIEST way to finetune llama-v2  on local machine with custom dataset! P.S. the tutorial also works for any other LLM and can also be used on the free version of google colab! Link to video is available in first comment!!!! üöÄ

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7087769851993165824?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7087769851993165824%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQHBddGJIjYCHg/feedshare-shrink_480/0/1689856014695?e=1707955200&v=beta&t=OeAvA5AmLXqGokpgledTK102DHXLuEqq9kNXhoQNTbA
285,65a1057ba5b8f0720000226f,8a9a1739-5f23-e5d7-724a-cc4fe0b44a7c,https://media.licdn.com/dms/image/D4D03AQGgvu01hAmu5A/profile-displayphoto-shrink_100_100/0/1674206621261?e=1710374400&v=beta&t=YDrqGuZTqNisHFUsSCVuovvs_J5icHQC35RI3D00x4A,Darius Singh,https://www.linkedin.com/in/ACoAADMl2E0B0Le70U7Hn3z5btq93y5MRbTbBOc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADMl2E0B0Le70U7Hn3z5btq93y5MRbTbBOc,"
Machine Learning Engineer
","
‚ú® OpenLLMs: Less is More for Open-Source Models ‚ú® ""OpenLLMs is a series of open-source language models fine-tuned on a small yet diverse, high-quality dataset of multi-round conversations.""‚û° Generic Models:1. OpenChat: based on LLaMA-13B with a context length of 2048.- Achieves 105.7% of ChatGPT score on the Vicuna GPT-4 evaluation.- Achieves 80.9% win-rate on AlpacaEval.2. OpenChat-8192: based on LLaMA-13B, with an extended context length of 8192.- Achieves 106.6% of ChatGPT score on the Vicuna GPT-4 evaluation.- Achieves 79.5% win-rate on AlpacaEval.‚û° Code Models:1. OpenCoderPlus: based on StarCoderPlus with a native context length of 8192.- Achieves 102.5% of ChatGPT score on the Vicuna GPT-4 evaluation.- Achieves a 78.7% win-rate on AlpacaEval.‚û° Dataset:1. openchat_sharegpt4_dataset: ~6k cleaned and filtered GPT-4 data from ShareGPT.‚ö†Ô∏è Note: The evaluation metrics represent a quantified measure of a subset of the model's capabilities. A score of 105% does not necessarily indicate that the model is better than ChatGPT in all scenarios or for all use cases. It is important to consider the specific tasks or applications for which the model was evaluated and compare the results accordingly.‚≠ê GitHub: https://lnkd.in/dK-9z4pnü§ó HF: https://lnkd.in/d6a5mVs9#machinelearning #artificialintelligence #nlp #opensource #llm 

          ‚Ä¶see more
        


GitHub - imoneoi/openchat: OpenChat: Advancing Open-source Language Models with Imperfect Data
",,https://www.linkedin.com/feed/update/urn:li:activity:7082336086617669632?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7082336086617669632%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQFw4Uv5mgvzQA/articleshare-shrink_800/0/1705047098422?e=1705658400&v=beta&t=lz6VfCr0-c20C6wAh8qDyH4StjTx-bnyh952uPAo6sc
286,65a1057ba5b8f07200002270,05c77906-0b51-4b56-1068-c261ed6868fc,https://media.licdn.com/dms/image/C4E03AQH4fk7rdSqpOw/profile-displayphoto-shrink_100_100/0/1517341724736?e=1710374400&v=beta&t=BP0A2WWVnehkGgk8OprWggBocv6SVnDoHkgYTw7YUCk,Fr√©d√©ric Simard,https://www.linkedin.com/in/ACoAABYu40MBpJsJ8ZrSpVIO50UEUypic0XyUko?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABYu40MBpJsJ8ZrSpVIO50UEUypic0XyUko,"
CEO at RE-AK Technologies inc.
","
Cheat sheet is perhaps an understatement here.I've summed up everything that comes to mind when mixing machine learning and brain machine interfaces (BCIs).The table of contents of the article:* The basics of machine learning* Two important lessons: cross-validation and the curse of dimensionality* The iterative approach to machine learning modeling* The iterative approach to data collectionEach section can be read on its own.https://lnkd.in/e8fEqJAz#bci  #cheatsheet  #machinelearning  #strategy  #datacollection 

          ‚Ä¶see more
        


Machine Learning Applied to Brain-Computer Interfaces‚Ää‚Äî‚ÄäCheat Sheet
",,https://www.linkedin.com/feed/update/urn:li:activity:7082093303231307776?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7082093303231307776%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQFcD0HJzC5hkA/articleshare-shrink_800/0/1704289675046?e=1705658400&v=beta&t=B3ebFoz5qhpNdFGKKmVWqk9N6xxG28U0AS5czGxOD-o
287,65a1057ba5b8f07200002271,280b4074-f281-2124-663e-4fa0cd0c9c58,https://media.licdn.com/dms/image/D4D03AQGgvu01hAmu5A/profile-displayphoto-shrink_100_100/0/1674206621261?e=1710374400&v=beta&t=YDrqGuZTqNisHFUsSCVuovvs_J5icHQC35RI3D00x4A,Darius Singh,https://www.linkedin.com/in/ACoAADMl2E0B0Le70U7Hn3z5btq93y5MRbTbBOc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADMl2E0B0Le70U7Hn3z5btq93y5MRbTbBOc,"
Machine Learning Engineer
","
The Prompt Engineering Guide by DAIR.AI is a comprehensive resource for getting into prompt engineering. I strongly recommend going through it. According to their website, ""Prompt engineering is not just about designing and developing prompts. It encompasses a wide range of skills and techniques that are useful for interacting and developing with LLMs. It's an important skill to interface, build with, and understand the capabilities of LLMs. You can use prompt engineering to improve the safety of LLMs and build new capabilities like augmenting LLMs with domain knowledge and external tools.""üåü Github: https://lnkd.in/dAV9YKA2üíª Website: https://lnkd.in/dukmKQ3u#machinelearning #artificialintelligence #data #nlp #promptengineering 

          ‚Ä¶see more
        


GitHub - dair-ai/Prompt-Engineering-Guide: üêô Guides, papers, lecture, notebooks and resources for prompt engineering
",,https://www.linkedin.com/feed/update/urn:li:activity:7079684866983833600?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7079684866983833600%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQE30RZb0Zmk3Q/articleshare-shrink_800/0/1704192221963?e=1705658400&v=beta&t=vTdbAW44Pfsbds3BoP68s58nIZanVz6okhA2sj82gEY
288,65a1057ba5b8f07200002272,07b2505d-5525-4ead-227d-b0e2ff86f4b5,https://media.licdn.com/dms/image/D4D03AQHDQRE4oq5SYQ/profile-displayphoto-shrink_100_100/0/1699716489912?e=1710374400&v=beta&t=9aDg78Acz3PHiN0YdqHzP_EPCJPApAO_JgHAYOz4YTI,Pratik Bhavsar,https://www.linkedin.com/in/ACoAABK1MIYB0MEAKyyqSG6dzaY1t4870tDPpNA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABK1MIYB0MEAKyyqSG6dzaY1t4870tDPpNA,"
üí• high performance RAG | IIT Bombay
","
Apply for ML intern hiring (lots of LLM work) LongShot AI - Gen AI for factchecked content
 

Software Engineer - NLP [REMOTE]
",,https://www.linkedin.com/feed/update/urn:li:activity:7077284036796125184?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7077284036796125184%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQEsIZUpaGSiJA/articleshare-shrink_800/0/1676997412650?e=1705658400&v=beta&t=laGl1wT9_3wizTu36j9I1WRSapxIRigTK8dx4MjReKQ
289,65a1057ba5b8f07200002273,b9cad68e-7aba-e28d-db90-c5b9f93148bd,https://media.licdn.com/dms/image/D4D03AQHDQRE4oq5SYQ/profile-displayphoto-shrink_100_100/0/1699716489912?e=1710374400&v=beta&t=9aDg78Acz3PHiN0YdqHzP_EPCJPApAO_JgHAYOz4YTI,Pratik Bhavsar,https://www.linkedin.com/in/ACoAABK1MIYB0MEAKyyqSG6dzaY1t4870tDPpNA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABK1MIYB0MEAKyyqSG6dzaY1t4870tDPpNA,"
üí• high performance RAG | IIT Bombay
","
Excellent summary of all tricks to infer higher context length in #llm by Galina Alperovich used in Anthropic 100k, MPT-32k, GPT4-8k etcALiBi positional embedding, Sparse Attention, FlashAttention, Multi-Query attention, Conditional computation

          ‚Ä¶see more
        


The Secret Sauce behind 100K context window in LLMs: all tricks in one place
",,https://www.linkedin.com/feed/update/urn:li:activity:7078010814590296064?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7078010814590296064%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQEmKwL_GFFPdg/articleshare-shrink_1280_800/0/1704305552475?e=1705658400&v=beta&t=iveNmd58Jzy6zK393kfcS1fYJWIs_lnz0AMt0FRahlU
290,65a1057ba5b8f07200002274,6a1f2777-85cf-57a0-356b-4c3bf75db5b9,https://media.licdn.com/dms/image/C4E03AQHVyH-IfD1KbQ/profile-displayphoto-shrink_100_100/0/1629877234109?e=1710374400&v=beta&t=0UZUl_dDUxLaZn-Hu-zToqEDe3rpL5cB2JkP5_jlNXc,"Sebastian Raschka, PhD",https://www.linkedin.com/in/ACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU,"
Machine learning and AI researcher since the early days ‚Ä¢ coding and working with LLMs at Lightning AI ‚Ä¢ ex-statistics professor at University of Wisconsin-Madison
","
One of the big bottlenecks with LLMs and Vision Transformers is GPU memory on consumer devices. I just wrote about my favorite techniques for reducing peak memory in PyTorch:1) Automatic Mixed-Precision Training2) Lower-Precision Training3) Training with Reduced Batch Size4) Gradient Accumulation and Microbatches5) Choosing Leaner Optimizers6) Instantiating Models on the Target Device7) Distributed Training and Tensor Sharding8) Parameter Offloading(I focused on techniques that don't require architecture changes; let me know if you have additional suggestions for a potential follow-up!)Link to the article here: https://lnkd.in/g4uR_iyr#deeplearning #ai #llms 

          ‚Ä¶see more
        


Optimizing Memory Usage for Training LLMs and Vision Transformers in PyTorch - Lightning AI
",,https://www.linkedin.com/feed/update/urn:li:activity:7081650473316872192?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7081650473316872192%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQFbWDh962Fvqw/articleshare-shrink_800/0/1704496528578?e=1705658400&v=beta&t=g_n9CA5wym_CaScF2-iUuAcYk2LfcP5FOqYeM4peEQA
291,65a1057ba5b8f07200002275,f91a77b3-8a22-cab8-282f-b3f2c47d4d70,https://media.licdn.com/dms/image/C4E0BAQFnrCtK_RBm8A/company-logo_100_100/0/1659136408730/pyquant_news_logo?e=1713398400&v=beta&t=xTsb25lppJb2q5UHORJx5VzfdVIgn1PplrkccG-tCrQ,PyQuant News üêç,https://www.linkedin.com/company/pyquant-news/,"
35K followers
","
pandas cheat sheet (PDF)Creating, cleaning, reshaping, summarizing, selecting, combining, grouping, windowing, plotting, and querying.(This is especially useful for my students.)Grab it free:https://lnkd.in/gxkcyVrf

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7081425890097692672?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7081425890097692672%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5610AQFC7kDhXkimPw/image-shrink_480/0/1688343497672?e=1705658400&v=beta&t=rnCGJt4DbDec7LK4ANjDBptqrfd9hqwuu09xgievkvw
292,65a1057ba5b8f07200002276,f623a36e-0986-a730-be22-e0150148c146,https://media.licdn.com/dms/image/C4D03AQG-9rOlgK84oQ/profile-displayphoto-shrink_100_100/0/1585905904257?e=1710374400&v=beta&t=LZKy80Ei6Iw5ynkF2sC7wmdA0tH5crirpLYRsRZuIXk,Oleksandr Honchar,https://www.linkedin.com/in/ACoAAA06vjIBSAlWpwepqoDB5WFVyJINEJRlXQs?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA06vjIBSAlWpwepqoDB5WFVyJINEJRlXQs,"
Director of AI Engineering & Partner @ Neurons Lab
","
This is a great example of where ""AI engineering"" is heading to. Today we have prompt engineering over prompt engineering (see my previous video with GPT-book-writing) but it's heading to the programmatic connection of different AI modulesAI solution builders should already look into this rather than trying to convince an LLM to act as some entity X.

          ‚Ä¶see more
        


Visual Programming for Compositional Visual Reasoning
",,https://www.linkedin.com/feed/update/urn:li:activity:7081598760329371648?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7081598760329371648%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQHbDNm9ASVLYQ/articleshare-shrink_800/0/1704386466076?e=1705658400&v=beta&t=5v8e7y1c09zyECuBAZuxBlRkcvcUzkab_n_FtqY4tsU
293,65a1057ba5b8f07200002277,b01c474f-3844-cf2d-c78f-6e7026f7fd84,https://media.licdn.com/dms/image/C560BAQGvLn9-Y96Jew/company-logo_100_100/0/1630667257285/neuroscience_news_logo?e=1713398400&v=beta&t=u4aMtYyUL2VQ9dP9cxF6bjBjUdkC-OdKFwuFYgIxasg,Neuroscience News,https://www.linkedin.com/company/neuroscience-news/,"
424K followers
","
The Lonely Brain: Unraveling the Neuroscience and Psychology of IsolationExplore how loneliness alters our brain's processing, contributes to mental health issues, and discuss potential interventions. Read more about how our brains handle isolation and the solutions science provides.#neuroscience

          ‚Ä¶see more
        


The Lonely Brain: Unraveling the Neuroscience and Psychology of Isolation - Neuroscience News
",,https://www.linkedin.com/feed/update/urn:li:activity:7081378383254736896?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7081378383254736896%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQFWsatHAliFFA/articleshare-shrink_800/0/1704727117427?e=1705658400&v=beta&t=GLM7CzRFuueHErC-QapZZZnWR2sKV3s1j_bTSSXI7FE
294,65a1057ba5b8f07200002278,73374a43-77df-6320-87c1-c8a72b350eae,https://media.licdn.com/dms/image/C5603AQE9OYZnYuKkdg/profile-displayphoto-shrink_100_100/0/1589362893991?e=1710374400&v=beta&t=EOnngnnllv452-ItvFVwOGDPcMyEp3PEfdg0I2fFctM,Pourav Raj,https://www.linkedin.com/in/ACoAACWkeScB3qlIe8o4feZ3vx9wYxia8ZA_8Qs?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACWkeScB3qlIe8o4feZ3vx9wYxia8ZA_8Qs,"
Product @ JobTwine | GrowthX
","
üìà Metrics provide invaluable insights into how users interact with your product. They help you understand adoption rates, task success, user satisfaction, and more. ‚è±Ô∏èüîçBy measuring these metrics, you can make data-driven decisions, optimize designs, and create seamless experiences that users love. üéØ‚úÖHere is the list if Metrics you can track üåüüí™#UXMetrics #UserExperience #product #data #dataanalytics 

          ‚Ä¶see more
        


UX Metrics
",,https://www.linkedin.com/feed/update/urn:li:activity:7076843716203749376?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7076843716203749376%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D1FAQFo7iXZBN2S8A/feedshare-document-cover-images_480/0/1687249554163?e=1705658400&v=beta&t=jewIqs2H1eYaRALYjGBXlVNhSA2r4U_06J7e_FRB3H0
295,65a1057ba5b8f07200002279,d1b5bef4-a8e4-1915-4ca6-d454c8c17d71,https://media.licdn.com/dms/image/D4E03AQHtC2BUAB6jkA/profile-displayphoto-shrink_100_100/0/1694687456770?e=1710374400&v=beta&t=ndmP3__bJjjA60t62U8lCwf_bck4TDX4LIp-qSsOgAc,Prithivi Da,https://www.linkedin.com/in/ACoAAANONyEBI75vYtjMK4f9hcDMhgneli34DsA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAANONyEBI75vYtjMK4f9hcDMhgneli34DsA,"
Building a Memory Assistant for Philomaths. Sharing wisdom from a 2 decade experience in creative problem solving.
","
Best write-up ever on LLM Agents by my favourite author Lilian Weng from OpenAI I devoured it like a fine tofu. You should too and checkout her other posts in LLMs to follow that up.https://lnkd.in/e5PBUve6

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7079821641832091648?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7079821641832091648%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQH9Gvy9ihoG5A/feedshare-shrink_480/0/1687961015255?e=1707955200&v=beta&t=h2IlFU3lAWglXJ_VLlkl1TvfqXobDmn_6u9ymfDyeVE
296,65a1057ba5b8f0720000227a,61938754-fdea-ab76-7734-76a7b6e6e6ae,https://media.licdn.com/dms/image/C4D03AQEmDwFNREkaIA/profile-displayphoto-shrink_100_100/0/1517524291944?e=1710374400&v=beta&t=9H8wRu-S3Mr0BN5zZEZBtWwefLpa0ZU_FPNQ9dTlNws,Robin Gras,https://www.linkedin.com/in/ACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ,"
Professor at University of Windsor, CSO and partner at Movyl Technologies and MVYL Associates
","
AbstractHow does language inform our downstream thinking? In particular, how do humans make meaning from language -- and how can we leverage a theory of linguistic meaning to build machines that think in more human-like ways? In this paper, we propose rational meaning construction, a computational framework for language-informed thinking that combines neural models of language with probabilistic models for rational inference. We frame linguistic meaning as a context-sensitive mapping from natural language into a probabilistic language of thought (PLoT) -- a general-purpose symbolic substrate for probabilistic, generative world modeling. Our architecture integrates two powerful computational tools that have not previously come together: we model thinking with probabilistic programs, an expressive representation for flexible commonsense reasoning; and we model meaning construction with large language models (LLMs), which support broad-coverage translation from natural language utterances to code expressions in a probabilistic programming language. We illustrate our framework in action through examples covering four core domains from cognitive science: probabilistic reasoning, logical and relational reasoning, visual and physical reasoning, and social reasoning about agents and their plans. In each, we show that LLMs can generate context-sensitive translations that capture pragmatically-appropriate linguistic meanings, while Bayesian inference with the generated programs supports coherent and robust commonsense reasoning. We extend our framework to integrate cognitively-motivated symbolic modules to provide a unified commonsense thinking interface from language. Finally, we explore how language can drive the construction of world models themselves.

          ‚Ä¶see more
        


Paper page - From Word Models to World Models: Translating from Natural Language to the Probabilistic Language of Thought
",,https://www.linkedin.com/feed/update/urn:li:activity:7078077890990395392?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7078077890990395392%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"
297,65a1057ba5b8f0720000227b,5c099622-03da-a7b5-3ec7-69a64146339a,https://media.licdn.com/dms/image/D4E03AQGiXHttEanAlQ/profile-displayphoto-shrink_100_100/0/1698777684597?e=1710374400&v=beta&t=sORMMiRym_C51JNd6GM_zzvFa1ytNzv-C-OW3I9ZYYA,Tanay Mehta,https://www.linkedin.com/in/ACoAACRs5-cBFISmyWYP0X_j7o-HJGznnYcRLg8?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACRs5-cBFISmyWYP0X_j7o-HJGznnYcRLg8,"
Data Science Graduate Student at the University of Bath | Kaggle Grandmaster | Ex NVIDIA | Open Source ML, LLMs and ML Software Engineering
","
üî¨ Fresh NLP research paper alert! Sharing the remarkable paper titled ""Full Parameter Fine-tuning for Large Language Models with Limited Resources"" authored by Kai Lv, Yuqing Yang, Tengxiao Liu, et al. from Fudan University, China üí°This work addresses the challenge of tuning the full parameters of Large Language Models (LLMs) with limited resources, a crucial step towards encouraging greater participation from researchers and advancing NLP applications.The researchers propose a novel optimizer called ""LOw-Memory Optimization (LOMO)"", which revolutionizes memory usage in LLM training. By integrating gradient computation and parameter update into a single step, LOMO significantly reduces memory requirements. Through the integration of LOMO with existing memory-saving techniques, memory usage is impressively reduced to just 10.8% compared to the standard approach! (DeepSpeed solution).The impact is staggering! This breakthrough enables the full parameter fine-tuning of a massive 65B model on a single machine equipped with 8√óRTX 3090, each with 24GB memory. With limited resources, researchers can now explore the vast potential of LLMs, driving innovation and benefiting both academia and society.Summary Points:- This paper proposes a new optimizer, LOw-Memory Optimization (LOMO), which reduces memory usage for full parameter fine-tuning of large language models (LLMs) with limited resources.- It is argued that larger models have a smoother loss surface, which should not have a large curvature when teaching natural language-based tasks.- Alternatives to gradient normalization and clipping are proposed, and a dynamic loss scaler is integrated with LOMO to mitigate precision degradation.- Results show that LOMO performs significantly better than Zero-shot, and generally outperforms LoRA in most experiments.- Future work aims to further lower the resource threshold required for training large language models, such as exploring parameter quantization techniques. Additionally, more applicable scenarios for LOMO and theoretical analyses for optimizing large language models will be investigated.üìÑ Paper: https://lnkd.in/d33MVrseüíª Code: https://lnkd.in/dTZyvdwe

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7080069890744680448?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7080069890744680448%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQE2WfEa22yFxg/feedshare-shrink_480/0/1687501038528?e=1707955200&v=beta&t=9odSUV0mLki6vwXjJSVMh3ILXNoiZWw9uK9KZKHdDe4
298,65a1057ba5b8f0720000227c,a58c37f8-9073-5b38-5967-26b67c792e70,https://media.licdn.com/dms/image/D5603AQGEADhHyEQ8rw/profile-displayphoto-shrink_100_100/0/1682553354695?e=1710374400&v=beta&t=kfjA-KO1Ea4gqAJ68vTh1_4ORnZzWv1qSW4bXFvg_tc,"Damien Benveniste, PhD",https://www.linkedin.com/in/ACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw,"
The ML Guy - Follow me to learn about Machine Learning Engineering, Machine Learning System Design, MLOps, and the latest techniques and news about the field. Join my AI newsletter and keep learning!
","
If you are looking for the ""best"" ACTIVATION function, be ready to spend some time looking for it because there are hundreds of them! Fortunately, you can safely cross-validate just a couple of them to find the right one. There are a few classes of activation functions (AF) to look out for:- The Sigmoid and Tanh based - Those activation functions were widely used prior to ReLU. People were very comfortable with those as they were reminiscent of Logistic Regression and they are differentiable. The problem with those is that, being squeezed between [0, 1] or [-1, 1], we had a hard time training deep networks as the gradient tends to vanish.- Rectified Linear Unit (ReLU https://lnkd.in/g8kgSfjT) back in 2011 changed the game when it comes to activation functions. I believe it became very fashionable after AlexNet won the ImageNet competition in 2012 (https://lnkd.in/gi27CxPF). We could train deeper models but the gradient would still die for negative numbers due to the zeroing in x < 0. Numerous AF were created to address this problem such as LeakyReLU and PReLU.- Exponential AF such as ELU (https://lnkd.in/geNqB2Mc) sped up learning by bringing the normal gradient closer to the unit natural gradient because of a reduced bias shift effect. They were solving for the vanishing gradient problem as well.- More recent AFs use learnable parameters such as Swish (https://lnkd.in/gAJb3cwd) and Mish (https://lnkd.in/gknpCc4g). Those adaptive AFs allow for different neurons to learn different activation functions for richer learning while adding parametric complexity to the networks.- The class of Gated Linear Unit (GLU) has been studied quite a bit in NLP architectures (https://lnkd.in/gHKgrd3d) and they control what information is passed up to the following layer using gates similar to the ones found in LSTMs. For example Google's PaLM model (https://lnkd.in/gakVMSwB) is trained with a SwiGLU activation (https://lnkd.in/gikSk2xD). Here is a nice review of many activation functions with some experimental comparisons: https://lnkd.in/g3jJGkyw. Looking at the PyTorch API (https://lnkd.in/gQtPSEN4) and the TensorFlow API (https://lnkd.in/gPcMSiED) can also give a good sense of what are the commonly used ones.----Receive 50 ML lessons (100 pages) when subscribing to our newsletter: TheAiEdge.ioWant to become an ML engineer? Join our next Masterclass: MasterClass.TheAiEdge.io#machinelearning #datascience #artificialintelligence

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7079481017337565184?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7079481017337565184%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQExWDbP-EHsKg/feedshare-shrink_480/0/1687854883753?e=1707955200&v=beta&t=8fxHyriDv7SmTxfUOeKdQQ5QYiRRNn-Xaj_XABLNFns
299,65a1057ba5b8f0720000227d,5ceb352e-eb86-a7e8-a05f-58b81b2a6baa,https://media.licdn.com/dms/image/C4E03AQH29xI6MM0P0A/profile-displayphoto-shrink_100_100/0/1548241763399?e=1710374400&v=beta&t=5ufJPp2CPRc2fnFqibJ10vAJY6s5s1d8ku2I6RCe04w,Bhoumik Shah,https://www.linkedin.com/in/ACoAABDZ6HEBoE8asUWi6JLWERskzACeCe_W7aE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABDZ6HEBoE8asUWi6JLWERskzACeCe_W7aE,"
Building SaaS for Logistics | Ex.Applied Scientist at Amazon | Ex.McKinsey | IITB
","
Long awaited GenAI vacation begins with Neha T.. (inspired by Sanyam Bhutani) Paper 1: Gorilla: Large Language Model Connected with Massive APIs [https://lnkd.in/gvv-D_Sj]Inspiration:- LLM‚Äôs potential to effectively use external tools via API calls remains unfulfilled- Limited context window does not allow us to give description of large numbers of APIs in prompt- API documentations changes frequently, it may not be possible to fine-tune LLM with every API changeSummary:- Developed an APIBench dataset consisting of 1645 machine learning APIs from HF, TorchHub, and TensorHub.- Generated synthetic dataset of 16450 query-API pairs using self-instruct- Fine-tuned a LLaMa-7B model using instruction fine-tuning- Conducted fine-tuning and inference in two settings: 0-shot and retrieval augmented- 0-shot: The model was trained to generate API requests solely based on user queries. During inference, only the user query was provided as the prompt. - Retrieval augmented: The API documentation of the relevant API was passed along with the user query as part of the prompt. During inference, the documentation of the relevant API was retrieved using BM25 or a GPT-based retrieval- Low accuracy of BM25 and GPT retrievals leads to cases where the documentation of a wrong API is passed to the LLM, resulting in poor performance.- The Oracle simulates a 100% accurate retrieval, it sets an upper-bound on performance improvement potential through more efficient retrievals.My take: [Refer figure in comment]- When using a retrieval system, Gorilla performs similarly to GPT 3.5. Therefore, if the goal is to build a general-purpose system capable of generalising to any APIs by simply adding documentation, Gorilla may not offer a significant advantage over GPT 3.5 [contrary to claims of author]- Gorilla 0-shot outperforms GPT 3.5 with a GPT retrieval. Hence, Gorilla 0-shot would be useful if you want LLM to use only a fixed set of APIs included in the training data. However, this performance gap can be narrowed by using a better retrieval system.- Gorilla model's performance in zero-shot setting is limited to the APIs within the training data. It may not generalise well to APIs outside of this data, and any API updates would require further fine-tuning- Why does Llama hallucinate more with retrieval (even Oracle)?Extensions:- There is a scope of building a robust retrieval system and ability to convert documents, user guides, code etc. to standard LLM readable API documents- Ability to ask follow-up questions if some API parameters are missing from user query would take us step closer to deploying this system in production- For a very specific task like converting user query to an API call, a smaller(~3.5B) model might give similar performance.- There is a need to go beyond a single API call, convert user query to multi-step API execution plan [aka Jarvis]#generativeai #llm #openai #copilot 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7076169361790533632?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7076169361790533632%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHtU7MEjI5quQ/feedshare-shrink_480/0/1687090243704?e=1707955200&v=beta&t=7zqNrVKTv_xXMQS19cqd_MXFoiebV9j9gF0mTaX_0WM
300,65a1057ba5b8f0720000227e,4be9240f-a741-b720-eaf0-f5d4e12347ad,https://media.licdn.com/dms/image/C4E0BAQH5ZTUMjFXhyg/company-logo_100_100/0/1630610511047/amazon_science_logo?e=1713398400&v=beta&t=q-4oOXo0BordU6VXkJqpj4R0M28LwU_BopSbigIgG8s,Amazon Science,https://www.linkedin.com/company/amazonscience/,"
327K followers
","
Computers are learning a sense of smell via the nascent science of digital olfaction. Osmo, an Amazon Alexa Fund company, uses machine learning to map the structure of a molecule directly to how humans perceive smell.#MachineLearning #AlexaFund

          ‚Ä¶see more
        


Can you teach a computer to smell? Osmo is trying
",,https://www.linkedin.com/feed/update/urn:li:activity:7074055653182341120?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7074055653182341120%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQG8RdCOPBFYfA/articleshare-shrink_800/0/1704065612227?e=1705658400&v=beta&t=L_Ap1etVj45nGJxcTopfIeI3IsJqnJ3tWbKEGm5YiNg
301,65a1057ba5b8f0720000227f,df22ff13-596f-9380-e4c5-400e582ffcdd,https://media.licdn.com/dms/image/D5603AQGEADhHyEQ8rw/profile-displayphoto-shrink_100_100/0/1682553354695?e=1710374400&v=beta&t=kfjA-KO1Ea4gqAJ68vTh1_4ORnZzWv1qSW4bXFvg_tc,"Damien Benveniste, PhD",https://www.linkedin.com/in/ACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw,"
The ML Guy - Follow me to learn about Machine Learning Engineering, Machine Learning System Design, MLOps, and the latest techniques and news about the field. Join my AI newsletter and keep learning!
","
With LangChain, it is not difficult to summarize text of any length. To summarize text with a LLM, there are a few strategies. If the whole text fits in the context window, then you can simply feed the raw data and get the result. LangChain refers to that strategy as the ‚Äústuff‚Äú chain type. Often, the number of tokens contained in the text is larger than the LLM's maximum capacity. A typical strategy is to break down the data into multiple chunks, summarize each chunk, and summarize the concatenated summaries in a final ""combine"" step. LangChain refers to this strategy as ‚Äúmap-reduce‚Äú.Another strategy is to begin the summary with the first chunk and refine it little by little with each of the following chunks. LangChain refers to this as ‚Äúrefine‚Äú. For example here is the prompt template used by LangChain for the refine step:""""""Your job is to produce a final summary We have provided an existing summary up to a certain point: {existing_answer} We have the opportunity to refine the existing summary (only if needed) with some more context below. ------------ {text} ------------ Given the new context, refine the original summary If the context isn't useful, return the original summary.""""""----Receive 50 ML lessons (100 pages) when subscribing to our newsletter: TheAiEdge.ioWant to become an ML engineer? Join our next Masterclass: MasterClass.TheAiEdge.io#machinelearning #datascience #artificialintelligence

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7071515173471076352?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7071515173471076352%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQELTC3lV-SOUw/feedshare-shrink_480/0/1685980598365?e=1707955200&v=beta&t=pTTAytyV-b8EgJc9_PmQQpHIXCrYjV8s-DKwxVPWy-E
302,65a1057ba5b8f07200002280,3f4e23e5-46d9-8353-9eb6-6387764707a9,https://media.licdn.com/dms/image/D5603AQGEADhHyEQ8rw/profile-displayphoto-shrink_100_100/0/1682553354695?e=1710374400&v=beta&t=kfjA-KO1Ea4gqAJ68vTh1_4ORnZzWv1qSW4bXFvg_tc,"Damien Benveniste, PhD",https://www.linkedin.com/in/ACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw,"
The ML Guy - Follow me to learn about Machine Learning Engineering, Machine Learning System Design, MLOps, and the latest techniques and news about the field. Join my AI newsletter and keep learning!
","
A lot about LLMs in just 3 pages! That is quite a good summary of LLMs' current state. This Cheatsheet is by Ashish Patel üáÆüá≥ and Abonia Sojasingarayar. Enjoy!----Find more similar content in my newsletter: TheAiEdge.io#machinelearning #datascience #artificialintelligence

          ‚Ä¶see more
        


Large Language Model Cheat Sheet
",,https://www.linkedin.com/feed/update/urn:li:activity:7071877613912285186?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7071877613912285186%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D1FAQHscStXx0Ecbg/feedshare-document-cover-images_480/0/1686066981981?e=1705658400&v=beta&t=93u0Fmpl43i9yURngiXzKRogNziZzpKO-CkrxA7vmCc
303,65a1057ba5b8f07200002281,cb864d7e-bd9f-98a3-7588-303c0e248bad,https://media.licdn.com/dms/image/C4E03AQHVyH-IfD1KbQ/profile-displayphoto-shrink_100_100/0/1629877234109?e=1710374400&v=beta&t=0UZUl_dDUxLaZn-Hu-zToqEDe3rpL5cB2JkP5_jlNXc,"Sebastian Raschka, PhD",https://www.linkedin.com/in/ACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU,"
Machine learning and AI researcher since the early days ‚Ä¢ coding and working with LLMs at Lightning AI ‚Ä¢ ex-statistics professor at University of Wisconsin-Madison
","
I often get requests to dispel some of the jargon behind transformers and LLMs!So here we go, my new article on ""Understanding Encoder and Decoder LLMs"".https://lnkd.in/gCYKTJnSIn short, in natural language processing, encoder, decoder, and hybrid architectures constitute diverse pathways to learning from texts. While both encoder and decoder architectures employ self-attention layers, their goals differ; encoders learn embeddings for predictive modeling tasks like classification, while decoders generate new text (for example, translating text or answering queries).Pioneering models like BERT and RoBERTa capitalized on the encoder architecture, while the GPT family of models made strides with decoders. And hybrid models such as BART and T5 integrate the strengths of both, exemplifying the transformative potential of combining diverse methods. #largelanguagemodels #ai #llm 

          ‚Ä¶see more
        


Understanding Encoder And Decoder LLMs
",,https://www.linkedin.com/feed/update/urn:li:activity:7075819596972249088?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7075819596972249088%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQFXctDAwU-_fA/articleshare-shrink_800/0/1704277993342?e=1705658400&v=beta&t=PsR81yRYtpgl97CKi4ojP4N-0P1tpNMUbbcCxzZ1YsA
304,65a1057ba5b8f07200002282,778b63bb-6cdc-28e8-d3c9-3e87de727302,https://media.licdn.com/dms/image/D5635AQEBzEFRC2EzLg/profile-framedphoto-shrink_100_100/0/1704907585971?e=1705658400&v=beta&t=x71pDAJzCbSPZxvt91sIkpmEr_5_pGLZIt6VZgw5eV0,Aman Chadha,https://www.linkedin.com/in/ACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU,"
GenAI Leadership @ Amazon AWS ‚Ä¢ Stanford AI ‚Ä¢ EB-1 ""Einstein Visa"" Recipient/Mentor ‚Ä¢ Ex-Ô£ø, Amazon Alexa, Nvidia, Qualcomm ‚Ä¢ EMNLP 2023 Outstanding Paper Award
","
 üß† All you need to know about Transformers, BERT, and GPTHere‚Äôs a bunch of #nlp primers to master important topics.üîπ Transformers: http://transformer.aman.ai- Mathematical background (Vectors, Matrix Multiplication, Dot Product, Masking, Sampling)- Attention (Additive/Multiplicative/Dot Product Attention, Self/Cross-Attention, Multihead Attention)- Core components of the Transformer Architecture (Embeddings, Positional Encoding, Skip Connections, Layer Normalization, Softmax)- Top-level Transformer Architecture (Encoder and Decoder stack)- Implementation details (Byte-Pair Encoding, Teacher Forcing, Label Smoothing)- Lessons learned (What are Transformers learning? Why is training them so hard?)- Pros/cons of Transformers relative to CNNs/RNNs- Relation between Transformers and Graph Neural Networksüîπ BERT: http://bert.aman.ai- Background: Pre-Training, Transformer Encoder- Contextualized Embeddings- Masked Language Modeling (MLM)- Next Sentence Prediction (NSP)- BERT‚Äôs Encoder Architecture vs. Other Decoder Architectures- The Strength of Bidirectionality- Supervised Fine-Tuningüîπ GPT: http://gpt.aman.ai- Background: Generative Pre-Training, Transformer Decoder- GPT-1: Improving Language Understanding by Generative Pre-Training- GPT-2: Language Models are Unsupervised Multitask Learners- GPT-3: Language Models are Few-Shot Learnersüëâüèº Connect/follow for more AI resources and drop me a message to share feedback!#artificialintelligence #machinelearning #ai #ml #deeplearning #computervision #speechrecognition #mlengineer #neuralnetworks

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7075687259630440448?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7075687259630440448%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHKD532Ec7DHA/feedshare-shrink_480/0/1686975301430?e=1707955200&v=beta&t=JBA9TcXMoQj6rk6KKFHjDhUGGIbOyHPzMSCv3RRu9BE
305,65a1057ba5b8f07200002283,947684ec-644a-8afe-2ef3-cb57740ab623,https://media.licdn.com/dms/image/D5603AQF5pJ6T7vIcUQ/profile-displayphoto-shrink_100_100/0/1674324994434?e=1710374400&v=beta&t=owiWeuxDD_cOkwy2kzTZt37IoQ8adqYl5TU7q_9rytk,Sudalai Rajkumar - SRK,https://www.linkedin.com/in/ACoAAAo06hgBCvufxwCCRJRMiq81GWx9xYQDEHI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAo06hgBCvufxwCCRJRMiq81GWx9xYQDEHI,"
Head of AI & ML @ Growfin | 4x Kaggle Grandmaster | AI Advisor
","
ICYMI -  The recent ""State of GPT"" talk by Andrej Karpathy at Microsoft Build is  one of the best talks about the current state of LLMs. A lot of information is packed in this 40 min talk about‚¶ø GPT training pipelines and their intuitions‚¶ø An understanding of how LLMs think / work‚¶ø How to leverage prompts to get better results‚¶ø Leveraging tools / plugins with LLMs to build applicationsLink: https://lnkd.in/gkJppW2MA must watch!#GPT #LLMs

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7074617759258591232?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7074617759258591232%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHSQH1dL7Cmpg/feedshare-shrink_480/0/1686720312621?e=1707955200&v=beta&t=0-vt3XvOd-BlcSUObh0MWOF4jnxJcLeqXInF_xCuK08
306,65a1057ba5b8f07200002284,aabf68d2-61ed-7eec-7edd-43c4dacb3dfe,https://media.licdn.com/dms/image/C5603AQFn_xSEHinw3g/profile-displayphoto-shrink_100_100/0/1520362182641?e=1710374400&v=beta&t=OfZSzuLDjKdAUxwezeVDS4onRtVcxS2aew0u2gu2Cig,"Vivek Das, PhD, M.Sc.",https://www.linkedin.com/in/ACoAAAUtbH0B5DTAsz0fsOvt7iRHUYTUZw7_WgY?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAUtbH0B5DTAsz0fsOvt7iRHUYTUZw7_WgY,"
Lead Data Scientist @ Novo Nordisk | Integrated Omics in Clinical Trials | Computational Systems Biology | Data Science I Applied ML/AI | Innovation | Mentor | Thought Leader
","
A very interesting survey publication encouraging researchers from field of NLP, Bioinformatics, Biologists & relevant Data Science field join forces to enrich & foster future interdisciplinary research in biomedicine and drug discovery. üòÉ‚ÄúThe recent development of transformer-based language models has substantially enriched the NLP field with novel architectures of self-attention that can greatly improve model accuracy, efficiency and interpretability. As a new potential force, transformer-based models have brushed up on SOTA performance with a large margin in most bioinformatics tasks.‚Äù

          ‚Ä¶see more
        


Applications of transformer-based language models in bioinformatics: a survey
",,https://www.linkedin.com/feed/update/urn:li:activity:7073704383095414784?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7073704383095414784%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQFiuZvh-waEUA/articleshare-shrink_800/0/1704131445576?e=1705658400&v=beta&t=5THyaCN-tL_U6VcuOCcDVso5IQmsdL5JgpkDCvgxrMI
307,65a1057ba5b8f07200002285,912bf26f-af49-8e62-044f-f0790b42ff4a,https://media.licdn.com/dms/image/C4E0BAQFnrCtK_RBm8A/company-logo_100_100/0/1659136408730/pyquant_news_logo?e=1713398400&v=beta&t=xTsb25lppJb2q5UHORJx5VzfdVIgn1PplrkccG-tCrQ,PyQuant News üêç,https://www.linkedin.com/company/pyquant-news/,"
35K followers
","
Free code from book: Algorithmic Trading with PythonAlgorithmic Trading with Python discusses modern quant trading methods in Python with a heavy focus on pandas, numpy, and scikit-learn.Get the code here:https://lnkd.in/gQ6ngEyV

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7073090710639427584?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7073090710639427584%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5610AQGEozx5vXuNPA/image-shrink_480/0/1686356237016?e=1705658400&v=beta&t=kzv_7LuuhowH7LAMlnBahsS6rz18T7-aN16h-WtY2BQ
308,65a1057ba5b8f07200002286,60f75a42-da12-9601-7deb-a3d74bed7b1b,https://media.licdn.com/dms/image/D4E03AQHiSo-xKDv6DQ/profile-displayphoto-shrink_100_100/0/1704885310096?e=1710374400&v=beta&t=9fQjXy_lA03kewsS2E2YMzAetRGdnwj0E1XxW1P1QPE,Ben Moseley,https://www.linkedin.com/in/ACoAAAflRV0BUPrFjPjcqd5trQaECv9eGjSkJqU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAflRV0BUPrFjPjcqd5trQaECv9eGjSkJqU,"
Postdoctoral Fellow at ETH Z√ºrich AI Center | Scientific Machine Learning
","
Very excited to announce that our entire ETH Z√ºrich Deep Learning in Scientific Computing Master's course is now on YouTube! üìñCourse learning objectives:‚úÖ Be aware of advanced applications of deep learning in scientific computing‚úÖ Be familiar with the design, implementation and theory of these algorithms‚úÖ Understand the pros/cons of using deep learning‚úÖ Understand key scientific machine learning concepts and themesProf. Siddhartha Mishra and I will talk you through a wide variety of scientific machine learning algorithms and applications, including physics-informed neural networks, neural operators, neural differential equations, differentiable physics and their applications in fluid dynamics, geophysics, engineering and more.#deeplearning #computing #SciML #algorithms #PDEs

          ‚Ä¶see more
        


ETH Z√ºrich DLSC: Course Introduction
",,https://www.linkedin.com/feed/update/urn:li:activity:7075033481746993152?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7075033481746993152%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQHFetvX1Xm_0w/articleshare-shrink_800/0/1704794670321?e=1705658400&v=beta&t=knZflDvPS6KUO5nCkBQ8-IWBncBZ4EviJwbMq3IwFFk
309,65a1057ba5b8f07200002287,94979af2-91ee-93d9-1922-518c453797f9,https://media.licdn.com/dms/image/C4E0BAQEH4nbL2sl5gA/company-logo_100_100/0/1635539130887/facebookai_logo?e=1713398400&v=beta&t=sFixUTJyqFvVkiEiDy7X9VTcRcgGTR2jo-a3QyjRJ70,AI at Meta,https://www.linkedin.com/company/aiatmeta/,"
672K followers
","
Introducing Voicebox, a new breakthrough generative speech system by Meta AI that can synthesize speech across six languages, perform noise removal, edit content, transfer audio style & more.More details & examples ‚û°Ô∏è https://bit.ly/3Naa1ItVoicebox generalizes across tasks and outperforms single-purpose AI models through in-context learning. Unlike prior autoregressive models, it can modify any part of a given sample ‚Äî not just the end of a clip. It also beats the previous state of the art with improvements on word error rates and audio similarity while delivering all of this with 20x faster performance.This work represents an important step forward for this field of research. Just as other work has done for images and text, we believe the generalization and scalability of Voicebox could usher in a new era of generative AI for speech, and we're excited to continue pushing it forward.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7075533881214451712?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7075533881214451712%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5605AQEER4RfEJd6Dg/feedshare-thumbnail_720_1280/0/1686938668813?e=1705658400&v=beta&t=1cx1XWs8C3Ye8NaqDqEiqQVmg5qdXpfAgi599lemlxs
310,65a1057ba5b8f07200002288,c61e817c-081a-fecb-cb1e-9cf78907d799,https://media.licdn.com/dms/image/D4E03AQHtC2BUAB6jkA/profile-displayphoto-shrink_100_100/0/1694687456770?e=1710374400&v=beta&t=ndmP3__bJjjA60t62U8lCwf_bck4TDX4LIp-qSsOgAc,Prithivi Da,https://www.linkedin.com/in/ACoAAANONyEBI75vYtjMK4f9hcDMhgneli34DsA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAANONyEBI75vYtjMK4f9hcDMhgneli34DsA,"
Building a Memory Assistant for Philomaths. Sharing wisdom from a 2 decade experience in creative problem solving.
","
ùó£ùóòùóôùóß (ùó£ùóÆùóøùóÆùó∫ùó≤ùòÅùó≤ùóø-ùóòùó≥ùó≥ùó∂ùó∞ùó∂ùó≤ùóªùòÅ ùóôùó∂ùóªùó≤-ùòÅùòÇùóªùó∂ùóªùó¥) ùòÄùóΩùóÆùó∞ùó≤ ùó∂ùòÄ ùòÄùó∞ùóÆùóøùó∂ùóπùòÜ ùóØùòÇùòÄùòÜ, Here is a mental model.Choosing a PEFT is simply matching them with your objectives.‚Üí Prompt Tuning:ùó™ùóµùóÆùòÅ: Prompt Tuning involves learning a set of continuous, trainable params that modify the pre-trained LLM's hidden states in response to task-specific prompts during inference, effectively fine-tuning the model at inference time.ùó™ùóµùó≤ùóª ùòÅùóº ùòÇùòÄùó≤: Prompt Tuning is a good choice when you have a large pre-trained LLM but want to fine-tune it for multiple different ùôôùô§ùô¨ùô£ùô®ùô©ùôßùôöùôñùô¢ ùô©ùôñùô®ùô†ùô® ùôñùô© ùôûùô£ùôõùôöùôßùôöùô£ùôòùôö ùô©ùôûùô¢ùôö with minimal computational resources. It is also useful when you want to generate diverse and high-quality text outputs based on specific prompts.‚Üí LoRA:ùó™ùóµùóÆùòÅ: LoRA (Low-Rank Adaptation) is a technique that modifies the pre-trained LLM's attention mechanism during fine-tuning by introducing a low-rank matrix factorization that learns task-specific attention patterns.ùó™ùóµùó≤ùóª ùòÅùóº ùòÇùòÄùó≤: LoRA is a good choice when you want to fine-tune a pre-trained LLM for a specific ùôôùô§ùô¨ùô£ùô®ùô©ùôßùôöùôñùô¢ ùô©ùôñùô®ùô† ùô©ùôùùôñùô© ùôßùôöùô¶ùô™ùôûùôßùôöùô® ùô©ùôñùô®ùô†-ùô®ùô•ùôöùôòùôûùôõùôûùôò ùôñùô©ùô©ùôöùô£ùô©ùôûùô§ùô£ ùô•ùôñùô©ùô©ùôöùôßùô£ùô®. It is also useful when you have limited computational resources and want to reduce the number of trainable parameters in the model.‚Üí Adapters:ùó™ùóµùóÆùòÅ: Adapters are tiny NN modules that are added to pre-trained LLMs, typically between the pre-trained layers, to adapt the model to new downstream tasks. During fine-tuning, only the weights of the adapter are learned, while the pre-trained model's parameters remain fixed.ùó™ùóµùó≤ùóª ùòÅùóº ùòÇùòÄùó≤: When you need to fine-tune ùô¢ùô™ùô°ùô©ùôûùô•ùô°ùôö ùôôùô§ùô¨ùô£ùô®ùô©ùôßùôöùôñùô¢ ùô©ùôñùô®ùô†ùô® ùô§ùô£ ùô©ùôùùôö ùô®ùôñùô¢ùôö ùô•ùôßùôö-ùô©ùôßùôñùôûùô£ùôöùôô ùô¢ùô§ùôôùôöùô°. Additionally, Adapters are flexible and can be quickly and easily plugged into different parts of the pre-trained model without requiring major modifications.‚Üí Prefix Tuning:ùó™ùóµùóÆùòÅ: Prefix tuning involves adding a small trainable prefix to the input of the pre-trained LLM during fine-tuning, which modifies the representation learned by the pre-trained model to better suit the downstream task.ùó™ùóµùó≤ùóª ùòÅùóº ùòÇùòÄùó≤: When you want to fine-tune a pre-trained LLM for a specific downstream task and have limited computational resources when you want to ùô¢ùô§ùôôùôûùôõùôÆ ùô©ùôùùôö ùôßùôöùô•ùôßùôöùô®ùôöùô£ùô©ùôñùô©ùôûùô§ùô£ ùô°ùôöùôñùôßùô£ùôöùôô ùôóùôÆ ùô©ùôùùôö ùô•ùôßùôö-ùô©ùôßùôñùôûùô£ùôöùôô ùô¢ùô§ùôôùôöùô° for a particular task.Papers:‚Ä¢ ""Adapters‚Äù - https://lnkd.in/epXRCzRN‚Ä¢ ‚ÄúLoRA‚Äù. https://lnkd.in/eFGq3yZW‚Ä¢ ""Prefix-Tuning‚Äù. https://lnkd.in/eJ9ixFpk‚Ä¢ ‚ÄúPrompt Tuning‚Äù - https://lnkd.in/ezB5zM8Q Repos:‚Ä¢ LoRA https://lnkd.in/exAMvMfG‚Ä¢ HuggingFace PEFT: https://lnkd.in/e7b-uzMN______________________Got some value from this post? Consider saving it using SaveLikeAPRO 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7075343751820275712?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7075343751820275712%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQEZguTSGTbLdQ/feedshare-shrink_480/0/1686883868619?e=1707955200&v=beta&t=Vc57YsweRu94VkPT8mUN23NPjz0lq1NPllfjcTFZu1c
311,65a1057ba5b8f07200002289,d8bec227-82f5-3364-818c-575e574c3926,https://media.licdn.com/dms/image/D5603AQGEADhHyEQ8rw/profile-displayphoto-shrink_100_100/0/1682553354695?e=1710374400&v=beta&t=kfjA-KO1Ea4gqAJ68vTh1_4ORnZzWv1qSW4bXFvg_tc,"Damien Benveniste, PhD",https://www.linkedin.com/in/ACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw,"
The ML Guy - Follow me to learn about Machine Learning Engineering, Machine Learning System Design, MLOps, and the latest techniques and news about the field. Join my AI newsletter and keep learning!
","
Behavioral interviews can be the deciding factor for people to decide if they could see themselves working with the interviewing candidate. It doesn't have to be a difficult interview! You just need to project the persona that represents the highest return on investment for the team and company in the next couple of years!Here is a cheatsheet for better guidance on the subject. Source: https://lnkd.in/gTEbj9dx----Receive 50 ML lessons (100 pages) when subscribing to our newsletter: TheAiEdge.ioWant to become an ML engineer? Join our next Masterclass: MasterClass.TheAiEdge.io#machinelearning #datascience #artificialintelligence

          ‚Ä¶see more
        


Behavioral Interviews CheatSheet! 
",,https://www.linkedin.com/feed/update/urn:li:activity:7067889952402894848?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7067889952402894848%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E1FAQE8pl2XlbzeVw/feedshare-document-cover-images_480/0/1685116227957?e=1705658400&v=beta&t=rwLuJEBhjyB5PRH0H3ZltoB6QAU8ruI25ZJRsL-HUnU
312,65a1057ba5b8f0720000228a,c61f464f-f961-c268-2189-e98b683f221a,https://media.licdn.com/dms/image/C4D03AQEmDwFNREkaIA/profile-displayphoto-shrink_100_100/0/1517524291944?e=1710374400&v=beta&t=9H8wRu-S3Mr0BN5zZEZBtWwefLpa0ZU_FPNQ9dTlNws,Robin Gras,https://www.linkedin.com/in/ACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ,"
Professor at University of Windsor, CSO and partner at Movyl Technologies and MVYL Associates
","

 

Untangling the Human Mind: The Interplay Between Cognition and Personality - Neuroscience News
",,https://www.linkedin.com/feed/update/urn:li:activity:7070378455997042688?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7070378455997042688%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQEQ33Cq5FcwBg/articleshare-shrink_800/0/1705037031372?e=1705658400&v=beta&t=Fo8hgR1b6sa6-c_1OxX8GOqZgME_6e8VJrV1CepKiYQ
313,65a1057ba5b8f0720000228b,174810e1-a2e2-40a0-34c8-bfdc9b31c5a9,https://media.licdn.com/dms/image/D4D03AQEjbencXzN2dg/profile-displayphoto-shrink_100_100/0/1701877154602?e=1710374400&v=beta&t=5ChbFh_atWspP0GcT-3L9kInL3iOYVzkU49o1tN2m2o,Mohan Nayak,https://www.linkedin.com/in/ACoAABOoNvUBrUMnp4rDYjz5coBw2cSCMO2UCEI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABOoNvUBrUMnp4rDYjz5coBw2cSCMO2UCEI,"
Aspiring Data Analyst | Python,Pandas, Numpy, Data Visualization, SQL, Excel,AWS
","
Here are some notes on trees:1. Definition: In computer science, a tree is a widely used data structure that represents a hierarchical structure. It consists of nodes connected by edges, where each node can have zero or more child nodes, except for the root node, which has no parent.2. Terminology:Root: The topmost node of the tree, which has no parent.Parent: A node that has one or more child nodes.Child: A node that has a parent node.Sibling: Nodes that share the same parent node.Leaf: A node with no children.Depth: The length of the path from the root to a particular node.Height: The length of the longest path from a node to a leaf. The height of the tree is the height of the root node.3. Types of Trees:Binary Tree: A tree in which each node has at most two children, often referred to as the left child and the right child.Binary Search Tree (BST): A binary tree where the left child is less than or equal to the parent, and the right child is greater than the parent. It allows efficient searching, insertion, and deletion operations.Balanced Tree: A tree in which the heights of the left and right subtrees of any node differ by at most one. Examples include AVL trees and Red-Black trees.B-tree: A self-balancing search tree that can have multiple keys per node and is commonly used in databases and file systems.Trie: A tree-like data structure used for efficient retrieval of keys associated with values, often used for dictionaries or autocomplete functionality.4. Tree Traversal:Pre-order: Visit the root node, then recursively traverse the left subtree, and finally the right subtree.In-order: Traverse the left subtree, visit the root node, and then traverse the right subtree. In the case of binary search trees, this gives a sorted order.Post-order: Traverse the left subtree, then the right subtree, and finally visit the root node.Level-order: Visit nodes at each level from left to right, starting from the root and moving down the tree level by level.5. Common Operations: Insertion: Adding a new node to the tree in the appropriate position based on certain rules. Deletion: Removing a node from the tree while maintaining the tree structure and any applicable properties.Searching: Finding a specific node or value in the tree by traversing the nodes based on certain conditions.Tree balancing: Performing operations to maintain or restore balance in a tree, such as AVL tree rotations or Red-Black tree color changes.Credit @Karun Karthik #data #computerscience 

          ‚Ä¶see more
        


Trees Notes
",,https://www.linkedin.com/feed/update/urn:li:activity:7070306575009112064?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7070306575009112064%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D561FAQFUF3HzJhO4vg/feedshare-document-cover-images_480/0/1685680780982?e=1705658400&v=beta&t=a4dGiJgEq_8APdSrKYiWwT1bq4odblOADfkMUYP-bOA
314,65a1057ba5b8f0720000228c,6f9a409b-8260-554e-1348-223a6bfed2c6,https://media.licdn.com/dms/image/C4D03AQH8NgmRA2aP2g/profile-displayphoto-shrink_100_100/0/1656245861490?e=1710374400&v=beta&t=T4BUS48m9p-krjsd1sIyE4YXEe02vLY030Smig-tRMk,Abid Ali Awan,https://www.linkedin.com/in/ACoAADaHYa8B7ovXnIHkBGBxCKESgHzacbleFDo?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADaHYa8B7ovXnIHkBGBxCKESgHzacbleFDo,"
Data Scientist | Technical Writer | Editor
","
Top free tools for detecting thesis, research papers, assignments, documentation, and blogs generated by AI models.https://lnkd.in/eDWDk9F3#gpt4 #chatgpt #claude #bard

          ‚Ä¶see more
        


Top 10 Tools for Detecting ChatGPT, GPT-4, Bard, and Claude - KDnuggets
",,https://www.linkedin.com/feed/update/urn:li:activity:7068997334088474624?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7068997334088474624%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQFGqGi7mrfmkQ/articleshare-shrink_800/0/1704939177855?e=1705658400&v=beta&t=-zm0TKeblRw5ENzuc1jORQvShkePvgn4qxfJgYOaZdo
315,65a1057ba5b8f0720000228d,f2131083-a638-8101-6ee2-e8c6aa14971e,https://media.licdn.com/dms/image/C4E0BAQFnrCtK_RBm8A/company-logo_100_100/0/1659136408730/pyquant_news_logo?e=1713398400&v=beta&t=xTsb25lppJb2q5UHORJx5VzfdVIgn1PplrkccG-tCrQ,PyQuant News üêç,https://www.linkedin.com/company/pyquant-news/,"
35K followers
","
150+ quantitative finance Python programs to help you gather, manipulate, and analyze stock market data.Free code on GitHub:Here's what's in the repo:‚Ä¢ Classification‚Ä¢ Screen stocks‚Ä¢ Portfolio strategiesAnd a lot more:https://lnkd.in/gNtaSAuH

          ‚Ä¶see more
        


GitHub - shashankvemuri/Finance: 150+ quantitative finance Python programs to help you gather, manipulate, and analyze stock market data
",,https://www.linkedin.com/feed/update/urn:li:activity:7068202755361832960?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7068202755361832960%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5610AQF4mRoegdcjVQ/image-shrink_800/0/1685190857667?e=1705658400&v=beta&t=gFV6xnf_Aw1J5RJjdItmJf8FSdBpgyiXV0fa0DtoAbQ
316,65a1057ba5b8f0720000228e,76e891c1-556f-059b-40cd-f7a99e77620a,https://media.licdn.com/dms/image/C4E03AQGfzEtRhrPHdw/profile-displayphoto-shrink_100_100/0/1619776973437?e=1710374400&v=beta&t=y9up1yBFMNfTMJvaDgcupbnl3OnJC7EgkzWAkOY4pyM,Sanyam Bhutani,https://www.linkedin.com/in/ACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0,"
Senior Data Scientist at H2O.ai | Kaggle Grandmaster
","
OpenAI Cookbook: Guide for using the GPT-4 API! üßë‚Äçüç≥ The Cookbook is a collection of crispy examples curated around different accomplishing common tasks with the API. If you're interested in building LLM powered applications, this is a very hands-on collection of examples with great code readability. In my experience, while the repository doesn't have an end to end flow with examples going from 0 to 100, it can be consumed in any order. I would suggest spending an evening going through the examples and re-implementing some of them. It really helped me understand embeddings and their workflow compared to the many other scattered tutorials out there:https://lnkd.in/dMequfBU

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7067667074231279616?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7067667074231279616%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQHkT174YINzGA/feedshare-shrink_480/0/1685063140736?e=1707955200&v=beta&t=xvL9joEZU21Op4rZR5QIvu54aKFW5SYjmF2fthkpP98
317,65a1057ba5b8f0720000228f,b551df9e-a22e-2346-d8c6-174dbcb2a40a,https://media.licdn.com/dms/image/D5603AQFudpdN1bt1Ig/profile-displayphoto-shrink_100_100/0/1703902906401?e=1710374400&v=beta&t=yZEVjCU4yJgJLcDDi258e9COnwi9nmtTcbnGML2R7JI,Vijay Chollangi üõ°,https://www.linkedin.com/in/ACoAADWWws0BnXRHGqBbPCjc7IrQw-C0Zo2DCF8?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADWWws0BnXRHGqBbPCjc7IrQw-C0Zo2DCF8,"
üßë‚ÄçüíªùêÄùêà ùêÑùêßùê≠ùê°ùêÆùê¨ùê¢ùêöùê¨ùê≠ ü§ñ||ùüñùüìùêä+ FamüöÄ||FullStack Java Developer||Building LinkedIn [ùê•ùêß] ||Passionate About Technology || Open for promotions || Helping Brands To Grow üìà||ùüëùüìùêåùê¢ùê•ùê•ùê¢ùê®ùêß+ Views||
","
üéäüî•Ultimate Cheat Sheets of Machine learning,  Deep learning and Artificial Intelligence üìöüî•
 

Data Science ‚ô®Ô∏è 
",,https://www.linkedin.com/feed/update/urn:li:activity:7067567725329436672?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7067567725329436672%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D561FAQG_BzYgrScWTQ/feedshare-document-cover-images_480/0/1685026818222?e=1705658400&v=beta&t=9U5IJxGcOXJo0blyXMP22xtWLQGzWv9AFAdpEoMeQiw
318,65a1057ba5b8f07200002290,8e481d50-e2ab-760e-4409-fb8ef04ea790,https://media.licdn.com/dms/image/C5603AQFqqGLBWJsyTQ/profile-displayphoto-shrink_100_100/0/1554819291662?e=1710374400&v=beta&t=BiRVCt_P7eT36qS21AUmybEQIuvMfHI4A4biG5dbbpE,Vahid M.,https://www.linkedin.com/in/ACoAAASV5GkBs70SN-jcISm3XwCtNuLHnVjBQHs?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAASV5GkBs70SN-jcISm3XwCtNuLHnVjBQHs,"
Data Scientist
","
A Review of Most Popular Optimizers for Training Neural NetworksIn this video (https://lnkd.in/g7WEHSVs), I describe 16 most popular optimization algorithms for training neural networks, starting from the basics of Gradient Descent algorithm, to more advanced ones like the Adam family of optimizers and Lookahead optimizer.I have categorized these optimizers into 5 categories shown in this image based on their update equation. If you are interested, feel free to check out my video: https://lnkd.in/g7WEHSVs #neuralnetworks #algorithms 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7066827292303323136?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7066827292303323136%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQF7vYFufB1Mbw/feedshare-shrink_480/0/1684848961086?e=1707955200&v=beta&t=PzDeJXxC964n0TXG9BqHR3Wml4Rpk3O1xAHBnINIB8k
319,65a1057ba5b8f07200002291,4451d074-10d8-a905-de4f-2234ddd4cb02,https://media.licdn.com/dms/image/D4D35AQF4p4ECqiKgnw/profile-framedphoto-shrink_100_100/0/1689748802619?e=1705658400&v=beta&t=aGbRWKULWfPRLPUZnQRYCv-dGic0lV0U64oQQlUNSsA,Atul Anand,https://www.linkedin.com/in/ACoAACcGI7IB-ezpONiwehhynPhMzfhvLCMqpaM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACcGI7IB-ezpONiwehhynPhMzfhvLCMqpaM,"
Consultant @ Deloitte | Designing AI Solutions
","
Scikit-LLM: Sklearn Meets Large Language ModelsIt comes with RoadMap:-* Zero-Shot Classification with OpenAI GPT 3/4* Multiclass classification* Multi-label classification* ChatGPT models* InstructGPT models* Few shot classifier* GPT Vectorizer * GPT Fine-tuning (optional) * Integration of other LLMsFor hands-on code check the GitHub:-

          ‚Ä¶see more
        


GitHub - iryna-kondr/scikit-llm: Seamlessly integrate powerful language models like ChatGPT into scikit-learn for enhanced text analysis tasks.
",,https://www.linkedin.com/feed/update/urn:li:activity:7066758440211095552?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7066758440211095552%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQF_XMRrMvnq-Q/articleshare-shrink_800/0/1704864565352?e=1705658400&v=beta&t=2n5l8bo-spB2M4SEDGwDFIQYyPX2hIffXHqmoKp0p9M
320,65a1057ba5b8f07200002292,6727e8b1-1537-edd7-bd47-2816327edc73,https://media.licdn.com/dms/image/D4D03AQFrh40bgEhFaw/profile-displayphoto-shrink_100_100/0/1666072954798?e=1710374400&v=beta&t=yWCZJdi89BcjFrZAC4AumkX567BXtK8wefoZB99RotA,Rashmi Margani,https://www.linkedin.com/in/ACoAABoSGHwB93YgMMhUhD28-dfmsdLXnCaRWF8?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABoSGHwB93YgMMhUhD28-dfmsdLXnCaRWF8,"
Sr Machine Learning Engineer | 2X Kaggle Master, Certified Tensorflow Developer | Generative AI
","
Scikit-LLM: Sklearn Meets Large Language ModelsIt comes with RoadMap:-* Zero-Shot Classification with OpenAI GPT 3/4* Multiclass classification* Multi-label classification* ChatGPT models* InstructGPT models* Few shot classifier* GPT Vectorizer * GPT Fine-tuning (optional) * Integration of other LLMsFor hands-on code check the GitHub:- https://lnkd.in/gTTzDhQ5

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7066271910254301184?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7066271910254301184%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQEGcKM6nEASUQ/feedshare-shrink_480/0/1684730507268?e=1707955200&v=beta&t=YzLcnKfHGqeaCfCUkur2omUR3jtlod9X2sptJOkNggo
321,65a1057ba5b8f07200002293,c8c75d9e-186e-4e33-a805-f7f96e315c20,https://media.licdn.com/dms/image/D4E35AQG9fKKgsfYkdQ/profile-framedphoto-shrink_100_100/0/1704411574886?e=1705658400&v=beta&t=Q36HOZCptyGoMyW-3G4QyTXlau2zPegu1XLY2jLNgVI,Manohar Sai Alapati,https://www.linkedin.com/in/ACoAADIuXOABZ9lwiravwEOR-AMVIWOIP553A-M?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADIuXOABZ9lwiravwEOR-AMVIWOIP553A-M,"
Graduate Research Assistant @ CMU | Artificial Intelligence Engineering | Actively Seeking Summer Internships
","
Did you ever wonder why exactly we use sigmoid function for binary classification, other than just matching the range of output?The answer lies in Generalized Linear Models (GLMs). GLMs extend the linear regression which implies modelling a Gaussian output, to model other distributions like Bernoulli for classification, Poisson for counts, etc.It does so, by adding a link function to the output of linear regression specific to the type of distribution we are interested in. And turns out, the link function for modelling a bernoulli distribution is derived to be a sigmoid.Learn more about this here! https://aman.ai/cs229/glm/#machinelearning #logisticregression #linearregression #statisticalmodeling 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7062267258894524417?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7062267258894524417%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQHZnD6yjpyziw/feedshare-shrink_480/0/1683775723761?e=1707955200&v=beta&t=P3jEaSgOF8sXhi02RIHQaXNeRfR3Gd79Y36pQKxqEvU
322,65a1057ba5b8f07200002294,28a679a3-f3d3-078a-8873-f032dae238f9,https://media.licdn.com/dms/image/C4D03AQFTwrdIn8d-mA/profile-displayphoto-shrink_100_100/0/1604245712566?e=1710374400&v=beta&t=l4-FrAa7wImnnZDPnH93cJEv7BZODxi5FSckrSiPUPI,Giannis Tolios,https://www.linkedin.com/in/ACoAAA4S6wIBSZyJZDZq6NnoXsAqh64btIYNPTE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA4S6wIBSZyJZDZq6NnoXsAqh64btIYNPTE,"
Data Scientist | Book Author at Leanpub | Contributor at Towards Data Science | Passionate about Climate Change Mitigation
","
ùóôùó≤ùóÆùòÅùòÇùóøùó≤ ùóòùóªùó¥ùó∂ùóªùó≤ùó≤ùóøùó∂ùóªùó¥ ùó≥ùóºùóø ùóßùó∂ùó∫ùó≤ ùó¶ùó≤ùóøùó∂ùó≤ùòÄ!üí°tsfresh is a python library that can be used for feature engineering of time series and other sequential data. The extracted features provide valuable insights about the statistical properties and dynamics of time series. Furthermore, the features can also be used to train machine learning models for classification, regression, clustering and other tasks. Have you ever applied feature engineering on time series data? You can check the links below for more information, and make sure to follow me for regular data science content!ùòÅùòÄùó≥ùóøùó≤ùòÄùóµ ùóöùó∂ùòÅùóµùòÇùóØ ùóøùó≤ùóΩùóºùòÄùó∂ùòÅùóºùóøùòÜ: https://lnkd.in/dCKNSmNrùóüùó≤ùóÆùóøùóª ùó†ùóü ùóÆùóªùó± ùóßùó∂ùó∫ùó≤ ùó¶ùó≤ùóøùó∂ùó≤ùòÄ ùóôùóºùóøùó≤ùó∞ùóÆùòÄùòÅùó∂ùóªùó¥ ùòÑùó∂ùòÅùóµ ùó£ùòÜùóñùóÆùóøùó≤ùòÅüìö: https://lnkd.in/dyByK4Fùóüùó≤ùóÆùóøùóª ùóóùóÆùòÅùóÆ ùó¶ùó∞ùó∂ùó≤ùóªùó∞ùó≤ ùòÑùó∂ùòÅùóµ ùóïùóøùó∂ùóπùóπùó∂ùóÆùóªùòÅüìö: https://bit.ly/3AphMUY#datascience #python #machinelearning #deeplearning #linkedin

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7064278183855931392?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7064278183855931392%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQF9oK0bxW347A/feedshare-shrink_480/0/1684255165627?e=1707955200&v=beta&t=Yvevi_aLkS4HTQACgQKpbAV5tZQnclpmp_LwsWdKS_8
323,65a1057ba5b8f07200002295,d52b42db-8026-c7da-6516-2d97fd129216,https://media.licdn.com/dms/image/C4E03AQEqPI3aLHNsew/profile-displayphoto-shrink_100_100/0/1644326740419?e=1710374400&v=beta&t=AnHKX0iOG4os-ay1V3KORn2Xkaxe6uCj2pcYcsj7T-k,David Salinas,https://www.linkedin.com/in/ACoAABGZcbQBmzIpW0ydmQpTq-9NwMo00bai8IQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABGZcbQBmzIpW0ydmQpTq-9NwMo00bai8IQ,"
Senior Machine Learning Scientist at Amazon at Amazon Web Services (AWS)
","
I am happy to share that our paper ""Optimizing Hyperparameters with Conformal Quantile Regression"" got accepted at ICML 2023! üéâ ü•≥This is joint work with Jacek Golebiowski, Aaron Klein, Matthias Seeger and Cedric Archambeau.The idea is to combine any tabular predictor (such as XGBoost ) to predict hyperparameter optimization performance, and to then obtain calibrated uncertainty with conformal predictions which allows to balance well exploration and exploitation. üí°ü§ìüëâ Feel free to check the paper if you are interested: https://lnkd.in/exXx6EJdYou can also reproduce the experiments using Syne Tune by running instructions on this repo: https://lnkd.in/eTK3GMWi üíªüì∫Hope it is useful or interesting to some of you :-)

          ‚Ä¶see more
        


Optimizing Hyperparameters with Conformal Quantile Regression
",,https://www.linkedin.com/feed/update/urn:li:activity:7061728656275959808?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7061728656275959808%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,
324,65a1057ba5b8f07200002296,682a367c-a12a-dda7-5e84-c097b88f7d0f,https://media.licdn.com/dms/image/C4D03AQEqVR_aEQEEkw/profile-displayphoto-shrink_100_100/0/1641820232203?e=1710374400&v=beta&t=YSUYbl-tCpDx23CTN6ukt90yDiDPVJnnlr1Mt9dl1HI,Francesco Lullo,https://www.linkedin.com/in/ACoAADl9a3kBUKNv9Y4lYFtYiVCrs_dj9rOHmM0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADl9a3kBUKNv9Y4lYFtYiVCrs_dj9rOHmM0,"
Tecnico di neurofisiopatologia
","

 ",,https://www.linkedin.com/feed/update/urn:li:activity:7058801957515186176?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7058801957515186176%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHopPtZrLFEpQ/feedshare-shrink_480/0/1681838392166?e=1707955200&v=beta&t=31hfeo4NShfXdlXiRTj3GxNGxZ2SjQiX7M97MJz9KSE
325,65a1057ba5b8f07200002297,e1ec4dcc-7135-6cda-4b4a-a64c6f4d7cfb,https://media.licdn.com/dms/image/C5603AQEReSODdvboJw/profile-displayphoto-shrink_100_100/0/1633380704182?e=1710374400&v=beta&t=UpqhSy91ifXKjGGp_l1CfRDY-tCo7_wLjXWG419mLQc,Alex Xu,https://www.linkedin.com/in/ACoAAAJcVUEBpKxeVUb94KnEePlKepfIXeP2RM0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAJcVUEBpKxeVUb94KnEePlKepfIXeP2RM0,"
Co-Founder of ByteByteGo | Author of the bestselling book series: ‚ÄòSystem Design Interview‚Äô
","
System Design Blueprint: The Ultimate Guide...--Subscribe to our weekly newsletter to get a Free System Design PDF (158 pages): https://bit.ly/3FEGliw--We've created a template to tackle various system design problems in interviews.Hope this checklist is useful to guide your discussions during the interview process.This briefly touches on the following discussion points:- Load Balancing- API Gateway- Communication Protocols- Content Delivery Network (CDN)- Database- Cache- Message Queue- Unique ID Generation- Scalability- Availability- Performance- Security- Fault Tolerance and Resilience- And more‚ÄîGet a Free System Design PDF (158 pages) by subscribing to our weekly newsletter today: https://lnkd.in/g9wAgcke#systemdesign #coding #interviewtips.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7054839805460803584?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7054839805460803584%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQFlzM7z7E89aA/feedshare-shrink_480/0/1682004881298?e=1707955200&v=beta&t=F8n5nsTEdaAFcxypqhQYshrexPCWQkOE1VqCz75zsDw
326,65a1057ba5b8f07200002298,79f6c501-7f1f-7853-94c6-aa9648e19daf,https://media.licdn.com/dms/image/D5603AQGEADhHyEQ8rw/profile-displayphoto-shrink_100_100/0/1682553354695?e=1710374400&v=beta&t=kfjA-KO1Ea4gqAJ68vTh1_4ORnZzWv1qSW4bXFvg_tc,"Damien Benveniste, PhD",https://www.linkedin.com/in/ACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw,"
The ML Guy - Follow me to learn about Machine Learning Engineering, Machine Learning System Design, MLOps, and the latest techniques and news about the field. Join my AI newsletter and keep learning!
","
If you are getting started on your Machine Learning journey I can only recommend those notes by Andrew Ng as a starting point. Those are the lecture notes used in the CS229 course in Stanford. This is where I personally started back in 2009! At the time, I read those in and out multiple times and kept referring to them over the years. They have evolved since then but all the original content is still there and it has been augmented over the years to adapt to ML evolution. Enjoy!----Receive a Machine Learning PDF (100 pages) when subscribing to our newsletter: TheAiEdge.io#machinelearning #datascience #artificialintelligence 

          ‚Ä¶see more
        


Andrew Ng's ML notes
",,https://www.linkedin.com/feed/update/urn:li:activity:7059191778310057986?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7059191778310057986%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D561FAQERKjG7fBPs2g/feedshare-document-cover-images_480/0/1683042362580?e=1705658400&v=beta&t=ZLcS6fm0ZPBQTHrRnvK-fC1MJzMBjMf-hwRJVjLAgzA
327,65a1057ba5b8f07200002299,a8975dc8-cdbf-f069-7431-820473ff65dd,https://media.licdn.com/dms/image/D4D03AQEjbencXzN2dg/profile-displayphoto-shrink_100_100/0/1701877154602?e=1710374400&v=beta&t=5ChbFh_atWspP0GcT-3L9kInL3iOYVzkU49o1tN2m2o,Mohan Nayak,https://www.linkedin.com/in/ACoAABOoNvUBrUMnp4rDYjz5coBw2cSCMO2UCEI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABOoNvUBrUMnp4rDYjz5coBw2cSCMO2UCEI,"
Aspiring Data Analyst | Python,Pandas, Numpy, Data Visualization, SQL, Excel,AWS
","
Comprehensive guide to mastering numpy and pandas.This guide will help you become a pro in these two essential libraries for Data analysis and manipulation.save it for later.source : Career trekCredit goes to : Michael Brotherslike share and follow for more. #pandas #dataanalysis #career #numpy  #share #like #help 

          ‚Ä¶see more
        


Numpy and Pandas
",,https://www.linkedin.com/feed/update/urn:li:activity:7059016389163962368?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7059016389163962368%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D561FAQG7otCEeB1A9g/feedshare-document-cover-images_480/0/1682400729320?e=1705658400&v=beta&t=txe7knZ1dQVXYa44PEvq4Wj2RA_uFQ7sxoAJzdZwvjg
328,65a10597a5b8f0720000229a,5578905b-2634-0996-4de3-01e5b0827e23,https://media.licdn.com/dms/image/D4E03AQEp4reMKwCN_w/profile-displayphoto-shrink_100_100/0/1681940125057?e=1710374400&v=beta&t=HGysiWr3hLx0KSVDJqGjhe8VFECDf8TibNIw_uYhgbA,Om Roy,https://www.linkedin.com/in/ACoAADxDY0UBmeD0K7raD57GYv4xWq1nkRcJYx8?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADxDY0UBmeD0K7raD57GYv4xWq1nkRcJYx8,"
Aspiring Research Scientist in Computational Neuroscience/Network Science
","
This is a dataset of EEG brainwave data that has been processed for us.The EEG signals are of three different mood states positive, neutral and negative. The authors used a Muse EEG headband which recorded the TP9, AF7, AF8 and TP10 EEG placements via dry electrodes. I created a model using a Deep Neural Network with Bidirectional LSTM and GRU layers. An Accuracy of 99.3% was achieved with this model in classifying the EEG signals.The PDF of the notebook is shown below.#EEG #Neuroscience #DeepLearning #NeuralNetworks #machinelearning#AI #keras #tensorflow #data #network 

          ‚Ä¶see more
        


EEG signal classification
",,https://www.linkedin.com/feed/update/urn:li:activity:7059017371113435136?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7059017371113435136%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E1FAQEB933Npl3kRQ/feedshare-document-cover-images_480/0/1682341217220?e=1705658400&v=beta&t=JnwmGIBICSsAvCtcfkewDDcmQLpsQ98KXLFf_WpUx3w
329,65a10597a5b8f0720000229b,da1cfd5c-456d-f243-ee5a-23914ba96cbf,https://media.licdn.com/dms/image/C5603AQFjTNZQu9kaeg/profile-displayphoto-shrink_100_100/0/1600275851433?e=1710374400&v=beta&t=rER3PTjGlceyOtPp7cK1w2mOfX4hV-aHQ2i6LqznNFY,Tianqi Chen,https://www.linkedin.com/in/ACoAAAvoKr0Bs_OUSOMOyh-dp-IJIspY0S_ragc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAvoKr0Bs_OUSOMOyh-dp-IJIspY0S_ragc,"
Faculty at CMU, Chief Technologist at OctoML
","
Can LLMs run natively on your phones? Yes, and we can do more! Introducing MLC-LLM, an open framework that brings language models (LLMs) directly into a broad class of platforms (CUDA, Vulkan, Metal) with GPU acceleration!In recent years, there has been remarkable progress in generative artificial intelligence (AI) and large language models (LLMs), which are becoming increasingly prevalent. Thanks to open-source initiatives, it is now possible to develop personal AI assistants using open-sourced models. However, LLMs tend to be resource-intensive and computationally demanding. To create a scalable service, developers may need to rely on powerful clusters and expensive hardware to run model inference. Additionally, deploying LLMs presents several challenges, such as their ever-evolving model innovation, memory constraints, and the need for potential optimization techniques.Love to see what it can enable with the open source ecosystem, bringing personal AI assistant to everyone, be it on cloud, browser, mobile and moreCheckout the github page https://lnkd.in/egb25Y47Try it out yourself https://mlc.ai/mlc-llm/

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7057921435599548416?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7057921435599548416%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQEfN4XVXKlA2A/feedshare-shrink_480/0/1682739598603?e=1707955200&v=beta&t=f5m3GhSRQP05XbZMtNraP7eti9hs3Fdxyc_H5Jt61ww
330,65a10597a5b8f0720000229c,c26d87f5-54b5-e193-309c-4dfd8f475b5b,https://media.licdn.com/dms/image/C4E03AQHVyH-IfD1KbQ/profile-displayphoto-shrink_100_100/0/1629877234109?e=1710374400&v=beta&t=0UZUl_dDUxLaZn-Hu-zToqEDe3rpL5cB2JkP5_jlNXc,"Sebastian Raschka, PhD",https://www.linkedin.com/in/ACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU,"
Machine learning and AI researcher since the early days ‚Ä¢ coding and working with LLMs at Lightning AI ‚Ä¢ ex-statistics professor at University of Wisconsin-Madison
","
Thanks to parameter-efficient finetuning techniques, customizing large language models (LLM) to our target data and target tasks doesn't have to be computationally prohibitive. You can finetune a 7B LLM on a single GPU in 1-2 hours using techniques like low-rank adaptation. I just wrote a new article explaining how Low-Rank Adaptation (LoRA) works, and how to use it to finetune a pretrained LLM like Meta's LLaMA: https://lnkd.in/gprVGmMG#largelanguagemodels #ai #machinelearning 

          ‚Ä¶see more
        


Parameter-Efficient LLM Finetuning With Low-Rank Adaptation (LoRA) - Lightning AI
",,https://www.linkedin.com/feed/update/urn:li:activity:7056976332169117696?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7056976332169117696%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQFEvwK_WrQLcA/articleshare-shrink_800/0/1704817142677?e=1705658400&v=beta&t=stTQi4lM086nMKW8tyfPVL6JSIX8z3t3wE3uI6S1L4Y
331,65a10597a5b8f0720000229d,7a175f6a-9cc9-21b6-16c2-063c9f92a16f,https://media.licdn.com/dms/image/D5635AQEBzEFRC2EzLg/profile-framedphoto-shrink_100_100/0/1704907585971?e=1705658400&v=beta&t=x71pDAJzCbSPZxvt91sIkpmEr_5_pGLZIt6VZgw5eV0,Aman Chadha,https://www.linkedin.com/in/ACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU,"
GenAI Leadership @ Amazon AWS ‚Ä¢ Stanford AI ‚Ä¢ EB-1 ""Einstein Visa"" Recipient/Mentor ‚Ä¢ Ex-Ô£ø, Amazon Alexa, Nvidia, Qualcomm ‚Ä¢ EMNLP 2023 Outstanding Paper Award
","
üìö Curated NLP Primers ‚û°Ô∏è Primers for common NLP topics: Attention, Autoregressive vs. Autoencoder Models, Token Sampling Methods, Transformers, BERTüîπ Attention: http://attention.aman.ai- Classic Sequence-to-Sequence Model- Sequence-to-Sequence Model with Attention- Context Vector- Compared: Attention Mechanism and Fixed-length Context Vector Approachüîπ Autoregressive vs. Autoencoder Models: http://enc-dec.aman.ai- How do Autoregressive/Decoder Models Work?- How do Autoencoder/Encoder Models Work?- Encoder-Decoder/Seq2Seq Models- Case Study: XLNet - the Best of Both Worlds (Permutation Language Modeling)üîπ Token Sampling Methods: http://token-smple.aman.ai- Background: Logits and Softmax- Related: Temperature- Greedy Decoding- Exhaustive Search Decoding- Beam Search- Constrained Beam Search- Top-k Sampling- Top-p Sampling (Nucleus Sampling)üîπ Transformers: http://transformer.aman.ai- Mathematical Background (Vectors, Matrix Multiplication, Dot Product, Masking, Sampling)- Attention (Additive/Multiplicative/Dot Product Attention, Self/Cross-Attention, Multihead Attention)- Core Components of the Transformer Architecture (Embeddings, Positional Encoding, Skip Connections, Layer Normalization, Softmax)- Top-level Transformer Architecture (Encoder and Decoder stack)- Implementation details (Byte-Pair Encoding, Teacher Forcing, Label Smoothing)- Lessons Learned (What are Transformers learning? Why is training them so hard?)- Pros/cons of Transformers relative to CNNs/RNNs- Relation between Transformers and Graph Neural Networksüîπ BERT: http://bert.aman.ai- Background: Pre-Training- Contextualized Embeddings- Masked Language Modeling (MLM)- Next Sentence Prediction (NSP)- BERT‚Äôs Encoder Architecture vs. Other Decoder Architectures- The Strength of Bidirectionality- Supervised Fine-Tuning#artificialintelligence #machinelearning #ai #ml

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7055390952143663105?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7055390952143663105%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQGvpd02m2WkWQ/feedshare-shrink_480/0/1682136278735?e=1707955200&v=beta&t=NKMap4cpfzC6aiL4wdsanuuIu8zvhFa-6lsAsa-zRg4
332,65a10597a5b8f0720000229e,0860b465-fe25-bfb8-4d0b-718ac204b885,https://media.licdn.com/dms/image/D5635AQEBzEFRC2EzLg/profile-framedphoto-shrink_100_100/0/1704907585971?e=1705658400&v=beta&t=x71pDAJzCbSPZxvt91sIkpmEr_5_pGLZIt6VZgw5eV0,Aman Chadha,https://www.linkedin.com/in/ACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU,"
GenAI Leadership @ Amazon AWS ‚Ä¢ Stanford AI ‚Ä¢ EB-1 ""Einstein Visa"" Recipient/Mentor ‚Ä¢ Ex-Ô£ø, Amazon Alexa, Nvidia, Qualcomm ‚Ä¢ EMNLP 2023 Outstanding Paper Award
","
üìù Recommender Systems in Production: Case Studies üîπ Synopses of the inner-workings of some of the most popular recommendation system platforms: http://rec-papers.aman.ai- TikTok's Monolith Recommender System by Zhuoran Liu et al.- Netflix's Recommender System by Carlos Gomez Uribe and Neil Hunt- LinkedIn's Talent and Search Recommendation System by Sahin Geyik et al.- DoorDash‚Äôs Search and Recommendations by Aamir Manasawala and Mitchell Koch- YouTube‚Äôs Deep Neural Network Recommender System by Paul Covington, Jay Adams, and Mehmet Emre Sargin- TikTok‚Äôs Deep Retrieval: Learning a Retrievable Structure for Large-Scale Recommendations by Weihao Gao et al.- Google‚Äôs Wide and Deep Recommender System by Heng-Tze Cheng et al.- Pinterest‚Äôs Pixie Real-time Recommender by Chantat Eksombatchai et al.Notes written in collaboration with Vinija Jain.#artificialintelligence #machinelearning #ai #ml #nlp

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7055753084731338752?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7055753084731338752%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHiyKV6Rq_yMg/feedshare-shrink_480/0/1682222616373?e=1707955200&v=beta&t=IwOlOZeP2on-uz9TcYkaCdQX8iWiPD5gHLg4By0rcBk
333,65a10597a5b8f0720000229f,6b371122-6396-5f42-4abb-caa72868d09a,https://media.licdn.com/dms/image/C4E03AQEJ3_43B6Bkzw/profile-displayphoto-shrink_100_100/0/1516837043210?e=1710374400&v=beta&t=fu4I3bZRf7CLohuMTFIF9Hg_D93ODpUnWJr_HNxgcrw,Elias Ebrahimzadeh,https://www.linkedin.com/in/ACoAABFA3EQBDjZNnb0lvI30vmRL_GfAzT5fcdE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABFA3EQBDjZNnb0lvI30vmRL_GfAzT5fcdE,"
Neuroscientist at the Neuraly Clinical Neuroscience Centre
","
I am delighted to share our new article titled ""Machine Learning Approaches and Non-Linear Processing of Extracted Components in frontal Region to Predict rTMS Treatment Response in Major Depressive Disorder"" published in OPEN ACCESS Journal of Frontiers in Systems Neuroscience.The article is available free to view and download using the below link.https://lnkd.in/eDKDNJ8W

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7053554187585904640?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7053554187585904640%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQEzSTyXYBz_Kg/feedshare-shrink_480/0/1681698366683?e=1707955200&v=beta&t=nJweZfqMQ_hbgKATjNbIiW5tgs9lEFqFGD33orxxlQ8
334,65a10597a5b8f072000022a0,b1f93358-8947-1969-e755-8c9d808419d1,https://media.licdn.com/dms/image/C4E03AQEIo3a_Cp4QuA/profile-displayphoto-shrink_100_100/0/1516766277221?e=1710374400&v=beta&t=9lLwxagq2xlRtoEtT3uBAgE5vaMAhAu35KPyVVeLpig,Nehaa Bansal,https://www.linkedin.com/in/ACoAABQLLuMBMEyQnAEXTQRgmsNecDzqzmQKnKA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABQLLuMBMEyQnAEXTQRgmsNecDzqzmQKnKA,"
Data Scientist | Thought Process Leader | Analytical Thinker | 1x AWS Certified | 5x Azure Certified | Certified Scrum Master | The views expressed in my posts are my own |
","
üöÄ ùêêùêÆùêûùê¨ùê≠ùê¢ùê®ùêß ùêÄùêßùê¨ùê∞ùêûùê´ùê¢ùêßùê† ùêíùê≤ùê¨ùê≠ùêûùê¶ ùêÆùê¨ùê¢ùêßùê† ùêãùêöùêßùê†ùêÇùê°ùêöùê¢ùêß, ùêèùê¢ùêßùêûùêúùê®ùêßùêû, ùêöùêßùêù ùê©ùê®ùê∞ùêûùê´ùêüùêÆùê• ùêãùêãùêåùê¨ ùê•ùê¢ùê§ùêû ùêÜùêèùêì-4! üé•üß†Exciting times in the world of natural language processing! With the advent of #gpt4 , ùêãùê®ùêßùê†ùêÇùê°ùêöùê¢ùêç, and #pinecone , the potential for building powerful and accurate question answering systems is greater than ever before.#llms like GPT-4 are incredibly good at understanding the nuances of human language and can generate responses that are not only accurate but also sound like they were written by a human. LongChaiN and PinEcone are powerful systems that allow for efficient and accurate indexing and retrieval of information, making it easier to build large-scale question answering systems.But it's not just about the technology - building effective question answering systems also requires careful consideration of the problem at hand and the specific needs of the users. How can we ensure that the system is accurate and reliable? How can we ensure that it can handle a wide variety of questions and use cases? How can we make it easy for users to interact with the system and get the information they need?üîé Answering these questions requires a deep understanding of both the technology and the user experience. And as with any technology, there are always trade-offs to be made. Do we prioritize accuracy over speed? Do we focus on a specific domain or try to build a more general system?As we continue to push the boundaries of what's possible with natural language processing, I'm excited to see how we can use these powerful tools to build question answering systems that are both accurate and useful for people in all kinds of contexts.""I tried few examples with langchain, explore them below.üìö Refer to my GitHub : https://lnkd.in/gcqsficHüìö Official documentation : https://lnkd.in/gDXwx8chImage credits : https://lnkd.in/d2KpdazP#langchain #Pinecone #GPT4 #SemanticSearch #QuestionAnswering #DocumentQnA #AI #MachineLearning #github #technology 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7053215431582511104?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7053215431582511104%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQE5C-UhxwFSBw/feedshare-shrink_480/0/1681455810729?e=1707955200&v=beta&t=mhvyO-9cUlZkjskbcKcPj8XSoUWoTWZEenVf9gJjYCs
335,65a10597a5b8f072000022a1,00f6462f-6d53-90ae-a6fe-6b19949cd7c4,https://media.licdn.com/dms/image/D5603AQE1F98y6w3c0g/profile-displayphoto-shrink_100_100/0/1669234244344?e=1710374400&v=beta&t=N4TqBbfKuHRLpFXpsP2TxyHN_-XO5JFKYpURz-i_NtA,Zak Jost,https://www.linkedin.com/in/ACoAAAl6frsBFNOnSh877YSXJagNVEEbMnInqdM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAl6frsBFNOnSh877YSXJagNVEEbMnInqdM,"
Graph ML; Senior Data Scientist at AirBnb
","
AWS Graph ML team releases GraphStorm, a framework to help enterprises scale GNN models to distributed environments, supporting billions of nodes and edges.  It provides both a model zoo for low code scenarios, and a code interface for plugging your custom DGL models into the distributed training/inference pipeline.

          ‚Ä¶see more
        


GitHub - awslabs/graphstorm
",,https://www.linkedin.com/feed/update/urn:li:activity:7053347420558016512?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7053347420558016512%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQGc4BFBbZ8qJA/articleshare-shrink_800/0/1704811049243?e=1705658400&v=beta&t=Hyn8IfvCJgfzkY6epjPLjTq3pVvxOJUlSU8lO5Eb1hY
336,65a10597a5b8f072000022a2,5a9fe76a-f210-f178-4ab8-85bd57d5e5f0,https://media.licdn.com/dms/image/C5603AQGCA0jXW9wIGQ/profile-displayphoto-shrink_100_100/0/1603913066364?e=1710374400&v=beta&t=M64xWhgI7OO0_FX5ZHok8lecx-QinGmoDc29X_wdRmI,Chip Huyen,https://www.linkedin.com/in/ACoAAAIQAJQBE3ykLNnsOPVvxwuuVCOir2zAjOQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAIQAJQBE3ykLNnsOPVvxwuuVCOir2zAjOQ,"
Real-time ML @ Claypot AI | ML Sys @ Stanford | Hiring strong streaming engineers
","
New post: Building LLM applications for productionLink: https://lnkd.in/gi6aKZyJI spent the last month talking with companies who are building applications on top of LLMs and realized: it‚Äôs easy to build something cool with LLMs, but very hard to build something production-ready with LLMs.There are several challenges that make productionizing LLM applications hard:1. The ambiguity of natural languages can make for a delightful user experience but a painful developer experience.2. The stochastic nature of LLMs can lead to inconsistency in user experience and silent failures.3. How fast things are evolving makes it very hard to make business decisions: analysis on cost-latency, build (using open source) vs. buy (using paid APIs), prompting vs. finetuning vs. newer techniques needs to be done constantly.This post discusses these challenges, and what companies are doing to address them. I also discuss more complex applications involving task composability, agent, and control flows.#llms #promptengineering #mlops #machinelearning #largelanguagemodels 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7051955337221844992?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7051955337221844992%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQFqp-eOe5j1Dg/feedshare-shrink_480/0/1681317170516?e=1707955200&v=beta&t=e6aosEM0RpMRVpEg8_XhglWzwGS9QN4aqhxC1Oeor4M
337,65a10597a5b8f072000022a3,0bcfc2a8-37b6-9f6a-7d1e-00fd0cea064a,https://media.licdn.com/dms/image/D5635AQEBzEFRC2EzLg/profile-framedphoto-shrink_100_100/0/1704907585971?e=1705658400&v=beta&t=x71pDAJzCbSPZxvt91sIkpmEr_5_pGLZIt6VZgw5eV0,Aman Chadha,https://www.linkedin.com/in/ACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU,"
GenAI Leadership @ Amazon AWS ‚Ä¢ Stanford AI ‚Ä¢ EB-1 ""Einstein Visa"" Recipient/Mentor ‚Ä¢ Ex-Ô£ø, Amazon Alexa, Nvidia, Qualcomm ‚Ä¢ EMNLP 2023 Outstanding Paper Award
","
üì∫ The best Stanford, CMU, and MIT courses for AI (with YouTube playlists)- With a multitude of AI courses available online, coming up with an study plan for AI can easily lead to decision fatigue.- I often get asked about which courses have been useful to me to build a foundation in AI. Here‚Äôs my list of courses along with their respective YouTube playlists (note that this is an ordered list of increasing difficulty, based on my personal experience).- Check out my watch list with all of the above pointers (and a much larger list of such resources and more): https://aman.ai/watchüìö Stanford Universityüîπ CS221 - Artificial Intelligence: Principles and Techniques by Percy Liang and Dorsa Sadigh: https://lnkd.in/grECwbD4üîπ CS229 - Machine Learning by Andrew Ng: https://lnkd.in/gY8a2yZNüîπ CS230 - Deep Learning by Andrew Ng: https://lnkd.in/gTk-gKPmüîπ CS231n - Convolutional Neural Networks for Visual Recognition by Fei-Fei Li and Andrej Karpathy: https://lnkd.in/gGUMZH_Güîπ CS224n - Natural Language Processing with Deep Learning by Christopher Manning: https://lnkd.in/giWDZGVXüîπ CS234 - Reinforcement Learning by Emma Brunskill: https://lnkd.in/gwZKQ-28üîπ CS330 - Deep Multi-task and Meta Learning by Chelsea Finn: https://lnkd.in/gvVr_Y4Müîπ CS25 - Transformers United: https://lnkd.in/gEtKgHGCüìö Carnegie Mellon Universityüîπ CS/LTI 11-711: Advanced NLP by Graham Neubig: https://lnkd.in/gSt29ZVtüîπ CS/LTI 11-747: Neural Networks for NLP by Graham Neubig: https://lnkd.in/gRRrY8uqüîπ CS/LTI 11-737: Multilingual NLP by Graham Neubig: https://lnkd.in/g8QkaTfyüîπ CS/LTI 11-777: Multimodal Machine Learning by Louis-Philippe Morency: https://lnkd.in/gKFJDbU4üîπ CS/LTI 11-785: Introduction to Deep Learning by Bhiksha Raj and Rita Singh: https://lnkd.in/gVp96GdBüîπ CS/LTI Low Resource NLP Bootcamp 2020 by Graham Neubig: https://lnkd.in/grYqa3YZüìö Massachusetts Institute of Technologyüîπ 6.S191 - Introduction to Deep Learning by Alexander Amini and Ava Amini: https://lnkd.in/gWMUpMQgüîπ 6.S094 - Deep Learning by Lex Fridman: https://lnkd.in/gcDgqbH6üîπ 6.S192 - Deep Learning for Art, Aesthetics, and Creativity by Ali Jahanian: https://lnkd.in/gEyRbEZxüìö University College Londonüîπ COMP M050 Reinforcement Learning by David Silver: https://lnkd.in/gEpkWmqh#artificialintelligence #machinelearning #ai #ml

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7052863983908753408?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7052863983908753408%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQFwWRQ81-cFdg/feedshare-shrink_480/0/1681533808024?e=1707955200&v=beta&t=UgIGV6EiFDGPU067zAZx2StlH90t9tF0rPvd4PCi4RE
338,65a10597a5b8f072000022a4,658e9a31-ca56-eadc-c63e-3b30022f8833,https://media.licdn.com/dms/image/D5603AQGNiuOdOwGOXA/profile-displayphoto-shrink_100_100/0/1664778459905?e=1710374400&v=beta&t=xBgaXiEzd_m7LRcAM3FAiTW3npUaSw7mDRGAhH05ro0,Vinija Jain,https://www.linkedin.com/in/ACoAAA4CfZwBGeQakt2b0sUVu1GdoGrJgBGwpJU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA4CfZwBGeQakt2b0sUVu1GdoGrJgBGwpJU,"
Machine Learning Leader at Amazon | Stanford AI | EMNLP Outstanding Paper Award Recipient
","
üìù Recommender Systems Paper Reviewsüîó Link for notes: http://recsys.vinija.ai üëãüèº Hey LinkedIn connections,‚û¢ I‚Äôve reviewed the workings of some of the industries best and vastly consumed recommendation system platforms listed below:‚Ä£ TikTok's Monolith by Zhuoran Liu et al.‚Ä£ Netflix's Recommender System by Carlos Gomez Uribe and Neil Hunt‚Ä£ LinkedIn's Talent and Search Recommendation System by Sahin Geyik et al.‚Ä£ DoorDash‚Äôs Search and Recommendations by Aamir Manasawala and Mitchell Koch‚Ä£ YouTube‚Äôs Deep Neural Network by Paul Covington, Jay Adams, and Mehmet Emre Sargin‚Ä£ Google‚Äôs Wide and Deep Learning by Heng-Tze Cheng et al.‚Ä£ Pinterest‚Äôs Pixie real-time recommender by Chantat Eksombatchai et al.‚û¢ This is written in collaboration with Aman Chadha, please feel free to reach out to us for any comments or suggestions!

          ‚Ä¶see more
        


Recommendation Systems ‚Ä¢ Research Papers
",,https://www.linkedin.com/feed/update/urn:li:activity:7050798569414365184?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7050798569414365184%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQGF3igiBmDY6A/articleshare-shrink_1280_800/0/1704602615759?e=1705658400&v=beta&t=-k7aCBXP9P9SIDYMSjLUYTGp6HMqpplW7WJTIVHwlwg
339,65a10597a5b8f072000022a5,4b7387dd-b9c5-ad7b-9c21-d4e8e78910ec,https://media.licdn.com/dms/image/D5603AQGgKMh7qt3BaQ/profile-displayphoto-shrink_100_100/0/1684715779373?e=1710374400&v=beta&t=lU11cNYnEyhJCLyqUrMHfim2XPV-S6RRNUKfMouztSs,Sahar Mor,https://www.linkedin.com/in/ACoAAAghAr0B3tunEx7sW1oXU31EBb8i9l-v4ac?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAghAr0B3tunEx7sW1oXU31EBb8i9l-v4ac,"
I help researchers and builders make sense of AI | ex-Stripe | aitidbits.ai | Advisor
","
Microsoft research presents the first attempt of using GPT-4 to generate instruction-following data for LLMs using Stanford's Alpaca dataset.Instruction following data is a type of dataset used to train computer programs to understand and carry out tasks based on natural language instructions. It helps improve the ability of LLMs to follow real-world instructions which is the step change we saw with Alpaca, based on Meta's LLaMA.Code https://lnkd.in/g8kk5-PmBlog post https://lnkd.in/gYG-Fg7GKudos Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7050166803393626112?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7050166803393626112%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQGmKQAifMxjpg/feedshare-shrink_480/0/1680890750399?e=1707955200&v=beta&t=VWA8MxqkQE_wOcK54cdu6WzrUBRiWE2lESc_rjkUnVQ
340,65a10597a5b8f072000022a6,5b1fc111-42eb-607a-ba79-40c3f754dc30,https://media.licdn.com/dms/image/D5603AQE6au_KCnXjnA/profile-displayphoto-shrink_100_100/0/1704308429288?e=1710374400&v=beta&t=huMqs7H7rfUKZvr4Z7NA6XVajsWR0ZIIKJIA5aMNOgg,Srishti Gureja,https://www.linkedin.com/in/ACoAACjhgJ0BoBdJPmLhwbc3PD0tpV2_5byPY_Q?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACjhgJ0BoBdJPmLhwbc3PD0tpV2_5byPY_Q,"
ML Engineer @ WriteSonic | Open Source @Eleuther AI | x: NLP + Differential Privacy @Translated, AI Fellow @ Pi School
","
High GPU memory costs? Fine-tuning an LLM? Read on!Heavily Parameterized Large Language Models + Basic Linear Algebra Theorem = Save GPU memory! üíØFine-tuning of large pre-trained LMs on downstream tasks yields impressive performances - there are many techniques to go about this concept called ‚Äútransfer learning‚Äù.Downsides of some popular ones - - Adaptors - introduce inference latency that becomes significant in online low batch size inference settings.- Prefix tuning etc. - reduce the model‚Äôs usable sequence length.Let‚Äôs talk about LoRA (low rank adaptation of LLMs), one such PEFT (parameter efficient fine-tuning) technique that relies on a simple concept - decomposition of non-full rank matrices.LoRA hypothesizes that ‚Äúchange in weights‚Äù during adaptation has a ‚Äúlow intrinsic rank‚Äù --> ŒîW is non full rank and so can be written as ŒîW = BA (see the figure).During training, the outputs from W and ŒîW are added component wise, like so -h = Wx + BAxTHAT‚ÄôS IT! All we‚Äôre now left to optimize is the new matrices B and A that contain a very smaller number of parameters (combined) than the full matrix due to their dimensions. ‚úÖIn one line - All of the pre-trained weights W are kept frozen and the rank decomposition matrices of the ‚Äúchange in weight matrix‚Äù, B and A are optimized.This yields significant benefits as compared to full-fine tuning -‚û°Ô∏è Time and memory efficiency - With a large percentage of the parameters being frozen, the training time and the GPU memory is saved. Saving is more when using stateful optimizers like Adam, Adadelta etc.‚û°Ô∏è Storage efficiency - No need to store huge checkpoints for different downstream tasks. Checkpoint size is greatly reduced with reduction in trainable parameters.‚û°Ô∏è No additional inference latency - (unlike adaptors) just add the learned matrix to the pre-trained one.‚û°Ô∏è Easy task-switching in deployment - all we need to change is a handful of weights as compared to the full model.Numbers? With GPT-3 175B, the VRAM consumption during training is reduced from 1.2TB to 350GB, and the trained checkpoint size reduced from 350GB to 35MB!!!LoRA achieves performances comparable to and sometimes even better than fine-tuning the full model.‚ÄúLow intrinsic rank‚Äù is inspired by the idea of ‚Äúlow intrinsic dimensionality‚Äù that these over-parameterized pre-trained models are seen to reside on, and that‚Äôs also the explanation behind why fine-tuning only a part of the full model rather than full fine-tuning can yield good results.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7048861610542534656?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7048861610542534656%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQHqRb5JYkfc_g/feedshare-shrink_2048_1536/0/1680579567755?e=1707955200&v=beta&t=ZiVfuoT8rr34vfPnpkfoncfo6NEEedWh0Gt29m_MaR8
341,65a10597a5b8f072000022a7,ea174b23-3e45-b21f-ec93-f7af728138d1,https://media.licdn.com/dms/image/C4E03AQGfzEtRhrPHdw/profile-displayphoto-shrink_100_100/0/1619776973437?e=1710374400&v=beta&t=y9up1yBFMNfTMJvaDgcupbnl3OnJC7EgkzWAkOY4pyM,Sanyam Bhutani,https://www.linkedin.com/in/ACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACGvqwEBikUIsBegy6pJOAI4ZFVomZpKTo0,"
Senior Data Scientist at H2O.ai | Kaggle Grandmaster
","
A comprehensive overview of current Large Language Models landscapeThe paper is a much needed detailed survey of all of the existing LLMs.Note: The yellow ones in the image are open sourcehttps://lnkd.in/d_Pj2FcG

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7048475652391321600?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7048475652391321600%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQHPOCl0HwN4Ww/feedshare-shrink_480/0/1680487549078?e=1707955200&v=beta&t=-k5h3iXw5dh85FDHHXyllBDUhDFit-jLMtrZsu-WE-o
342,65a10597a5b8f072000022a8,4a97f532-5f1a-65b5-d501-7669de234a6c,https://media.licdn.com/dms/image/C4D03AQF0Yoj2yz4-5g/profile-displayphoto-shrink_100_100/0/1573764223047?e=1710374400&v=beta&t=qy0xwsmthmby5dRnj5e56ErYPXgE0cbL6Iv-hgZ1Kho,Yves Jacquier,https://www.linkedin.com/in/ACoAAAAlYF4Bis2jJlO4BX9nH-A1nX0Ud90Rdsk?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAAlYF4Bis2jJlO4BX9nH-A1nX0Ud90Rdsk,"
Executive Director - Ubisoft La Forge
","
Curious to read what you think. Twitter opensources its recommendation algorithm.
 

GitHub - twitter/the-algorithm-ml: Source code for Twitter's Recommendation Algorithm
",,https://www.linkedin.com/feed/update/urn:li:activity:7047719511269007363?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7047719511269007363%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQEzsh925QZGaQ/articleshare-shrink_800/0/1703947061629?e=1705658400&v=beta&t=NBL6CvGsVaddTMcHBi_bab8wfTs-to07H7hG66dVOdQ
343,65a10597a5b8f072000022a9,2bcbad5b-a2c6-e3ea-1648-bee0262740b4,https://media.licdn.com/dms/image/C4E03AQFtC3ZH506r6A/profile-displayphoto-shrink_100_100/0/1517578865199?e=1710374400&v=beta&t=rX1ZuyXupewBHqElwttuauoBaZe3YSd11eKwaSHFoPw,Vassilis N. Ioannidis,https://www.linkedin.com/in/ACoAABf7POQBHkJ5L-wLdfUUB4BQ8j9af1ruBGE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABf7POQBHkJ5L-wLdfUUB4BQ8j9af1ruBGE,"
Team Leader @ Amazon Search AI | AWS AI | MERL | PhD
","
The Amazon Web Services (AWS) Graph ML team has open sourced GraphStorm. GraphStorm is a graph machine learning (GML) framework for enterprise use cases. It simplifies the development, training and deployment of GML models for industry-scale graphs by providing scalable training and inference pipelines of Graph Machine Learning (GML) models for extremely large graphs (measured in billons of nodes and edges). GraphStorm is an #opensource effort that will allow the GML community to innovate on using #gnn in their business with #lowcodenocode. Distributed training that is part of this approach also allows to scale to billion node graphs that are common across the industry.GraphStorm allows users to also exploit powerful language models #llms  #bert as node encoders for the GNN models. You can find more information in our paper https://lnkd.in/gvEJEucA. This release summarize the efforts in the team for the last 2 years and I am glad to see it out there. Give it a try!!https://lnkd.in/gNsxYDEq#ml #machinelearning #aws #languagemodels 

          ‚Ä¶see more
        


GitHub - awslabs/graphstorm
",,https://www.linkedin.com/feed/update/urn:li:activity:7047312261446582272?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7047312261446582272%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQHHy4pLijRnDg/articleshare-shrink_800/0/1704432862167?e=1705658400&v=beta&t=GAEE2F3iS7TbmlHJUY0pX-k4Mpfrmtvi94tdSA97ouE
344,65a10597a5b8f072000022aa,7a4c1590-86b3-8f54-7316-1490eac8a861,https://media.licdn.com/dms/image/C5603AQHCWJrtuM1ucQ/profile-displayphoto-shrink_100_100/0/1556256053337?e=1710374400&v=beta&t=uSA9roAQcK7I1kd2sZKlTX3iV3KkvXeT8WRA9jk5qwQ,Natalia Vassilieva,https://www.linkedin.com/in/ACoAAAM5gxMBxp5sVnhJUYcXNPJkVjoshhWHY9Y?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAM5gxMBxp5sVnhJUYcXNPJkVjoshhWHY9Y,"
Sr. Director of Product, Machine Learning at Cerebras Systems
","
A busy and exciting day today! At Cerebras Systems, we've open-sourced a family of large auto-regressive language models ranging from 111M to 13B parameters, all trained on (parts of) our Andromeda AI supercomputer. The team did through evaluation of the trained models, and based on the comparison with other published models,  Cerebras-GPT models provide the highest accuracy for a given training compute budget. With these trained models, the team also derived a new scaling law for GPT models trained on Pile dataset, which can be used to predict model accuracy for a given training compute budget. To the best of our knowledge, Cerebras-GPT is the first scaling law that predicts model performance for a public dataset.Today‚Äôs release is designed to be used by and reproducible by anyone! Check the released models on HuggingFace: https://lnkd.in/gj-Te-FW And I'm heading today to #MemCon at Computer History Museum  - happy to connect there and chat about larger language models, memory requirements for deep learning, and AI accelerators :) #ai #deeplearning #IamCerebras

          ‚Ä¶see more
        


cerebras (Cerebras)
",,https://www.linkedin.com/feed/update/urn:li:activity:7046559137026998272?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7046559137026998272%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/C5627AQFCSviL1BS_qg/articleshare-shrink_800/0/1704225922226?e=1705658400&v=beta&t=Kd3GXpZmdeOaVYPQ9gDQQNWvKrVHntFXVD5hZtCxbok
345,65a10597a5b8f072000022ab,ceefa1ba-a823-c67a-b88b-f2ca5c94c3cf,https://media.licdn.com/dms/image/D5603AQGNiuOdOwGOXA/profile-displayphoto-shrink_100_100/0/1664778459905?e=1710374400&v=beta&t=xBgaXiEzd_m7LRcAM3FAiTW3npUaSw7mDRGAhH05ro0,Vinija Jain,https://www.linkedin.com/in/ACoAAA4CfZwBGeQakt2b0sUVu1GdoGrJgBGwpJU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA4CfZwBGeQakt2b0sUVu1GdoGrJgBGwpJU,"
Machine Learning Leader at Amazon | Stanford AI | EMNLP Outstanding Paper Award Recipient
","
ü§ñüìù : Reinforcement Learning with Human Feedback (RLHF)üîó Link for notes: https://lnkd.in/gCzePeXk üëãüèº Hey LinkedIn connections,‚û¢ One common theme we‚Äôre seeing with the recent LLM‚Äôs being launched (ChatGPT, GPT-4 etc) is that they are fine-tuned with RLHF.‚û¢ In this article, I go over the training process of RLHF, use cases, and how it can produce bias.‚û¢ This is written in collaboration with Aman Chadha, please feel free to reach out to us for any comments or suggestions!

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7043422152749948928?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7043422152749948928%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C5622AQEY8PjRW40NfQ/feedshare-shrink_2048_1536/0/1679256414804?e=1707955200&v=beta&t=xE8mnymufyFXn2QP8hto2xeSyXCiFdqYd9m6wf_Y3oA
346,65a10597a5b8f072000022ac,e5d84913-35a1-ad8e-44b2-2997640d642a,https://media.licdn.com/dms/image/D5603AQHLwo7d_7vKNg/profile-displayphoto-shrink_100_100/0/1701769075230?e=1710374400&v=beta&t=5lLKLNjyNpB7kY5aOz9Dm0z5VoirsZxlX5i9xuqm5w0,Steve Nouri,https://www.linkedin.com/in/ACoAAAj_qcABebPCFHyk-0_-nNFZsxiGnzK5i6c?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAj_qcABebPCFHyk-0_-nNFZsxiGnzK5i6c,"
Generative AI Founder | Advisor @ Fortune 500 | 1.5 Million Followers | Keynote Speaker | Top Voice DS & AI
","
This week in #AI‚úÖ Adobe--> AI image creator Firefly.‚úÖ Microsoft --> Bing Image Creator.‚úÖ NVIDIA --> cloud tools for Generative AI.‚úÖ Opera --> LLM-based browser.‚úÖ GitHub --> CopilotX.‚úÖ Canva --> several AI-powered tools.‚úÖ Unity --> Unity AI.‚úÖ Google --> Bard.‚úÖ OpenAI --> ChatGPT Plugins.‚úÖ OpenAI --> browsing capability to fetch from the web.‚úÖ OpenAI --> plugins to upload/process video clips.Anything missed?Subscribe to the AI Frontier newsletter to stay updated about the latest AI products and features https://lnkd.in/gR9uwTwi#artificialintelligence #technology  Img via barsee

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7045624883174649856?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7045624883174649856%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHJNFBgWr273Q/feedshare-shrink_480/0/1679807872763?e=1707955200&v=beta&t=a7cqM4-cn26MfWW259VxGRZDPArieu9h75os4j0hFSs
347,65a10597a5b8f072000022ad,8c4d43e5-a169-4b7c-543a-950075fc0611,https://media.licdn.com/dms/image/C4E03AQHVyH-IfD1KbQ/profile-displayphoto-shrink_100_100/0/1629877234109?e=1710374400&v=beta&t=0UZUl_dDUxLaZn-Hu-zToqEDe3rpL5cB2JkP5_jlNXc,"Sebastian Raschka, PhD",https://www.linkedin.com/in/ACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU,"
Machine learning and AI researcher since the early days ‚Ä¢ coding and working with LLMs at Lightning AI ‚Ä¢ ex-statistics professor at University of Wisconsin-Madison
","
Understanding the shortcomings of large language models (LLMs) requires understanding the shortcomings of the underlying evaluation metrics. After covering perplexity and BLEU, let's now discuss ROUGE, which has been used in all recent papers evaluating LLMs on summarization tasks.Where BLEU is commonly used for translation tasks, ROUGE is a popular metric for scoring text summaries. Similar to BLEU, it's usually applied to n-grams, but for simplicity, we will focus on 1-grams (single words). There are quite some similarities between BLEU and ROUGE. The precision-based BLEU score checks how many words in the candidate translation occur in the reference translation. The ROUGE score takes a flipped approach, checking how many words in the reference text occur in the generated text (here, typically a summarization instead of translation) -- this is more of a recall-based score.While ROUGE was originally just recall-based as mentioned above, modern implementations compute the ROUGE as an F1 score that is the harmonic mean of recall (how many words in candidate occur in the reference) and precision (how many words in the reference occur in the candidate). It's absolutely worth knowing about ROUGE since *all* papers introducing new summarization models at computational linguistic conferences in 2021 use ROUGE -- 69% of these papers use *only* ROUGE according to the ""Repairing the Cracked Foundation: A Survey of Obstacles in Evaluation Practices for Generated Text"" (https://lnkd.in/gVM2QQRk) survey.Of course, ROUGE has similar shortcomings as BLEU, and studies found that ROUGE does not significantly correlate with content generated by humans.#largelanguagemodels #ai #deeplearning 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7045392065324609536?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7045392065324609536%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQExy2ZdCebMtg/feedshare-shrink_480/0/1679752364225?e=1707955200&v=beta&t=X1vWqQlhcuFh77d0ikVtN-dtwFzpbB3yHFhgEA4fYlg
348,65a10597a5b8f072000022ae,1cb6dd3f-7536-6d77-4468-c225510e3edb,https://media.licdn.com/dms/image/C4D03AQGPllmYD_t_1w/profile-displayphoto-shrink_100_100/0/1622036357997?e=1710374400&v=beta&t=T-R3xZ-JM0IguWfjTN2sD1GhrRsT3iK7VL9r7o2NquY,Emeka Boris Ama,https://www.linkedin.com/in/ACoAACZlUmoBIDbF4OoeTUMQIRRRQmOkzwQZLno?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACZlUmoBIDbF4OoeTUMQIRRRQmOkzwQZLno,"
MLOps(Cloud - AWS) + Machine Learning Engineer + Software Engineer. Making a difference with ML and Data Science
","
Are you looking to learn MLOps?Here is a course from Weights & Biases Pls like and share.#share #mlopscourse #mlops #ml #devops Link: https://lnkd.in/dYc6zu6X

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7039936027330818048?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7039936027330818048%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C4D22AQGZiYE7syN1rg/feedshare-shrink_480/0/1678451543143?e=1707955200&v=beta&t=Vo7GuKp22pKrxxs5Qtl8MxIiOV7U19HHZxWbDY5RPUA
349,65a10597a5b8f072000022af,72b76bec-dd1c-a873-a8d9-1471715674cf,https://media.licdn.com/dms/image/C5603AQHAN44WHZQZpA/profile-displayphoto-shrink_100_100/0/1553184748527?e=1710374400&v=beta&t=wDFrFEckBjnMF0mPKlKppTj4KYq2m9xTIxaroRv64Uo,Lenon Alexander Minorics,https://www.linkedin.com/in/ACoAACs30XYBsM8RdiFu4T25FBNODsOK-d0jNyI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACs30XYBsM8RdiFu4T25FBNODsOK-d0jNyI,"
Senior Applied Scientist at Amazon
","
Our paper about manifold restricted shapley values got accepted at AISTATS 2023 https://lnkd.in/esezCCkU In this paper, we show the pitfalls of existing XAI methodologies and propose a solution that outperforms state-of-the-art XAI algorithms#AmazonScience

          ‚Ä¶see more
        


Manifold restricted interventional shapley values
",,https://www.linkedin.com/feed/update/urn:li:activity:7038877594624131072?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7038877594624131072%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQF0bEVSJ2GEiw/articleshare-shrink_800/0/1703865411829?e=1705658400&v=beta&t=1xQ7vkato8C33g6sVrcXB9CubtKQZd-bScCnlczzlbg
350,65a10597a5b8f072000022b0,995bb368-9750-0028-fe1a-ea9badc0bb7f,https://media.licdn.com/dms/image/C4E0BAQH5ZTUMjFXhyg/company-logo_100_100/0/1630610511047/amazon_science_logo?e=1713398400&v=beta&t=q-4oOXo0BordU6VXkJqpj4R0M28LwU_BopSbigIgG8s,Amazon Science,https://www.linkedin.com/company/amazonscience/,"
327K followers
","
To enable language models that are lightweight enough for runtime use, Amazon scientists propose using an LLM-based teacher model to generate customized training examples for student models.#LLM #NLProc

          ‚Ä¶see more
        


Using large language models (LLMs) to synthesize training data
",,https://www.linkedin.com/feed/update/urn:li:activity:7040335650352414720?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7040335650352414720%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D34AQE1AVX8--39tQ/ugc-proxy-shrink_800/0/1678546822824?e=1705658400&v=beta&t=w4GMD54QLvXDFal2iZs9gtLAeU6btdWKWTiG-e0B_Tg
351,65a10597a5b8f072000022b1,b802e17d-dd7f-94c4-8233-d0ca8fd94e9f,https://media.licdn.com/dms/image/D4E03AQHlDrrMgdW81w/profile-displayphoto-shrink_100_100/0/1680035432469?e=1710374400&v=beta&t=-vUIbi1Q6d_yibA5oKRnwxnsXbcTPzU3lNUaMV75mFM,Matthew Hepburn,https://www.linkedin.com/in/ACoAAAPwt64BGmrsa6RrMPuzKHxkX5S7BEIlIgY?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAPwt64BGmrsa6RrMPuzKHxkX5S7BEIlIgY,"
Principal Product Marketing Manager, Amazon Science
","
At WSDM, Amazon scientists will present a paper which explains how augmenting query-product graphs with hypergraphs that describe product-product relationships can improve the recall score by more than 48%. The idea is that knowing which types of products are related to each other can help the GNN generalize from high-frequency to low-frequency queries: https://lnkd.in/guw3D7ks#AmazonScience #NeuralNetworks

          ‚Ä¶see more
        


Using hypergraphs to improve product retrieval
",,https://www.linkedin.com/feed/update/urn:li:activity:7040348531013931008?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7040348531013931008%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQFcdvzaCKMuDg/articleshare-shrink_800/0/1704545434359?e=1705658400&v=beta&t=QDNx83KZbS86X_o_nh28j0Sb3tf5HT6TlGPKtbls5h4
352,65a10597a5b8f072000022b2,e1ea1aa9-2907-a239-43b5-ddf617e22311,https://media.licdn.com/dms/image/C4D03AQEmDwFNREkaIA/profile-displayphoto-shrink_100_100/0/1517524291944?e=1710374400&v=beta&t=9H8wRu-S3Mr0BN5zZEZBtWwefLpa0ZU_FPNQ9dTlNws,Robin Gras,https://www.linkedin.com/in/ACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ,"
Professor at University of Windsor, CSO and partner at Movyl Technologies and MVYL Associates
","

 ",,https://www.linkedin.com/feed/update/urn:li:activity:7038871531078262784?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7038871531078262784%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C5622AQFDJjUiJ6Zutg/feedshare-shrink_480/0/1678122071021?e=1707955200&v=beta&t=5h7b0hWCUapnZLKG7aYlcMLSDNXvqT5JVAUyoQQV5fI
353,65a10597a5b8f072000022b3,216d46d6-5261-472c-a722-8c04807a4277,https://media.licdn.com/dms/image/D5635AQGXW0U7XhrOLA/profile-framedphoto-shrink_100_100/0/1660002772504?e=1705658400&v=beta&t=GCO4ys4jXbkiM-Qc6-U3aMntzetq4B1LehdMoLq8hvg,"Valeriy Manokhin, PhD, MBA, CQF",https://www.linkedin.com/in/ACoAADrXMbQB9bMdpMT4ritwB7eHLY3EBA0i6ZU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADrXMbQB9bMdpMT4ritwB7eHLY3EBA0i6ZU,"
Head of Data Science | Author of bestselling book ""Practical Guide to Applied Conformal Prediction""
","
In a comprehensive review of over 200+ machine learning competitions in 2022, when it comes to tabular data looking for winning solution using deep learning is like looking for a needle in a haystack in a dark barn when the needle is not even there.https://lnkd.in/e9B3na-E#machinelearning #tabulardata #deeplearning #data 

          ‚Ä¶see more
        


Tabular Data Competitions - Winning Strategies
",,https://www.linkedin.com/feed/update/urn:li:activity:7038925359186104320?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7038925359186104320%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQHtX0aepI8o-w/articleshare-shrink_800/0/1704996240157?e=1705658400&v=beta&t=zdJXolKE-tK-C5jaAzUg0ino0ddUODeCXUjttHqhRgo
354,65a10597a5b8f072000022b4,85dcb978-99b2-bc5c-5221-47c365ee498d,https://media.licdn.com/dms/image/C4E03AQFc7-OG4E1V2Q/profile-displayphoto-shrink_100_100/0/1659957271022?e=1710374400&v=beta&t=b6NZKfwRKZJaMBkPJ8J-7O1upS7Jocf8FpslouxwCtc,David Stutz,https://www.linkedin.com/in/ACoAABufnVgBV-fr4vSMKqiLPgwbbykptOb6QYc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABufnVgBV-fr4vSMKqiLPgwbbykptOb6QYc,"
Research scientist at Google DeepMind
","
I always wanted to start a series of articles about my PhD research on adversarial examples and confidence-calibrated adversarial training. As a first step, I created several code examples for illustrating these concepts and put them on GitHub: https://lnkd.in/ekh-AKkj 

          ‚Ä¶see more
        


GitHub - davidstutz/pytorch-adversarial-examples-training-articles: PyTorch code corresponding to my blog series on adversarial examples and (confidence-calibrated) adversarial training.
",,https://www.linkedin.com/feed/update/urn:li:activity:7032034614147731456?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7032034614147731456%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQEtO9-_iF5KrA/articleshare-shrink_800/0/1676565730052?e=1705658400&v=beta&t=ooem_Wd1RgHSTLlD0QGqCl-9yG86zwj4O2hXk_ivU04
355,65a10597a5b8f072000022b5,9e61bdb7-e69a-8cb2-d8d0-06e05551cb0e,https://media.licdn.com/dms/image/D4E03AQHtC2BUAB6jkA/profile-displayphoto-shrink_100_100/0/1694687456770?e=1710374400&v=beta&t=ndmP3__bJjjA60t62U8lCwf_bck4TDX4LIp-qSsOgAc,Prithivi Da,https://www.linkedin.com/in/ACoAAANONyEBI75vYtjMK4f9hcDMhgneli34DsA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAANONyEBI75vYtjMK4f9hcDMhgneli34DsA,"
Building a Memory Assistant for Philomaths. Sharing wisdom from a 2 decade experience in creative problem solving.
","
üöÄ Vocabulary bottleneck and how XLM-V tackles it ? ‚Üí What is Vocabulary Bottleneck ?Multilingual LLMs typically rely on a single vocabulary shared across 100+ languages. mT5 and XLM-R shares 250K vocabulary across 100+ languages. Minus shared tokens, this equals to average of 2,500 unique tokens per language. That‚Äôs **very less** for modelling complex languages like Tamil or even Chinese. ‚Üí Short story long: Increasing model parameters exponentially while keeping the data and hence the vocabulary static is sub-optimal for training LLMs.The model size and the number of training tokens should be scaled equally: for every doubling of model size the number of training tokens should also be doubled.This DeepMind paper proves that increasing tokens massively help - (https://lnkd.in/e4QwNkPB) Chinchilla is trained on ~few trillion tokens. ‚Üí Solution Construct a large multilingual vocabulary by attending to two core principles: (1) vocabularies can be improved by de-emphasizing token sharing between languages with little lex- ical overlap and (2) proper vocabulary capacity allocation for individual languages is crucial for en- suring that diverse languages are well-represented.See the image to understand how tokens using the new vocabulary are typically more semantically meaningful. ‚Üí How you can apply this is in daily life ?Try fine-tuning on hard benchmarks like GoEmotions to see the power for the large 1M vocabulary in English. Then extend it to your use case. Replicate the same into other hard multilingual benchmarks. HF model repo: https://lnkd.in/e5PKmjRH

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7029682916972470272?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7029682916972470272%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C4E22AQEvCuAhr1iptA/feedshare-shrink_480/0/1676007012164?e=1707955200&v=beta&t=-iU7-YZeSinek0QIi3-KP-S0uoUXEbYrnZnpgm5nUs8
356,65a10597a5b8f072000022b6,c1e06514-10eb-2efc-38de-fcdef728e439,https://media.licdn.com/dms/image/C4E03AQHVyH-IfD1KbQ/profile-displayphoto-shrink_100_100/0/1629877234109?e=1710374400&v=beta&t=0UZUl_dDUxLaZn-Hu-zToqEDe3rpL5cB2JkP5_jlNXc,"Sebastian Raschka, PhD",https://www.linkedin.com/in/ACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU,"
Machine learning and AI researcher since the early days ‚Ä¢ coding and working with LLMs at Lightning AI ‚Ä¢ ex-statistics professor at University of Wisconsin-Madison
","
Since transformers have such a big impact on everyone's research agenda, I wanted to flesh out a short reading list for machine learning researchers and practitioners getting started with large language models:https://lnkd.in/gBhC4X-h#machinelearning #deeplearning #largelanguagemodels 

          ‚Ä¶see more
        


Understanding Large Language Models -- A Transformative Reading List
",,https://www.linkedin.com/feed/update/urn:li:activity:7028733215162982400?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7028733215162982400%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5627AQEA4q9DUd_ReA/articleshare-shrink_800/0/1704052327321?e=1705658400&v=beta&t=4hXNcmmLs9aUrdk7IO06mqAJAYHwm4fWhB-S8ioLMVI
357,65a10597a5b8f072000022b7,b98319a6-b548-66d6-7eaa-9395454cdc6f,https://media.licdn.com/dms/image/D4D03AQFrh40bgEhFaw/profile-displayphoto-shrink_100_100/0/1666072954798?e=1710374400&v=beta&t=yWCZJdi89BcjFrZAC4AumkX567BXtK8wefoZB99RotA,Rashmi Margani,https://www.linkedin.com/in/ACoAABoSGHwB93YgMMhUhD28-dfmsdLXnCaRWF8?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABoSGHwB93YgMMhUhD28-dfmsdLXnCaRWF8,"
Sr Machine Learning Engineer | 2X Kaggle Master, Certified Tensorflow Developer | Generative AI
","
Stanford University NLP With Deep learning course, Winter 2023 is finally out with notes & hands-on code to practice, do check the link üëáhttps://lnkd.in/gCRgfTU5#nlp #deeplearning #ai

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7028343481056059392?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7028343481056059392%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C5622AQHqEpDM0LvLPA/feedshare-shrink_1280/0/1675687664943?e=1707955200&v=beta&t=RTdSgevU3OCMRypo8Ag_7CbUvMnx100K4x5fX0LLNqM
358,65a10597a5b8f072000022b8,96a79f82-5595-9d9e-4941-6b4b30d948e9,https://media.licdn.com/dms/image/C4D03AQEmDwFNREkaIA/profile-displayphoto-shrink_100_100/0/1517524291944?e=1710374400&v=beta&t=9H8wRu-S3Mr0BN5zZEZBtWwefLpa0ZU_FPNQ9dTlNws,Robin Gras,https://www.linkedin.com/in/ACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAXWclQBhUVEon-PX4Le5kIz1dTFQ4X69mQ,"
Professor at University of Windsor, CSO and partner at Movyl Technologies and MVYL Associates
","

 ",,https://www.linkedin.com/feed/update/urn:li:activity:7026918520483450880?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7026918520483450880%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C5622AQGrX83pRXbmOw/feedshare-shrink_480/0/1675272626632?e=1707955200&v=beta&t=q45y4XFdvkTt5E7K0DRCwTjIz9r7UWKpzakvAcYLOe4
359,65a10597a5b8f072000022b9,ba1d7685-6578-ea62-636a-4c165f867e1c,https://media.licdn.com/dms/image/C4D03AQHNWwINzIuVaw/profile-displayphoto-shrink_100_100/0/1517056074035?e=1710374400&v=beta&t=IawKBfqAwB2VzvMUTDv94fN-WJtddlIuI8uJ8qGDX8Y,Vincent Boucher,https://www.linkedin.com/in/ACoAAAT6B7ABGZT2LhGEkaN712Lix5D9e2xsJI0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAT6B7ABGZT2LhGEkaN712Lix5D9e2xsJI0,"
President of Montreal.AI and Quebec.AI
","
Multimodal Deep LearningAkkus et al.: https://lnkd.in/e-dHw8vY#ArtificialIntelligence #Multimodal #DeepLearning

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7025575825513054208?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7025575825513054208%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C4E22AQHs9-kFfOICFQ/feedshare-shrink_480/0/1675027804472?e=1707955200&v=beta&t=q-UKX8bKHPuHHn2b6Dd40RTtRftWKGKr-CxdZqwovX8
360,65a10597a5b8f072000022ba,64745045-9e18-7a75-1805-b0ef4e8f7d2a,https://media.licdn.com/dms/image/C4D03AQHBLoV7GRUP2w/profile-displayphoto-shrink_100_100/0/1642552032280?e=1710374400&v=beta&t=6fHP9zlPn3MfDX75uR_yOGRirqSCpNHqYVzC4P-vK0s,Yann LeCun,https://www.linkedin.com/in/ACoAAAADFk0BbiOeu2Wrer11SaPH_5m1GM8pG6Q?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAADFk0BbiOeu2Wrer11SaPH_5m1GM8pG6Q,"
VP & Chief AI Scientist at Meta
","
Excellent WaPo article about large language models and chatbots that corroborates what I've been posting recently: they are useful but they make stuff up. They detail the reasons why large tech cos have been hesitant to release such things for public use.

          ‚Ä¶see more
        


Big Tech was moving cautiously on AI. Then came ChatGPT.
",,https://www.linkedin.com/feed/update/urn:li:activity:7025141400795017216?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7025141400795017216%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQEeLAooS2DXrg/articleshare-shrink_800/0/1704819270957?e=1705658400&v=beta&t=9JMxgLvdFgnEgxABxvV49UTgLq09obJMHCaSW6DWxWU
361,65a10597a5b8f072000022bb,49997bf8-0262-c109-a3d0-23374f5bd634,https://media.licdn.com/dms/image/C4E0BAQGuCNI11jj7-w/company-logo_100_100/0/1678818380992/weights_biases_logo?e=1713398400&v=beta&t=JpUVq1a4FTkLO-0Ej-pY79EnagMdt7-zmKOG2YE-7Ew,Weights & Biases,https://www.linkedin.com/company/wandb/,"
60K followers
","
Deep Learning Tuning Playbook!For all W&B Sweeps users, there is lots of great information here from Google Research about how to get good results with deep learning, especially focusing on hyperparameter tuning ‚öñÔ∏èhttps://lnkd.in/dNRRvG-B

          ‚Ä¶see more
        


GitHub - google-research/tuning_playbook: A playbook for systematically maximizing the performance of deep learning models.
",,https://www.linkedin.com/feed/update/urn:li:activity:7022214506801975296?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7022214506801975296%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/C4E22AQE0KswydXuQnA/feedshare-shrink_800/0/1674226232809?e=1707955200&v=beta&t=Iy_UkBXv7mU8wiCk3kCD_fN1ZsIV_D4i-OXDJLk5As0
362,65a10597a5b8f072000022bc,815f67dc-2bd6-daa2-2d78-6502b9dce6c9,https://media.licdn.com/dms/image/D5603AQF5pJ6T7vIcUQ/profile-displayphoto-shrink_100_100/0/1674324994434?e=1710374400&v=beta&t=owiWeuxDD_cOkwy2kzTZt37IoQ8adqYl5TU7q_9rytk,Sudalai Rajkumar - SRK,https://www.linkedin.com/in/ACoAAAo06hgBCvufxwCCRJRMiq81GWx9xYQDEHI?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAo06hgBCvufxwCCRJRMiq81GWx9xYQDEHI,"
Head of AI & ML @ Growfin | 4x Kaggle Grandmaster | AI Advisor
","
An amazing video lecture by Andrej Karpathy on ""Let's build GPT: from scratch, in code, spelled out."" Video: https://lnkd.in/gYvb39J7Github: https://lnkd.in/gv4utkMRColab: https://lnkd.in/gg_ckieh#GPT #ChatGPT 

          ‚Ä¶see more
        


Let's build GPT: from scratch, in code, spelled out.
",,https://www.linkedin.com/feed/update/urn:li:activity:7021322858660335619?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7021322858660335619%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/C4D27AQF3r24et5_LHw/articleshare-shrink_800/0/1704995464320?e=1705658400&v=beta&t=ZkzrvrJHcl87gp0e26Fa2GZSwIzvwanvJ2TRyOAk1f8
363,65a10597a5b8f072000022bd,3a109858-68f1-9bcf-421d-a82f7de0fb99,https://media.licdn.com/dms/image/D4D03AQE0-UGFdlcP5w/profile-displayphoto-shrink_100_100/0/1679392873147?e=1710374400&v=beta&t=vkin-gXntcG3ep1ueLbNZnxJsbdT41Djqv6vc5g_g70,Daniel Vila Suero,https://www.linkedin.com/in/ACoAAAmaxuQB0yuvejYin78IVGuD5-IXhPUDu-g?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAmaxuQB0yuvejYin78IVGuD5-IXhPUDu-g,"
Building Argilla, the open-source feedback platform for LLMs
","
Document AI: LiLT a better language agnostic LayoutLM modelA layout transformer for multilingual document processing that outperforms LayoutLM v1. It comes with an MIT license, allowing for commercial use.Learn to fine-tune in this blog post by Philipp Schmid: #documentai #opensource #transformers

          ‚Ä¶see more
        


Document AI: LiLT a better language agnostic LayoutLM model
",,https://www.linkedin.com/feed/update/urn:li:activity:7018608901138898944?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7018608901138898944%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5634AQEMGj_J26f4DQ/ugc-proxy-shrink_800/0/1673366762409?e=1705658400&v=beta&t=PioMNvp17A3U6p3LDM_2yusuG_gDf_RpIHfaWrRocug
364,65a10597a5b8f072000022be,8ffc5989-343f-c432-dfd1-649de91c6cae,https://media.licdn.com/dms/image/C5103AQFjlk-Jow8APg/profile-displayphoto-shrink_100_100/0/1564304935230?e=1710374400&v=beta&t=nKlS2diGLNv6bJmz-0fSkP1fTqcJGY-U9pgpD5J8RXw,Xavier Bresson,https://www.linkedin.com/in/ACoAAAIK2dwBQTWil0cp2NWBtgE3pDli6LQXFJE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAIK2dwBQTWil0cp2NWBtgE3pDli6LQXFJE,"
Prof of Computer Science (AI) at National University of Singapore & Director of Graph Deep Learning Lab & Distinguished Researcher at Element Inc
","
Our paper ""Benchmarking Graph Neural Networks"" has been accepted for publication at Journal of Machine Learning Research (JMLR)! https://lnkd.in/g2UUjsYX(after rejection from NeurIPS, ICLR and ICML :)

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7013077709471825920?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7013077709471825920%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C5622AQGIcT5ya18MKw/feedshare-shrink_480/0/1672048021892?e=1707955200&v=beta&t=87Ok26dCtrWlv_Sku2bYOjbHDMrI1rD0nK6JxIZJFRM
365,65a10597a5b8f072000022bf,8805f662-5ea8-e907-d682-772c3dcd33c4,https://media.licdn.com/dms/image/C4D03AQEjNHuP79k5cQ/profile-displayphoto-shrink_100_100/0/1639094828263?e=1710374400&v=beta&t=pyGclV1UdA_-KGn9Jp2HZKe1oOQabme8hA_zSYMbnU0,Tomas Vykruta,https://www.linkedin.com/in/ACoAAAAVfCMBeRSLCnlfNTt3opYSoD1iB0IO8tE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAAVfCMBeRSLCnlfNTt3opYSoD1iB0IO8tE,"
Founder @ EvolutionIQ.. Twitter @tvykruta. Helping Injured & Disabled Individuals Return to Work Sooner, Saving Billions for our Economy. Formerly Google AI.
","
A new breakthrough in LLM's (Large Language Models) from Google AI. CALM is an early-out technique to dramatically cut down on inference cost by only partially computing tokens, while maintaining the same quality.As models are now approaching 1 trillion parameters cost becomes an increasingly large barrier.

          ‚Ä¶see more
        


Accelerating text generation with Confident Adaptive Language Modeling (CALM)
",,https://www.linkedin.com/feed/update/urn:li:activity:7014240785709551616?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7014240785709551616%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQFz_Tl2ykObQg/articleshare-shrink_1280_800/0/1704620738199?e=1705658400&v=beta&t=UCOvG2tZMSX0WuteH8COpFGRQxrkH2v-XPmKWjQNAXE
366,65a10597a5b8f072000022c0,61fddb40-a76e-9782-5a73-38362a099025,https://media.licdn.com/dms/image/C4D03AQGkpDhbH7K8JA/profile-displayphoto-shrink_100_100/0/1590241077618?e=1710374400&v=beta&t=fQiw6bTxke65ZGlRTH0YpeFcL4XlktVrLKvulgmbeQ8,Aditi Khinvasara,https://www.linkedin.com/in/ACoAADDoOL0BaLnEBvQk8Pt0Df_CyG7ELcwIG8c?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADDoOL0BaLnEBvQk8Pt0Df_CyG7ELcwIG8c,"
Co-Founder of The Ravit Show | ACCA | Love to share resources on trending topics for the community | Community Evangelist
","
Data and artificial intelligence (AI) are closely related, as the data that an AI system processes is a key factor in its ability to learn and make decisions. In fact, data is often referred to as the ""fuel"" that powers AI systems. What do you think?Data science is a broad field that involves using statistical and computational techniques to extract insights and knowledge from data.It involves working with large datasets and using tools and techniques such as machine learning, visualization, and statistical analysis to understand patterns and relationships in the data.AI, on the other hand, is focused on building systems that can perform tasks that would normally require human intelligence, such as learning, decision making, and problem solving. AI techniques include machine learning, natural language processing, and computer vision.The combination of data science and AI can be particularly powerful, as data science provides a way to analyze and understand large amounts of data, while AI provides a way to automate and scale the analysis and decision making process. For example, a data scientist might use machine learning algorithms to build a model that can predict customer churn based on historical data, and an AI system might be used to continuously monitor and analyze customer data in real-time to identify potential churn risk and take automated actions to prevent it.Overall, the combination of data science and AI has the potential to drive innovation and transform a wide range of industries, from healthcare and finance to transportation and manufacturing.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7014543616719138816?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7014543616719138816%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C4D22AQHsW3oYL8PnKQ/feedshare-shrink_480/0/1672397520086?e=1707955200&v=beta&t=j4Q4s9gRBRXPCZj21EoWfQaUSc_GkMcYgYbgTImjiq0
367,65a105b2a5b8f072000022c2,2f1defe0-50e0-23ff-644f-ffde853fb6aa,https://media.licdn.com/dms/image/C4D03AQHBLoV7GRUP2w/profile-displayphoto-shrink_100_100/0/1642552032280?e=1710374400&v=beta&t=6fHP9zlPn3MfDX75uR_yOGRirqSCpNHqYVzC4P-vK0s,Yann LeCun,https://www.linkedin.com/in/ACoAAAADFk0BbiOeu2Wrer11SaPH_5m1GM8pG6Q?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAADFk0BbiOeu2Wrer11SaPH_5m1GM8pG6Q,"
VP & Chief AI Scientist at Meta
","

 ",,https://www.linkedin.com/feed/update/urn:li:activity:7013554198684270593?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7013554198684270593%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C4E22AQHMzgulQC6XkQ/feedshare-shrink_480/0/1671995338372?e=1707955200&v=beta&t=1AqqRvPDn2zVnmLVFn4WI2eYHD8yXLACGSkmo0BXQPE
368,65a105b2a5b8f072000022c3,383ba746-ef70-6bcd-ef0a-54f951cb18b8,https://media.licdn.com/dms/image/C4E03AQHVKPXGXT9G5w/profile-displayphoto-shrink_100_100/0/1517877121618?e=1710374400&v=beta&t=9SBmCyAli_JC0Y24gICqniD7GBW9EnqI6CwK4EQyx5c,Kalyan KS,https://www.linkedin.com/in/ACoAACOxXccBybNmyDeDKs9aU0WmznYNEE--2u0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACOxXccBybNmyDeDKs9aU0WmznYNEE--2u0,"
NLP Researcher | LLMs | Founder @Akmmus AI
","
‚ôæ TinyML and Efficient Deep Learning (MIT 2022 Course)========================================This course covers‚úîÔ∏è Basics of Deep Learning‚úîÔ∏è Pruning and Sparsity ‚úîÔ∏è Quantization ‚úîÔ∏è Neural Architecture Search‚úîÔ∏è Knowledge Distillation‚úîÔ∏è Tiny Neural Network Design for Microcontrollers‚úîÔ∏è Distributed Training and Gradient Compression‚úîÔ∏è On-Device Training and Transfer Learning‚úîÔ∏è TinyEngine - Efficient Training and Inference on Microcontrollers‚úîÔ∏è Efficient Point Cloud Recognition‚úîÔ∏è Efficient Video Understanding and GANs‚úîÔ∏è Efficient Transformers‚úîÔ∏è Quantum Machine Learningüî¥ For the latest AI and Data Science updates, check https://lnkd.in/gBN6jYtT üî¥ Course videos playlist link: https://lnkd.in/gmmksrenüî¥ Course webpage link: https://lnkd.in/gRj_hCAP==========================================#deeplearning #tinyml #tinymachinelearning #quantummachinelearning #datascience #ai #moocs #MIT #machinelearning 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7009232060632489984?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7009232060632489984%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C5622AQHTjdBG306S2g/feedshare-shrink_480/0/1671131147656?e=1707955200&v=beta&t=lmabh5eUs2S81i5PWWnDy_sYkE_xN3KH4bImfjBIcOU
369,65a105b2a5b8f072000022c4,c8d17539-505a-0288-30e9-6027649b3d70,https://media.licdn.com/dms/image/D4D03AQEYhGxgOXZ2uw/profile-displayphoto-shrink_100_100/0/1665173710831?e=1710374400&v=beta&t=79ENqB89hgxIvr5wVmcA6JujdOS-nSes96-0KNIMnYo,Ayush Thakur,https://www.linkedin.com/in/ACoAACPorBUBlkdNi44PH5WARVBpKJsSyF2taNk?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACPorBUBlkdNi44PH5WARVBpKJsSyF2taNk,"
Machine Learning Engineer at Weights & Biases | Google Developer Expert in Machine Learning | Kaggle Notebooks Master
","
ChatGPT is all the craze now, and it truly deserves it. However, the underlying training strategy - Reinforcement Learning with Human Feedback(RLHF), is something not known to many.I went through a few of the papers by OpenAIand summarized them: http://wandb.me/rlhf-part1Here's a quick summary of summary for the paper ""Learning to Summarize with Human Feedback"":- Generate preference data- Learn a reward model- Learn a policy model by using the learned reward functionCheck out the report to learn more. :)#reinforcementlearning #machinelearning 

          ‚Ä¶see more
        


Understanding Reinforcement Learning from Human Feedback (RLHF): Part 1
",,https://www.linkedin.com/feed/update/urn:li:activity:7009515910709293056?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7009515910709293056%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/C4D27AQFnfF40a7WsKA/articleshare-shrink_480/0/1704730838994?e=1705658400&v=beta&t=6c5jmylINT9FR5j8N4HfSyW-XP-Ek0sYvjgdpVz49qo
370,65a105b2a5b8f072000022c5,c58280ac-98ad-cc84-bcdc-bdb9e6404e91,https://media.licdn.com/dms/image/D5603AQGEADhHyEQ8rw/profile-displayphoto-shrink_100_100/0/1682553354695?e=1710374400&v=beta&t=kfjA-KO1Ea4gqAJ68vTh1_4ORnZzWv1qSW4bXFvg_tc,"Damien Benveniste, PhD",https://www.linkedin.com/in/ACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw,"
The ML Guy - Follow me to learn about Machine Learning Engineering, Machine Learning System Design, MLOps, and the latest techniques and news about the field. Join my AI newsletter and keep learning!
","
Sometime we just need to sit back and relax watching videos! Here are great YouTube channels to learn Machine Learning from. Enjoy:- What's AI by Louis Bouchard: https://lnkd.in/euVngxvQ- Abhishek Thakur (Practical videos, Talks) : https://lnkd.in/eTPrcvEN- Ahlad Kumar (Deep learning, Theoretical): https://lnkd.in/eVGxpXfw- Aladdin Persson (PyTorch, TensorFlow): https://lnkd.in/e29966pV- Andreas Mueller: https://lnkd.in/eQYM3WyC- Data School (Python, Machine learning, Theoretical): https://lnkd.in/eXEjf27Q- Connor Shorten (Theoretical): https://lnkd.in/ejdwwyzq- Jeremy Howard (Deep learning, Theoretical): https://lnkd.in/ec3DGa7g- Rasa (Rasa, AI, NLP): https://lnkd.in/ehUe-qPE- Yannic Kilcher (NLP, Machine learning, Deep learning, Theoretical): https://lnkd.in/ebRk-bMB- OpenAI (NLP, Machine learning, AI): https://lnkd.in/eWvCKiqz- Two Minute Papers (Machine Learning and AI Research, Scientific Papers): https://lnkd.in/eQY_5_SV- Machine Learnia (Machine Learning, Scikit Learn, Python): https://lnkd.in/enFTrVh9- Mark Saroufim (Machine Learning Engineering, Practical videos, Books review): https://lnkd.in/ez32nFS5- sentdex (Python for AI and Finance): https://lnkd.in/eMsdgVbSI found that curated list of YouTubers on this awesome repo: https://lnkd.in/eVgmFN8Y. That repo has similar lists for many other software skills, so make sure to check it out.---I offer Machine Learning consulting services: https://lnkd.in/gqzuB6kMI offer Data Science career mentoring: https://lnkd.in/gGBMXuR4Follow me on Twitter: https://lnkd.in/eQ454QHD #machinelearning #datascience #youtube 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7009556893308223488?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7009556893308223488%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C4E22AQGk-Yc7PyAm-w/feedshare-shrink_480/0/1671208593634?e=1707955200&v=beta&t=L15p_aq9yZHEupSoz79fOYCsnYwWmest9YylIGuYspc
371,65a105b2a5b8f072000022c6,709e0ad1-b33e-09f8-03da-95322fbb6187,https://media.licdn.com/dms/image/D4D03AQHdnd33hAERuw/profile-displayphoto-shrink_100_100/0/1679083003289?e=1710374400&v=beta&t=X3EykKbKBW3NmYj9nC-UvQkyAO-SBlF2-zswImlKOBk,Misal Raj,https://www.linkedin.com/in/ACoAAA2IefYBVqBmytQ9xavdt77GgrULTjqEJ90?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA2IefYBVqBmytQ9xavdt77GgrULTjqEJ90,"
Learner üë®üèª‚Äçüíª
","
Someone built a chrome extension that lets you augment your prompts to ChatGPT with results from the web.One Step ahead wow...! üëèüèº üëèüèº GitHub: https://lnkd.in/dkWCE-zp#github #openai #chatgpt OpenAI 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7005958988068491264?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7005958988068491264%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C4D05AQGUz_60LtVl_w/videocover-low/0/1670350775197?e=1705658400&v=beta&t=DDem_eBktUW5NKKJNAijqg1fq2_qI6OJKvECc_DXI0k
372,65a105b2a5b8f072000022c7,47680524-d76c-b882-f9b6-c691de32e58d,https://media.licdn.com/dms/image/C4D03AQEtjiG_Bs08aQ/profile-displayphoto-shrink_100_100/0/1567619914305?e=1710374400&v=beta&t=LDRLnI-rCttiNcqZGt3kUCdjk5Yrt8_ybEMPaA-x8c8,Nikita I.,https://www.linkedin.com/in/ACoAAC1DMnUBhsZuhvw0YLdT-V58I4YpwptPg8A?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAC1DMnUBhsZuhvw0YLdT-V58I4YpwptPg8A,"
Lead Machine Learning Engineer - GraphML
","
üï∏ Why Graph Algorithms & Graph Neural Networks for RecSys ‚ùìGraph Neural Networks & Graph Algorithms are very hot topic for RecSys now üì≤ But why large companies like Pinterest, eBay, Amazon, Baidu, Alibaba, Rakuten, Netflix and Uber use it in Production ‚ùîüîé üîΩHere is my (opinionated) guide:üî∑ Scalability of Graph Algorithms (Candidate Selection)Graph Algorithms (metapath-based Random Walks) are more accurate than Neural Networks and Matrix Factorization and scale to Billion-Size datasets (Pixie, RP3Beta, P3Alpha) [1]üî∑ Powerful Graph Features and Graph EmbeddingsDuring recent Kaggle H&M Personalized Fashion Recommendation competition, the winner (1st place) used Graph Embeddings [2]üî∑ Domain Knowledge and HeuristicsRecSys needs many context-based heuristics: cold start for new users/items, compatitbility of items, aggregate diversity/novelty etc. Graph are useful to encode/store such information and make it available for the user (Metapath, Knowledge-Aware, Context-Aware Pre-Filtering and Post-Filtering)  [3]üî∑ Session-Based RecommendationsSession-based RecSys uses sequence of user activities to predict the next-based action [4]Practical challenges for usual approach (i.e. Matrix Factorization):üîπ Dynamic Changes of User Preferences in Timeüîπ Non-linear Dependenciesüîπ Limited Number of Known UsersFirst place of RecSys Challenge 2022 for session-based recommendations used LightGBM with Graph Neural Networks [5]üî∑ Fairness & DiversityGraph Algorithms could be useful to maximize aggregate diversity with approaches like maximum flow (FairMatch [6]). Very important, cause Rich-Get-Richer recommendations lead to Echo Chambers and Misinformation Propagation [7]üî∑ CounterFactuals & CausalityRecSys needs to improve not just clicks or purchases, but generated uplift or treatment effect. Given experiments are costly, it may require causal inference and counterfactuals evaluation which is modeled as Graph as well [8]üî∑ Trustworthy ExperimentsRandomized Trials could suffer from interference if the treatment of one unit affect another. To place units in condition as close to the All Treated vs All Control world, Cluster-Randomized Trial assign units to treatment/control in Graph Clusters [9]‚è¨  Links in Comments:üîΩ Materials to Startüëâ Graph Algorithms Scalability, Accuracy and Benchmarks [1]üëâ Graph Embeddings - 1st Place in Kaggle H&M Competition [2]üëâ Session-Based Recommendations for Recsys [4] [5]üîΩ Practical Topicsüëâ Domain Knowledge and Heuristics for RecSys [3]üëâ Inductive and Temporal Capabilties with GNN üëâ Fairness & Diversity with Graph Algorithms [6]üëâ Misinformation Propagation due to Echo Chambers [7]üîΩ Advanced Topicsüëâ CounterFactuals & Causality with Graphs [8]üëâ Trustworthy Experiments with Cluster-Randomized Trials [9]#graph #graphneuralnetworks #recsys #scalability #graphfeatures #embedding #domainknowledge #fairness #diversity #causality #trustworthyai #neuralnetworks #kaggle #session #ai

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7005832760263077888?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7005832760263077888%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C4D22AQHy8_cf84nzLQ/feedshare-shrink_480/0/1670320691154?e=1707955200&v=beta&t=cw_K3T8mj48ChsJSrq-_h_sQvZroHoIJvyc3edd5JoQ
373,65a105b2a5b8f072000022c8,4c99c27b-01cf-e9e9-c1d1-1d9b53628758,https://media.licdn.com/dms/image/C4D03AQFvVNt7jLmtVw/profile-displayphoto-shrink_100_100/0/1629998305467?e=1710374400&v=beta&t=MdtxcfaF7isMVX9ACydkuUe8U7ucoEXxObkgHtcGwVU,Manousos Klados,https://www.linkedin.com/in/ACoAAAHuokEB2mWvYbZQ4dHLunyPmwAl-QSHEnE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAHuokEB2mWvYbZQ4dHLunyPmwAl-QSHEnE,"
Associate Professor at CITY College, University of York Europe Campus
","
I am completely in love with the faces of my #student when I demonstrate them the practical aspects of #neurofeedback. Here you can see a protocol for #depression which tries to normalize #prefrontal alpha asymmetry. However the student hopefully she wasn‚Äôt suffering from depression that‚Äôs why you see the left and right alpha to be equal. If you like #neuropsychology and #neuroscience you should consider joining us on the #MSc in #cognitive neuropsychology or on the #MA in #clinical neurpsycholoy at CITY College, University of York Europe Campus  #university #europe

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7004503237110239232?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7004503237110239232%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C5622AQGRcsKuk02vEw/feedshare-shrink_480/0/1670003708243?e=1707955200&v=beta&t=omdV1r6m8c3Egtq_neaaPZvkV2uEvIVclOKI6CFE-Ts
374,65a105b2a5b8f072000022c9,695a3034-58ed-a34f-892a-49383eb8cbea,https://media.licdn.com/dms/image/D5603AQGh1Z95nvtKlQ/profile-displayphoto-shrink_100_100/0/1694010449294?e=1710374400&v=beta&t=8EwfJ7XhVJCW5qBJnBADGDBiTPraxzbEb-Az3ZghGbM,Frank Kumli,https://www.linkedin.com/in/ACoAAAAcrKsBjwbowb6d9XsNfIJ6QJBcBoEZfyg?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAAcrKsBjwbowb6d9XsNfIJ6QJBcBoEZfyg,"
Head of Innovation & Entrepreneurship @ Basel Area Business & Innovation | Promoting Collaborative Innovation
","
Strategy Maps!Understanding company or competitive strategy doesn't come from listening to their senior executives rattle off carefully coached  talking pointsInstead, corporate strategy is found, as Drucker said, where companies allocate their time and moneyIt is found by mining resource allocation and relationship data Who are their:Vendors?Partners?Investments?M&A targets?These are the non-BS predictors  of strategyThe Strategy Maps in this book by CB Insights shine a light on the strategy of some of the world's most  important companiesCheck it out here: https://lnkd.in/euv5SCmc?#innovation #strategy #strategymaps #tech #bigtech #retail #healthcare #digitalhealth

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7001151762564800512?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7001151762564800512%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C4E22AQG2ba3b4CDx4w/feedshare-shrink_480/0/1669204654576?e=1707955200&v=beta&t=ACnG6UpKRzWmoP0Py9rYa7sTyqulbpAT_ENnYPXR470
375,65a105b2a5b8f072000022ca,8ac79b43-9ec1-4bcb-7f0a-1869dcbe9a98,https://media.licdn.com/dms/image/C4D03AQG-9rOlgK84oQ/profile-displayphoto-shrink_100_100/0/1585905904257?e=1710374400&v=beta&t=LZKy80Ei6Iw5ynkF2sC7wmdA0tH5crirpLYRsRZuIXk,Oleksandr Honchar,https://www.linkedin.com/in/ACoAAA06vjIBSAlWpwepqoDB5WFVyJINEJRlXQs?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA06vjIBSAlWpwepqoDB5WFVyJINEJRlXQs,"
Director of AI Engineering & Partner @ Neurons Lab
","
Collaboration of Hugging Face and Arxiv on demos related to the ML papers is an amazing step towards the reproducibility of results and trust in the field. I hope many more companies and individuals will pick up from there and will do the same with their work

          ‚Ä¶see more
        


Discover State-of-the-Art Machine Learning Demos on arXiv | arXiv.org blog
",,https://www.linkedin.com/feed/update/urn:li:activity:7001107394537615360?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7001107394537615360%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/C4D10AQGW80d3tz556g/image-shrink_800/0/1669194076826?e=1705658400&v=beta&t=bIP-CDKS_0kuFeWj-IFEbhey9Yq9642pEI46JYdVeJ4
376,65a105b2a5b8f072000022cb,ba92b454-1e93-8668-7570-f6d9c8910316,https://media.licdn.com/dms/image/D5603AQG9NK0CAgKtVg/profile-displayphoto-shrink_100_100/0/1687301791875?e=1710374400&v=beta&t=Bolt2zUMX7vi6uTl04U5LmzIk8J4LR-CV26o0v_KAIU,Lior S.,https://www.linkedin.com/in/ACoAADMTPYsBtfLtDZlCPxc0G4n0-rFYtqhC0yE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADMTPYsBtfLtDZlCPxc0G4n0-rFYtqhC0yE,"
I cover the latest breakthroughs in AI ‚Üí Ex-ML Engineer/Researcher ‚Üí Built the most read technical newsletter in AI
","
TabPFN is a new tabular data classification method that takes 1 second & yields SOTA performance! TabPFN is radically different from previous ML methods. It is meta-learned to approximate Bayesian inference with a prior based on principles of causality and simplicity.Brilliant work from Frank HutterPaper: https://lnkd.in/dRixNFceCode: https://lnkd.in/dJCBinDe‚ÜìCheck out https://AlphaSignal.ai to get a weekly summary of the top 1% papers, news, repos, and tweets in Machine Learning.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7000854438819074049?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7000854438819074049%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C4D22AQEIm0n5tCyvBQ/feedshare-shrink_480/0/1669133767113?e=1707955200&v=beta&t=k5V3B9Ru14_Ri-Lb18I2UDR5VHxMNDfiL3Xad3wwtb8
377,65a105b2a5b8f072000022cc,a9404582-e99c-b104-5f96-adf2056bd435,,ADARSH C.,https://www.linkedin.com/in/ACoAABZZ9sIB_FSTPRIfLfDOf7vFVRTq2MEj5JA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABZZ9sIB_FSTPRIfLfDOf7vFVRTq2MEj5JA,"
Blockchain Developer | Sharing the latest developments in the world of Tech,Web3 & AI |Content Creator | Exploring how to get better at the game of Life | Dm for Collab
","
‚ô¶Ô∏èSystem Design Interview Prep for FAANGSystem Design is one of the most important parts of any tech interview process. s. Here is the curated list of the top engineering amazing articles to help you learn more about their architecture and prepare for System Design (HLD) Interviews.I would highly suggest you to go through 1-2 articles everyday. It would hardly take 40 mins/day. Consistency is key ‚ù§Ô∏è‚úÖ Things you must know in System Design üëâSystem design basics: https://bit.ly/3SuUR0YüëâHorizontal and vertical scaling: https://bit.ly/3slq5xhüëâ Load balancing and Message queues: https://bit.ly/3sp0FP4üëâHigh-level design and low-level design, Consistent Hashing, Monolithic and Microservices architecture: https://bit.ly/3DnEfEmüëâ Caching, Indexing, Proxies: https://bit.ly/3SvyVDcüëâ Networking, How Browsers work, Content Network Delivery ( CDN): https://bit.ly/3TOHQRbüëâ Database Sharding, CAP Theorem, Database schema Design: https://bit.ly/3CZtfLNüëâ Concurrency, API, Components + OOP + Abstraction : https://bit.ly/3sqQrhjüëâ Estimation and Planning, Performance: https://bit.ly/3z9dSPNüëâ Map Reduce, Patterns, and Microservices: https://bit.ly/3zcsfmvüëâ SQL vs NoSQL and Cloud: https://bit.ly/3z8Aa49üëâ Most Popular System Design Questions: https://bit.ly/3Dp40Ux‚úÖ System Design Case Studiesüëâ Design Netflix: https://bit.ly/3GrAUG1üëâ Design Reddit: https://bit.ly/3OgGJrLüëâ Design Messenger App : https://bit.ly/3DoAAXiüëâ Design Instagram: https://bit.ly/3BFeHlhüëâ Design Dropbox: https://bit.ly/3SnhncUüëâ Design Youtube: https://bit.ly/3dFyvvyüëâ Design Tinder: https://bit.ly/3Mcyj3Xüëâ Design Yelp: https://bit.ly/3E7IgO5üëâ Design Whatsapp: https://bit.ly/3M2GOhPüëâ Design URL shortener : https://bit.ly/3xP078xüëâ Design Amazon Prime Video: https://bit.ly/3hVpWP4üëâ Design Twitter: https://bit.ly/3qIG9Ihüëâ Design Uber: https://bit.ly/3fyvnlTüëâ Design TikTok : https://bit.ly/3UUlKxPüëâ Design Facebook's Newsfeed: https://bit.ly/3RldaW7üëâ Design Web Crawler: https://bit.ly/3DPZTBBüëâ Design API Rate Limiter: https://bit.ly/3BIVuh7‚úÖ All solved case studies: https://bit.ly/3dCG1rcüëâ System Design Important terms - https://bit.ly/3Om9d3Hüëâ Most Popular System Design Questions: https://bit.ly/3E9oH7Küëâ Complete System Design Basics Series: https://bit.ly/3rG1cfrI hope it helps you out in your next interview.Do save the link and share with the person in need.Do Follow ADARSH CHETAN for more such amazing stuff ‚ù§Ô∏è#interview #interviewpreparation #interviewprep #leetcode

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7000672063132741633?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7000672063132741633%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C4D22AQH_B0gmDzHmCg/feedshare-shrink_480/0/1669090284114?e=1707955200&v=beta&t=vnM7JSZJTz2QiaXSjhVahezeWZJFR3PsqKiD4XVoa4I
378,65a105b2a5b8f072000022cd,dac86854-cff4-a15f-6f34-4ee560820b6e,https://media.licdn.com/dms/image/C5603AQE48l0Ksvlisw/profile-displayphoto-shrink_100_100/0/1579105396847?e=1710374400&v=beta&t=aa60mdo5wR4aaHdCkJyNqC6i5pNOiIrbxqX-PEMqT4Q,Martin Ciupa,https://www.linkedin.com/in/ACoAAANoUnwBORTv6gvBulqiP20nbTvyN0Izlfg?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAANoUnwBORTv6gvBulqiP20nbTvyN0Izlfg,"
AI Entrepreneur. Keynote Speaker, Interests in: AI/Cybernetics, Physics, Consciousness Studies/Neuroscience, Philosophy: Ethics/Maths//Science.
","
Comment Large Language Models (LLM) are currently a big thing in AI (overblown/hyped to my thinking as a route to AGI).  Though this book size review is a significant contribution, as they are likely useful in some narrow AI applications, plus a potentially useful component in future Neuro-Symbolic Hybrid AI architecture (something I‚Äôm working on).Title: Holistic Evaluation of Language ModelsSee‚Ä¶ https://lnkd.in/eP8tc55GAbstract: Language models (LMs) are becoming the foundation for almost all major language technologies, but their capabilities, limitations, and risks are not well understood. We present Holistic Evaluation of Language Models (HELM) to improve the transparency of language models. First, we taxonomize the vast space of potential scenarios (i.e. use cases) and metrics (i.e. desiderata) that are of interest for LMs. Then we select a broad subset based on coverage and feasibility, noting what‚Äôs missing or underrepresented (e.g. question answering for neglected English dialects, metrics for trustworthiness). Second, we adopt a multi-metric approach: We measure 7 metrics (accuracy, calibration, robustness, fairness, bias, toxicity, and efficiency) for each of 16 core scenarios to the extent possible (87.5% of the time), ensuring that metrics beyond accuracy don‚Äôt fall to the wayside, and that trade-offs across models and metrics are clearly exposed. We also perform 7 targeted evaluations, based on 26 targeted scenarios, to more deeply analyze specific aspects (e.g. knowledge, reasoning, memorization/copyright, disinformation). Third, we conduct a large-scale evaluation of 30 prominent language models (spanning open, limited-access, and closed models) on all 42 scenarios, including 21 scenarios that were not previously used in mainstream LM evaluation. Prior to HELM, models on average were evaluated on just 17.9% of the core HELM scenarios, with some prominent models not sharing a single scenario in common. We improve this to 96.0%: now all 30 models have been densely benchmarked on a set of core scenarios and metrics under standardized conditions. Our evaluation surfaces 25 top-level findings concerning the interplay between different scenarios, metrics, and models. For full transparency, we release all raw model prompts and completions publicly3 for further analysis, as well as a general modular toolkit for easily adding new scenarios, models, metrics, and prompting strategies.4 We intend for HELM to be a living benchmark for the community, continuously updated with new scenarios, metrics, and models.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6999108979347836928?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6999108979347836928%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C4E22AQHA3hgRkfh4qQ/feedshare-shrink_480/0/1668717615837?e=1707955200&v=beta&t=exEfxEdbTf8kMydyeP3lYZdP6ikroRHSaYwUilHlhLE
379,65a105b3a5b8f072000022ce,7120ca39-41fb-871c-0c0c-e58360b5ab3c,https://media.licdn.com/dms/image/D4D03AQEzdcuDVK0XSw/profile-displayphoto-shrink_100_100/0/1702550409037?e=1710374400&v=beta&t=l_OheskwduVGz1WWxuK_sLxfa2Twc2Wj0drlFoWDLdo,Mohammed Boussardi,https://www.linkedin.com/in/ACoAACzWg90B-vCRVhcPi_y2VId2CJ5vzZvISmw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACzWg90B-vCRVhcPi_y2VId2CJ5vzZvISmw,"
Oracle Apex Developer at Popay | Proficient in Java, Python, C++ & PL/SQL | Passionate about Expanding Skills in Programming and Networking
","
Rocky Xu  üòçü§©ü§©
 

Goldman Sachs - Company that Ruled the World | 2022 Documentary
",,https://www.linkedin.com/feed/update/urn:li:activity:6997596829630484480?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6997596829630484480%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/C5627AQHqx-UUGFL1iw/articleshare-shrink_1280_800/0/1705000667242?e=1705658400&v=beta&t=I9xrH5vQxWFx5ddEoN4HfSTf__t-xpfmnVPAXJk9vEw
380,65a105b3a5b8f072000022cf,a178556f-394b-59eb-2f9f-6c7ee8516bf6,https://media.licdn.com/dms/image/D5635AQFT2QP4_1IAsw/profile-framedphoto-shrink_100_100/0/1668012887571?e=1705658400&v=beta&t=2YxvvyucnXl6LhDL_U6bajnW8gAG6-cnvg7IpVNurYY,Mike Patterson,https://www.linkedin.com/in/ACoAAAAhvqsBARE9C-xEStaz3eplk310Ny2fHsM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAAhvqsBARE9C-xEStaz3eplk310Ny2fHsM,"
Hyperscale Data Center Operations | IT Leadership | Cross-functional Team Leadership | IT Strategy and Disaster Recovery
","
I am sure this will get lost amongst the other 11K #metalayoffs posts.  But, I too am part of the list who received notice today.  It has been a pleasure building all of the relationships with people over the almost 5 years(next month).  I can only hope I am able work at another company with such great people.  Stay Strong and my heart goes out to the affected and not and to the great family at the Meta Prineville Datacenter.#opentowork

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6996237783199535104?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6996237783199535104%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C4E22AQEsVEYHzsD_eQ/feedshare-shrink_480/0/1668033069908?e=1707955200&v=beta&t=prWOrIVAEONwT9IfleLUHyrkii29r6AD0L71oP-cbO0
381,65a105b3a5b8f072000022d0,82891c61-5b99-78f7-6f51-824edb8a8579,https://media.licdn.com/dms/image/C4D03AQFTwrdIn8d-mA/profile-displayphoto-shrink_100_100/0/1604245712566?e=1710374400&v=beta&t=l4-FrAa7wImnnZDPnH93cJEv7BZODxi5FSckrSiPUPI,Giannis Tolios,https://www.linkedin.com/in/ACoAAA4S6wIBSZyJZDZq6NnoXsAqh64btIYNPTE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA4S6wIBSZyJZDZq6NnoXsAqh64btIYNPTE,"
Data Scientist | Book Author at Leanpub | Contributor at Towards Data Science | Passionate about Climate Change Mitigation
","
ùóôùó≤ùóÆùòÅùòÇùóøùó≤ ùóòùóªùó¥ùó∂ùóªùó≤ùó≤ùóøùó∂ùóªùó¥ ùó≥ùóºùóø ùóßùó∂ùó∫ùó≤ ùó¶ùó≤ùóøùó∂ùó≤ùòÄ!üí°tsfresh is a python library that can be used for systematic feature engineering of time series and other sequential data. The extracted features can be used to provide new insights into the statistical properties and dynamics of time series. They can also be used to train machine learning models for classification, regression, clustering and other tasks. Have you ever applied feature engineering on time series data? You can check the links below for more information, and make sure to follow me for regular data science content!ùòÅùòÄùó≥ùóøùó≤ùòÄùóµ ùóöùó∂ùòÅùóµùòÇùóØ ùóøùó≤ùóΩùóºùòÄùó∂ùòÅùóºùóøùòÜ: https://lnkd.in/dCKNSmNrùóúùóïùó† ùóóùóÆùòÅùóÆ ùó¶ùó∞ùó∂ùó≤ùóªùó∞ùó≤ ùó£ùóøùóºùó≥ùó≤ùòÄùòÄùó∂ùóºùóªùóÆùóπ ùóñùó≤ùóøùòÅùó∂ùó≥ùó∂ùó∞ùóÆùòÅùó≤üìö: https://lnkd.in/dT5EeKsyùóîùóπùóΩùóµùóÆ ùó¶ùó∂ùó¥ùóªùóÆùóπ-ùóÆ ùòÑùó≤ùó≤ùó∏ùóπùòÜ ùó†ùóü ùóªùó≤ùòÑùòÄ ùòÄùòÇùó∫ùó∫ùóÆùóøùòÜüß†: https://lnkd.in/duSJp8u9#datascience #python #machinelearning #deeplearning #linkedin 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6996165180195782656?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6996165180195782656%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C4D22AQGwbKHbXQtQNw/feedshare-shrink_480/0/1668015760644?e=1707955200&v=beta&t=QaeNcl4VDu-hn0OOls1qzQtcxpKxWhYLeFL75tlMr98
382,65a105b3a5b8f072000022d1,0f877471-bf87-a92d-c059-9c4f1452329b,https://media.licdn.com/dms/image/C5603AQFvncvflX_kMQ/profile-displayphoto-shrink_100_100/0/1564316873635?e=1710374400&v=beta&t=DRxjFCzRMNJSc3QM233eAmSZ8rflNQHLrn8k0KQuOhg,Elvis S.,https://www.linkedin.com/in/ACoAACxhXeUBTYZYCwIa4nsvSBsETtrS0uhGNPc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACxhXeUBTYZYCwIa4nsvSBsETtrS0uhGNPc,"
Co-Founder at DAIR.AI | Prev: Meta AI, Galactica LLM, PapersWithCode, Elastic
","
This new deep learning course by Andrej Karpathy is üî•!I like that it goes deep into how to implement and use neural networks. The content complements other courses where NN details are typically skipped.https://lnkd.in/eurRvzt3#machinelearning #deeplearning #ai

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6994648654934331392?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6994648654934331392%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C4E22AQFhbADvMtLp5w/feedshare-shrink_480/0/1667654192387?e=1707955200&v=beta&t=E9cKF5KfSFzf18At5iel8pfXIRKWbtXk9BGhm2ASweA
383,65a105b3a5b8f072000022d2,f4f60f3f-c9d7-a0e7-5354-b2bdfe08cac7,https://media.licdn.com/dms/image/D5635AQEBzEFRC2EzLg/profile-framedphoto-shrink_100_100/0/1704907585971?e=1705658400&v=beta&t=x71pDAJzCbSPZxvt91sIkpmEr_5_pGLZIt6VZgw5eV0,Aman Chadha,https://www.linkedin.com/in/ACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU,"
GenAI Leadership @ Amazon AWS ‚Ä¢ Stanford AI ‚Ä¢ EB-1 ""Einstein Visa"" Recipient/Mentor ‚Ä¢ Ex-Ô£ø, Amazon Alexa, Nvidia, Qualcomm ‚Ä¢ EMNLP 2023 Outstanding Paper Award
","
I‚Äôm #hiring for both full-time and intern roles for Amazon Alexa AI. We're looking for exceptional AI scientists skilled at deep learning, who are eager to work on cutting-edge AI, and build the next generation of Amazon #alexa. If this is you, get in touch!#amazon #jobs #artificialintelligence #machinelearning #ai #ml  #deeplearning #research #speech #nlp #datascience #mlengineer #neuralnetworks #career #python #internship

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6994520676401389568?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6994520676401389568%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C5622AQEBs3Xnb92SCg/feedshare-shrink_480/0/1667623679955?e=1707955200&v=beta&t=5bcwM6fqqdlWJqsNEb9AdikOyDY3O4KzgeNXglkrZdA
384,65a105b3a5b8f072000022d3,7c6eedbe-dad9-ae83-0453-78dd9e3a054d,https://media.licdn.com/dms/image/D5603AQGEADhHyEQ8rw/profile-displayphoto-shrink_100_100/0/1682553354695?e=1710374400&v=beta&t=kfjA-KO1Ea4gqAJ68vTh1_4ORnZzWv1qSW4bXFvg_tc,"Damien Benveniste, PhD",https://www.linkedin.com/in/ACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw,"
The ML Guy - Follow me to learn about Machine Learning Engineering, Machine Learning System Design, MLOps, and the latest techniques and news about the field. Join my AI newsletter and keep learning!
","
If you are preparing for Machine Learning INTERVIEWS, you may want to check out this repos to help you prepare: https://lnkd.in/g7gXhmYv. I would also checkout Khang Pham's repo (https://lnkd.in/gxNeJxgC) as there seems to be a lot of good material on there as well. Materials for Machine Learning System Design interviews are quite rare online so it is always to find something free that is actually useful. I often see people being overwhelmed by the amount of things to learn for interviews, but it is actually not that difficult to narrow down a curriculum to a few items. Training to become good at the job and training to be good at interviewing are 2 different things entirely! The skills needed to sale yourself during a 45 min interview are very different from the ones you need to deliver value during the job. There is a similar parallel in my opinion in the academia: somebody good at solving homework (therefore getting a 4.0 GPA) is not necessarily good at doing research and vice-versa. Looking for Data Science career mentoring and/or Machine Learning consulting services? Let's chat: https://lnkd.in/gGBMXuR4#machinelearning #deeplearning #datascience #interviewquestions 

          ‚Ä¶see more
        


GitHub - alirezadir/machine-learning-interview-enlightener: This repo is meant to serve as a guide for Machine Learning/AI technical interviews.
",,https://www.linkedin.com/feed/update/urn:li:activity:6993233295736008704?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6993233295736008704%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/C5627AQEc8b4wfly_uw/articleshare-shrink_800/0/1704922373341?e=1705658400&v=beta&t=5plYet9EVr908Yw2ca8n8uB91LXBJCuc4z5x-iz7yAY
385,65a105b3a5b8f072000022d4,3e6627aa-e62d-7f75-d460-e718902c92af,https://media.licdn.com/dms/image/C4E03AQHVyH-IfD1KbQ/profile-displayphoto-shrink_100_100/0/1629877234109?e=1710374400&v=beta&t=0UZUl_dDUxLaZn-Hu-zToqEDe3rpL5cB2JkP5_jlNXc,"Sebastian Raschka, PhD",https://www.linkedin.com/in/ACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU,"
Machine learning and AI researcher since the early days ‚Ä¢ coding and working with LLMs at Lightning AI ‚Ä¢ ex-statistics professor at University of Wisconsin-Madison
","
A question often arises when teaching is how XGBoost and LightGBM differ. The short fun-fact summary is that the tree-building algorithms are a tad different.XGBoost's trees are based on breadth-first search, comparing different features at each node. LightGBM performs depth-first search, focusing on a single feature at a time and growing the tree from there. 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6992841236227207170?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6992841236227207170%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQHxH_Y5_GLoiQ/feedshare-shrink_480/0/1667223270804?e=1707955200&v=beta&t=FQRknn5DLqtzoh0Ii9fWUYI2MuGeIeK7K5QzqxEJb54
386,65a105b3a5b8f072000022d5,abf27181-b5d5-567f-f0d5-d44aa7aeaef2,https://media.licdn.com/dms/image/C4D03AQHcbAAW_YYAkw/profile-displayphoto-shrink_100_100/0/1656177859481?e=1710374400&v=beta&t=xXZ7fdZ3nZMzIEH9jqjeqtLYrcGO9VMixsonb7t8ciA,Surbhi Walecha,https://www.linkedin.com/in/ACoAACN2Wz0BAtXYDTNFKXbgQKMrYbd7fEgJXAU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACN2Wz0BAtXYDTNFKXbgQKMrYbd7fEgJXAU,"
Big Data @ CNH Industrial | 350+ Resume reviewed | Mentor | Spark | Scala | PySpark | Hadoop | Hive | HBase | Azure | AWS | Matillion
","
PayPal SQL interview question (Easy Breezyüòú) Using SUM and CASE WHEN together !------------------------------------------------------------------------This problem is taken from Nick Singh üìïüêí's SQL interview platform, DataLemur üêí (Ace the SQL Interview); it's an PayPal easy level problem from the BONUS questions.‚ùì Given a table of bank deposits and withdrawals, return the final balance for each account.Table:transactions: transaction_id, account_id, transaction_type, accountHint:For final balance we need sum of positives (Deposit) and negative (Withdrawal)Solution:========================Attached Image üòé#sql #interview #data  #dataanalyst  #dataengineer #sundaysql

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6992449620710703104?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6992449620710703104%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQFu1ZBsFEDrJw/feedshare-shrink_480/0/1667129902085?e=1707955200&v=beta&t=Ltv8LfVFoovKJe-5MznJAxTJ2vwgx7U4G2wcQUt0wq0
387,65a105b3a5b8f072000022d6,28fe3630-2c99-ea4e-dd93-ce89fe37794a,https://media.licdn.com/dms/image/D4E03AQGifl1EghwlPg/profile-displayphoto-shrink_100_100/0/1679622265927?e=1710374400&v=beta&t=ycsq6ybpcTJ7BqFFf2Z65bTwMTOPu1ofnai6QZCyvqY,Juan David Garc√≠a Castro,https://www.linkedin.com/in/ACoAADAiQy8Bm2famgpfc5HfQhjmICkC-FVmjBk?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADAiQy8Bm2famgpfc5HfQhjmICkC-FVmjBk,"
Machine learning and data science professional - M.Sc student in Artificial Intelligence.
","
Today I finished reading two books that helped me to understand and deepen the different stages of the life cycle of a machine learning project, as well as to understand the value that we should and can deliver with these technologies. These books cover from how we handle the data to be used in the models to when we deploy and monitor the performance in production. Most important at the end of this was the last chapter of each book which covers the topic of responsible AI and how we must ensure we detect and mitigate the biases that can occur in the data, models, and results as well as develop applications that are inclusive to both those developing the application and those using it. Based on the above, I would like to share some resources that talk about and contribute to the development of responsible IA. Chip Huyen (Designing machine learning systems)Valliappa Lakshmanan (Machine learning design patterns)  Google Responsible AI practices: https://lnkd.in/eW3ha5JzIBM AI fairnesshttps://lnkd.in/eGNgB3G9 #machinelearning #ai #data #mlops

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6991883536110649344?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6991883536110649344%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQFFjuizaz0mow/feedshare-shrink_480/0/1666994936655?e=1707955200&v=beta&t=9x-4K-q3XKlm7RnvqC1J-xVnZUZV2oHj8_oPDNS9bP4
388,65a105b3a5b8f072000022d7,31bde1ed-9aaa-3007-c038-204243ba9d48,,Benjamin Han,https://www.linkedin.com/in/ACoAAAA3bQMBvVjN8LEtIBXkWQh6NKfXp_YW8ag?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAA3bQMBvVjN8LEtIBXkWQh6NKfXp_YW8ag,"
Envision Language + Knowledge + AI @ Apple AIML | Ex-Microsoft, IBM Research, Google
","
Come to work on exciting initiatives with us at #AppleKnowledgePlatform!Direct link to apply to Knowledge Platform (deadline 12/7): https://lnkd.in/gV7ktwdM#Hiring #Knowledgegraphs #AI #NLGPU #MachineLearning #DeepLearning #KnowledgeRepresentation #Reasoning #Apple

          ‚Ä¶see more
        


The 2023 AI/ML Residency Program Application is now Open
",,https://www.linkedin.com/feed/update/urn:li:activity:6991439498899320832?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6991439498899320832%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/C5627AQGAvZwf1ojD3A/articleshare-shrink_800/0/1704233209816?e=1705658400&v=beta&t=FsNQMCtQUUbYo6BGsW_IkURr8bObXzxykloRMbbMUtU
389,65a105b3a5b8f072000022d8,8a6a7067-85b1-fc58-2768-0b21510b675a,https://media.licdn.com/dms/image/C4E03AQGi8z94DPnYgg/profile-displayphoto-shrink_100_100/0/1517670208875?e=1710374400&v=beta&t=oEO8FtUBHdDGFVG43v-lzJx5XpE_c0IxtCiI1GTz7b8,Satya Mallick,https://www.linkedin.com/in/ACoAAAC6BhsByMVPofWRAnrqsWd2ttISLkUpIRk?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAC6BhsByMVPofWRAnrqsWd2ttISLkUpIRk,"
CEO @ OpenCV | AI, Computer Vision, Machine Learning
","
CenterNet is an Anchor-free object detection model. Instead of predicting bounding boxes from anchor boxes, it predicts center points and regresses the box size to predict the bounding boxes. https://lnkd.in/g_2dnwV5In today's blog post, you will learn the following -* What is object detection in general?* Difference between anchor-based v/s anchor-free object detection?* Advantages of anchor-free object detection.* What is the CenterNet: Objects as Points algorithm, and how it works?* How to use pre-trained models from the TensorFlow model zoo?https://lnkd.in/g_2dnwV5P.S. There is another version of CenterNet that was released almost at the same time as the CenterNet model we discussed in today's post. It is named CenterNet: Keypoint Triplets for Object Detection.#objectdetection #centernet #anchorless #tensorflow #deeplearning #ai #keypointdetection #explanation #theory 

          ‚Ä¶see more
        


CenterNet: Objects as Points ‚Äì Anchor-free Object Detection Explained
",,https://www.linkedin.com/feed/update/urn:li:activity:6991417679433658368?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6991417679433658368%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/C5627AQFf2h8SlOIxZA/articleshare-shrink_1280_800/0/1704109883141?e=1705658400&v=beta&t=68rqgcPQ04yISneOE5e6-SCRNXY5ZEGMFVKoqoocqKc
390,65a105b3a5b8f072000022d9,cca6bfbf-66d0-e860-d26f-c34fc232b6c4,https://media.licdn.com/dms/image/C4E03AQHVyH-IfD1KbQ/profile-displayphoto-shrink_100_100/0/1629877234109?e=1710374400&v=beta&t=0UZUl_dDUxLaZn-Hu-zToqEDe3rpL5cB2JkP5_jlNXc,"Sebastian Raschka, PhD",https://www.linkedin.com/in/ACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAxqHaUBEa6zzXN--gv-wd8ih0vevPvr9eU,"
Machine learning and AI researcher since the early days ‚Ä¢ coding and working with LLMs at Lightning AI ‚Ä¢ ex-statistics professor at University of Wisconsin-Madison
","
Linear algebra can sometimes feel like magic ‚ú®Ready for the 2 most fascinating ways to multiply 2 matrices? Yes, that's right: multiplying two matrices column-by-row (instead of row-by-column) -- it looks like an error at first, doesn't it?!And block multiplication ... it's very fascinating because it's super relevant as we are working with larger and larger matrices (or tensors) these days -- think large language models and distributed training with tensor parallelism (that I briefly mentioned in an earlier post).

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6989554704183635968?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6989554704183635968%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQEZnKXDnyuHEw/feedshare-shrink_480/0/1666439700654?e=1707955200&v=beta&t=e83CyunDUp8YRg9RuISjK9nzPWcuizc4fk4YrfwMRsg
391,65a105b3a5b8f072000022da,c43b53f4-8e73-6e4a-a206-0c6234400291,https://media.licdn.com/dms/image/C4D03AQFcFViXg1T69g/profile-displayphoto-shrink_100_100/0/1516303645074?e=1710374400&v=beta&t=B8NcAcO7HYN5DPDIEZpJtUtwghc43sWTR9AiLdRXUaU,"Bojan Tunguz, Ph.D.",https://www.linkedin.com/in/ACoAAACtHQMBTsH6C8rrVqP5YOv1H9T55PU6NPA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAACtHQMBTsH6C8rrVqP5YOv1H9T55PU6NPA,"
Machine Learning at NVIDIA | Physicist | Quadruple Kaggle Grandmaster
","
A very interesting project from Meta Research - xFormers, a modular and field agnostic library to flexibly generate transformer architectures from interoperable and optimized building blocks.Link to repo: https://lnkd.in/g8StqkB7#DataScience #MachineLearning #ArtificialIntelligence #DeepLearning #DS #ML #AI #DL #NLP

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6990288659639930880?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6990288659639930880%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C5622AQGprofsqUpDKg/feedshare-shrink_480/0/1666614687937?e=1707955200&v=beta&t=1pMoW16m4eBC1SS9pcC1tNUXhclHKM2vWRqfrONhsA0
392,65a105b3a5b8f072000022db,c02d84f1-12e0-d458-87de-8b0a99e6f3cd,https://media.licdn.com/dms/image/D5635AQEBzEFRC2EzLg/profile-framedphoto-shrink_100_100/0/1704907585971?e=1705658400&v=beta&t=x71pDAJzCbSPZxvt91sIkpmEr_5_pGLZIt6VZgw5eV0,Aman Chadha,https://www.linkedin.com/in/ACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU,"
GenAI Leadership @ Amazon AWS ‚Ä¢ Stanford AI ‚Ä¢ EB-1 ""Einstein Visa"" Recipient/Mentor ‚Ä¢ Ex-Ô£ø, Amazon Alexa, Nvidia, Qualcomm ‚Ä¢ EMNLP 2023 Outstanding Paper Award
","
üìà Evaluation Metrics for AI Models: The all-you-need-to-know primerüëâüèº TLDR; http://metrics.aman.ai- Building evaluation pipelines to understand the offline performance of a model is a critical skill for any data-driven organization. - To this end, adopting the right metrics is key to accurately representing and understanding your model‚Äôs performance.‚úÖ I‚Äôve put together an Evaluation Metrics primer here: http://metrics.aman.ai- This Evaluation Metrics primer covers:üîπ Evaluation Metrics for Classification (Accuracy, Confusion Matrix, Precision, Recall, PR Tradeoff, F1 Score, Sensitivity, Specificity, ROC Curves, AUC, DET Curves) üîπ Evaluation Metrics for Regression (MAE, MSE, RMSE, RMSLE, R2, IoU, AP, mAP)üîπ Evaluation Metrics for NLP Models (WER, Perplexity, BLEU, METEOR, ROUGE, GLUE, MOS)üîπ Evaluation Metrics for Information Retrieval/Search Systems (Precision@k, Recall@k, F1@k, Mean Reciprocal Rank, mAP@k, NDCG)üîπ Evaluation Metrics for Compression Models (BER)üîπ Evaluation Metrics for GAN-based Models (Fr√©chet Inception Distance)üîπ Evaluation Metrics for Recommender Systems (NDCG, DCG, CTR)üëâüèº If you enjoyed my Evaluation Metrics primer and have a penchant for the domain, my team at Amazon Alexa AI is hiring exceptional scientists and interns. Get in touch to learn more.#artificialintelligence #machinelearning #ai #ml #transformers #researchscientist #deeplearning #datamining #research #engineering #researchers #whatinspiresme #education #speechrecognition #speech #datascientists #nlp #datascience #science #technology #mlengineer #neuralnetworks

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6989800456768163840?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6989800456768163840%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C5622AQEAFEA-h7XAsg/feedshare-shrink_480/0/1666498292048?e=1707955200&v=beta&t=ioT9KcVSFHWxYnZN8gYMCVwiHnC566MKPCaMGl4tYrc
393,65a105b3a5b8f072000022dc,e632cb4e-93d6-b800-bf06-5a23b5b11c2a,https://media.licdn.com/dms/image/D5603AQGNiuOdOwGOXA/profile-displayphoto-shrink_100_100/0/1664778459905?e=1710374400&v=beta&t=xBgaXiEzd_m7LRcAM3FAiTW3npUaSw7mDRGAhH05ro0,Vinija Jain,https://www.linkedin.com/in/ACoAAA4CfZwBGeQakt2b0sUVu1GdoGrJgBGwpJU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA4CfZwBGeQakt2b0sUVu1GdoGrJgBGwpJU,"
Machine Learning Leader at Amazon | Stanford AI | EMNLP Outstanding Paper Award Recipient
","
üë©üèª‚ÄçüíªLeetcodeüîó https://lnkd.in/g2drwbsNüëãüèºHey LinkedIn connections,Just wanted to share a bit more about my prep. I‚Äôve hand selected the best leetcode problems for strings, grid, dynamic programming, backtracking etc. and they are here in my repository: https://lnkd.in/g2drwbsNFeel free to check it out, I hope you find this helpful in your prep! Aman Chadha and I will add to this list so stay tuned! #programming #python #leetcode #algorithms

          ‚Ä¶see more
        


GitHub - vinija/LeetCode
",,https://www.linkedin.com/feed/update/urn:li:activity:6989424827237351424?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6989424827237351424%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/C5627AQGD0SvA2q6Ntw/articleshare-shrink_800/0/1704455320197?e=1705658400&v=beta&t=Zl0KF2PXfRwMwFHF9MO9C-PMhZQy38LRtwyDQVaA7lw
394,65a105b3a5b8f072000022dd,7f9b73a4-6142-b892-7778-4d291a366aea,https://media.licdn.com/dms/image/C5603AQGZ-kqFX6LsuQ/profile-displayphoto-shrink_100_100/0/1517558278180?e=1710374400&v=beta&t=d6vg4BhuP4FsL3gtxgL3lhR82G5mMSJxv6yQKiVTvDY,Frank Hutter,https://www.linkedin.com/in/ACoAAAqDvaUByqtZs51aYJFBAY-iUdM_9D12Klg?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAqDvaUByqtZs51aYJFBAY-iUdM_9D12Klg,"
Professor Of Computer Science at University of Freiburg
","
I am happy to announce a new line of work that I'm extremely excited about: we introduce TabPFN, a new tabular data classification method that takes 1 second to train & test and yields SOTA performance (competitive to what state-of-the-art AutoML achieves in 1h, and much better than hyperparameter-optimized gradient boosting). Current limits: up to 1k data points, 100 features, 10 classes.TabPFN is radically different from previous ML methods. It is meta-learned to approximate Bayesian inference with a prior based on principles of causality and simplicity. It thus has very smooth uncertainty estimates.TabPFN happens to be a transformer, but this is not your usual trees vs nets battle. Given a new data set, there is no costly gradient-based training. Rather, it‚Äôs a single forward pass of a fixed network: you feed in (Xtrain, ytrain, Xtest); the network outputs p(y_test). TabPFN is fully learned: We only specified the task (strong predictions in a single forward pass, for millions of synthetic datasets) but not *how* it should be solved. Still, TabPFN outperforms decades worth of manually-created algorithms. A big step up in learning to learn.Imagine the possibilities! Portable real-time ML with a single forward pass of a medium-sized neural net (25M parameters). Go, #GreenAutoML! Please share widely; there are endless possibilities for improvements & extensions and we'd love to tackle them with your help.Please see our blog post https://lnkd.in/es7eg5kM for details, code and the paper. Also, we just got an oral at the #NeurIPS table representation learning workshop https://lnkd.in/eMDqZhB8 Joint work with my outstanding students Noah Hollmann, Samuel M√ºller and Katharina Eggensperger.[Note: I edited the first sub-sentence of this post, which previously read ""This may revolutionize data science: "", since some people misunderstood this as claiming that the particular model we trained revolutionizes data science. This was never the intended meaning, and I apologize for any confusion; while the precise TabPFN model we trained is an extremely strong model (in aggregate across 85 purely numerical datasets without missing values where it applies, it takes less than one second on a GPU to yield better results than any other ML / AutoML method trained for 1 hour), this particular model is far too limited to have huge impact by itself. But the fact that it was *learned* is disruptive. I still believe that *this line of work* has the potential to (=*may*) revolutionize ML for tabular data, just like deep learning revolutionized computer vision. I also believe that this may shake up data science, since it shifts the focus from the algorithms (which can now be learned with a transformer) to the data. If the domain expert can describe hypotheses for the data-generating process, this line of work will likely help them to directly obtain better results. I realize that this intended interpretation was far from obvious for readers and thus reworded.]

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6989198881657913345?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6989198881657913345%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C4E22AQFNDgqqiYlMUA/feedshare-shrink_480/0/1666354630337?e=1707955200&v=beta&t=LwaHaEXTGAHuYWuGu4jMSuQn7xVjf8P7koFmxj_QOrA
395,65a105b3a5b8f072000022de,814a3446-4363-64ca-bf34-e3ac3fed6960,https://media.licdn.com/dms/image/D5603AQGEADhHyEQ8rw/profile-displayphoto-shrink_100_100/0/1682553354695?e=1710374400&v=beta&t=kfjA-KO1Ea4gqAJ68vTh1_4ORnZzWv1qSW4bXFvg_tc,"Damien Benveniste, PhD",https://www.linkedin.com/in/ACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw,"
The ML Guy - Follow me to learn about Machine Learning Engineering, Machine Learning System Design, MLOps, and the latest techniques and news about the field. Join my AI newsletter and keep learning!
","
I found this nice github repo with tons of materials to learn how to deal with Deep Learning in PRODUCTION: https://lnkd.in/gJrGybryTo me, this kind of content is much more valuable than most textbooks on the subject. I'll take time to study that repo in my spare time. Let me know what you think about the repo.Need help to get to the next level of your Data Science / Machine Learning career? Need advising to build Machine Learning solutions? Let's chat: https://lnkd.in/gGBMXuR4#machinelearning #deeplearning #datascience #github 

          ‚Ä¶see more
        


GitHub - ahkarami/Deep-Learning-in-Production: In this repository, I will share some useful notes and references about deploying deep learning-based models in production.
",,https://www.linkedin.com/feed/update/urn:li:activity:6989284097323933696?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6989284097323933696%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/C5627AQHSlRzYmxGZrw/articleshare-shrink_800/0/1704002087781?e=1705658400&v=beta&t=w6AjHTPxg6jr95ACpSElH3RCeNpqON2M2j_GGRrHuXw
396,65a105b3a5b8f072000022df,1fb1e5ca-c71c-b363-86d6-10ff325a6033,https://media.licdn.com/dms/image/C4D03AQFcFViXg1T69g/profile-displayphoto-shrink_100_100/0/1516303645074?e=1710374400&v=beta&t=B8NcAcO7HYN5DPDIEZpJtUtwghc43sWTR9AiLdRXUaU,"Bojan Tunguz, Ph.D.",https://www.linkedin.com/in/ACoAAACtHQMBTsH6C8rrVqP5YOv1H9T55PU6NPA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAACtHQMBTsH6C8rrVqP5YOv1H9T55PU6NPA,"
Machine Learning at NVIDIA | Physicist | Quadruple Kaggle Grandmaster
","
It's not just Stable Diffusion that has been getting a lot of attention lately. The whole generative AI landscape is blooming. Sequoia Capital has come up with a handy little visualization to help us keep track of some of the most exciting players. I expect that this chart will only become even more crowded before this year is even over. :)#MachineLearning #DataScience #ArtificialIntelligence #ML #DS #AI #GenerativeAI 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6988468211872645120?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6988468211872645120%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQE3osTzSI3yDQ/feedshare-shrink_480/0/1666180659394?e=1707955200&v=beta&t=khUriIo39n6om3Xsz9yMwao83XKI-CGqRY2071e-_iM
397,65a105b3a5b8f072000022e0,afe97507-2681-f33e-69da-eecf0a8af873,https://media.licdn.com/dms/image/D560BAQGFpRpGKIeK6w/company-logo_100_100/0/1688581512782/pytorch_logo?e=1713398400&v=beta&t=PpzZq2REepkndNguYHvGhBbKkm4iNPBKoATlVMFfHc0,PyTorch,https://www.linkedin.com/company/pytorch/,"
228K followers
","
Interested in becoming a PyTorch contributor? Viacheslav Kovalevskyi walks you through the process, starting with why, sharing the pre-requirements, outlining ways to find issues to work on, and more. Learn about this process: 
 

PyTorch Contributor: Why And How To Become One
",,https://www.linkedin.com/feed/update/urn:li:activity:6986061831584837633?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6986061831584837633%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/C4D27AQEITHoj_ad7xw/articleshare-shrink_800/0/1704912320938?e=1705658400&v=beta&t=__6VCArEZlfbO8Ygqsu4HDMLv303T0yh3Nfn198Vuws
398,65a105b3a5b8f072000022e1,723a085b-5ff3-cc81-396a-f800d473a242,https://media.licdn.com/dms/image/D5635AQEBzEFRC2EzLg/profile-framedphoto-shrink_100_100/0/1704907585971?e=1705658400&v=beta&t=x71pDAJzCbSPZxvt91sIkpmEr_5_pGLZIt6VZgw5eV0,Aman Chadha,https://www.linkedin.com/in/ACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU,"
GenAI Leadership @ Amazon AWS ‚Ä¢ Stanford AI ‚Ä¢ EB-1 ""Einstein Visa"" Recipient/Mentor ‚Ä¢ Ex-Ô£ø, Amazon Alexa, Nvidia, Qualcomm ‚Ä¢ EMNLP 2023 Outstanding Paper Award
","
üî• Break into AI and Data Science using my Distilled AI primersüëâüèº Looking to kickstart a career in AI as a SWE/MLE/Scientist? Here are seven primers covering some of the pillars of AI and Data Science: Python, PyTorch, TensorFlow, NumPy, Pandas, Matplotlib, and SQL. With these tools in your arsenal, you'll have endless possibilities of carving your niche in AI! üöÄüîπ Python (http://python.aman.ai): The swiss army knife for AI and beyond. Most deep learning frameworks are based on Python.üîπ PyTorch (http://pytorch.aman.ai): The holy grail of deep learning frameworks. Developed by Meta, most commonly used.üîπ TensorFlow (http://tensorflow.aman.ai): The second most common deep learning framework. Developed by Google.üîπ NumPy (http://numpy.aman.ai): Numerical computing with multi-dimensional arrays.üîπ Pandas (http://pandas.aman.ai): Data manipulation and analysis.üîπ Matplotlib (http://matplotlib.aman.ai): The most commonly used plotting library.üîπ SQL (http://sql.aman.ai): Storage, manipulation, and retrieval of structured data.üëâüèº Connect/follow for more AI resources and drop me a message to share feedback!#artificialintelligence #machinelearning #ai #ml #deeplearning #computervision #nlp #naturallanguageprocessing #speech #speechai #vision #computervision #mlengineer #neuralnetworks #datascience #tensorflow #pandas #python #data 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6984703137009856512?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6984703137009856512%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C5622AQEOL3AdqmlR_A/feedshare-shrink_2048_1536/0/1665282995618?e=1707955200&v=beta&t=XR2gT93jv1ydaDr1YHV-tbZ0L8mmsmBUuDGKpU2aIz4
399,65a105b3a5b8f072000022e2,bf96d32e-6e84-2fb9-45ce-0d2168121c60,,Abhishek K.,https://www.linkedin.com/in/ACoAABKY7t8BEj6mwhuMMwEi3V0o_LoRkABghhQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABKY7t8BEj6mwhuMMwEi3V0o_LoRkABghhQ,"
Tensorflow Certified Data Scientist
","
Recently finished Chip Huyen's book Designing Machine Learning Systems. Seems like long road ahead in becoming a good data scientist but an exciting one. Probably need some rereads to really internalize everything, excited to use learnings in future projects.https://lnkd.in/dMxmKrAB

          ‚Ä¶see more
        


Designing Machine Learning Systems
",,https://www.linkedin.com/feed/update/urn:li:activity:6983281645546029056?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6983281645546029056%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/C5627AQGFDDXVN92a3Q/articleshare-shrink_480/0/1704743881676?e=1705658400&v=beta&t=JxMYrUGLi4KMM9TKtNUWYsq4o5lkJgAhC_Nc9KGsGGU
400,65a105b3a5b8f072000022e3,aa93e447-f044-b392-7f42-33ef85a49a56,https://media.licdn.com/dms/image/D4D03AQGCwczqA7rdpA/profile-displayphoto-shrink_100_100/0/1678381383991?e=1710374400&v=beta&t=NgwlrKbGr3bufbpOfyghw85WW-_P85M19allrj6IhIM,Sergios Karagiannakos,https://www.linkedin.com/in/ACoAAB5BYwYBK-2g8rcKqhtJc4UG7nH9CBR8ZFM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAB5BYwYBK-2g8rcKqhtJc4UG7nH9CBR8ZFM,"
Data Engineer @ Causaly | Founder of AI Summer | Author of Deep Learning in Production
","
How diffusion models work: the math from scratchDiffusion models are a new class of state-of-the-art generative models that generate diverse high-resolution images. They have already attracted a lot of attention after OpenAI, Nvidia and Google managed to train large-scale models. Example architectures that are based on diffusion models are GLIDE, DALLE-2, Imagen, and the full open-source stable diffusion.In this new blog post, we will dig our way up from the basic principles. There are already a bunch of different diffusion-based architectures. We will focus on the most prominent one, which is the Denoising Diffusion Probabilistic Models (DDPMs).Once we understand the forward and reverse diffusion, we will dive into the math behind the training process. We will also explore two methodologies on how to scale these types of architectures, called cascade diffusion models and latent diffusion models.Finally, we will discuss score-based models and their similarities/differences with diffusion models, and we will explore an interesting work that aims to encapsulate both types of models under the same umbrella. Without further ado, here it is:https://lnkd.in/duba9D9m#machinelearning #deeplearning #python #art #ai

          ‚Ä¶see more
        


How diffusion models work: the math from scratch | AI Summer
",,https://www.linkedin.com/feed/update/urn:li:activity:6982625214341738496?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6982625214341738496%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/C4D27AQHTeuA90CQmnA/articleshare-shrink_800/0/1704423183214?e=1705658400&v=beta&t=ByVt24Aop_MRQl0zrAxWrrBHpJSItT_XjBiH-fuskos
401,65a105b3a5b8f072000022e4,2fce32b7-e547-e15c-2736-30b3e62354c6,https://media.licdn.com/dms/image/D5603AQGEADhHyEQ8rw/profile-displayphoto-shrink_100_100/0/1682553354695?e=1710374400&v=beta&t=kfjA-KO1Ea4gqAJ68vTh1_4ORnZzWv1qSW4bXFvg_tc,"Damien Benveniste, PhD",https://www.linkedin.com/in/ACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAT2LbsB3xS0kxwoZu8TsNvAXS5jonOKqiw,"
The ML Guy - Follow me to learn about Machine Learning Engineering, Machine Learning System Design, MLOps, and the latest techniques and news about the field. Join my AI newsletter and keep learning!
","
In many cases, it is just fallacious to rely on the INTERPRETABILITY provided by a linear model! Real data are usually messy, non linear or non-normal. I think there is a common misconception that interpretability is not possible beyond Linear Regression in Machine Learning. Actually, explainable AI is a very well understood domain for many model paradigms nowadays. I always find the interpretability of a linear model pretty weak in most cases.There are many way to define the concept of interpretability. For example, the Shapley value comes from a game theory approach (https://lnkd.in/e6jBm8YD) applied to Machine Learning (https://lnkd.in/edS9phkH). One approach that has always been very appealing to me is understanding the functional dependency of the underlying features using the derivative (e.g. https://lnkd.in/g84Nvihr). Attached is an example where I tried to take a stab at that type of problems using the functional relationships between the different variables. Let me know what you think!That is always a good learning experience to challenge yourself where you try to find your own solution to this kind of problems. That is a great way to reach the next level in your own understanding of Machine Learning. Just don't be scared to make mistakes! ----Try our tool for employee voice: https://lnkd.in/eRW5MmjC.#machinelearning #datascience #explainableai 

          ‚Ä¶see more
        


Explanatory ML for time series data
",,https://www.linkedin.com/feed/update/urn:li:activity:6982709819438723072?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6982709819438723072%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E1FAQG2fAehqSrX8A/feedshare-document-cover-images_480/0/1664807687157?e=1705658400&v=beta&t=o1J3eZWbnzPUE4KNss08BTt_AYOYnGL84f_rrzfA2EI
402,65a105b3a5b8f072000022e5,13d7e662-0e9c-f895-6ef9-131a97824150,https://media.licdn.com/dms/image/D4E03AQFC1DXT8AP87Q/profile-displayphoto-shrink_100_100/0/1684601954554?e=1710374400&v=beta&t=Wfx-RZMsk-RIiV0i22LkAnDCE-abPRdS779jkpQG8pk,Ultan O.,https://www.linkedin.com/in/ACoAACXcPFABVvLV7ciBCy7JSlhi2oFubEQ46v8?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACXcPFABVvLV7ciBCy7JSlhi2oFubEQ46v8,"
üéì Get Ivy League Education, Resources & Tools Free üéì ‚Üí MIT Academic Scholar | McKinsey & Co. Scholar | George Moore Academic Scholar | Ad Astra Academic Scholar
","
Math fundamentals of AI üßÆSome first principles used across different AI applications ‚ûó‚ûïMath primer: http://math.aman.aiTopics CoveredüëâLinear Algebra (Vectors, Plotting Vectors, Norm)üëâDifferential Calculus (Differentiating a Function, Partial üëâDerivatives, Gradients, Jacobians, Hessians)üëâProbability Theory (Random Variable, Central Limit Theorem, üëâExpectation, Variance, Conditional Probability) üëâProbability Distributions and their PDF/CDFs (Bernoulli, Gaussian,üëâPoisson, Uniform, T-distribution, Chi-squared, Exponential)Credit : Aman Chadha Connect for more Data Science Insights and Innovations!Ultan O‚ÄôRourke#ai #computervision #datascience #math #machinelearning

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6981263629950033920?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6981263629950033920%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C4E22AQHv6zSICXVTzQ/feedshare-shrink_480/0/1664462954403?e=1707955200&v=beta&t=KBsIyUhovmZHV768UUfaNi4S904P3fQE-SDNsHSLiiM
403,65a105b3a5b8f072000022e6,2219a075-9687-9695-111a-180d86a12b23,https://media.licdn.com/dms/image/D5603AQHGPzHRm2kodQ/profile-displayphoto-shrink_100_100/0/1694941746105?e=1710374400&v=beta&t=2v4DbS0QqGLj4THalAWxbfBCD0z1iWvnXBHQxt0HPi0,Aishwarya Srinivasan,https://www.linkedin.com/in/ACoAABcIe6wBDNmiG5woZcoYzaD2wy6FIbMNQNU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABcIe6wBDNmiG5woZcoYzaD2wy6FIbMNQNU,"
Senior AI Advocate | LinkedIn Top Voice Data & AI | EB1A Recipient | 480k+ Followers | Ex-Google, IBM
","
3 FREE Resources to learn MLOps üöÄ‚≠êÔ∏èüî• :1. MLOps with Github: https://lnkd.in/gsWuCjg62. Made with ML: https://madewithml.com/3. MLOps Specialization: https://lnkd.in/g822-xJu

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6979712348152377344?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6979712348152377344%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C5605AQEP4ahF3DF0Eg/videocover-high/0/1664092818159?e=1705658400&v=beta&t=0f4Yzniy_n85Nq78yqXiKB6rJwDVcZUP-fgp9bbL6ns
404,65a105b3a5b8f072000022e7,bb4c5500-c4da-f5af-4535-d71881fcff33,https://media.licdn.com/dms/image/D5635AQEBzEFRC2EzLg/profile-framedphoto-shrink_100_100/0/1704907585971?e=1705658400&v=beta&t=x71pDAJzCbSPZxvt91sIkpmEr_5_pGLZIt6VZgw5eV0,Aman Chadha,https://www.linkedin.com/in/ACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU,"
GenAI Leadership @ Amazon AWS ‚Ä¢ Stanford AI ‚Ä¢ EB-1 ""Einstein Visa"" Recipient/Mentor ‚Ä¢ Ex-Ô£ø, Amazon Alexa, Nvidia, Qualcomm ‚Ä¢ EMNLP 2023 Outstanding Paper Award
","
 üß† All you need to know about Transformers, BERT, and GPTHere‚Äôs a bunch of #nlp primers to master important topics.üîπ Transformers: http://transformer.aman.ai- Mathematical background (Vectors, Matrix Multiplication, Dot Product, Masking, Sampling)- Attention (Additive/Multiplicative/Dot Product Attention, Self/Cross-Attention, Multihead Attention)- Core components of the Transformer Architecture (Embeddings, Positional Encoding, Skip Connections, Layer Normalization, Softmax)- Top-level Transformer Architecture (Encoder and Decoder stack)- Implementation details (Byte-Pair Encoding, Teacher Forcing, Label Smoothing)- Lessons learned (What are Transformers learning? Why is training them so hard?)- Pros/cons of Transformers relative to CNNs/RNNs- Relation between Transformers and Graph Neural Networksüîπ BERT: http://bert.aman.ai- Background: Pre-Training, Transformer Encoder- Contextualized Embeddings- Masked Language Modeling (MLM)- Next Sentence Prediction (NSP)- BERT‚Äôs Encoder Architecture vs. Other Decoder Architectures- The Strength of Bidirectionality- Supervised Fine-Tuningüîπ GPT: http://gpt.aman.ai- Background: Generative Pre-Training, Transformer Decoder- GPT-1: Improving Language Understanding by Generative Pre-Training- GPT-2: Language Models are Unsupervised Multitask Learners- GPT-3: Language Models are Few-Shot Learnersüëâüèº Connect/follow for more AI resources and drop me a message to share feedback!#artificialintelligence #machinelearning #ai #ml #deeplearning #computervision #speechrecognition #mlengineer #neuralnetworks

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6976761397317709824?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6976761397317709824%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C5622AQHZ20xk6GKABQ/feedshare-shrink_480/0/1663389538016?e=1707955200&v=beta&t=kj0mAfFvN3sqPN1vz12kB603Svu250UbToJtoGQ6ID4
405,65a105b3a5b8f072000022e8,6a7e7678-90ee-c5ac-5d07-ff3f5debd94f,https://media.licdn.com/dms/image/D4E03AQFy8bxpjxXX_g/profile-displayphoto-shrink_100_100/0/1701910533399?e=1710374400&v=beta&t=KanSaojxjfWqaDB7lKICI5Z8AmbgVr4oqM1KfJpOk-4,Ankur Warikoo,https://www.linkedin.com/in/ACoAAABOlvUB-6uQpj5VtIz3pACOBVaAzOdTRBA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAABOlvUB-6uQpj5VtIz3pACOBVaAzOdTRBA,"
Founder @WebVeda, Content creator @wariCrew, Speaker, Author. Eternal Optimist.
","
Which of these 90-day challenges are you going to pick, starting today?#mind #success #challenge #warikoo
 

Ten 90-day challenges
",,https://www.linkedin.com/feed/update/urn:li:activity:6978549810438004736?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6978549810438004736%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D1FAQFf0GwobXmqYw/feedshare-document-cover-images_480/0/1663815908965?e=1705658400&v=beta&t=Q7i9jVKsexwJxmwXTbVBiM2Ti_I0D1uDTE1Jrb7KkCU
406,65a105b3a5b8f072000022e9,c9fc2ebd-d5a7-b0de-d82f-16bb63134c6a,https://media.licdn.com/dms/image/D5603AQFRSkIegFVgnw/profile-displayphoto-shrink_100_100/0/1664158029047?e=1710374400&v=beta&t=PPv6pwyvmGWoN9erdtz6cDEMVWD2OQgFwwj_jNR33h0,Junwei Huang,https://www.linkedin.com/in/ACoAAAE-NmQBy1v6a2S-oqxVTel1n6lTF8ixdL0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAE-NmQBy1v6a2S-oqxVTel1n6lTF8ixdL0,"
Principal Data Scientist @Mastercard | Lead AI/ML Innovation on cloud | Aligning technology with business | Microsoft Certified
","
I came across an interesting paper from #carnegiemellon on building #ml -enabled systems. Introducing üëâ Collaboration Challenges in Building ML-Enabled Systems: Communication, Documentation, Engineering, and Process (2022) üëà by Nadia Nahar, Shurui Zhou, Grace Lewis and Christian K√§stner. üëá87% ML projects fail and 53% do not make it from prototype to production.The authors interviewed 45 practitioners from 28 organizations and identified 3 key collaboration challenges and offered recommendations.1‚É£  Requirements and Planning challengesüëâ Product team and project managers have unrealistic expectations about model capabilities such as ‚Äúno false positives‚Äù. ML training can help. üëâ Model development with unclear model requirements. Recommendation‚ú≥Ô∏èConsult data scientists from the beginning. ‚ú≥Ô∏èHire managers understanding both SE and ML. 2‚É£  Training data quality and quantity.üëâ Provided data or public data are noisy. üëâ Data documentation is insufficient. üëâ the #datateam does not have context to understand what data is needed. üëâ hard to convince the product team to continuously provide data. Even they do, the data is not consistent. üëâ Security block data access and make data-handling expensive. Recommendation‚ú≥Ô∏èbudget for data collection, access to domain experts, or hire a dedicated data team.‚ú≥Ô∏èadopt a formal contract, specifying data quantity and quality expectation. ‚ú≥Ô∏èconsider data validation and monitoring as a key feature of the product early on.3‚É£  Product-Model integrationüëâ DS wants #engineering support, while engineers can‚Äôt integrate the model due to insufficient knowledge. Some SE even perform ML tasks without enough ML understanding. üëâ DS and SE uses different jargons. ‚ÄúPerformance‚Äù means model accuracy to DS but response time to SE. üëâ SE often complain about code quality, documentation and no #versioncontrol to data and models. Recommendation‚ú≥Ô∏è define processes, responsibilities, and boundaries carefully‚ú≥Ô∏è recruit dedicated engineers for model deployment‚ú≥Ô∏è establish a culture with mutual understanding and exchange.‚ú≥Ô∏è avoid siloing #datascientists, increase communication and #interdisciplinary training.(Big tech still expect engineering skills from all data science hires.)See QA for model and product in the paper. üëá

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6977636326443552768?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6977636326443552768%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C5622AQGYFTBqxppW3w/feedshare-shrink_480/0/1663598137104?e=1707955200&v=beta&t=Uy-n_D6BO1YXI0oY3ogv4Euby-8DUIy3DCdcYqc2awY
407,65a105b3a5b8f072000022ea,305abc40-5ea4-3f02-6805-d29b67c64734,https://media.licdn.com/dms/image/D4D03AQF8Qy4hUAwdiw/profile-displayphoto-shrink_100_100/0/1681701145044?e=1710374400&v=beta&t=sPUvieXdVgYHSs1vlzMfVgGI0jaIxdM2XT_2713S4jU,Ashish Patel üáÆüá≥,https://www.linkedin.com/in/ACoAAATOnMIBYFNuqVOB33Dkrrhcd4bGpGp6FIM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAATOnMIBYFNuqVOB33Dkrrhcd4bGpGp6FIM,"
üî• 6x Linkedln Top Voice | AI Research Scientist & Chief Data Scientist at IBM | Generative AI Expert | Author - Hands-on Time Series Analytics with Python | IBM Quantum ML Certified | 11+ Years in AI | MLOps | IIMA |
","
üëè ùêñùê®ùê´ùê•ùêù ùêÅùê¢ùê†ùê†ùêûùê¨ùê≠ ùêÇùê®ùê•ùê•ùêûùêúùê≠ùê¢ùê®ùêß:125+ ùêçùêãùêè ùê•ùêöùêßùê†ùêÆùêöùê†ùêû ùêåùê®ùêùùêûùê• Collection  one place...‚úîÔ∏è‚úîÔ∏è‚úîÔ∏èüëè ùêàùêßùêúùê•ùêÆùêùùêûùê¨: Blogs, Videos, Codes in Colab etc. that made your learning easy.ü¶ã Github: https://lnkd.in/gMCGU7q5üí™ ùêãùêöùêßùê†ùêÆùêöùê†ùêû ùê¶ùê®ùêùùêûùê•ùê•ùê¢ùêßùê† (ùêãùêå) is the application of various statistical and probabilistic techniques to determine the probability of a given sequence of words occurring in a sentence. Language models analyze bodies of textual data to provide a basis for their word predictions.üïäÔ∏è ùêàùê¶ùê©ùê®ùê´ùê≠ùêöùêßùêúùêû------------------Language models determine word probability by analyzing text data. They interpret this data by feeding it through an algorithm that establishes rules for context in natural language. Then, the model applies these rules in language tasks to accurately predict or produce new sentences.üé≤ ùêàùêßùêùùêÆùê¨ùê≠ùê´ùê≤ ùêÄùê©ùê©ùê•ùê¢ùêúùêöùê≠ùê¢ùê®ùêß----------------------üéØ Speech RecognitionüéØ Machine TranslationüéØ Natural Language GenerationüéØ Part-of-Speech TaggingüéØ ParsingüéØ Optical Character RecognitionüéØ Grammer InductionüéØ Information Retrievalüé≤ ùêÇùê®ùêÆùê´ùê¨ùêûùê¨-------------------1. Natural Language Processing Specialization: https://lnkd.in/dswF7VtT2. Introduction to Huggingface Course on NLP: https://lnkd.in/dDP3V_wm#naturallanguageprocessing #artificialintelligence #machinelearning

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6962274362078978048?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6962274362078978048%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C4D22AQGDWTTLjgX8fg/feedshare-shrink_480/0/1659935559627?e=1707955200&v=beta&t=ylcDG5g6tcsU5DGYjQXMjY8upudlF1N6ZqcdCOU-zxk
408,65a105b3a5b8f072000022eb,d27ae7a7-32ce-0586-62d2-0ff036cde052,https://media.licdn.com/dms/image/D5603AQFRSkIegFVgnw/profile-displayphoto-shrink_100_100/0/1664158029047?e=1710374400&v=beta&t=PPv6pwyvmGWoN9erdtz6cDEMVWD2OQgFwwj_jNR33h0,Junwei Huang,https://www.linkedin.com/in/ACoAAAE-NmQBy1v6a2S-oqxVTel1n6lTF8ixdL0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAE-NmQBy1v6a2S-oqxVTel1n6lTF8ixdL0,"
Principal Data Scientist @Mastercard | Lead AI/ML Innovation on cloud | Aligning technology with business | Microsoft Certified
","
I came across an interesting paper offering a snapshot of data scientists and their work at Microsoft. Introducing üëâ Data Scientists in Software Teams: State of the Art and Challenges (IEEE Nov 2018) üëà by Miryung Kim, Tom Zimmermann, Robert DeLine, and Andrew Begel.They surveyed 2397 (793 responded) Microsoft employees: 599 (216) with Data Scientist title and 1798 (577) affiliated with data work. Problems data scientists at Microsoft work on:1‚É£ üí°User engagement: build user journey, offer users discount. 2‚É£ üí°Analysis of software artefacts to understand productivity and quality, e.g. identify bugs. 3‚É£ üí°Domain specific: assessing NLP platform, stock price forecast, ads pricing, search behavior etc.4‚É£ üí°Traditional business: predicting investment, demand, revenue, adoption, and growth of sales.Tools they use:Excel > SQL > R > Python > MATLAB > Minitab > SPSS > JMP, as well as Azure ML, C, C++, C#. (Interesting, R was much more popular than Python in MS: 27% vs 17%). They found 9 clusters of Data Scientists:1‚É£ üëâ Polymath: do it all, from goal setting to results communication to leaders. Most have PhDs.2‚É£ üëâ Data Evangelist: IC with business and product skills, doing analysis, share and act on data insights. 3‚É£ üëâ Data Preparer: proficiency with SQL and less on algorithms, stitching different streams of data.4‚É£ üëâ Data Shaper: mainstream data scientists with MSc or PhD. Good at algorithms, ML and optimization, less into business, product, or front end. 5‚É£ üëâ Data Analyzer: most have MSc and manipulate data by statistics or Bayesian Monte Carlo statistics. 6‚É£ üëâ Platform Builder: build platforms to collect data, most from software engineer with background in big data, distributed systems, back-end and front-end programming. 7‚É£ üëâ50% Moonlighter: most likely software engineers doing data science 50% of the time. Unlikely familiar with Monte Carlo, unstructured data, Python, or ML. 8‚É£ üëâ20% Moonlighter: most likely software engineers or program managers doing data science 20% of the time, with product development skills. 9‚É£ üëâ Insights Actor: rare find, >50% time on acting and sharing insights. Challenges they face:1‚É£  ‚ú≥Ô∏èLow data quality, delayed availability, lack of documentation, etc. 2‚É£ ‚ú≥Ô∏èScale over big data is expensive and machine learning is not magic on any data. 3‚É£ ‚ú≥Ô∏èConvince engineer team the value of data science so that they can collect high quality data.See more in the paperüëá#datascience #machinelearning

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6954789689740460032?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6954789689740460032%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C5622AQHiHYwu4I0lBw/feedshare-shrink_480/0/1658151075050?e=1707955200&v=beta&t=y6gthkW0tz3wZm5SABGB4fPlkDZSUCGcmStDqOWgqCQ
409,65a105b9a5b8f072000022ec,a51a542f-2753-bb85-8c63-9791019a8b26,https://media.licdn.com/dms/image/C5603AQEReSODdvboJw/profile-displayphoto-shrink_100_100/0/1633380704182?e=1710374400&v=beta&t=UpqhSy91ifXKjGGp_l1CfRDY-tCo7_wLjXWG419mLQc,Alex Xu,https://www.linkedin.com/in/ACoAAAJcVUEBpKxeVUb94KnEePlKepfIXeP2RM0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAJcVUEBpKxeVUb94KnEePlKepfIXeP2RM0,"
Co-Founder of ByteByteGo | Author of the bestselling book series: ‚ÄòSystem Design Interview‚Äô
","
A visual guide on how to choose the right Database...Picking a database is a long-term commitment so the decision shouldn‚Äôt be made lightly. The important thing to keep in mind is to choose the right database for the right job. Data can be structured (SQL table schema), semi-structured (JSON, XML, etc.), and unstructured (Blob).Common database categories include:üîπ Relationalüîπ Columnarüîπ Key-valueüîπ In-memoryüîπ Wide columnüîπ Time Seriesüîπ Immutable ledgerüîπGeospatialüîπGraphüîπDocumentüîπText searchüîπBlobThanks, Satish Chandra GuptaOver to you - Which database have you used for which workload?‚ÄîSubscribe to our weekly newsletter to get a Free System Design PDF (158 pages): https://bit.ly/3FEGliw #systemdesign #coding #interviewtips.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:6925471018350252032?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6925471018350252032%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C5622AQGO-t3flx4f7g/feedshare-shrink_480/0/1651160958484?e=1707955200&v=beta&t=7KIV-vwnw97WUdxVD0GzuQjq0e_-PCa4LD87ak8IG0s
410,65a105b9a5b8f072000022ed,06a8dc10-8bd4-d257-36c4-522cfe1b52a7,https://media.licdn.com/dms/image/C560BAQF6UBz8OytMyg/company-logo_100_100/0/1630641029887/ai4diversity_logo?e=1713398400&v=beta&t=VJTwWAlfMMgqfW-CnHGW4jXN56TH6Ne7nGMGB4TUtiM,AI4Diversity,https://www.linkedin.com/company/ai4diversity/,"
497K followers
","
Save this for later üòé
 

excel
",,https://www.linkedin.com/feed/update/urn:li:activity:6888957691897757696?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6888957691897757696%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/C561FAQFQ0QEqTpIxYw/feedshare-document-cover-images_480/0/1642455450692?e=1705658400&v=beta&t=ki1vD63cxZSztDZyJRkoPOEDQmk57OOZNH-ecu-NajM
411,65a105b9a5b8f072000022ee,dfd208f9-d988-3a90-0942-9b60194ac218,https://media.licdn.com/dms/image/D5603AQF1jz-pHuLrOA/profile-displayphoto-shrink_100_100/0/1695439999226?e=1710374400&v=beta&t=AJ8J2-1RoHXGBOgKPlITENJzKxSbMkOO6EHajL8Qe14,Soma Dhavala,https://www.linkedin.com/in/ACoAAACADkYBij00p7vwmP0tRP4LaOyqeAKuPZE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAACADkYBij00p7vwmP0tRP4LaOyqeAKuPZE,"
Director - ML
","
Off late I became interested in Stochastic Differential Equations (SDEs). They could be a unifying mathematical framework for connecting different areas I am interested in: optimisation & sampling for eg. SDEs have a wide ranging applications in Mathematical Finance, Stochastic Control/Game Theory/ Reinforcement Learning, to name a few. They are even showing up in Deep Generative Modeling.I chanced upon Stochastic Control course by Prof. Puduru Viswanadha Reddy at IITM, friend and former colleague. He laid a very rigorous (in the Math sense) foundation going from Measure Theory > Probability > Stochastic Process > Stochastic Calculus >  SDEs.  SDEs are very complex objects, and VIshwa's treatment is the best I have seen.Nithin Nagaraj Puduru Viswanadha Reddy Bharath Sriperumbudur Snehanshu Saha, Ph.D Prathosh AP, PhD

          ‚Ä¶see more
        


EE6432 - Stochastic Control - YouTube
",,https://www.linkedin.com/feed/update/urn:li:activity:6882139788430979072?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A6882139788430979072%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,
412,65a124e0a5b8f0720000253c,ceabf86c-eb4f-8685-6751-b296a58615ae,,Donna Morelli,https://www.linkedin.com/in/ACoAAANdDGEBFeo1Nj3g3i8MAGCA7k4hoLVW2vQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAANdDGEBFeo1Nj3g3i8MAGCA7k4hoLVW2vQ,"
Data Analyst, Science | Technology | Health Care
","
Newly Discovered Genetic Mutation Protects Against Parkinson‚Äôs Disease and Offers Hope for New Therapies. A previously unidentified genetic mutation in a small protein provides significant protection against Parkinson‚Äôs disease and offers a new direction for exploring potential treatments, according to a new University of Southern California (USC) Leonard Davis School of Gerontology study. Published: January 02. 2024.Excerpt: The variant, located in a mitochondrial microprotein dubbed SHLP2, was found to be highly protective against Parkinson‚Äôs disease; individuals with this mutation are half as likely to develop the disease as those who do not carry it. The variant form of the protein is relatively rare and is found primarily in people of European descent.The findings appear January 3, 2024, in the journal Molecular Psychiatry.First discovered by Pinchas Cohen at USC Leonard Davis School in 2016, SHLP2 is made within the cell‚Äôs mitochondria. Previous research from Cohen Lab established SHLP2 is associated with protection from aging-related diseases including cancer and that levels of the microprotein change in patients with Parkinson‚Äôs disease; they rise as the body attempts to counteract the pathology of Parkinson‚Äôs disease but often fail to mount additional production as the disease progresses.This latest finding builds upon the USC team‚Äôs prior mitochondrial research and represents an advance at the intersection of longevity science, precision health, and microprotein discovery.Note: ‚ÄúThis study advances our understanding of why people might get Parkinson‚Äôs and how we might develop new therapies for this devastating disease,‚Äù said Cohen, professor of gerontology, medicine and biological sciences and senior author of the study. ‚ÄúAlso, because most research is done on well-established protein-coding genes in the nucleus, it underscores the relevance of exploring mitochondrial-derived microproteins as a new approach to the prevention and treatment of diseases of aging.‚ÄùPublication: Nature | Molecular Psychiatry03 January 2024A naturally occurring variant of SHLP2 is a protective factor in Parkinson‚Äôs diseasehttps://lnkd.in/ePtGaHsghttps://lnkd.in/esFZtStA

          ‚Ä¶see more
        


Newly Discovered Genetic Mutation Protects Against Parkinson‚Äôs Disease and Offers Hope for New Therapies
",,https://www.linkedin.com/feed/update/urn:li:activity:7148297377207001088?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7148297377207001088%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4E27AQEvH_pEC7mE4Q/articleshare-shrink_800/0/1704286216530?e=1705665600&v=beta&t=9RzbeyZVUazRzR-lC0gYzsW9h54JKLJBFe7Bsq-mKb0
413,65a124e0a5b8f0720000253d,2fd4bb90-07af-a43e-fe7d-f69423c7220f,https://media.licdn.com/dms/image/C4E03AQHXCHWaNFfffQ/profile-displayphoto-shrink_100_100/0/1520866735377?e=1710374400&v=beta&t=l1p1OlVSaho9plyRJ9ECfHeub8U66DxMtst_7E8RJF0,"Steven Murphy, PhD, ICD.D",https://www.linkedin.com/in/ACoAAA2s_-ABOCToivzxfqW9sV-oUlcP9UxtIJM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA2s_-ABOCToivzxfqW9sV-oUlcP9UxtIJM,"
President and Vice Chancellor, Ontario Tech University
","
So many Ontario Tech University alumni, faculty, students and staff are making the world a better place through technology. Hamayal Choudhry‚Äôs smart arm was born at Ontario Tech to provide a better prosthetic at a much more affordable price. Tech with a conscience isn‚Äôt a slogan: it‚Äôs impacting real people and our planet tangibly. The identified ‚Äòproblem‚Äô was an ethical one, and this happens everyday in research labs from engineering to social science and humanities to health sciences and more. Here‚Äôs to 2024 and making a world that needs it, a much better place! üëèüèªüëèüèªüëèüèªüçæüéâ

          ‚Ä¶see more
        


smartARM‚Äôs story begins at Ontario Tech University
",,https://www.linkedin.com/feed/update/urn:li:activity:7147985363670642688?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7147985363670642688%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5610AQGoLZ0P_uzy7w/image-shrink_1280/0/1704211530530?e=1705665600&v=beta&t=mWS9QUQ_eU8JiOlJO8ppisnRrh_HLjSlKaR-5ll3E4Y
414,65a124e0a5b8f0720000253e,b596fb23-ef87-25f6-244f-3cea8e981c26,https://media.licdn.com/dms/image/D4D03AQFpramTnkoElw/profile-displayphoto-shrink_100_100/0/1670580633493?e=1710374400&v=beta&t=S032I_0r57qA_Thm98T7Xu_Nn46maV3uUmXnh4kYuiU,Bruno Neri,https://www.linkedin.com/in/ACoAAABlS2EBjKE-dekAzG21UIzH0d46NEotnuQ?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAABlS2EBjKE-dekAzG21UIzH0d46NEotnuQ,"
Technical Leader - Artificial Intelligence and Deep Learning Enthusiast - Senior Software Engineer at ALTEN Italia
","
""TimeGraphs: Graph-based Temporal Reasoning"" by Paridhi Maheshwari, Hongyu Ren, Rok Sosic, Jure Leskovec et al.""Many real-world systems exhibit temporal, dynamic behaviors, which are captured as time series of complex agent interactions. To perform temporal reasoning, current methods primarily encode temporal dynamics through simple sequence-based models. However, in general these models fail to efficiently capture the full spectrum of rich dynamics in the input, since the dynamics is not uniformly distributed. In particular, relevant information might be harder to extract and computing power is wasted for processing all individual timesteps, even if they contain no significant changes or no new information. Here we propose TimeGraphs, a novel approach that characterizes dynamic interactions as a hierarchical temporal graph, diverging from traditional sequential representations. Our approach models the interactions using a compact graph-based representation, enabling adaptive reasoning across diverse time scales. Adopting a self-supervised method, TimeGraphs constructs a multi-level event hierarchy from a temporal input, which is then used to efficiently reason about the unevenly distributed dynamics. This construction process is scalable and incremental to accommodate streaming data. We evaluate TimeGraphs on multiple datasets with complex, dynamic agent interactions, including a football simulator, the Resistance game, and the MOMA human activity dataset. The results demonstrate both robustness and efficiency of TimeGraphs on a range of temporal reasoning tasks. Our approach obtains state-of-the-art performance and leads to a performance increase of up to 12.2% on event prediction and recognition tasks over current approaches. Our experiments further demonstrate a wide array of capabilities including zero-shot generalization, robustness in case of data sparsity, and adaptability to streaming data flow.""Paper: https://lnkd.in/dsvCC-T5#machinelearning 

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7150838439242895360?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7150838439242895360%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQFHLD9wlnfetw/feedshare-shrink_480/0/1704892738339?e=1707955200&v=beta&t=WcZjO7ruBH3NaecAhudEyylhVm3M3s70Au9mgIt36rE
415,65a124e0a5b8f0720000253f,63d33327-6f36-86f2-d381-1ce5e51b284e,https://media.licdn.com/dms/image/D4E03AQFh6L32y18PAw/profile-displayphoto-shrink_100_100/0/1687119571913?e=1710374400&v=beta&t=haaUeeJhfZhTmEUwRGIj23AhHaRZGieNAKyHee2dScE,Maxime Labonne,https://www.linkedin.com/in/ACoAACHMnvUBcdKptayD76qA_A4NmTapmg0ti-Q?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACHMnvUBcdKptayD76qA_A4NmTapmg0ti-Q,"
Sr. Machine Learning Scientist @ JPMorgan
","
üîÄ PhixtralI made the first efficient Mixture of Experts with phi-2 models. ü•≥It combines 2 to 4 fine-tuned models (2.8B parameters) and is better than each individual expert. It's inspired by the Mixtral architecture made by Mistral AI.You can compare the results of Phixtral with other models on my new leaderboard YALL - Yet Another LLM Leaderboard: https://lnkd.in/gjWKF-5uA big thanks to Vincent Nguyen for the inference code and the dynamic configuration of the number of experts!phixtral-2/4x2_8 were made with a custom version of the mergekit library (by Charles Goddard) and the following models:- dolphin-2_6-phi-2 (Eric Hartford)- phi-2-dpo (Xuechen Li)- phi-2-sft-dpo-gpt4_en-ep1 (Yhyu13)- phi-2-coder (Manuel Romero)Thanks to the authors of these amazing models!I'm sharing a Colab notebook to run these models in 4-bit precision on a free T4 GPU and a link to the models on Hugging Face.ü§ó phixtral-2x2_8: https://lnkd.in/e-FKsEMuü§ó phixtral-4x2_8: https://lnkd.in/epwh4j37üíª Colab: https://lnkd.in/ebJQKT3D

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7150758415961620481?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7150758415961620481%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQGyoxC3WzgWJg/feedshare-shrink_480/0/1704847527778?e=1707955200&v=beta&t=m7gGsVsI5TQTLmKGRaUB6lNvI35NDDMbunSShJ8YXCM
416,65a124e0a5b8f07200002540,85dddc98-422e-cfbe-fc04-0b325d02374b,https://media.licdn.com/dms/image/D5635AQHHCW7gXpgoqQ/profile-framedphoto-shrink_100_100/0/1697123720926?e=1705665600&v=beta&t=tZUK6BODQh_xsxdO-p6JsOh6n06lMpqEtNAxht2XOnE,Zhihao Wang,https://www.linkedin.com/in/ACoAACU5qNcB__wes2Mt7ovXmlHQKJIn_OjSMmc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACU5qNcB__wes2Mt7ovXmlHQKJIn_OjSMmc,"
Phd Student at University of Maryland
","
Excited to share our latest publication: the development of DeepED, the first AI-powered model for Ecosystem Demography (EDv3). This model, now integrated into NASA's Carbon Monitoring System and the GEDI mission, revolutionizes process-based ecosystem modeling. DeepED enables rapid, sophisticated computations across any spatial scale and supports extensive long-term projections. Its application heralds a new era in ecosystem research, offering broader implications for global carbon monitoring.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7150564593856102400?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7150564593856102400%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D10AQFH1Gtitn4fng/image-shrink_480/0/1704747916258?e=1705665600&v=beta&t=2qAU0PNSQ1WnZt4reIqiOoWv9p9k62PqTeWyUoYnSnk
417,65a124e0a5b8f07200002541,13aa5259-fcdb-7aab-88dd-f84515c99398,https://media.licdn.com/dms/image/C4D0BAQG1yEbzvWYiXw/company-logo_100_100/0/1642603423308/towards_data_science_logo?e=1713398400&v=beta&t=y8CIwK9dQB-BTSDO6I7B3oL7VUGVvPS986H7M3mioNE,Towards Data Science,https://www.linkedin.com/company/towards-data-science/,"
601K followers
","
Conditional Variational Autoencoders with Learnable Conditional Embeddings - An approach to add conditions to CVAE models without retraining by Tim Daniel Rose
 

Conditional Variational Autoencoders with Learnable Conditional Embeddings
",,https://www.linkedin.com/feed/update/urn:li:activity:7150260744494678016?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7150260744494678016%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5610AQE-1LagdVNXVg/image-shrink_800/0/1704754981608?e=1705665600&v=beta&t=-dpg8YDq_V5201YKtxCGL7OlHX-tA_0Yuaz-g9bv1Oo
418,65a124e0a5b8f07200002542,a6440100-2128-ac15-984a-5253b5d47a17,https://media.licdn.com/dms/image/D4E03AQGkUXwoJ7Rfmw/profile-displayphoto-shrink_100_100/0/1697745181281?e=1710374400&v=beta&t=aHVPt5WxqVVs2HScs_bul9lEtPeJRfSdbS_uzwbvhPE,Lu√≠s Fernando Torres,https://www.linkedin.com/in/ACoAAC6XxAgBjJ2wCMoFG8Ya7038pmsXf8VTCCM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAC6XxAgBjJ2wCMoFG8Ya7038pmsXf8VTCCM,"
Data Science | Machine Learning | Deep Learning | Artificial Intelligence | Neural Networks | Computer Vision | NLP | Seeking Remote Positions
","
Large language models are one of the most amazing tools to have surfaced in recent years. But, although powerful, they still have some shortcomings. Hallucinations, for example, happen when a model comes up with a convincing answer to something it doesn't really have access to. Retrieval-augmented generation (RAG) is one of the ways we can help a large language model reduce its hallucinations and provide more accurate and source-based answers to the questions a user makes. In my recent Kaggle Notebook, Retrieval Augmented Generation with Mistral 7b üìÅ, we explore how to build an RAG system to fetch relevant information from documents to power an LLM response. You can read the notebook on the PDF file, but for a more enhanced reading experience, I suggest you view it on Kaggle by clicking the link below üëáüèª: üîó https://shorturl.at/cvGH9Thank you very much!

          ‚Ä¶see more
        


RAG
",,https://www.linkedin.com/feed/update/urn:li:activity:7150224333070589953?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7150224333070589953%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D1FAQF8rvVCZxhQ0Q/feedshare-document-cover-images_480/0/1704741032333?e=1705665600&v=beta&t=A6CKrUKEamvIPYPonEbFe_BR2fB5GvshXbNoDcAQi-c
419,65a124e0a5b8f07200002543,fe139009-b21c-a5d3-1d1a-db23050a1702,https://media.licdn.com/dms/image/C4E03AQEl5grbZGDr1A/profile-displayphoto-shrink_100_100/0/1623379778435?e=1710374400&v=beta&t=yK_pYvwY6i9B5sU31gKb_pIjqwOt9VcbKWnw-EbH_6Y,Akshay Pachaar,https://www.linkedin.com/in/ACoAACDRc3cBwnfUnZ2dYUQEIPx2zG1QfUqNJ84?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACDRc3cBwnfUnZ2dYUQEIPx2zG1QfUqNJ84,"
Lead Data Scientist at TomTom | BITS Pilani | 3 Patents | ùïè (113K+)
","
5 GitHub repositories that will give you superpowers as an AI/ML Engineer: 1Ô∏è‚É£ Awesome Artificial IntelligenceA curated list of Artificial Intelligence:- courses- books- video lectures- and papers with codeCheck this out üëáhttps://lnkd.in/g3bQGjfr2Ô∏è‚É£ CleanlabYou're missing out on a lot if you haven't started using Cleanlab yet!Cleanlab helps you clean data and labels by automatically detecting issues in a ML dataset. It's like a magic wand! ü™Ñ‚ú® Check this outüëáhttps://lnkd.in/dY2fp5YW3Ô∏è‚É£ 500 projects with codeA curated list of 500 AI, Machine learning, Computer vision & NLP Projects with codeCheck this outüëáhttps://lnkd.in/gnY3K75d4Ô∏è‚É£ Prompt Engineering GuideA guide that contains all the latest papers, learning guides, lectures, references, and tools related to prompt engineering for LLMs.Happy Prompting!Check this outüëáhttps://lnkd.in/dC6jBSDZ5Ô∏è‚É£ Lit-GPTLit-GPT is a fully open-source & hackable implementation of SOTA LLMs, it provides everything you need as an LLM Developer. Key features include:- Flash attention- 4 & 8-bit quantization- Finetuning using LoRA & LLaMA-adapterCheck thisüëáhttps://lnkd.in/dzKepQUvThat's a wrap!If you interested in:- Python üêç- ML/MLOps üõ†- CV/NLP üó£- LLMs üß†- AI Engineering ‚öôÔ∏èFind me ‚Üí https://lnkd.in/em_V4unu ‚úîÔ∏èEveryday, I share tutorials on above topics!Cheers!

          ‚Ä¶see more
        


GitHub - Lightning-AI/lit-gpt: Hackable implementation of state-of-the-art open-source LLMs based on nanoGPT. Supports flash attention, 4-bit and 8-bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed.
",,https://www.linkedin.com/feed/update/urn:li:activity:7149376618468114434?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7149376618468114434%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5610AQFOaJddFOnyUw/image-shrink_800/0/1704544214832?e=1705665600&v=beta&t=jSysAFDjdw5XIifLtuugNn4VPaqY-xho5Ekz55qf9dE
420,65a124e0a5b8f07200002544,e6a4d29e-0f8d-3d38-75d1-97e21cd36f79,https://media.licdn.com/dms/image/D4E03AQEg0ivtNmCzpw/profile-displayphoto-shrink_100_100/0/1684743177342?e=1710374400&v=beta&t=9abWo0RShxCrDyu8qPHl6FRnmd9zeW7FEiWfzUkexVs,Will Dean,https://www.linkedin.com/in/ACoAABinjcMBMxlMMi7hAMZLK8HhpGzWhB1_L3s?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABinjcMBMxlMMi7hAMZLK8HhpGzWhB1_L3s,"
Bayesian Statistics | Data Science
","
üêç Excited to share the journey behind my Python package, ""conjugate-models""!In my first Bayesian Statistics course, I encountered Bayesian conjugate models, having to solve for the posterior and posterior predictive distributions. Today, they're a cornerstone in my toolkit‚Äîtheir closed-form solutions enable rapid data analysis.In developing this package, I sought to merge these models with a practical, robust API. One that I wish I had in my earlier career use-cases. Whether you're new to Bayesian stats or a seasoned pro, discover how ""conjugate-models"" can elevate your analyses! üöÄRepo: https://lnkd.in/d2TQCfTgDocumentation: https://lnkd.in/d-Zx-88J#BayesianStatistics #PythonPackage #DataScience #conjugatemodels

          ‚Ä¶see more
        


GitHub - wd60622/conjugate: Bayesian Conjugate Models in Python
",,https://www.linkedin.com/feed/update/urn:li:activity:7150035508872503296?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7150035508872503296%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D4D27AQHqrId1Lt0wwA/articleshare-shrink_800/0/1704700745925?e=1705665600&v=beta&t=a_3LlN2JuA3EBDQI4wp6zMCjAmAeV2NwNjc_ib4uL7A
421,65a124e0a5b8f07200002545,0eba8877-a4a2-25d8-e373-be8cc34c8410,https://media.licdn.com/dms/image/C5603AQGsZ_F6Fn1gIw/profile-displayphoto-shrink_100_100/0/1642350086001?e=1710374400&v=beta&t=TI1Xb-oIhXqeNwHTQRyG-s3Cv3QeMWD1lZiaPShqePk,Dmytro Nikolaiev,https://www.linkedin.com/in/ACoAADWKdycBqHyKinzwK7QI9d7OLWtWcwDD-TA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADWKdycBqHyKinzwK7QI9d7OLWtWcwDD-TA,"
ML Scientist @ ChainML | DS Mentor @ Lighthouse Labs | #keep_AI_posted
","
üìú Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body TeleoperationIncredible work by Stanford University introduces Mobile ALOHA, a low-cost and whole-body robot that can complete complex autonomously with 50 demonstrations. The total price of a robot is under $32k and all code, data, and tutorials were publicly released.Website: https://lnkd.in/gRXnCmWMPaper: https://lnkd.in/gEMvSfqnTutorial: https://lnkd.in/gdGYNj6q#keep_AI_posted #ai #nlp #llm #robotics

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7150154237174251520?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7150154237174251520%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5605AQGaJSEsVjNoOQ/videocover-low/0/1704723162694?e=1705665600&v=beta&t=VltjIrHTg6oAVz2DqGdcwEMTewpX8Yv05XmsUfqvlZo
422,65a124e0a5b8f07200002546,5c72ab9e-d36b-52b1-cc9c-edb58d6ad930,https://media.licdn.com/dms/image/D4D03AQH1jwTZYuaUcA/profile-displayphoto-shrink_100_100/0/1670679538725?e=1710374400&v=beta&t=sGtcG8jNPBO8khpCverWqJBUGeSdeP1vfkcLlKvRbOg,Pascal Biese,https://www.linkedin.com/in/ACoAACOuW9cBGe8UMxy2NSSkLE3bSdlcrAnh9YA?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACOuW9cBGe8UMxy2NSSkLE3bSdlcrAnh9YA,"
Daily LLM Research Nuggets for 22k+ Experts üì≤ü§ó | AI/ML Engineer | NLP
","
30+ Strategies to Mitigate Hallucinations ‚öñ A major obstacle stands between the current capabilities of Large Language Models (LLMs) and their safe application in real-world settings‚Äîhallucination, the generation of plausible-sounding but factually inaccurate content. This challenge takes on critical significance when considering the deployment of LLMs in high-stakes domains like healthcare and finance.This latest paper delves into the issue of content hallucination in LLMs, offering an overview of more than 30 strategies devised to tackle this problem. As LLMs become more fluent, ensuring the factual integrity of their generated content is paramount for safe integration into sectors where accuracy is non-negotiable.The authors propose a comprehensive taxonomy of the various approaches, effectively mapping out the landscape of current interventions. Techniques range from Retrieval Augmented Generation (RAG) to advanced Knowledge Retrieval strategies and feedback mechanisms designed to keep model outputs in check.For the full taxonomy, check out the original paper below.[arXiv] https://lnkd.in/dvGxZqAj‚ÜìLiked this post? Get weekly AI highlights and papers-of-the-week directly to your inbox üëâ llmwatch.com

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7150079220990238721?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7150079220990238721%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQFj7lJNCNXVYg/feedshare-shrink_480/0/1704711727142?e=1707955200&v=beta&t=FOENGaiCD4o3DzTw-62KhQxbPs5hz24a7jNXCbqxBfU
423,65a124e0a5b8f07200002547,1f1f68fc-eced-c202-613b-0c47cc7b7d10,https://media.licdn.com/dms/image/C5603AQFvncvflX_kMQ/profile-displayphoto-shrink_100_100/0/1564316873635?e=1710374400&v=beta&t=DRxjFCzRMNJSc3QM233eAmSZ8rflNQHLrn8k0KQuOhg,Elvis S.,https://www.linkedin.com/in/ACoAACxhXeUBTYZYCwIa4nsvSBsETtrS0uhGNPc?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACxhXeUBTYZYCwIa4nsvSBsETtrS0uhGNPc,"
Co-Founder at DAIR.AI | Prev: Meta AI, Galactica LLM, PapersWithCode, Elastic
","
From LLM to Conversational AgentProposes RAISE, an advanced architecture to enhance LLMs for conversational agents. It's inspired by the ReAct framework and integrates a dual-component memory system. It utilizes a scratchpad and retrieved examples to augment the agent's capabilities. The scratchpad serves as a transient storage (akin to short-term memory) and the retrieval module operates as the agent's long-term memory. So you can think of this as a framework that combines ReAcT, a scratchpad, and a retrieval system.This system mirrors human short-term and long-term memory and helps to maintain context and continuity which are key in conversational systems.One benefit of such a system is the ability to customize and control the behavior of the conversational system. This work also shows the potential to fine-tune the LLM within the RAISE framework which leads to enhanced controllability. RAISE was tested on the real-estate domain and showed superior performance as compared to the conventional conversational agents. For every use case, there might be a need to control for different aspects of an LLM-powered agent. This can range from customizing the working memory components to changing the effectiveness of retrieval of certain types of information.I like the idea of modularity in a conversational agent but that means there are more variables to control. Lots of potential with this framework for building more tailored and personalized agents. (paper link in the comments)

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7150166307680784384?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7150166307680784384%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQETajxJy7vKAQ/feedshare-shrink_480/0/1704732490627?e=1707955200&v=beta&t=PrerkaNSbjm0gnmPVwWxk6279-korKAhKNuGt3XKd-Y
424,65a124e0a5b8f07200002548,ba8527b8-ef96-f0cf-a6f2-eb607f0bcb1b,https://media.licdn.com/dms/image/C4D03AQEl_LZo3E4U8w/profile-displayphoto-shrink_100_100/0/1625227462036?e=1710374400&v=beta&t=AZZ8_WJhW7OxUnde6VlTTlqQjUnXCyKytKt-PR236uU,David Sauerwein,https://www.linkedin.com/in/ACoAABbvcqABBMag23QcD1slzswS9n4Do7rO3CM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABbvcqABBMag23QcD1slzswS9n4Do7rO3CM,"
AI/ML at AWS | PhD in Quantum Physics
","
Many aspects of large language models are still poorly understood. At the outset, the simple fact that they can be trained at all is not obvious.Training a 65 Billion parameter large language model (LLM) boils down to trying to find the global minimum of a highly non-convex loss function with 65 Billion parameters. That's a daunting task.While it‚Äôs typically impossible to get to the global minimum for any deep learning algorithm (even if you did, there is no way to know), the community has developed a range of heuristics and tricks that help to find ‚Äúgood enough‚Äù local minima that work surprisingly well.Examples are:1/ Changes to the gradient descent algorithm (e.g. batch gradient descent, batch normalization, introduction of momentum,...)2/ Learning methods (e.g. annealing, teacher learning,...)3/ Reshaping of the loss landscape itself (e.g. skip connections, regularization, ‚Ä¶)The reasons why these methods work better in some scenarios than in others are often not well understood. However, new theoretical insights into the loss landscape of neural networks and the algorithms we use to explore them can have deep practical implications.For example, researchers found new ways to visualize the loss landscape of neural networks to understand why some algorithms work better than others (see image, link in comments). They are also still learning about new and unintuitive properties of gradient descent that may help optimize its performance (see comments for links).I expect 2024 to be the year of highly effective, smaller models. But I‚Äôd be amazing if we also find faster, more reliable ways to train them.#machinelearning #datascience #science #optimization

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7149843419677237248?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7149843419677237248%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4D22AQEyiYJJqBFGvg/feedshare-shrink_480/0/1704655508162?e=1707955200&v=beta&t=m09CjVy-8crd4RU81dK1onksefprlSHI-SNRi-h_KZY
425,65a124e0a5b8f07200002549,0e531164-e51b-3b05-5d4c-533266bee2ac,https://media.licdn.com/dms/image/C4D0BAQG1yEbzvWYiXw/company-logo_100_100/0/1642603423308/towards_data_science_logo?e=1713398400&v=beta&t=y8CIwK9dQB-BTSDO6I7B3oL7VUGVvPS986H7M3mioNE,Towards Data Science,https://www.linkedin.com/company/towards-data-science/,"
601K followers
","
AutoGluon-TimeSeries: Every Time Series Forecasting Model In One Library - A powerful library by Amazon‚Ää (coding example included) by Nikos Kafritsas
 

AutoGluon-TimeSeries: Every Time Series Forecasting Model In One Library
",,https://www.linkedin.com/feed/update/urn:li:activity:7149070658092552192?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7149070658092552192%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/sync/D5610AQFe2ivzxZ6iVA/image-shrink_800/0/1704471242944?e=1705665600&v=beta&t=qppPYiixnbyh1fMxYv03gjAYa8UPoYP-HnHvfWB1KvM
426,65a124e0a5b8f0720000254a,19428c68-7279-318f-012a-1574e0a7bd9b,https://media.licdn.com/dms/image/D4E03AQFXoR8Xgye8Vw/profile-displayphoto-shrink_100_100/0/1680859507281?e=1710374400&v=beta&t=jLguKrRofJ6IswdFpriAPlNTnCz6meovl2QS-rg00l4,Maria Vechtomova,https://www.linkedin.com/in/ACoAAA52t5EBCgJM7kgrMphKQD3ijSGTLl2xHzU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAA52t5EBCgJM7kgrMphKQD3ijSGTLl2xHzU,"
MLOps Tech Lead | Join 22k followers to learn about MLOps | Marvelous MLOps | Public speaker
","
Evidently AI  has a blog on ML system design: 300 case studies to learn from. They constantly update the page (last update is in December 2023).Check it out: https://lnkd.in/edCE5vaBThis is pure gold! Collection of papers and blogs from the industry leaders like Netflix, Spotify, Meta, Uber, and many more. Couple of interesting use cases:‚û°Ô∏è Call routing by Nubank: https://lnkd.in/ecXUNXC4‚û°Ô∏è Prevent fraudulent transactions by Stripe: https://lnkd.in/ep_qFUvR‚û°Ô∏è Demand forecast in fashion by Zalando: https://lnkd.in/e7893N3M#machinelearning #datascience #systemdesign

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7149260803865530368?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7149260803865530368%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQEoCrD9FzwU9A/feedshare-shrink_480/0/1704516600836?e=1707955200&v=beta&t=lkWz1HKIm09QwOWT_-qPgwfzoYjWdW4zKPKZNeXIAPw
427,65a124e0a5b8f0720000254b,2c3e4ec4-f051-fe55-88a4-ff423e06feea,https://media.licdn.com/dms/image/D4E03AQF6vorKIc_rDg/profile-displayphoto-shrink_100_100/0/1703628958212?e=1710374400&v=beta&t=mDh5ASm_Bz6tI7AUJ3L_iWFs4lPuSq8z7wpor2_Lz4c,Aniket Maurya,https://www.linkedin.com/in/ACoAABX5KEgBX_f0Ap7tJvvr9yXhqh9jp_rYCws?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABX5KEgBX_f0Ap7tJvvr9yXhqh9jp_rYCws,"
Developer Advocate @ Lightning AI ‚ö°Ô∏è | Creator of GradsFlow
","
TinyLlama 1.1B built with Lit-GPT ‚ö°Ô∏è - Pretrained on 1 trillion tokens - Total 3 epochs- Built upon existing Llama architecture and tokenizer- Full pretraining code - https://lnkd.in/eEKNXHMA- Paper: https://lnkd.in/eWs3VGcn

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7149248215375126528?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7149248215375126528%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQFM2_dB6ZX6oQ/feedshare-shrink_480/0/1704473632270?e=1707955200&v=beta&t=Hok4SlhWFaJ6L_LCRLjenw0EM-STP1WT6KneHb8Q52k
428,65a124e0a5b8f0720000254c,a879fc26-ba07-13bc-45f1-33921b906673,https://media.licdn.com/dms/image/D5635AQEBzEFRC2EzLg/profile-framedphoto-shrink_100_100/0/1704907585971?e=1705665600&v=beta&t=vPInJ9uQ9tIIhvvhwz3AraZ2tl3V1LbvORzhu9T9s9w,Aman Chadha,https://www.linkedin.com/in/ACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAOfvYEBZZvCf4uBUNXyTvIRtEJAo4QBlwU,"
GenAI Leadership @ Amazon AWS ‚Ä¢ Stanford AI ‚Ä¢ EB-1 ""Einstein Visa"" Recipient/Mentor ‚Ä¢ Ex-Ô£ø, Amazon Alexa, Nvidia, Qualcomm ‚Ä¢ EMNLP 2023 Outstanding Paper Award
","
üîπ All you need to know about Large Language Models: http://llm.aman.ai‚û°Ô∏è Embeddings‚û°Ô∏è Contextualized vs. Non-Contextualized Embeddings‚û°Ô∏è How do Large Language Models (LLMs) work?‚û°Ô∏è LLM Training Steps‚û°Ô∏è Computing Similarity between Embeddings (Dot Product Similarity, Geometric Intuition, Cosine Similarity, Cosine Similarity vs. Dot Product Similarity)‚û°Ô∏è Retrieval/Knowledge-Augmented LLMs (Process, Summary, LLM Knobs, Token Sampling, Prompt Engineering, Token Healing)‚û°Ô∏è Vector Database Feature Matrix‚û°Ô∏è Context Length Scaling (Challenges with Context Scaling, The ‚ÄúNeedle in a Haystack‚Äù Test, Positional Interpolation, Rotary Positional Encoding. Attention with Linear Biases, Dynamically Scaled RoPE)‚û°Ô∏è Traditional DBs v/s Vector DBs (When Not to Use Vector DBs?‚û°Ô∏è Knowledge Graphs with LLMs: Best of Both WorldsContinuous V/s Discrete Knowledge Representation‚û°Ô∏è Leaderboards (ü§ó Open LLM Leaderboard, ü§ó Massive Text Embedding Benchmark (MTEB) Leaderboard, ü§ó Chatbot Arena Leaderboard, Hallucination Leaderboard)‚û°Ô∏è Methods to Knowledge-Augment LLMs (RAG, Fine-tuning vs. Prompting, RAG vs. Fine-tuning)‚û°Ô∏è Recent Techniques Powering LLMs‚û°Ô∏è List of Popular LLMs- LLaMA- Llama 2- GPT-4- Bard API- Claude- Claude 2.1- Alpaca- Vicuna- StableVicuna- Dolly 2.0- StableLM- OpenLLaMA- MPT- Falcon- RedPajama- Pythia- Orca- XGen- OpenLLMs- LlongMA-2- Qwen- Mistral 7B- Mixtral: Mistral‚Äôs 8x7B MoE Model- Zephyr: Direct Distillation of LM Alignment- Yi- Effi- Starling- NexusRaven-V2- MediTron-70B: Scaling Medical Pretraining for Large Language Models- Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations- Notus- OpenChat- Phi-2- DeciLM- LLM360‚û°Ô∏è Popular Indic LLMs- OpenHathi- BharatGPT- Dhenu- Krutrim‚û°Ô∏è Popular Code LLMs- SQLCoder- Panda-Coder- Magicoder: Source Code is All You Need- AlphaCode 2‚û°Ô∏è Frameworks- LangChain- LangFlow- Flowise- Ragas- LLaMA2-Accessory- LLaMA Factory üëâüèº Connect/follow for more AI resources and drop me a message to share feedback!#artificialintelligence #machinelearning #deeplearning #neuralnetworks

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7149247448874385408?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7149247448874385408%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQEHiRl1RMEecw/feedshare-shrink_480/0/1704513418014?e=1707955200&v=beta&t=AOMoTIU89rj46Bb9vmziQpDUv1IpWyiwpR4FpbRYr3Y
429,65a124e0a5b8f0720000254d,07cb20e6-9ae4-6102-a14a-95ceb0089223,https://media.licdn.com/dms/image/D4D03AQE_lAgtIt6K3Q/profile-displayphoto-shrink_100_100/0/1668585420879?e=1710374400&v=beta&t=Qfwc0_1TJnp967Ob5QtZDRSesX4DRmKETG8cAMP19CA,Eduardo Ordax,https://www.linkedin.com/in/ACoAAAJXQIEBA0FD4IckM2LrQQQUyKaXcBEIz68?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAJXQIEBA0FD4IckM2LrQQQUyKaXcBEIz68,"
MLOps EMEA Lead at AWS | Helping customers to accelerate their Machine Learning Journey
","
Today, I'll delve into the Vector Database landscape, exploring the diverse options available in the market. If you're curious to learn more, keep reading!This post aims to provide a high-level overview rather than a technical summary or an in-depth explanation of how Vector DB operates. It will focus on presenting the various available options and guide you on choosing the most suitable one based on your specific use case.Although Vector DB has been a longstanding technology, it is currently gaining traction as a trending topic, especially with the rise of Generative AI and the increasing demand for RAG architectures. In fact, companies like Amazon leverages vector databases to power their recommendation systems, resulting in more personalized and accurate recommendations.A vector database is a type of database that stores data as high-dimensional vectors, which are mathematical representations of features or attributes. Each vector has a certain number of dimensions, which can range from tens to thousands, depending on the complexity and granularity of the data(they just created applying some kind of transformation or embedding function to the raw data).As follows, some of its unique differences and advantages:üî∏ Data type: Unlike traditional relational databases, vector databases are designed to handle one specific type of data: vector embeddings.üî∏ Similarity search: Vector databases have the ability to perform similarity searches that find the best match between a user's prompt and a particular vector embedding. üî∏ Scalability: Vector databases are designed to handle large-scale data. They can store and search billions of high-dimensional vectors, making them suitable for large-scale machine-learning applications.üî∏ Performance: Vector databases provide high-speed search performance. They use advanced indexing techniques to ensure fast retrieval of similar vectors, even in large-scale databases.üî∏ Flexibility: Vector databases support flexible data models. They can handle structured and unstructured data.üî∏ Efficiency: They use dimensionality reduction techniques to compress high-dimensional vectors into lower-dimensional spaces without losing significant informationDeciding between options can be challenging. In the document shared below, you'll find a comprehensive overview of various solutions, neatly categorized by   languages, cloud vs on-prem, open source vs closed-source, and more. Explore as well the available choices on AWS and discover what's ready to be utilized at Amazon Bedrock for leveraging knowledge bases instead of constructing your own RAG architecture from the ground up. To know more about available Vector DB at Amazon Web Services (AWS) click here: https://lnkd.in/e2p4KQ4XIf you find this information valuable, please consider liking the post.#vectorDB #RAG #LLM #GenerativeAI Pinecone Chroma Vespa.ai Qdrant Redis Zilliz Elasticsearch developer 

          ‚Ä¶see more
        


Vector DB Landscape
",,https://www.linkedin.com/feed/update/urn:li:activity:7148916026972205056?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7148916026972205056%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E1FAQGwsAizp18yFQ/feedshare-document-cover-images_480/0/1704406138420?e=1705665600&v=beta&t=R30FzHAQ9Wg-rjzuLs7BbR_heluZTvIOcx68ExovDDw
430,65a124e0a5b8f0720000254e,2a894e11-20e9-64b6-de40-4578a5534b79,https://media.licdn.com/dms/image/D560BAQFbVTDw-oWXmw/company-logo_100_100/0/1681327675102?e=1713398400&v=beta&t=Ir5hx7xUuaUo5T2BZZ9XorhXXE6Rv1XeKkDVGjYlWDo,LlamaIndex,https://www.linkedin.com/company/llamaindex/,"
67K followers
","
Advanced RAG Cheat Sheet + Recipes üßë‚Äçüç≥We‚Äôre publishing a comprehensive diagram outlining all the different components of advanced RAG, the pain points they solve, and links to LlamaIndex resources. Here‚Äôs some core concepts that motivate advanced RAGs:üí° Success metric for RAG is: retrieval is good, and generation is good.üí° Ways to improve retrieval: chunk-sizes, structured knowledge, sliding windows, KGs, ensemble retrieval, and moreüí° Generation must be able to use the documents effectively, with help from: compression, reranking, and moreüí° Interleave generation and retrieval for greater query understandingWhether you‚Äôre looking to start building with LLMs for the first time, or you‚Äôre a seasoned RAG veteran, there‚Äôs something here for everyone üî•(Seriously you could print this as a poster! üñ®Ô∏è)Our full blog post also contains code recipes for each of the components mentioned here: https://lnkd.in/eW8k9xxTCredits: Full credits go to Val Andrei Fajardo for driving this as a holiday project üéÑAlso credits to ‚ÄúRetrieval-Augmented Generation for Large Language Models: A Survey‚Äù by Gao et al. which served as inspiration for this! https://lnkd.in/g3cBvndU

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7149087685326864384?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7149087685326864384%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D4E22AQEVzH-1BN1w1Q/feedshare-shrink_480/0/1704475326626?e=1707955200&v=beta&t=9aMfk6uKmwhhTW26pc39sLFvAyoL7--caWc_h3zAB0U
431,65a124e0a5b8f0720000254f,3833cb79-5892-0b39-12fa-8d91643a8330,https://media.licdn.com/dms/image/D5603AQG9NK0CAgKtVg/profile-displayphoto-shrink_100_100/0/1687301791875?e=1710374400&v=beta&t=Bolt2zUMX7vi6uTl04U5LmzIk8J4LR-CV26o0v_KAIU,Lior S.,https://www.linkedin.com/in/ACoAADMTPYsBtfLtDZlCPxc0G4n0-rFYtqhC0yE?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADMTPYsBtfLtDZlCPxc0G4n0-rFYtqhC0yE,"
I cover the latest breakthroughs in AI ‚Üí Ex-ML Engineer/Researcher ‚Üí Built the most read technical newsletter in AI
","
Big for finance. JPMorgan just announced DocLLM. Their new LLM can understand documents, invoices, financial reports and contracts.They key? The model skips costly image encoders and only focuses on bounding box data to understand layout structure.Trained on 5.5M documents in outperforms SotA LLMs on 14 out of 16 datasets across all tasks, and generalizes well to 4 out of 5 previously unseen datasets.Paper: https://lnkd.in/ggMHXDGy‚ÜìAre you technical? Check out https://AlphaSignal.ai to get a weekly summary of the latest models, repos and papers in AI. Read by 150,000+ engineers and researchers.

          ‚Ä¶see more
        
",,https://www.linkedin.com/feed/update/urn:li:activity:7148739975784673280?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7148739975784673280%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29,https://media.licdn.com/dms/image/D5622AQHRTc2F88jkOg/feedshare-shrink_480/0/1704392426859?e=1707955200&v=beta&t=ZLfF9P0j6NvEcjx57f9MniwmP9PKxWcw9coBQrYnLCY
